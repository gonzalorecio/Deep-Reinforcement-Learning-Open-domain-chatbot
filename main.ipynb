{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web-based interface of the chatbot interface: https://gonzalorecio.com/chatbot/robot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotFace:\n",
    "    chatbot_mood_API   = 'https://chatbot-mood.herokuapp.com/mood'\n",
    "    chatbot_status_API = 'https://chatbot-mood.herokuapp.com/internal_state'\n",
    "\n",
    "    def change_mood(self, mood):\n",
    "        req_obj = {'action': mood}\n",
    "        x = requests.post(self.chatbot_mood_API, data = req_obj)\n",
    "        # print(x)\n",
    "        \n",
    "    def change_status(self, status):\n",
    "        req_obj = {'status': status}\n",
    "        x = requests.post(self.chatbot_status_API, data = req_obj)\n",
    "        \n",
    "    def neutral(self):\n",
    "        self.change_mood('neutral')\n",
    "        \n",
    "    def happy(self):\n",
    "        self.change_mood('happy')\n",
    "        \n",
    "    def sad(self):\n",
    "        self.change_mood('sad')\n",
    "        \n",
    "    def angry(self):\n",
    "        self.change_mood('angry')\n",
    "        \n",
    "    def focused(self):\n",
    "        self.change_mood('focused')\n",
    "        \n",
    "    def confused(self):\n",
    "        self.change_mood('confused')\n",
    "    \n",
    "    def start_blinking(self):\n",
    "        self.change_mood('start_blinking')\n",
    "        \n",
    "    def stop_blinking(self):\n",
    "        self.change_mood('stopt_blinking')\n",
    "        \n",
    "    def status_listening(self):\n",
    "        self.change_status('listening')\n",
    "        \n",
    "    def status_thinking(self):\n",
    "        self.change_status('thinking')\n",
    "        \n",
    "    def status_none(self):\n",
    "        self.change_status('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = ChatbotFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.confused()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.happy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.status_thinking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.status_listening()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.status_none()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.neutral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sentiments.BERTGRU_model import BERTGRUSentiment\n",
    "import requests\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) \n[Clang 6.0 (clang-600.0.57)]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ChatbotFace:\n",
    "    '''Chatbot face according to sentiment analysis. '''\n",
    "    chatbot_mood_API   = 'https://chatbot-mood.herokuapp.com/mood'\n",
    "    chatbot_status_API = 'https://chatbot-mood.herokuapp.com/internal_state'\n",
    "\n",
    "    def change_mood(self, mood):\n",
    "        req_obj = {'action': mood}\n",
    "        x = requests.post(self.chatbot_mood_API, data = req_obj)\n",
    "        # print(x)\n",
    "        \n",
    "    def change_status(self, status):\n",
    "        req_obj = {'status': status}\n",
    "        x = requests.post(self.chatbot_status_API, data = req_obj)\n",
    "    \n",
    "    def status_custom(self,text):\n",
    "      self.change_status(text)\n",
    "    \n",
    "    def predict_sentiment(self,sentence):\n",
    "        model_path = '/content/drive/MyDrive/CIR/BERT_sentiment.pt'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        model = BERTGRUSentiment(bert,\n",
    "                                  hidden_dim=256,\n",
    "                                  output_dim=1,\n",
    "                                  n_layers=2,\n",
    "                                  bidirectional=True,\n",
    "                                  dropout=0.25)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        odel.eval()\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        tokens = tokens[:max_input_length-2]\n",
    "        indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        prediction = torch.sigmoid(model(tensor))\n",
    "    \n",
    "        return prediction.item()\n",
    "    \n",
    "    def mood_prediction(self,utterance):\n",
    "      self.change_mood('start_blinking')\n",
    "      score = self.predict_sentiment(utterance)\n",
    "      print(score)\n",
    "      self.status_custom(utterance)\n",
    "      if '?' not in utterance:\n",
    "        if score <= 0.55 and score> 0.45: \n",
    "          self.change_mood('neutral')\n",
    "        elif score <= 1 and score> 0.55:\n",
    "          self.change_mood('happy')\n",
    "        elif score <= 0.45 and score> 0:\n",
    "          self.change_mood('sad')\n",
    "      else: \n",
    "        self.change_mood('confused')\n",
    "      \n",
    "    def start_blinking(self):\n",
    "        self.change_mood('start_blinking')\n",
    "        \n",
    "    def stop_blinking(self):\n",
    "        self.change_mood('stopt_blinking')\n",
    "        \n",
    "    def status_listening(self):\n",
    "        self.change_status('listening')\n",
    "        \n",
    "    def status_thinking(self):\n",
    "        self.change_status('thinking')\n",
    "        \n",
    "    def status_none(self):\n",
    "        self.change_status('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d6e62ecdaeac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchatbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatbotFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmood_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This film is great'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e1c5c77dfc10>\u001b[0m in \u001b[0;36mmood_prediction\u001b[0;34m(self, utterance)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmood_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_mood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_blinking'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e1c5c77dfc10>\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                   dropout=0.25)\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CIR/BERT_sentiment.pt'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CIR/BERT_sentiment.pt'",
     "output_type": "error"
    }
   ],
   "source": [
    "chatbot = ChatbotFace()\n",
    "chatbot.mood_prediction('This film is great')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech import google_speech as speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "hola hola\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hola hola'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "speech.speech_to_audio(lang=\"en-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "s = 'what are you saying?? :D'\n",
    "speech.text_to_speech(s, speed=150, voice=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola china \n"
     ]
    }
   ],
   "source": [
    "from google_trans_new import google_translator  \n",
    "translator = google_translator()  \n",
    "translate_text = translator.translate('สวัสดีจีน', lang_tgt='es')  \n",
    "print(translate_text)\n",
    "#output: Hello china"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from google_trans_new import google_translator  \n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, lang='en'):\n",
    "        print('Loading model and tokenizers...')\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        self.face = ChatbotFace()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.reset_chatbot(lang=lang)\n",
    "        print('Chatbot ready.')\n",
    "    \n",
    "    def reset_chatbot(self, lang='en'):\n",
    "        self.chat_history_ids = self.tokenizer.encode(self.tokenizer.bos_token, return_tensors='pt')\n",
    "        if lang=='es':\n",
    "            self.voice = 0 # 0: spanish female, 1: english female, 2: english male\n",
    "        else:\n",
    "            self.voice = 1 # 0: spanish female, 1: english female, 2: english male\n",
    "        self.translator = google_translator()  \n",
    "        self.lang = lang\n",
    "        \n",
    "    def listen_and_get_question(self):\n",
    "        face.status_listening()\n",
    "        lang = 'en-US' if self.lang=='en' else 'es-ES'\n",
    "        question = speech.speech_to_audio()\n",
    "        if self.lang=='es':\n",
    "            question = self.translate(question, lang='en')\n",
    "        face.status_none()\n",
    "        return question\n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        return self.tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "    \n",
    "    def generate_answer(self, question):\n",
    "        face.status_thinking()\n",
    "        question_ids = self.tokenizer.encode(question + self.tokenizer.eos_token, return_tensors='pt')\n",
    "        input_ids = torch.cat([self.chat_history_ids, question_ids], dim=-1)\n",
    "        self.chat_history_ids = self.model.generate(input_ids, max_length=1000, pad_token_id=self.tokenizer.eos_token_id)\n",
    "        answer_ids = self.chat_history_ids[:, input_ids.shape[-1]:][0]\n",
    "        text = self.decode(answer_ids)\n",
    "        if self.lang == 'es':\n",
    "            text = self.translate(text, lang='es')\n",
    "        face.status_none()\n",
    "        return text\n",
    "    \n",
    "    def get_sentiment_analysis(self, text):\n",
    "        return True\n",
    "        \n",
    "    def speak(self, text):\n",
    "        self.face.happy()\n",
    "        speech.text_to_speech(text, speed=150, voice=self.voice)\n",
    "        self.face.neutral()\n",
    "        \n",
    "    def translate(self, text, lang):\n",
    "        translated_text = self.translator.translate(text, lang_tgt=lang)\n",
    "        if type(translated_text) == list:\n",
    "            return translated_text[0]\n",
    "        return translated_text\n",
    "    \n",
    "    def no_understand(self):\n",
    "        text = \"Sorry, I couldn't understand you\"\n",
    "        if self.lang == 'es':\n",
    "            text = self.translete(text, lang='es')\n",
    "        self.speak(text)\n",
    "    \n",
    "    def run_chat(self):\n",
    "        self.reset_chatbot(lang=self.lang)\n",
    "        self.face.neutral()\n",
    "        question = ''\n",
    "        while(question != 'goodbye'):\n",
    "            question = self.listen_and_get_question()\n",
    "            if question is None:\n",
    "                print('Fallo')\n",
    "                self.no_understand()\n",
    "                continue\n",
    "            print('Question:', question)\n",
    "            answer = self.generate_answer(question)\n",
    "            print('Answer:', answer)\n",
    "            self.speak(answer)\n",
    "            \n",
    "#             self.reset_chatbot(lang=self.lang)\n",
    "            print(self.chat_history_ids)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizers...\n",
      "Chatbot ready.\n"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot(lang='es')\n",
    "# chatbot.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reset_chatbot(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "hello\n",
      "Question: hello\n",
      "Answer: Hello!\n",
      "tensor([[50256, 31373, 50256, 15496,  5145, 50256]])\n",
      "Listening...\n",
      "Recognizing...\n",
      "how are you\n",
      "Question: how are you\n",
      "Answer: I'm good, how are you?\n",
      "tensor([[50256, 31373, 50256, 15496,  5145, 50256,  4919,   389,   345, 50256,\n",
      "            40,  1101,   922,   837,   703,   389,   345,  5633, 50256]])\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-946a6090c472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchatbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_chat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-1f897fe00925>\u001b[0m in \u001b[0;36mrun_chat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'goodbye'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten_and_get_question\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mquestion\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fallo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-1f897fe00925>\u001b[0m in \u001b[0;36mlisten_and_get_question\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlisten_and_get_question\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mlang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'en-US'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'en'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'es-ES'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_to_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'es'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Workspace\\Master\\CIR\\Final Project\\MAI-CIR\\speech\\google_speech.py\u001b[0m in \u001b[0;36mspeech_to_audio\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Listening...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recognizing...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    618\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chatbot.run_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}