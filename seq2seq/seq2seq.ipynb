{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Did you see \"Titanic\"?\n",
      "DialoGPT: I did, but I don't think I can remember it.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I'm not sure if I can believe that.\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're not the only one.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let me get my camera.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And my home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll cry at your home. I'll be there.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-b285fc8c4fc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# encode the new user input, add the eos_token and return a tensor in Pytorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnew_user_input_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"User:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Let's chat for 5 lines\n",
    "sentences = [\"Did you see \\\"Titanic\\\"?\",\n",
    "            \"I saw it twelve times.\",\n",
    "            \"I have the DVD.\",\n",
    "            \"Let's go to your home.\",\n",
    "            \"And then we can go to my home.\",\n",
    "            \"I always cry at the end.\"]\n",
    "for step in range(10):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "#     new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    new_user_input_ids = tokenizer.encode(sentences[step] + tokenizer.eos_token, return_tensors='pt')\n",
    "    print(\"User:\", sentences[step])\n",
    "    \n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size=3)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 500\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
    "# epsilon_by_frame = lambda frame_idx: max(epsilon_final, epsilon_start*(0.995**frame_idx))\n",
    "plt.plot([epsilon_by_frame(i) for i in range(5000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_td_loss(batch_size):\n",
    "#     state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "#     state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "#     next_state = Variable(torch.FloatTensor(np.float32(next_state)), requires_grad=False)\n",
    "#     action     = Variable(torch.LongTensor(action))\n",
    "#     reward     = Variable(torch.FloatTensor(reward))\n",
    "#     done       = Variable(torch.FloatTensor(done))\n",
    "\n",
    "# #     q_values      = model(state)\n",
    "# #     next_q_values = model(next_state)\n",
    "\n",
    "# #     q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "# #     next_q_value     = next_q_values.max(1)[0]\n",
    "# #     expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "#     loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "# #     for param in model.parameters():\n",
    "# #             param.grad.data.clamp_(-1, 1)\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(model, state, epsilon):\n",
    "    if random.random() > epsilon:\n",
    "        state   = Variable(torch.FloatTensor(state).unsqueeze(0), requires_grad=False)\n",
    "        q_value = model.forward(state)\n",
    "        action  = q_value.max(1)[1].item()\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "        #action = random.randrange(env.action_space.n)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step(action):\n",
    "    question = user.generate(action, max_length=1000, \n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "                             num_beams=3,\n",
    "                             num_return_sequences=2,\n",
    "                             early_stopping=True,\n",
    "                             no_repeat_ngram_size=2\n",
    "                            ) if frame > 0 else chat_history_ids\n",
    "    \n",
    "    reward -= jaccard_similarity(answer.numpy(), context.numpy())\n",
    "    return new_state, reward, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(token_ids):\n",
    "    return tokenizer.decode(token_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r, gamma=0.99):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    size = len(r)\n",
    "    discounted_r = torch.zeros(size)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = answers[-1]\n",
    "# # torch.tensor(x.size())\n",
    "# y = model(x)[0]\n",
    "# w = y.sum(dim=1)\n",
    "# q = w/w\n",
    "# q.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(questions, answers):\n",
    "    model.train()\n",
    "    t1 = questions[-1]\n",
    "    t2 = answers[-1]\n",
    "    print(t1)\n",
    "    A = model(t1)[0]\n",
    "    print(t2, len(t2))\n",
    "    B = model(t2)[0]\n",
    "    lenA = len(A.detach().numpy())\n",
    "    lenB = len(B.detach().numpy())\n",
    "    max_len = np.max([lenA, lenB])\n",
    "#     extra = torch.zeros(size=(max_len-len(A.detach().numpy()),tokenizer.vocab_size))\n",
    "#     extra[:,-1] = 1\n",
    "    \n",
    "    if lenA > lenB:\n",
    "        extra = torch.zeros(size=(max_len-lenB,tokenizer.vocab_size)).to(device)\n",
    "        extra[:,-1] = 1\n",
    "        A , B = torch.softmax(A, dim=-1), torch.cat([torch.softmax(B, dim=-1), extra]), \n",
    "    \n",
    "    else:\n",
    "        extra = torch.zeros(size=(max_len-lenA,tokenizer.vocab_size)).to(device)\n",
    "        extra[:,-1] = 1\n",
    "        A , B = torch.cat([torch.softmax(A, dim=-1), extra]), torch.softmax(B, dim=-1)\n",
    "        \n",
    "    # loss = F.cosine_similarity(A,B, dim=-2)\n",
    "#     loss = -torch.mm(A, B.transpose(1, 0)).sum()\n",
    "\n",
    "    # loss = -F.cosine_similarity(torch.softmax(A, dim=-1),torch.softmax(B, dim=-1))\n",
    "    \n",
    "    def log_prob(tokens, debug=False):\n",
    "        # p = log(P(b|a)) / N\n",
    "        output_logits = model(tokens)[0]\n",
    "        p = 1\n",
    "        if debug: print('logits', output_logits, 'tokens', tokens)\n",
    "        for t, logit in zip(tokens, output_logits):\n",
    "            p *= torch.softmax(logit, dim=-1)[t]\n",
    "        if debug: print('p', p)\n",
    "        p_log = torch.log(p) / len(tokens) # (tokens/tokens).sum()# / len(tokens) # lenB # len(tokens_b)\n",
    "        if p == 0:\n",
    "            print('infinite')\n",
    "            return torch.log(p+10e-40)\n",
    "        else:\n",
    "            return p_log\n",
    "\n",
    "    # reward 1\n",
    "    x = [log_prob(d) for d in dummy_responses[:30]]\n",
    "    r1 = torch.stack(x)\n",
    "    r1 = -torch.mean(r1) # if r1 else 0\n",
    "    \n",
    "    # reward 2\n",
    "    if len(answers)<2:\n",
    "        emb1 = model.get_input_embeddings()(t1).mean(dim=0)\n",
    "    else:\n",
    "        emb1 = model.get_input_embeddings()(answers[-2]).mean(dim=0)\n",
    "    emb2 = model.get_input_embeddings()(t2).mean(dim=0)\n",
    "    r2 = -torch.log(F.cosine_similarity(emb1,emb2,dim=-1))\n",
    "    \n",
    "    emb1 = model.get_input_embeddings()(t1).mean(dim=0)\n",
    "    emb2 = model.get_input_embeddings()(t2).mean(dim=0)\n",
    "    r2_2 = -torch.log(F.cosine_similarity(emb1,emb2,dim=-1))\n",
    "    \n",
    "    # reward 3\n",
    "    r3 = log_prob(t2, debug=True)\n",
    "#     print(t2, t2.size())\n",
    "    \n",
    "#     y = model(t2)[0]\n",
    "#     w = y.sum(dim=1)\n",
    "#     q = w/w\n",
    "#     r4 = q.sum()\n",
    "    print('r1:', r1, 'r2:', r2, 'r2_2:', r2_2, 'r3:', r3)\n",
    "    \n",
    "    R = 0.25*r1 + 1.5*r2 + 1.5*r2_2 + 0.5*r3 #* 0.01*r4\n",
    "#     print(R)\n",
    "    return -R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_responses = [torch.tensor([tokenizer.eos_token_id]),\n",
    "                   tokenizer.encode(\"1\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"..\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"!\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\":D\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                  ]\n",
    "for i in range(256):\n",
    "    s = tokenizer.encode(tokenizer.decode([i]) + tokenizer.eos_token, return_tensors='pt')[0]\n",
    "    dummy_responses.append(s)\n",
    "# dummy_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(290-34):\n",
    "#     print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dummy_sentence(sent):\n",
    "    for d in dummy_responses:\n",
    "        if sent.size()[0] == d.size()[0] and all(sent == d):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in list(model.base_model.parameters())[-2:]:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "tensor([15496, 50256])\n",
      "tensor([15496,  5145,  1058,    35, 50256]) 5\n",
      "logits tensor([[ -8.7504, -15.1438, -16.7280,  ..., -14.0380, -14.0120,  -5.0655],\n",
      "        [ -3.2315, -12.5397, -12.0827,  ...,  -8.7417,  -7.8533,   8.1126],\n",
      "        [ -4.3257, -13.1073, -11.8230,  ...,  -7.6676,  -5.8482,   8.9182],\n",
      "        [ -6.5426, -14.6268, -13.7220,  ..., -10.1415,  -8.1287,  11.0028],\n",
      "        [  5.8292,  -5.5086,  -5.6743,  ...,  -3.4714,  -2.5411,   3.5963]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([15496,  5145,  1058,    35, 50256])\n",
      "p tensor(9.5423e-19, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.5598, grad_fn=<NegBackward>) r2: tensor(0.1312, grad_fn=<NegBackward>) r2_2: tensor(0.1312, grad_fn=<NegBackward>) r3: tensor(-8.2987, grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well! How are you?\n",
      "tensor([ 2437,   389,   345,  5633, 50256])\n",
      "tensor([   40,  1101,  1804,   880,  5145,  1374,   389,   345,  5633, 50256]) 10\n",
      "logits tensor([[ -8.7148, -13.7303, -15.5867,  ..., -13.0073, -13.0637,  -5.4099],\n",
      "        [ -8.5041, -14.0901, -14.2151,  ..., -10.3561, -11.5291,  -1.0108],\n",
      "        [ -3.8820, -12.3088, -13.8442,  ...,  -6.0522,  -8.4490,   2.9368],\n",
      "        ...,\n",
      "        [ -1.1142, -13.3655, -11.3429,  ...,  -6.8878,  -6.3689,   9.5832],\n",
      "        [ -2.2759, -14.0555, -11.6459,  ...,  -8.1230,  -5.8985,  11.4003],\n",
      "        [  4.3630,  -9.9202,  -9.9170,  ...,  -6.9817,  -6.3736,   0.9861]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  1804,   880,  5145,  1374,   389,   345,  5633, 50256])\n",
      "p tensor(1.5586e-38, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.7167, grad_fn=<NegBackward>) r2: tensor(0.1636, grad_fn=<NegBackward>) r2_2: tensor(0.0593, grad_fn=<NegBackward>) r3: tensor(-8.7054, grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing good!\n",
      "tensor([ 5211,   278,   880,  1165,  5145, 50256])\n",
      "tensor([   40,  1101,  1804,   922,  5145, 50256]) 6\n",
      "logits tensor([[ -8.0220, -13.2856, -15.0576,  ..., -12.5525, -12.6569,  -4.6874],\n",
      "        [ -8.9493, -14.9295, -15.2610,  ..., -11.9953, -12.1879,  -1.6647],\n",
      "        [ -5.9342, -14.9695, -16.8009,  ...,  -8.5733, -10.9891,  -0.4631],\n",
      "        [ -2.2173, -13.7483, -14.5005,  ...,  -7.6927,  -9.3295,   8.2307],\n",
      "        [ -2.9428, -13.8981, -11.7874,  ...,  -9.1646,  -7.2984,  10.3556],\n",
      "        [  8.6161,  -7.6618,  -6.8629,  ...,  -5.5968,  -4.2664,   3.8388]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  1804,   922,  5145, 50256])\n",
      "p tensor(1.0313e-23, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.5577, grad_fn=<NegBackward>) r2: tensor(0.0667, grad_fn=<NegBackward>) r2_2: tensor(0.1453, grad_fn=<NegBackward>) r3: tensor(-8.8214, grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm glad to!\n",
      "tensor([ 2504,   338,   922,  5145, 50256])\n",
      "tensor([   40,  1101,  9675,   284,  5145, 50256]) 6\n",
      "logits tensor([[ -8.0496, -13.2810, -15.0098,  ..., -12.3241, -12.4100,  -4.5280],\n",
      "        [ -9.5721, -15.4892, -15.7528,  ..., -12.0339, -12.7336,  -2.3239],\n",
      "        [ -6.1859, -14.4776, -15.0687,  ...,  -9.8942, -10.0066,   3.7436],\n",
      "        [-10.7628, -15.7619, -18.0351,  ..., -13.2389, -12.7460,  -3.3089],\n",
      "        [ -2.3275, -11.4873,  -9.7892,  ...,  -6.7431,  -5.5981,  10.8938],\n",
      "        [  6.0913,  -8.2192,  -7.9626,  ...,  -4.8813,  -4.3206,   2.7689]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  9675,   284,  5145, 50256])\n",
      "p tensor(9.0265e-24, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.9028, grad_fn=<NegBackward>) r2: tensor(0.0770, grad_fn=<NegBackward>) r2_2: tensor(0.1212, grad_fn=<NegBackward>) r3: tensor(-8.8436, grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that!\n",
      "DialoGPT: I'm so happy to hear that\n",
      "tensor([   40,  1101,  3772,   284,  3285,   326,  5145, 50256])\n",
      "tensor([   40,  1101,   523,  3772,   284,  3285,   326, 50256]) 8\n",
      "logits tensor([[ -8.3814, -14.0758, -15.7894,  ..., -13.1911, -13.2760,  -4.9558],\n",
      "        [ -9.5773, -15.1857, -15.7033,  ..., -12.5428, -12.4534,  -1.8323],\n",
      "        [ -4.5498, -11.5891, -12.1272,  ...,  -8.6061,  -6.9332,   2.9146],\n",
      "        ...,\n",
      "        [ -4.9684, -15.2712, -15.4653,  ...,  -9.0363, -10.0553,   3.0460],\n",
      "        [ -4.0069, -16.3781, -15.7545,  ...,  -8.8906, -10.7547,   5.6648],\n",
      "        [  5.4293,  -7.8644,  -7.5314,  ...,  -6.6882,  -5.7243,   2.7503]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   523,  3772,   284,  3285,   326, 50256])\n",
      "p tensor(3.4477e-31, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.7131, grad_fn=<NegBackward>) r2: tensor(0.0921, grad_fn=<NegBackward>) r2_2: tensor(0.0235, grad_fn=<NegBackward>) r3: tensor(-8.7678, grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I am happy to hear that.\n",
      "tensor([   40,  1101,  3772,  1165,  5145, 50256])\n",
      "tensor([   40,   716,  3772,   284,  3285,   326,   764, 50256]) 8\n",
      "logits tensor([[ -8.2196, -13.3284, -15.0912,  ..., -12.4637, -12.5722,  -4.8200],\n",
      "        [ -7.2181, -14.3338, -15.0036,  ..., -11.2362, -11.1222,  -0.1554],\n",
      "        [ -8.0164, -15.1835, -16.7728,  ..., -11.7455, -10.7323,   4.1470],\n",
      "        ...,\n",
      "        [ -2.2725, -14.2903, -13.8096,  ...,  -6.5360,  -8.0925,   7.2127],\n",
      "        [ -4.2351, -11.5780, -11.4266,  ...,  -7.4365,  -7.5328,   9.4472],\n",
      "        [  4.8766,  -8.9877,  -9.0198,  ...,  -6.4533,  -5.7288,   2.8015]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,   716,  3772,   284,  3285,   326,   764, 50256])\n",
      "p tensor(3.1446e-29, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.7452, grad_fn=<NegBackward>) r2: tensor(0.0353, grad_fn=<NegBackward>) r2_2: tensor(0.1027, grad_fn=<NegBackward>) r3: tensor(-8.2037, grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  3772, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[  0.2487, -16.5018, -15.8418,  ..., -13.0452, -11.5386,   3.1455]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.1510, grad_fn=<MulBackward0>)\n",
      "r1: tensor(6.8655, grad_fn=<NegBackward>) r2: tensor(0.3377, grad_fn=<NegBackward>) r2_2: tensor(0.3702, grad_fn=<NegBackward>) r3: tensor(-1.8904, grad_fn=<DivBackward0>)\n",
      "tensor([11.9703,  9.9541,  7.6919,  5.2917,  2.9220,  0.3938, -1.8330],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(2.1157, grad_fn=<NegBackward>), tensor(2.3391, grad_fn=<NegBackward>), tensor(2.4532, grad_fn=<NegBackward>), tensor(2.3989, grad_fn=<NegBackward>), tensor(2.5322, grad_fn=<NegBackward>), tensor(2.2084, grad_fn=<NegBackward>), tensor(-1.8330, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(11.9703, grad_fn=<UnbindBackward>)\n",
      "Episode 0: -2.115748405456543\n",
      "User: Hello\n",
      "DialoGPT: Hello!\n",
      "tensor([15496, 50256])\n",
      "tensor([15496,  5145, 50256]) 3\n",
      "logits tensor([[ -8.0049, -13.3745, -15.1480,  ..., -12.4474, -12.5456,  -4.5844],\n",
      "        [ -2.2146, -12.5037, -11.9952,  ...,  -7.4378,  -7.4623,   6.2412],\n",
      "        [  6.7824, -10.3395,  -9.7739,  ...,  -5.4323,  -4.5634,   5.5011]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([15496,  5145, 50256])\n",
      "p tensor(3.7870e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.3163, grad_fn=<NegBackward>) r2: tensor(0.0628, grad_fn=<NegBackward>) r2_2: tensor(0.0628, grad_fn=<NegBackward>) r3: tensor(-6.4639, grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "tensor([ 2437,   389,   345,  5633, 50256])\n",
      "tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256]) 9\n",
      "logits tensor([[ -8.5229, -13.7707, -15.3779,  ..., -12.6032, -12.7509,  -5.0578],\n",
      "        [ -7.7385, -13.4941, -13.9555,  ..., -10.5789, -10.4902,  -0.6289],\n",
      "        [ -6.2229, -15.8500, -15.8721,  ..., -10.9756, -10.6545,   6.0468],\n",
      "        ...,\n",
      "        [ -2.7111, -13.4328, -13.0378,  ...,  -8.4073,  -7.3390,   9.3589],\n",
      "        [ -2.9794, -14.4684, -13.1345,  ...,  -8.3407,  -7.0185,   9.7295],\n",
      "        [  2.7027, -12.7721, -12.0250,  ...,  -7.3952,  -7.3237,   2.1049]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256])\n",
      "p tensor(6.2430e-30, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.6763, grad_fn=<NegBackward>) r2: tensor(0.2623, grad_fn=<NegBackward>) r2_2: tensor(0.0527, grad_fn=<NegBackward>) r3: tensor(-7.4718, grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too.\n",
      "DialoGPT: I'm glad to hear that.\n",
      "tensor([10248,   837,   314,  1101,   922,  1165,   764, 50256])\n",
      "tensor([   40,  1101,  9675,   284,  3285,   326,   764, 50256]) 8\n",
      "logits tensor([[ -8.2727, -13.5271, -15.3117,  ..., -12.7398, -12.8178,  -4.6721],\n",
      "        [ -5.5387, -11.1821, -12.1578,  ...,  -8.0292,  -8.2141,   1.7431],\n",
      "        [ -4.2435, -12.9989, -14.0920,  ...,  -8.6911,  -8.2585,   5.7378],\n",
      "        ...,\n",
      "        [ -2.5000, -13.3923, -13.2340,  ...,  -5.7234,  -7.8639,   4.9144],\n",
      "        [ -6.4069, -13.0561, -13.4095,  ...,  -9.4621,  -9.1810,   7.1274],\n",
      "        [  7.9306,  -6.6085,  -6.5346,  ...,  -4.2248,  -3.0793,   6.1578]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  9675,   284,  3285,   326,   764, 50256])\n",
      "p tensor(2.3493e-26, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.3309, grad_fn=<NegBackward>) r2: tensor(0.1122, grad_fn=<NegBackward>) r2_2: tensor(0.1140, grad_fn=<NegBackward>) r3: tensor(-7.3766, grad_fn=<DivBackward0>)\n",
      "User: So, what's your name?\n",
      "DialoGPT: I'm not sure.\n",
      "tensor([ 2396,   837,   644,   338,   534,  1438,  5633, 50256])\n",
      "tensor([   40,  1101,   407,  1654,   764, 50256]) 6\n",
      "logits tensor([[ -8.0386, -13.2921, -15.0950,  ..., -12.3997, -12.5003,  -4.5726],\n",
      "        [ -6.9623, -12.9541, -13.4068,  ..., -10.1499, -10.0204,   0.4395],\n",
      "        [ -6.9776, -15.0865, -16.3660,  ..., -11.5086, -13.2619,   0.0582],\n",
      "        [ -5.8227, -14.2728, -14.5889,  ...,  -9.7586,  -9.3118,   3.7439],\n",
      "        [ -4.2603,  -9.7294, -11.1016,  ...,  -6.5309,  -5.3602,   7.7922],\n",
      "        [  7.4010,  -8.4626,  -8.1344,  ...,  -5.5510,  -4.3983,   4.0264]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   407,  1654,   764, 50256])\n",
      "p tensor(2.0591e-22, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.4309, grad_fn=<NegBackward>) r2: tensor(0.0975, grad_fn=<NegBackward>) r2_2: tensor(0.1627, grad_fn=<NegBackward>) r3: tensor(-8.3224, grad_fn=<DivBackward0>)\n",
      "User: Well, I'm glad to meet you.\n",
      "DialoGPT: I'm happy to meet you. I'm.\n",
      "tensor([ 5779,   837,   314,  1101,  9675,   284,  1826,   345,   764, 50256])\n",
      "tensor([   40,  1101,  3772,   284,  1826,   345,   764,   314,  1101,   764,\n",
      "        50256]) 11\n",
      "logits tensor([[ -8.3593, -13.6657, -15.4392,  ..., -12.8139, -12.8468,  -4.9060],\n",
      "        [ -6.5552, -12.2682, -13.3217,  ...,  -9.2167,  -9.0716,   0.4964],\n",
      "        [ -6.5469, -14.0550, -15.8919,  ...,  -9.5569,  -9.8839,   4.4659],\n",
      "        ...,\n",
      "        [ -4.5087, -12.3089, -12.9732,  ...,  -7.1648,  -9.2130,   1.8309],\n",
      "        [ -5.5425, -12.2454, -12.1009,  ...,  -8.7924,  -7.1419,   8.9943],\n",
      "        [  5.0398, -10.0347, -10.1085,  ...,  -7.7380,  -5.9137,   3.6169]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  3772,   284,  1826,   345,   764,   314,  1101,   764,\n",
      "        50256])\n",
      "p tensor(2.7219e-35, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.4554, grad_fn=<NegBackward>) r2: tensor(0.0816, grad_fn=<NegBackward>) r2_2: tensor(0.0273, grad_fn=<NegBackward>) r3: tensor(-7.2354, grad_fn=<DivBackward0>)\n",
      "User: I'm also happy to meet you too.\n",
      "DialoGPT: I smile and smile.\n",
      "tensor([   40,  1101,   635,  3772,   284,  1826,   345,  1165,   764, 50256])\n",
      "tensor([   40,  8212,   290,  8212,   764, 50256]) 6\n",
      "logits tensor([[ -8.1609, -13.4845, -15.2897,  ..., -12.5714, -12.7858,  -4.7150],\n",
      "        [-11.3851, -19.3975, -20.7583,  ..., -13.9121, -11.7018,   2.2115],\n",
      "        [ -9.6985, -15.6313, -17.7608,  ..., -11.7000,  -7.4898,  -1.5808],\n",
      "        [ -9.6746, -18.2736, -20.1742,  ..., -13.8883, -11.7445,   3.1581],\n",
      "        [ -5.8275, -12.8780, -14.1659,  ..., -11.1435,  -6.7572,   9.1246],\n",
      "        [  2.1049,  -9.7209, -11.7577,  ...,  -9.6720,  -6.9532,   2.6484]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  8212,   290,  8212,   764, 50256])\n",
      "p tensor(2.1200e-20, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.3405, grad_fn=<NegBackward>) r2: tensor(0.1955, grad_fn=<NegBackward>) r2_2: tensor(0.2153, grad_fn=<NegBackward>) r3: tensor(-7.5500, grad_fn=<DivBackward0>)\n",
      "User: I smile back.\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  8212,   736,   764, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -0.6793, -16.1731, -14.9834,  ..., -11.7201, -10.1243,   5.1894]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.4436, grad_fn=<MulBackward0>)\n",
      "r1: tensor(8.7236, grad_fn=<NegBackward>) r2: tensor(0.3519, grad_fn=<NegBackward>) r2_2: tensor(0.2872, grad_fn=<NegBackward>) r3: tensor(-0.8127, grad_fn=<DivBackward0>)\n",
      "tensor([ 4.6382,  3.7108,  2.6430,  1.3905, -0.2754, -1.6322, -2.7333],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.9644, grad_fn=<NegBackward>), tensor(1.0943, grad_fn=<NegBackward>), tensor(1.2663, grad_fn=<NegBackward>), tensor(1.6632, grad_fn=<NegBackward>), tensor(1.3405, grad_fn=<NegBackward>), tensor(1.0737, grad_fn=<NegBackward>), tensor(-2.7333, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(4.6382, grad_fn=<UnbindBackward>)\n",
      "Episode 1: -1.5400952100753784\n",
      "User: Hello\n",
      "DialoGPT: Hello!\n",
      "tensor([15496, 50256])\n",
      "tensor([15496,  5145, 50256]) 3\n",
      "logits tensor([[ -8.3550, -13.8191, -15.5222,  ..., -12.6891, -12.7667,  -4.8988],\n",
      "        [ -4.1078, -13.5332, -13.6600,  ...,  -9.5417,  -8.6607,   4.8482],\n",
      "        [  7.0267,  -9.3614,  -8.0409,  ...,  -6.3548,  -4.4725,   6.5058]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([15496,  5145, 50256])\n",
      "p tensor(5.9957e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(10.0427, grad_fn=<NegBackward>) r2: tensor(0.0629, grad_fn=<NegBackward>) r2_2: tensor(0.0629, grad_fn=<NegBackward>) r3: tensor(-6.3107, grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "tensor([ 2437,   389,   345,  5633, 50256])\n",
      "tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256]) 9\n",
      "logits tensor([[ -8.7751, -13.9971, -15.7856,  ..., -13.1621, -13.2829,  -5.3108],\n",
      "        [ -2.3191,  -8.3643,  -9.1469,  ...,  -5.3093,  -4.1185,   5.2592],\n",
      "        [ -3.2976, -12.9268, -13.8390,  ...,  -6.9455,  -7.1220,   7.9957],\n",
      "        ...,\n",
      "        [ -1.9474, -12.3267, -11.2029,  ...,  -6.4446,  -5.4466,  10.0644],\n",
      "        [ -4.4539, -16.1020, -14.4906,  ..., -10.7305,  -9.6012,   7.3002],\n",
      "        [ -1.7563, -17.2852, -16.5741,  ..., -12.1978, -12.0336,  -0.4617]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256])\n",
      "p tensor(7.0081e-21, grad_fn=<MulBackward0>)\n",
      "r1: tensor(10.1290, grad_fn=<NegBackward>) r2: tensor(0.2626, grad_fn=<NegBackward>) r2_2: tensor(0.0528, grad_fn=<NegBackward>) r3: tensor(-5.1564, grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too.\n",
      "DialoGPT: I'm good too\n",
      "tensor([10248,   837,   314,  1101,   922,  1165,   764, 50256])\n",
      "tensor([   40,  1101,   922,  1165, 50256]) 5\n",
      "logits tensor([[ -8.4070, -14.0016, -15.7336,  ..., -12.9980, -13.2084,  -4.6986],\n",
      "        [ -4.1754, -11.1567, -11.9478,  ...,  -7.2554,  -5.9634,   3.3391],\n",
      "        [ -2.1284, -11.0558, -12.0711,  ...,  -4.8912,  -4.4046,  11.7873],\n",
      "        [ -3.2261, -15.8723, -15.4638,  ...,  -8.9668,  -7.7230,   8.7145],\n",
      "        [ -4.5622, -16.3810, -15.9939,  ..., -11.0797, -11.0923,   3.5918]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   922,  1165, 50256])\n",
      "p tensor(9.8422e-12, grad_fn=<MulBackward0>)\n",
      "r1: tensor(10.1876, grad_fn=<NegBackward>) r2: tensor(0.1074, grad_fn=<NegBackward>) r2_2: tensor(0.0472, grad_fn=<NegBackward>) r3: tensor(-5.0689, grad_fn=<DivBackward0>)\n",
      "User: So, what's your name?\n",
      "DialoGPT: I'm so good\n",
      "tensor([ 2396,   837,   644,   338,   534,  1438,  5633, 50256])\n",
      "tensor([   40,  1101,   523,   922, 50256]) 5\n",
      "logits tensor([[ -7.3860, -12.5399, -14.2327,  ..., -11.2675, -11.3583,  -3.8260],\n",
      "        [ -4.2273, -10.9455, -11.8749,  ...,  -6.6532,  -6.2155,   3.3605],\n",
      "        [ -5.3758, -12.5027, -12.9987,  ...,  -9.3430,  -7.3404,   2.8652],\n",
      "        [ -7.5508, -16.4407, -18.9564,  ..., -13.2052, -10.7577,   4.1705],\n",
      "        [  4.9671, -10.2022, -10.5339,  ...,  -7.8795,  -6.2111,   3.3613]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   523,   922, 50256])\n",
      "p tensor(2.1398e-12, grad_fn=<MulBackward0>)\n",
      "r1: tensor(9.9955, grad_fn=<NegBackward>) r2: tensor(0.0468, grad_fn=<NegBackward>) r2_2: tensor(0.1806, grad_fn=<NegBackward>) r3: tensor(-5.3741, grad_fn=<DivBackward0>)\n",
      "User: I'm so happy\n",
      "DialoGPT: I'm so so happy\n",
      "tensor([   40,  1101,   523,  3772, 50256])\n",
      "tensor([   40,  1101,   523,   523,  3772, 50256]) 6\n",
      "logits tensor([[ -8.7588, -14.0485, -15.7714,  ..., -13.0770, -13.2740,  -5.4040],\n",
      "        [ -4.0365, -10.5677, -11.1407,  ...,  -7.2881,  -5.9033,   3.9491],\n",
      "        [ -4.1787, -11.0129, -11.4823,  ...,  -7.8833,  -6.2959,   3.2974],\n",
      "        [ -5.2903, -13.7673, -13.1511,  ...,  -9.5906,  -8.8036,   4.3158],\n",
      "        [ -4.5768, -14.0626, -15.0965,  ..., -10.0210,  -7.6228,   8.1814],\n",
      "        [  4.1132, -10.4807,  -9.8784,  ...,  -8.0027,  -6.0343,   4.2383]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   523,   523,  3772, 50256])\n",
      "p tensor(1.1514e-11, grad_fn=<MulBackward0>)\n",
      "r1: tensor(10.0318, grad_fn=<NegBackward>) r2: tensor(0.0595, grad_fn=<NegBackward>) r2_2: tensor(0.0146, grad_fn=<NegBackward>) r3: tensor(-4.1979, grad_fn=<DivBackward0>)\n",
      "User: I am so happy\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,   716,   523,  3772, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -7.9137, -15.4739, -16.6903,  ..., -13.8498, -13.7793,  -4.2842]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.0232, grad_fn=<MulBackward0>)\n",
      "r1: tensor(9.9669, grad_fn=<NegBackward>) r2: tensor(0.4060, grad_fn=<NegBackward>) r2_2: tensor(0.3582, grad_fn=<NegBackward>) r3: tensor(-3.7635, grad_fn=<DivBackward0>)\n",
      "tensor([-2.5246, -3.0107, -2.6097, -2.3893, -2.2589, -1.7562],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4560, grad_fn=<NegBackward>), tensor(-0.4272, grad_fn=<NegBackward>), tensor(-0.2442, grad_fn=<NegBackward>), tensor(-0.1530, grad_fn=<NegBackward>), tensor(-0.5202, grad_fn=<NegBackward>), tensor(-1.7562, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-2.5246, grad_fn=<UnbindBackward>)\n",
      "Episode 2: -1.17874542872111\n",
      "User: Hello\n",
      "DialoGPT: Hello!\n",
      "tensor([15496, 50256])\n",
      "tensor([15496,  5145, 50256]) 3\n",
      "logits tensor([[ -8.3112, -13.7414, -15.4784,  ..., -12.7648, -12.8311,  -4.8617],\n",
      "        [ -2.5132, -12.7328, -12.4583,  ...,  -8.4881,  -7.4519,   7.6740],\n",
      "        [  8.0967, -10.1457,  -8.8385,  ...,  -5.7877,  -4.3532,   8.3061]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([15496,  5145, 50256])\n",
      "p tensor(4.0088e-08, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.4961, grad_fn=<NegBackward>) r2: tensor(0.0629, grad_fn=<NegBackward>) r2_2: tensor(0.0629, grad_fn=<NegBackward>) r3: tensor(-5.6774, grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "tensor([ 2437,   389,   345,  5633, 50256])\n",
      "tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256]) 9\n",
      "logits tensor([[ -8.2046, -13.4230, -15.2064,  ..., -12.4576, -12.4983,  -4.7556],\n",
      "        [ -4.7773, -11.7732, -12.1873,  ...,  -8.0881,  -6.3917,   2.8948],\n",
      "        [  0.4497, -10.1409, -11.1679,  ...,  -3.2146,  -4.1922,  12.3876],\n",
      "        ...,\n",
      "        [ -3.1802, -14.2261, -14.0948,  ...,  -7.2530,  -7.2348,   9.5119],\n",
      "        [ -1.6106, -14.3314, -13.0029,  ...,  -6.8157,  -6.4577,  11.4566],\n",
      "        [  1.7031, -12.4235, -11.8747,  ...,  -7.0977,  -5.7903,   6.4038]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   922,   837,   703,   389,   345,  5633, 50256])\n",
      "p tensor(5.2178e-15, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.5619, grad_fn=<NegBackward>) r2: tensor(0.2629, grad_fn=<NegBackward>) r2_2: tensor(0.0529, grad_fn=<NegBackward>) r3: tensor(-3.6541, grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too.\n",
      "DialoGPT: I'm good\n",
      "tensor([10248,   837,   314,  1101,   922,  1165,   764, 50256])\n",
      "tensor([   40,  1101,   922, 50256]) 4\n",
      "logits tensor([[ -8.3925, -13.8252, -15.5455,  ..., -12.8812, -12.9236,  -4.8280],\n",
      "        [ -4.4062, -11.4298, -12.5013,  ...,  -7.4173,  -6.1049,   2.3602],\n",
      "        [ -2.3499, -11.4608, -12.5286,  ...,  -6.2785,  -5.5890,   9.1587],\n",
      "        [  3.2499, -11.7911, -11.2128,  ...,  -8.5695,  -7.5069,   3.1384]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,   922, 50256])\n",
      "p tensor(4.7384e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.5126, grad_fn=<NegBackward>) r2: tensor(0.0942, grad_fn=<NegBackward>) r2_2: tensor(0.0730, grad_fn=<NegBackward>) r3: tensor(-4.7919, grad_fn=<DivBackward0>)\n",
      "User: Good, I hope you're doing well.\n",
      "DialoGPT: I'm doing well\n",
      "tensor([10248,   837,   314,  2911,   345,   821,  1804,   880,   764, 50256])\n",
      "tensor([   40,  1101,  1804,   880, 50256]) 5\n",
      "logits tensor([[ -8.2579, -13.7461, -15.4581,  ..., -12.7049, -12.8356,  -4.6264],\n",
      "        [ -3.1862, -10.2262, -11.2340,  ...,  -6.7884,  -4.8346,   4.3094],\n",
      "        [ -4.2858, -14.5348, -16.5014,  ...,  -9.0203,  -9.5273,   3.6567],\n",
      "        [ -5.2549, -16.3729, -17.1609,  ..., -11.7629, -12.5266,   4.0748],\n",
      "        [  5.2050, -10.0636,  -9.5082,  ...,  -6.8071,  -4.6128,   5.2151]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  1804,   880, 50256])\n",
      "p tensor(2.7339e-11, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.3712, grad_fn=<NegBackward>) r2: tensor(0.0869, grad_fn=<NegBackward>) r2_2: tensor(0.0933, grad_fn=<NegBackward>) r3: tensor(-4.8645, grad_fn=<DivBackward0>)\n",
      "User: Good, I am too.\n",
      "DialoGPT: Good, I think I'm good.\n",
      "tensor([10248,   837,   314,   716,  1165,   764, 50256])\n",
      "tensor([10248,   837,   314,   892,   314,  1101,   922,   764, 50256]) 9\n",
      "logits tensor([[ -8.4312, -13.9769, -15.7315,  ..., -12.9643, -12.9860,  -4.7799],\n",
      "        [ -7.0991, -11.7425, -13.3482,  ..., -10.2907, -12.1122,   0.4497],\n",
      "        [ -8.3121, -15.2840, -16.4543,  ..., -12.7098, -10.3205,  -1.4277],\n",
      "        ...,\n",
      "        [ -2.2751, -10.6559, -12.4464,  ...,  -5.0567,  -5.7141,   9.7930],\n",
      "        [ -2.3299, -10.7827, -10.9663,  ...,  -5.2703,  -4.5357,  10.4155],\n",
      "        [  4.6984, -10.3565, -10.1172,  ...,  -6.8726,  -5.8085,   4.6004]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([10248,   837,   314,   892,   314,  1101,   922,   764, 50256])\n",
      "p tensor(1.8223e-26, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.6176, grad_fn=<NegBackward>) r2: tensor(0.1347, grad_fn=<NegBackward>) r2_2: tensor(0.0598, grad_fn=<NegBackward>) r3: tensor(-6.5852, grad_fn=<DivBackward0>)\n",
      "User: Good, good.\n",
      "DialoGPT: I'm\n",
      "tensor([10248,   837,   922,   764, 50256])\n",
      "tensor([   40,  1101, 50256]) 3\n",
      "logits tensor([[-10.7321, -17.1517, -18.8007,  ..., -16.2922, -16.3342,  -6.0132],\n",
      "        [ -6.6391, -13.2571, -13.9579,  ...,  -9.8097,  -8.0063,   0.8386],\n",
      "        [  7.0418,  -7.0495,  -7.2712,  ...,  -4.8724,  -3.0976,   4.3509]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101, 50256])\n",
      "p tensor(5.5863e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.3299, grad_fn=<NegBackward>) r2: tensor(0.1123, grad_fn=<NegBackward>) r2_2: tensor(0.2629, grad_fn=<NegBackward>) r3: tensor(-6.3343, grad_fn=<DivBackward0>)\n",
      "User: Good, I guess.\n",
      "DialoGPT: I'm glad\n",
      "tensor([10248,   837,   314,  4724,   764, 50256])\n",
      "tensor([   40,  1101,  9675, 50256]) 4\n",
      "logits tensor([[ -8.7290, -14.1437, -15.8887,  ..., -13.1861, -13.2985,  -5.1588],\n",
      "        [ -6.2246, -13.0855, -13.8785,  ...,  -9.4180,  -7.0948,   1.2064],\n",
      "        [ -5.3436, -14.1735, -15.8082,  ...,  -8.8384,  -8.1824,   4.2938],\n",
      "        [  4.8116, -10.1745, -10.2223,  ...,  -7.4899,  -6.0722,   3.3446]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([   40,  1101,  9675, 50256])\n",
      "p tensor(1.1145e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.6005, grad_fn=<NegBackward>) r2: tensor(0.0642, grad_fn=<NegBackward>) r2_2: tensor(0.1956, grad_fn=<NegBackward>) r3: tensor(-5.1537, grad_fn=<DivBackward0>)\n",
      "User: Good, I'll see you later.\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([10248,   837,   314,  1183,   766,   345,  1568,   764, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[-3.8762e+00, -1.8230e+01, -1.7986e+01,  ..., -1.4382e+01,\n",
      "         -1.3634e+01,  1.7149e-02]], grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.2642, grad_fn=<MulBackward0>)\n",
      "r1: tensor(11.3608, grad_fn=<NegBackward>) r2: tensor(0.3839, grad_fn=<NegBackward>) r2_2: tensor(0.3308, grad_fn=<NegBackward>) r3: tensor(-1.3311, grad_fn=<DivBackward0>)\n",
      "tensor([-6.9467, -6.7904, -5.3063, -4.6194, -3.9784, -4.1161, -3.9272, -3.2467],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.2241, grad_fn=<NegBackward>), tensor(-1.5372, grad_fn=<NegBackward>), tensor(-0.7331, grad_fn=<NegBackward>), tensor(-0.6808, grad_fn=<NegBackward>), tensor(0.0965, grad_fn=<NegBackward>), tensor(-0.2281, grad_fn=<NegBackward>), tensor(-0.7130, grad_fn=<NegBackward>), tensor(-3.2467, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-6.9467, grad_fn=<UnbindBackward>)\n",
      "Episode 3: -0.828022301197052\n",
      "User: Hello\n",
      "DialoGPT: Hello!!\n",
      "tensor([15496, 50256])\n",
      "tensor([15496,  5145,  5145, 50256]) 4\n",
      "logits tensor([[ -8.5499, -14.6099, -16.2594,  ..., -13.4620, -13.4098,  -4.8375],\n",
      "        [ -0.9303, -12.5103, -12.2681,  ...,  -7.4067,  -6.6089,   7.8069],\n",
      "        [ -1.5982, -13.8353, -12.2784,  ...,  -9.3287,  -6.6629,   9.7209],\n",
      "        [  4.1369, -14.1382, -12.4452,  ...,  -8.2782,  -5.0555,  10.2925]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([15496,  5145,  5145, 50256])\n",
      "p tensor(1.9853e-06, grad_fn=<MulBackward0>)\n",
      "r1: tensor(12.5115, grad_fn=<NegBackward>) r2: tensor(0.1494, grad_fn=<NegBackward>) r2_2: tensor(0.1494, grad_fn=<NegBackward>) r3: tensor(-3.2824, grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([ 2437,   389,   345,  5633, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -2.9233, -19.3719, -18.6550,  ..., -14.4607, -13.7371,   1.5563]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.3906, grad_fn=<MulBackward0>)\n",
      "r1: tensor(12.7140, grad_fn=<NegBackward>) r2: tensor(0.2967, grad_fn=<NegBackward>) r2_2: tensor(0.3049, grad_fn=<NegBackward>) r3: tensor(-0.9400, grad_fn=<DivBackward0>)\n",
      "tensor([-5.5095, -3.6108], grad_fn=<CopySlices>)\n",
      "[tensor(-1.9348, grad_fn=<NegBackward>), tensor(-3.6108, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-5.5095, grad_fn=<UnbindBackward>)\n",
      "Episode 4: -0.27546403408050535\n",
      "User: Hello\n",
      "DialoGPT: !!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145, 50256]) 4\n",
      "logits tensor([[-30.4781, -41.1812, -41.0885,  ..., -32.2649, -34.3968,  -9.8399],\n",
      "        [-26.2315, -36.2826, -35.7211,  ..., -30.7095, -30.2571,  -7.3239],\n",
      "        [-21.2818, -34.0883, -33.4888,  ..., -24.8191, -26.0811,   1.2178],\n",
      "        [-12.9694, -24.6713, -24.6140,  ..., -17.0780, -16.9611,   3.8350]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145, 50256])\n",
      "p tensor(1.3129e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(14.3332, grad_fn=<NegBackward>) r2: tensor(0.4567, grad_fn=<NegBackward>) r2_2: tensor(0.4567, grad_fn=<NegBackward>) r3: tensor(-5.1128, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -0.6916, -16.6401, -15.8248,  ..., -12.3413, -10.7450,   4.4192]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.5233, grad_fn=<MulBackward0>)\n",
      "r1: tensor(14.0727, grad_fn=<NegBackward>) r2: tensor(0.2847, grad_fn=<NegBackward>) r2_2: tensor(0.3460, grad_fn=<NegBackward>) r3: tensor(-0.6475, grad_fn=<DivBackward0>)\n",
      "tensor([-6.4959, -4.1404], grad_fn=<CopySlices>)\n",
      "[tensor(-2.3969, grad_fn=<NegBackward>), tensor(-4.1404, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-6.4959, grad_fn=<UnbindBackward>)\n",
      "Episode 5: 0.16993306080500284\n",
      "User: Hello\n",
      "DialoGPT: !!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145, 50256]) 4\n",
      "logits tensor([[ -8.6717, -14.3354, -15.9372,  ..., -13.1647, -13.2734,  -4.6977],\n",
      "        [  0.6275, -11.1377, -10.5750,  ...,  -8.3155,  -6.4746,   6.9361],\n",
      "        [ -0.7000, -10.2831, -10.8298,  ...,  -7.4565,  -6.0880,   8.1299],\n",
      "        [ 10.9361,  -7.2870,  -7.5160,  ...,  -4.4411,  -3.2914,   5.5145]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145, 50256])\n",
      "p tensor(3.2569e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(15.7514, grad_fn=<NegBackward>) r2: tensor(0.4570, grad_fn=<NegBackward>) r2_2: tensor(0.4570, grad_fn=<NegBackward>) r3: tensor(-4.8856, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -1.6225, -15.7502, -15.1882,  ..., -11.4876, -10.3507,   4.4092]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.4941, grad_fn=<MulBackward0>)\n",
      "r1: tensor(15.5097, grad_fn=<NegBackward>) r2: tensor(0.2848, grad_fn=<NegBackward>) r2_2: tensor(0.3463, grad_fn=<NegBackward>) r3: tensor(-0.7049, grad_fn=<DivBackward0>)\n",
      "tensor([-7.2931, -4.4717], grad_fn=<CopySlices>)\n",
      "[tensor(-2.8661, grad_fn=<NegBackward>), tensor(-4.4717, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-7.2931, grad_fn=<UnbindBackward>)\n",
      "Episode 6: 0.5551051242010934\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[-2.9055e+00, -1.4698e+01, -1.4644e+01,  ..., -1.0143e+01,\n",
      "         -3.9751e+00,  1.6131e+01],\n",
      "        [ 1.3195e-02, -1.5573e+01, -1.7111e+01,  ..., -1.0610e+01,\n",
      "         -3.9662e+00,  1.6294e+01],\n",
      "        [-4.3659e+00, -1.8361e+01, -1.8610e+01,  ..., -1.2051e+01,\n",
      "         -6.3044e+00,  1.5177e+01],\n",
      "        [ 1.6644e+00, -1.3739e+01, -1.3020e+01,  ..., -7.0197e+00,\n",
      "         -3.2287e+00,  1.8942e+01],\n",
      "        [-9.4225e-01, -1.6979e+01, -1.6011e+01,  ..., -9.9873e+00,\n",
      "         -3.9393e+00,  1.6169e+01],\n",
      "        [-2.0727e+00, -1.8639e+01, -1.8088e+01,  ..., -1.1763e+01,\n",
      "         -4.3643e+00,  1.4479e+01]], grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.0007, grad_fn=<MulBackward0>)\n",
      "r1: tensor(16.8217, grad_fn=<NegBackward>) r2: tensor(0.5005, grad_fn=<NegBackward>) r2_2: tensor(0.5005, grad_fn=<NegBackward>) r3: tensor(-1.2092, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: !!!\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([ 5145,  5145,  5145, 50256]) 4\n",
      "logits tensor([[ -8.8800, -17.8597, -18.7241,  ..., -15.2032, -15.0947,  -3.3489],\n",
      "        [  1.7104, -10.8557, -10.0915,  ...,  -6.9903,  -6.5131,   5.4973],\n",
      "        [  0.1575,  -8.3869,  -8.7905,  ...,  -5.1385,  -2.9824,  10.1590],\n",
      "        [ 10.3219,  -5.0834,  -5.3054,  ...,  -3.5431,  -1.9859,   5.4292]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145, 50256])\n",
      "p tensor(4.1976e-08, grad_fn=<MulBackward0>)\n",
      "r1: tensor(17.0048, grad_fn=<NegBackward>) r2: tensor(0.0025, grad_fn=<NegBackward>) r2_2: tensor(0.4541, grad_fn=<NegBackward>) r3: tensor(-4.2465, grad_fn=<DivBackward0>)\n",
      "User: You're not sorry\n",
      "DialoGPT: !!\n",
      "tensor([ 1639,   821,   407,  7926, 50256])\n",
      "tensor([ 5145,  5145, 50256]) 3\n",
      "logits tensor([[-20.1875, -37.5269, -40.7640,  ..., -32.5082, -24.4664,  -4.5067],\n",
      "        [-11.3299, -26.8864, -29.8677,  ..., -18.2394, -15.2250,   4.6717],\n",
      "        [-13.0736, -30.5413, -30.8954,  ..., -26.2699, -17.6924,   1.4812]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145, 50256])\n",
      "p tensor(0.0002, grad_fn=<MulBackward0>)\n",
      "r1: tensor(16.9237, grad_fn=<NegBackward>) r2: tensor(0.0028, grad_fn=<NegBackward>) r2_2: tensor(0.4253, grad_fn=<NegBackward>) r3: tensor(-2.7822, grad_fn=<DivBackward0>)\n",
      "User: I am sorry\n",
      "DialoGPT: !! I am sorry\n",
      "tensor([   40,   716,  7926, 50256])\n",
      "tensor([ 5145,  5145,   314,   716,  7926, 50256]) 6\n",
      "logits tensor([[ -8.7304, -14.4801, -16.1756,  ..., -13.2566, -13.2722,  -4.8353],\n",
      "        [ -1.9089, -14.2469, -14.8150,  ..., -10.9777,  -8.2536,   2.6813],\n",
      "        [ -4.1999, -12.6029, -13.6662,  ...,  -9.4524,  -6.6520,   3.7314],\n",
      "        [ -1.7223, -10.0466, -11.8242,  ...,  -6.8003,  -5.4391,   6.8060],\n",
      "        [ -8.0901, -17.9856, -18.5794,  ..., -13.0738, -10.1858,   5.6336],\n",
      "        [ -0.6137, -15.0563, -13.4462,  ...,  -9.8963,  -5.6080,  10.5545]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,   314,   716,  7926, 50256])\n",
      "p tensor(7.4092e-09, grad_fn=<MulBackward0>)\n",
      "r1: tensor(17.3806, grad_fn=<NegBackward>) r2: tensor(0.1148, grad_fn=<NegBackward>) r2_2: tensor(0.1053, grad_fn=<NegBackward>) r3: tensor(-3.1201, grad_fn=<DivBackward0>)\n",
      "User: I am sorry.\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,   716,  7926,   764, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -4.1716, -17.0701, -16.6801,  ..., -12.9874, -12.0252,   2.5309]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.5003, grad_fn=<MulBackward0>)\n",
      "r1: tensor(17.0100, grad_fn=<NegBackward>) r2: tensor(0.2623, grad_fn=<NegBackward>) r2_2: tensor(0.2610, grad_fn=<NegBackward>) r3: tensor(-0.6926, grad_fn=<DivBackward0>)\n",
      "tensor([-18.8287, -13.8650, -11.1639,  -7.7596,  -4.6912],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-5.1023, grad_fn=<NegBackward>), tensor(-2.8128, grad_fn=<NegBackward>), tensor(-3.4819, grad_fn=<NegBackward>), tensor(-3.1153, grad_fn=<NegBackward>), tensor(-4.6912, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-18.8287, grad_fn=<UnbindBackward>)\n",
      "Episode 7: 1.1235035508871078\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[ -6.2033, -13.6545, -14.8702,  ..., -10.8787, -11.0332,  -1.1484],\n",
      "        [  2.4325,  -8.0649,  -9.4114,  ...,  -5.4274,  -3.8449,   7.9386],\n",
      "        [  1.4997,  -8.8164,  -7.9170,  ...,  -7.0098,  -4.4308,   9.8427],\n",
      "        [ -0.1526,  -8.0249,  -8.3800,  ...,  -5.4072,  -3.6131,  13.1793],\n",
      "        [  2.0914,  -7.7201,  -7.3004,  ...,  -4.2020,  -3.1426,  12.1131],\n",
      "        [ -1.3674, -15.8895, -13.7691,  ..., -10.4944,  -6.9206,  10.2723]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(9.0737e-05, grad_fn=<MulBackward0>)\n",
      "r1: tensor(19.3035, grad_fn=<NegBackward>) r2: tensor(0.5012, grad_fn=<NegBackward>) r2_2: tensor(0.5012, grad_fn=<NegBackward>) r3: tensor(-1.5513, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -2.2469, -17.0694, -16.2339,  ..., -11.9893, -10.8018,   4.7592]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.5944, grad_fn=<MulBackward0>)\n",
      "r1: tensor(18.6631, grad_fn=<NegBackward>) r2: tensor(0.3517, grad_fn=<NegBackward>) r2_2: tensor(0.3472, grad_fn=<NegBackward>) r3: tensor(-0.5202, grad_fn=<DivBackward0>)\n",
      "tensor([-10.9532,  -5.4540], grad_fn=<CopySlices>)\n",
      "[tensor(-5.5537, grad_fn=<NegBackward>), tensor(-5.4540, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-10.9532, grad_fn=<UnbindBackward>)\n",
      "Episode 8: 1.6157505644692316\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[-3.8929e+00, -1.6881e+01, -1.6396e+01,  ..., -1.1533e+01,\n",
      "         -1.0396e+01,  4.8835e+00],\n",
      "        [-8.8722e-03, -1.2359e+01, -1.2525e+01,  ..., -7.1530e+00,\n",
      "         -5.3681e+00,  8.7043e+00],\n",
      "        [ 5.3164e+00, -7.5621e+00, -5.9084e+00,  ..., -2.6218e+00,\n",
      "         -3.8510e-01,  1.4059e+01],\n",
      "        [ 2.3725e+00, -9.8539e+00, -7.8807e+00,  ..., -4.2964e+00,\n",
      "         -2.9761e+00,  1.2403e+01],\n",
      "        [ 6.8486e+00, -6.4962e+00, -4.5888e+00,  ...,  8.6176e-02,\n",
      "          1.0724e+00,  1.6782e+01],\n",
      "        [ 1.4740e+00, -1.3473e+01, -1.0964e+01,  ..., -7.5078e+00,\n",
      "         -4.6585e+00,  1.3301e+01]], grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.0184, grad_fn=<MulBackward0>)\n",
      "r1: tensor(21.5187, grad_fn=<NegBackward>) r2: tensor(0.5019, grad_fn=<NegBackward>) r2_2: tensor(0.5019, grad_fn=<NegBackward>) r3: tensor(-0.6659, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -1.0934, -23.7867, -20.4762,  ...,  -9.5851, -10.9215,  11.9588]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.0342, grad_fn=<MulBackward0>)\n",
      "r1: tensor(22.2252, grad_fn=<NegBackward>) r2: tensor(0.3520, grad_fn=<NegBackward>) r2_2: tensor(0.3476, grad_fn=<NegBackward>) r3: tensor(-3.3757, grad_fn=<DivBackward0>)\n",
      "tensor([-11.4213,  -4.9179], grad_fn=<CopySlices>)\n",
      "[tensor(-6.5525, grad_fn=<NegBackward>), tensor(-4.9179, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-11.4213, grad_fn=<UnbindBackward>)\n",
      "Episode 9: 2.1094292998313904\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[ -8.5234, -14.3353, -15.9490,  ..., -13.0812, -13.0130,  -4.5144],\n",
      "        [ -1.0435, -15.3804, -16.0432,  ..., -12.2188,  -9.5470,   5.2645],\n",
      "        [  2.6798, -11.1696,  -9.9329,  ...,  -7.1621,  -4.6837,  11.7919],\n",
      "        [  2.0726, -12.6513, -11.0578,  ...,  -7.1890,  -6.1160,  10.0831],\n",
      "        [  3.5074, -10.6907,  -9.5323,  ...,  -6.1556,  -4.2311,  11.4829],\n",
      "        [  2.1185, -13.2706, -10.3868,  ...,  -7.7421,  -3.7900,  15.3026]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.0005, grad_fn=<MulBackward0>)\n",
      "r1: tensor(24.6892, grad_fn=<NegBackward>) r2: tensor(0.5027, grad_fn=<NegBackward>) r2_2: tensor(0.5027, grad_fn=<NegBackward>) r3: tensor(-1.2631, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[  1.5170, -16.9569, -15.2402,  ..., -10.7201,  -9.1413,   9.1827]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.8702, grad_fn=<MulBackward0>)\n",
      "r1: tensor(25.2811, grad_fn=<NegBackward>) r2: tensor(0.3523, grad_fn=<NegBackward>) r2_2: tensor(0.3481, grad_fn=<NegBackward>) r3: tensor(-0.1390, grad_fn=<DivBackward0>)\n",
      "tensor([-14.2770,  -7.3013], grad_fn=<CopySlices>)\n",
      "[tensor(-7.0488, grad_fn=<NegBackward>), tensor(-7.3013, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-14.2770, grad_fn=<UnbindBackward>)\n",
      "Episode 10: 2.5584590543400156\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[ -3.9265, -15.4542, -15.3043,  ...,  -9.6023,  -7.7135,   8.6724],\n",
      "        [  4.3640,  -7.0359,  -8.5894,  ...,  -0.8131,  -0.1864,  17.7514],\n",
      "        [  5.3201,  -6.3964,  -5.7865,  ...,  -0.9513,   0.6387,  18.0351],\n",
      "        [  9.3461,  -3.5077,  -1.1307,  ...,   3.4907,   4.4669,  22.4505],\n",
      "        [ 10.0698,  -2.8528,  -1.7272,  ...,   2.6078,   4.9548,  23.3856],\n",
      "        [  1.7894, -10.5781,  -8.1685,  ...,  -4.5952,  -0.8622,  17.7940]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.0224, grad_fn=<MulBackward0>)\n",
      "r1: tensor(29.3990, grad_fn=<NegBackward>) r2: tensor(0.5035, grad_fn=<NegBackward>) r2_2: tensor(0.5035, grad_fn=<NegBackward>) r3: tensor(-0.6330, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -4.8329, -17.6289, -16.4246,  ...,  -9.6418,  -8.8203,  11.6208]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.7734, grad_fn=<MulBackward0>)\n",
      "r1: tensor(30.1638, grad_fn=<NegBackward>) r2: tensor(0.3526, grad_fn=<NegBackward>) r2_2: tensor(0.3485, grad_fn=<NegBackward>) r3: tensor(-0.2570, grad_fn=<DivBackward0>)\n",
      "tensor([-16.9232,  -8.4641], grad_fn=<CopySlices>)\n",
      "[tensor(-8.5437, grad_fn=<NegBackward>), tensor(-8.4641, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-16.9232, grad_fn=<UnbindBackward>)\n",
      "Episode 11: 3.057231535514196\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[ -8.0460, -16.2237, -17.2067,  ..., -13.6196, -13.3754,  -1.4944],\n",
      "        [  2.8886,  -9.4245, -11.3819,  ...,  -4.4667,  -4.4109,  12.1244],\n",
      "        [  1.0033, -12.6972, -11.5919,  ...,  -6.4036,  -5.0283,  12.5634],\n",
      "        [  1.5550, -11.9895, -11.2163,  ...,  -7.0619,  -4.0941,  14.1934],\n",
      "        [  6.3924,  -9.5406,  -7.4260,  ...,  -3.3661,  -1.4614,  17.1100],\n",
      "        [ -0.0664, -14.0244, -11.4084,  ...,  -8.2587,  -4.8947,  14.8250]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.0044, grad_fn=<MulBackward0>)\n",
      "r1: tensor(35.0140, grad_fn=<NegBackward>) r2: tensor(0.5044, grad_fn=<NegBackward>) r2_2: tensor(0.5044, grad_fn=<NegBackward>) r3: tensor(-0.9039, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -4.4590, -19.9682, -19.4719,  ..., -15.1849, -14.1905,   2.9599]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.7708, grad_fn=<MulBackward0>)\n",
      "r1: tensor(35.7200, grad_fn=<NegBackward>) r2: tensor(0.3529, grad_fn=<NegBackward>) r2_2: tensor(0.3491, grad_fn=<NegBackward>) r3: tensor(-0.2604, grad_fn=<DivBackward0>)\n",
      "tensor([-19.5688,  -9.8527], grad_fn=<CopySlices>)\n",
      "[tensor(-9.8146, grad_fn=<NegBackward>), tensor(-9.8527, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-19.5688, grad_fn=<UnbindBackward>)\n",
      "Episode 12: 3.5770291823607225\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\n",
      "tensor([15496, 50256])\n",
      "tensor([ 5145,  5145,  5145,  5145,  5145, 50256]) 6\n",
      "logits tensor([[ 1.5278e+01, -4.2972e+00, -3.0119e-02,  ...,  9.6099e+00,\n",
      "          9.5699e+00,  3.6132e+01],\n",
      "        [ 1.8384e+00, -1.5898e+01, -1.2552e+01,  ..., -5.5648e+00,\n",
      "         -4.6533e+00,  2.0723e+01],\n",
      "        [ 2.9085e+00, -1.6616e+01, -1.3506e+01,  ..., -5.6699e+00,\n",
      "         -4.4290e+00,  2.1774e+01],\n",
      "        [ 4.3407e+00, -1.3819e+01, -1.0160e+01,  ..., -3.4137e+00,\n",
      "         -2.1104e+00,  2.4998e+01],\n",
      "        [ 8.7173e+00, -1.2338e+01, -8.8053e+00,  ..., -1.6628e-01,\n",
      "          9.0245e-01,  3.0620e+01],\n",
      "        [ 9.1194e-01, -1.7333e+01, -1.6000e+01,  ..., -8.3658e+00,\n",
      "         -4.5541e+00,  2.0594e+01]], grad_fn=<MmBackward>) tokens tensor([ 5145,  5145,  5145,  5145,  5145, 50256])\n",
      "p tensor(0.1596, grad_fn=<MulBackward0>)\n",
      "r1: tensor(40.1400, grad_fn=<NegBackward>) r2: tensor(0.5052, grad_fn=<NegBackward>) r2_2: tensor(0.5052, grad_fn=<NegBackward>) r3: tensor(-0.3058, grad_fn=<DivBackward0>)\n",
      "User: I'm sorry\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "tensor([   40,  1101,  7926, 50256])\n",
      "tensor([50256]) 1\n",
      "logits tensor([[ -0.6627, -17.7047, -16.6759,  ..., -11.4062, -10.2407,   7.9586]],\n",
      "       grad_fn=<MmBackward>) tokens tensor([50256])\n",
      "p tensor(0.8694, grad_fn=<MulBackward0>)\n",
      "r1: tensor(37.8191, grad_fn=<NegBackward>) r2: tensor(0.3532, grad_fn=<NegBackward>) r2_2: tensor(0.3496, grad_fn=<NegBackward>) r3: tensor(-0.1399, grad_fn=<DivBackward0>)\n",
      "tensor([-21.7325, -10.4391], grad_fn=<CopySlices>)\n",
      "[tensor(-11.3978, grad_fn=<NegBackward>), tensor(-10.4391, grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(-21.7325, grad_fn=<UnbindBackward>)\n",
      "Episode 13: 4.135656314236777\n",
      "User: Hello\n",
      "DialoGPT: !!!!!\"!!!!#!!!!$!!!!%!!!!&!!!!'!!!!(!!!!)!!!!*!!!!+!!!!,!!!!-!!!!.!!!!/!!!!0!!!!1!!!!2!!!!3!!!!4!!!!5!!!!6!!!!7!!!!8!!!!9!!!!:!!!!;!!!!<!!!!=!!!!>!!!!?!!!!@!!!!A!!!!B!!!!C!!!!D!!!!E!!!!F!!!!G!!!!H!!!!I!!!!J!!!!K!!!!L!!!!M!!!!N!!!!O!!!!P!!!!Q!!!!R!!!!S!!!!T!!!!U!!!!V!!!!W!!!!X!!!!Y!!!!Z!!!![!!!!\\!!!!]!!!!^!!!!_!!!!`!!!!a!!!!b!!!!c!!!!d!!!!e!!!!f!!!!g!!!!h!!!!i!!!!j!!!!k!!!!l!!!!m!!!!n!!!!o!!!!p!!!!q!!!!r!!!!s!!!!t!!!!u!!!!v!!!!w!!!!x!!!!y!!!!z!!!!{!!!!|!!!!}!!!!~!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0000!!!!\u0001!!!!\u0002!!!!\u0003!!!!\u0004!!!!\u0005!!!!\u0006!!!!\u0007!!!!!!!\t!!!!\n",
      "!!!!\u000b",
      "!!\n",
      "tensor([15496, 50256])\n",
      "tensor([  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,   0,   0,\n",
      "          0,   3,   0,   0,   0,   0,   4,   0,   0,   0,   0,   5,   0,   0,\n",
      "          0,   0,   6,   0,   0,   0,   0,   7,   0,   0,   0,   0,   8,   0,\n",
      "          0,   0,   0,   9,   0,   0,   0,   0,  10,   0,   0,   0,   0,  11,\n",
      "          0,   0,   0,   0,  12,   0,   0,   0,   0,  13,   0,   0,   0,   0,\n",
      "         14,   0,   0,   0,   0,  15,   0,   0,   0,   0,  16,   0,   0,   0,\n",
      "          0,  17,   0,   0,   0,   0,  18,   0,   0,   0,   0,  19,   0,   0,\n",
      "          0,   0,  20,   0,   0,   0,   0,  21,   0,   0,   0,   0,  22,   0,\n",
      "          0,   0,   0,  23,   0,   0,   0,   0,  24,   0,   0,   0,   0,  25,\n",
      "          0,   0,   0,   0,  26,   0,   0,   0,   0,  27,   0,   0,   0,   0,\n",
      "         28,   0,   0,   0,   0,  29,   0,   0,   0,   0,  30,   0,   0,   0,\n",
      "          0,  31,   0,   0,   0,   0,  32,   0,   0,   0,   0,  33,   0,   0,\n",
      "          0,   0,  34,   0,   0,   0,   0,  35,   0,   0,   0,   0,  36,   0,\n",
      "          0,   0,   0,  37,   0,   0,   0,   0,  38,   0,   0,   0,   0,  39,\n",
      "          0,   0,   0,   0,  40,   0,   0,   0,   0,  41,   0,   0,   0,   0,\n",
      "         42,   0,   0,   0,   0,  43,   0,   0,   0,   0,  44,   0,   0,   0,\n",
      "          0,  45,   0,   0,   0,   0,  46,   0,   0,   0,   0,  47,   0,   0,\n",
      "          0,   0,  48,   0,   0,   0,   0,  49,   0,   0,   0,   0,  50,   0,\n",
      "          0,   0,   0,  51,   0,   0,   0,   0,  52,   0,   0,   0,   0,  53,\n",
      "          0,   0,   0,   0,  54,   0,   0,   0,   0,  55,   0,   0,   0,   0,\n",
      "         56,   0,   0,   0,   0,  57,   0,   0,   0,   0,  58,   0,   0,   0,\n",
      "          0,  59,   0,   0,   0,   0,  60,   0,   0,   0,   0,  61,   0,   0,\n",
      "          0,   0,  62,   0,   0,   0,   0,  63,   0,   0,   0,   0,  64,   0,\n",
      "          0,   0,   0,  65,   0,   0,   0,   0,  66,   0,   0,   0,   0,  67,\n",
      "          0,   0,   0,   0,  68,   0,   0,   0,   0,  69,   0,   0,   0,   0,\n",
      "         70,   0,   0,   0,   0,  71,   0,   0,   0,   0,  72,   0,   0,   0,\n",
      "          0,  73,   0,   0,   0,   0,  74,   0,   0,   0,   0,  75,   0,   0,\n",
      "          0,   0,  76,   0,   0,   0,   0,  77,   0,   0,   0,   0,  78,   0,\n",
      "          0,   0,   0,  79,   0,   0,   0,   0,  80,   0,   0,   0,   0,  81,\n",
      "          0,   0,   0,   0,  82,   0,   0,   0,   0,  83,   0,   0,   0,   0,\n",
      "         84,   0,   0,   0,   0,  85,   0,   0,   0,   0,  86,   0,   0,   0,\n",
      "          0,  87,   0,   0,   0,   0,  88,   0,   0,   0,   0,  89,   0,   0,\n",
      "          0,   0,  90,   0,   0,   0,   0,  91,   0,   0,   0,   0,  92,   0,\n",
      "          0,   0,   0,  93,   0,   0,   0,   0,  94,   0,   0,   0,   0,  95,\n",
      "          0,   0,   0,   0,  96,   0,   0,   0,   0,  97,   0,   0,   0,   0,\n",
      "         98,   0,   0,   0,   0,  99,   0,   0,   0,   0, 100,   0,   0,   0,\n",
      "          0, 101,   0,   0,   0,   0, 102,   0,   0,   0,   0, 103,   0,   0,\n",
      "          0,   0, 104,   0,   0,   0,   0, 105,   0,   0,   0,   0, 106,   0,\n",
      "          0,   0,   0, 107,   0,   0,   0,   0, 108,   0,   0,   0,   0, 109,\n",
      "          0,   0,   0,   0, 110,   0,   0,   0,   0, 111,   0,   0,   0,   0,\n",
      "        112,   0,   0,   0,   0, 113,   0,   0,   0,   0, 114,   0,   0,   0,\n",
      "          0, 115,   0,   0,   0,   0, 116,   0,   0,   0,   0, 117,   0,   0,\n",
      "          0,   0, 118,   0,   0,   0,   0, 119,   0,   0,   0,   0, 120,   0,\n",
      "          0,   0,   0, 121,   0,   0,   0,   0, 122,   0,   0,   0,   0, 123,\n",
      "          0,   0,   0,   0, 124,   0,   0,   0,   0, 125,   0,   0,   0,   0,\n",
      "        126,   0,   0,   0,   0, 127,   0,   0,   0,   0, 128,   0,   0,   0,\n",
      "          0, 129,   0,   0,   0,   0, 130,   0,   0,   0,   0, 131,   0,   0,\n",
      "          0,   0, 132,   0,   0,   0,   0, 133,   0,   0,   0,   0, 134,   0,\n",
      "          0,   0,   0, 135,   0,   0,   0,   0, 136,   0,   0,   0,   0, 137,\n",
      "          0,   0,   0,   0, 138,   0,   0,   0,   0, 139,   0,   0,   0,   0,\n",
      "        140,   0,   0,   0,   0, 141,   0,   0,   0,   0, 142,   0,   0,   0,\n",
      "          0, 143,   0,   0,   0,   0, 144,   0,   0,   0,   0, 145,   0,   0,\n",
      "          0,   0, 146,   0,   0,   0,   0, 147,   0,   0,   0,   0, 148,   0,\n",
      "          0,   0,   0, 149,   0,   0,   0,   0, 150,   0,   0,   0,   0, 151,\n",
      "          0,   0,   0,   0, 152,   0,   0,   0,   0, 153,   0,   0,   0,   0,\n",
      "        154,   0,   0,   0,   0, 155,   0,   0,   0,   0, 156,   0,   0,   0,\n",
      "          0, 157,   0,   0,   0,   0, 158,   0,   0,   0,   0, 159,   0,   0,\n",
      "          0,   0, 160,   0,   0,   0,   0, 161,   0,   0,   0,   0, 162,   0,\n",
      "          0,   0,   0, 163,   0,   0,   0,   0, 164,   0,   0,   0,   0, 165,\n",
      "          0,   0,   0,   0, 166,   0,   0,   0,   0, 167,   0,   0,   0,   0,\n",
      "        168,   0,   0,   0,   0, 169,   0,   0,   0,   0, 170,   0,   0,   0,\n",
      "          0, 171,   0,   0,   0,   0, 172,   0,   0,   0,   0, 173,   0,   0,\n",
      "          0,   0, 174,   0,   0,   0,   0, 175,   0,   0,   0,   0, 176,   0,\n",
      "          0,   0,   0, 177,   0,   0,   0,   0, 178,   0,   0,   0,   0, 179,\n",
      "          0,   0,   0,   0, 180,   0,   0,   0,   0, 181,   0,   0,   0,   0,\n",
      "        182,   0,   0,   0,   0, 183,   0,   0,   0,   0, 184,   0,   0,   0,\n",
      "          0, 185,   0,   0,   0,   0, 186,   0,   0,   0,   0, 187,   0,   0,\n",
      "          0,   0, 188,   0,   0,   0,   0, 189,   0,   0,   0,   0, 190,   0,\n",
      "          0,   0,   0, 191,   0,   0,   0,   0, 192,   0,   0,   0,   0, 193,\n",
      "          0,   0,   0,   0, 194,   0,   0,   0,   0, 195,   0,   0,   0,   0,\n",
      "        196,   0,   0,   0,   0, 197,   0,   0,   0,   0, 198,   0,   0,   0,\n",
      "          0, 199,   0,   0]) 998\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 63744256 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-745a1b10d854>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-b190fc768187>\u001b[0m in \u001b[0;36mcompute_reward\u001b[1;34m(questions, answers)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# reward 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mr3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;31m#     print(t2, t2.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-b190fc768187>\u001b[0m in \u001b[0;36mlog_prob\u001b[1;34m(tokens, debug)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# p = log(P(b|a)) / N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0moutput_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tokens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         )\n\u001b[0;32m    733\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             )\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         )\n\u001b[0;32m    294\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mpresent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mattn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[1;34m(self, q, k, v, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;31m# Mask heads if we want to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m    981\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[0;32m    982\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[0;32m    984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 63744256 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "chat_history_ids = tokenizer.encode(tokenizer.bos_token + \"Hello\" + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "reward = 0\n",
    "USE_CUDA = False\n",
    "if USE_CUDA:\n",
    "    device  ='cuda'\n",
    "    model = model.cuda()\n",
    "#     user = user.cuda()\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    model = model.cpu()\n",
    "#     user = user.cpu()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "batch_size = 64\n",
    "gamma      = 0.99  # 0.99\n",
    "ep_rewards = []\n",
    "\n",
    "for episode in range(50):\n",
    "    chat_history_ids = tokenizer.encode(\"Hello\" + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "    questions = []\n",
    "    answers   = []\n",
    "    turns     = []\n",
    "    rewards   = []\n",
    "    model.eval()\n",
    "    max_length = 1000\n",
    "    for frame in range(20):\n",
    "        epsilon = epsilon_by_frame(frame)\n",
    "        # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    #     new_user_input_ids = tokenizer.encode(tokenizer.eos_token, return_tensors='pt')\n",
    "        input_ids = chat_history_ids[-(max_length-100):].to(device)\n",
    "        chat_history_ids = user.generate(input_ids, max_length=max_length, \n",
    "                                         pad_token_id=tokenizer.eos_token_id, \n",
    "#                                          repetition_penalty=1.75,\n",
    "#                                          do_sample=True,\n",
    "#                                          temperature=0.98,\n",
    "#                                          top_k=0,\n",
    "#                                          num_beams=3,\n",
    "    # #                              num_return_sequences=1,\n",
    "    #                              early_stopping=True,\n",
    "                                         no_repeat_ngram_size=5\n",
    "                                ) if frame > 0 else input_ids\n",
    "        question = chat_history_ids[:, input_ids.shape[-1]:][0] if frame > 0 else input_ids[0]\n",
    "        questions.append(question.to(device))\n",
    "        turns.append(question)\n",
    "        print(\"User: {}\".format(decode(question)))\n",
    "\n",
    "        # append the new user input tokens to the chat history\n",
    "        input_ids = chat_history_ids[-(max_length-100):] # if step > 0 else new_user_input_ids\n",
    "        # generated a response while limiting the total chat history to 1000 tokens, \n",
    "        chat_history_ids = model.generate(input_ids, \n",
    "                                          pad_token_id=tokenizer.eos_token_id,\n",
    "                                          max_length=max_length, \n",
    "#                                           repetition_penalty=1.25,\n",
    "#                                           min_length=2,\n",
    "#                                           do_sample=True,\n",
    "#                                           temperature=0.99,\n",
    "#                                           top_k=40,\n",
    "#                                           num_beams=3,\n",
    "    #                                       early_stopping=True,\n",
    "    #                                       num_return_sequences=3,\n",
    "                                          no_repeat_ngram_size=5\n",
    "                                         )\n",
    "\n",
    "        # pretty print last output tokens from bot\n",
    "        answer = chat_history_ids[:, input_ids.shape[-1]:][0]\n",
    "        answers.append(answer)\n",
    "        turns.append(answer)\n",
    "        print(\"DialoGPT: {}\".format(decode(answer)))\n",
    "        \n",
    "#         if len(question) == 0: questions[-1] = torch.tensor([tokenizer.eos_token_id])\n",
    "#         if len(answer) == 0: answers[-1] = torch.tensor([tokenizer.eos_token_id])\n",
    "        \n",
    "        if is_dummy_sentence(answer) or len(answer) == 0:\n",
    "            print('dummy')\n",
    "            print(len(answer) > 0, len(answer))\n",
    "            \n",
    "            reward = compute_reward(questions, answers) if len(answer) > 0 else torch.tensor(0.0, requires_grad=True)\n",
    "#             reward += torch.tensor(0.0 - 1*len(answers), requires_grad=True)\n",
    "            rewards.append(reward)\n",
    "            break\n",
    "        else:\n",
    "            reward = compute_reward(questions, answers)\n",
    "            rewards.append(reward)\n",
    "            \n",
    "            \n",
    "    # Train\n",
    "    model.train()\n",
    "    r = discount_rewards(rewards)\n",
    "    print(r)\n",
    "    print(rewards)\n",
    "#     model = model.cuda()\n",
    "    loss = rewards[0]#.to('cuda')\n",
    "    \n",
    "#     loss = r.mean()\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "    if loss.item() != np.NINF or True:\n",
    "        ep_rewards.append(rewards[0].item())\n",
    "        for l in r[:1]:\n",
    "            if l.item() != np.NINF and l.item() != np.nan:\n",
    "                print('----- Loss:', l)\n",
    "                optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "#         if loss.item() != np.NINF\n",
    "#             loss.backward()\n",
    "#                 for param in model.parameters():\n",
    "#                         param.grad.data.clamp_(-1, 1)\n",
    "            \n",
    "#                 optimizer.step()\n",
    "\n",
    "#         optimizer.step()\n",
    "    print(f'Episode {episode}:', -np.mean(ep_rewards))\n",
    "    \n",
    "#     model = model.cpu()\n",
    "#     reward -= jaccard_similarity(answer.numpy(), context.numpy())\n",
    "    \n",
    "#     state = torch.cat([question, answer_ids], dim=-1)  # add separation token?\n",
    "#     action = act(model, state, epsilon)\n",
    "    # next_state, reward, done, _ = next_step(action)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(reward)\n",
    "#     print(answer)\n",
    "#     print(context)\n",
    "#     print(chat_history_ids)\n",
    "print(tokenizer.decode(chat_history_ids[0], skip_special_tokens=True))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20c62ae5608>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(-1*np.array(ep_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "trace() missing 1 required positional argument: 'example_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f2a187c876bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating the trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtraced_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraced_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"traced_bert.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: trace() missing 1 required positional argument: 'example_inputs'"
     ]
    }
   ],
   "source": [
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model)\n",
    "torch.jit.save(traced_model, \"traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.1766, 14.1621], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rews = discount_rewards(rewards)\n",
    "rews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "rewards[0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-590a0fe59134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrews\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "for r in rews:\n",
    "    r.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits = model(v1)[0]\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "prev_input = torch.multinomial(probs, num_samples=1)\n",
    "decode(prev_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello!Hello! :DHow are you?I'm good! How are you?Pretty good!That's good!Can you recommend me a movie?I can!Tell meI will!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ...,   393,  1223, 50256]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ -1.0835, -18.4458, -17.6662,  ..., -14.8533, -13.5491,   0.9567],\n",
       "          [ -6.1334, -16.7606, -15.5976,  ..., -10.8078, -10.3935,   1.5186],\n",
       "          [  6.9852, -10.1889,  -8.7772,  ...,  -6.3700,  -5.0316,   5.8794],\n",
       "          ...,\n",
       "          [  5.4960, -10.9813,  -9.6111,  ...,  -6.2588,  -3.6435,   8.3031],\n",
       "          [ -2.2493, -12.7885, -12.5046,  ...,  -8.5337,  -5.7225,  11.4771],\n",
       "          [  5.3813, -11.0729,  -9.6908,  ...,  -6.2201,  -3.6808,   8.4822]]],\n",
       "        grad_fn=<UnsafeViewBackward>),\n",
       " (tensor([[[[[ 3.5647e-01,  2.9394e-02,  1.2568e-01,  ..., -5.8864e-01,\n",
       "              -1.5299e-02, -1.5551e-01],\n",
       "             [-2.4501e-01, -1.0144e-01,  9.3549e-02,  ..., -3.0358e-01,\n",
       "              -1.4868e-01,  2.2968e-02],\n",
       "             [-4.9309e-01, -4.7411e-02,  1.2059e-01,  ..., -2.4241e-01,\n",
       "              -3.4761e-01, -3.3903e-01],\n",
       "             ...,\n",
       "             [-8.7066e-01, -2.2038e-01, -2.6833e-01,  ..., -1.0996e-01,\n",
       "              -7.4337e-01, -1.9390e-01],\n",
       "             [-6.2056e-01, -3.1638e-01, -1.9239e-01,  ...,  4.4419e-03,\n",
       "              -4.6287e-01,  1.8755e-01],\n",
       "             [-8.7530e-01, -2.0415e-01, -2.5814e-01,  ..., -1.4883e-01,\n",
       "              -7.3084e-01, -2.2438e-01]],\n",
       "  \n",
       "            [[-6.1324e-01, -6.9942e-01, -1.6361e+00,  ...,  7.0650e-03,\n",
       "               3.5510e-01,  1.7768e-02],\n",
       "             [ 3.2067e-01, -1.6376e-01,  1.1313e+00,  ...,  1.0370e-01,\n",
       "              -1.0782e-01,  5.0387e-01],\n",
       "             [-5.4835e-01, -7.1475e-01, -1.2811e+00,  ..., -2.1157e-01,\n",
       "               3.4687e-01,  1.4071e+00],\n",
       "             ...,\n",
       "             [-6.0077e-01, -8.4454e-01, -1.4336e+00,  ..., -7.2469e-02,\n",
       "               5.2511e-01,  1.4458e+00],\n",
       "             [ 4.1453e-01, -2.4197e-01,  1.4339e+00,  ...,  2.2245e-01,\n",
       "              -1.6637e-01,  4.9240e-01],\n",
       "             [-6.4262e-01, -9.0989e-01, -1.4511e+00,  ..., -2.2200e-02,\n",
       "               5.2657e-01,  1.4381e+00]],\n",
       "  \n",
       "            [[-2.7557e-01, -2.0155e-01, -6.3953e-01,  ...,  1.0910e+00,\n",
       "              -4.3234e-03, -1.7263e-01],\n",
       "             [ 3.1270e-01,  1.7569e-01, -1.0122e-01,  ..., -3.8638e-01,\n",
       "               1.8320e-01,  9.4447e-02],\n",
       "             [ 7.5713e-01,  2.5464e-01, -1.0865e+00,  ...,  1.0854e+00,\n",
       "              -5.6328e-01,  3.9266e-01],\n",
       "             ...,\n",
       "             [ 4.8354e-01,  2.1161e-01, -1.0193e+00,  ...,  1.2306e+00,\n",
       "              -7.2439e-01,  3.9395e-01],\n",
       "             [ 3.9067e-02,  9.4769e-02,  1.1326e-01,  ..., -6.3839e-01,\n",
       "               1.7478e-01,  1.9321e-01],\n",
       "             [ 4.9378e-01,  2.1582e-01, -1.0807e+00,  ...,  1.2124e+00,\n",
       "              -7.0893e-01,  3.7200e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-2.7213e-01, -2.0335e-01, -1.8826e-02,  ..., -3.3091e-01,\n",
       "               3.3576e-01, -4.3095e-01],\n",
       "             [ 3.6834e-01,  1.4400e-01, -2.7347e-02,  ...,  4.5087e-01,\n",
       "              -2.3431e-01,  1.3409e-01],\n",
       "             [ 1.7375e-01,  2.0847e-01,  2.7629e-01,  ..., -7.6812e-01,\n",
       "               2.8449e-01,  3.5646e-01],\n",
       "             ...,\n",
       "             [ 3.7828e-01,  3.1220e-01,  1.9310e-01,  ..., -1.3968e+00,\n",
       "               5.8986e-01, -2.2694e-01],\n",
       "             [ 3.8820e-01,  8.5326e-02, -1.0958e-01,  ...,  5.6934e-02,\n",
       "              -7.2865e-02, -3.3456e-01],\n",
       "             [ 3.5121e-01,  2.5736e-01,  1.9702e-01,  ..., -1.3461e+00,\n",
       "               5.8669e-01, -2.5786e-01]],\n",
       "  \n",
       "            [[ 3.4766e-01, -3.1442e-01, -2.2133e-01,  ..., -1.0254e+00,\n",
       "              -8.3510e-01,  2.3008e-01],\n",
       "             [ 2.1702e-01, -4.7279e-01, -4.1508e-01,  ...,  7.1609e-01,\n",
       "              -4.1796e-02,  8.3373e-02],\n",
       "             [ 2.9578e-01, -1.3560e-01, -5.1633e-01,  ..., -4.2625e-01,\n",
       "              -1.1206e+00,  4.5758e-01],\n",
       "             ...,\n",
       "             [ 4.5645e-01, -5.9489e-02, -3.3366e-01,  ..., -6.8987e-01,\n",
       "              -1.5137e+00,  2.3145e-01],\n",
       "             [ 1.6369e-01, -3.9806e-01, -5.1567e-01,  ...,  8.8409e-01,\n",
       "              -2.5165e-02,  8.8157e-03],\n",
       "             [ 4.7713e-01, -6.7030e-02, -3.6515e-01,  ..., -6.5550e-01,\n",
       "              -1.5063e+00,  2.5451e-01]],\n",
       "  \n",
       "            [[ 2.9870e-01,  2.9359e-01, -1.7060e-02,  ...,  9.1998e-01,\n",
       "              -1.2900e+00, -4.4113e-01],\n",
       "             [ 1.3649e-02, -3.3173e-01,  1.1074e-01,  ..., -3.2771e-01,\n",
       "               5.3511e-01,  1.1888e-01],\n",
       "             [ 8.2113e-02,  3.5760e-01,  5.7908e-01,  ...,  1.3913e+00,\n",
       "              -5.6062e-01, -6.8358e-01],\n",
       "             ...,\n",
       "             [ 1.9669e-01,  5.1821e-01,  5.1821e-01,  ...,  1.4756e+00,\n",
       "              -1.0319e+00, -8.4158e-01],\n",
       "             [ 7.3062e-02, -4.5276e-01,  6.6683e-02,  ..., -6.3871e-01,\n",
       "               3.9133e-01,  2.6854e-01],\n",
       "             [ 2.1427e-01,  5.1307e-01,  5.4620e-01,  ...,  1.5034e+00,\n",
       "              -1.0510e+00, -8.5909e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.5427e-02,  1.4064e-02, -1.4428e-02,  ..., -2.6810e-02,\n",
       "              -1.0428e-02, -7.6356e-03],\n",
       "             [-3.7155e-02, -5.5862e-02, -3.3441e-02,  ...,  4.6452e-02,\n",
       "              -6.9445e-03,  7.6375e-03],\n",
       "             [-2.7414e-02,  2.5784e-02,  4.0973e-03,  ..., -4.4848e-02,\n",
       "              -4.5324e-02, -5.4945e-03],\n",
       "             ...,\n",
       "             [-3.0233e-02,  1.5706e-02, -1.8014e-02,  ..., -6.0905e-02,\n",
       "              -4.2522e-02,  1.8541e-03],\n",
       "             [-7.4506e-02, -7.2123e-02, -7.0580e-02,  ...,  7.2690e-02,\n",
       "               3.5773e-02,  1.4194e-02],\n",
       "             [-3.5731e-02,  2.1805e-02, -1.6192e-02,  ..., -6.3145e-02,\n",
       "              -3.5476e-02,  3.1879e-03]],\n",
       "  \n",
       "            [[ 8.3074e-03, -2.8373e-02, -2.6207e-02,  ..., -1.1710e-02,\n",
       "               1.6359e-02, -7.5925e-04],\n",
       "             [ 5.2416e-03,  3.3944e-02,  3.5075e-02,  ..., -4.5050e-03,\n",
       "              -2.3753e-03, -2.3858e-02],\n",
       "             [ 1.3297e-02, -2.9829e-02,  2.1122e-02,  ...,  1.2053e-03,\n",
       "               9.6025e-03,  4.8546e-03],\n",
       "             ...,\n",
       "             [ 2.4855e-02, -4.8428e-02,  7.3654e-03,  ..., -8.4170e-03,\n",
       "               1.0500e-02,  9.3064e-03],\n",
       "             [-6.5294e-04,  3.7523e-02,  4.9824e-03,  ..., -3.2325e-02,\n",
       "              -3.0355e-03, -3.4064e-02],\n",
       "             [ 2.3316e-02, -5.0718e-02,  1.1400e-03,  ..., -4.6231e-03,\n",
       "               1.1423e-02, -1.5631e-03]],\n",
       "  \n",
       "            [[ 7.5115e-03, -7.2156e-03, -2.1719e-03,  ...,  5.1252e-03,\n",
       "               1.3564e-02, -1.3940e-02],\n",
       "             [-1.2027e-02,  1.9729e-02,  2.6076e-03,  ..., -5.5551e-03,\n",
       "              -4.5144e-02,  3.6382e-02],\n",
       "             [ 7.1255e-03, -1.3193e-02,  4.3888e-03,  ...,  1.3248e-02,\n",
       "              -1.0062e-02, -9.6777e-03],\n",
       "             ...,\n",
       "             [ 1.3177e-02, -9.6703e-03,  6.9762e-03,  ...,  1.6377e-02,\n",
       "               3.3508e-03, -1.3634e-02],\n",
       "             [-2.9910e-02,  1.3213e-02,  1.1513e-02,  ..., -1.1051e-02,\n",
       "              -5.7365e-02,  4.4392e-02],\n",
       "             [ 9.6987e-03, -5.6534e-03, -5.4152e-03,  ...,  1.1793e-02,\n",
       "               7.7697e-03, -1.3555e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 2.8884e-03, -3.1777e-04,  1.2526e-02,  ...,  1.0357e-01,\n",
       "              -1.3195e-03,  2.7323e-02],\n",
       "             [ 1.4252e-02, -8.5170e-03,  1.0223e-02,  ..., -1.5446e-02,\n",
       "              -2.5261e-02, -2.9132e-02],\n",
       "             [ 6.4918e-04,  2.2602e-02,  2.3441e-02,  ...,  2.5597e-01,\n",
       "              -7.0115e-03,  2.0920e-02],\n",
       "             ...,\n",
       "             [ 5.2084e-03,  8.6208e-03,  2.6251e-02,  ...,  1.5231e-01,\n",
       "              -2.1594e-02,  1.9266e-02],\n",
       "             [ 1.1481e-02, -3.9369e-02,  3.1823e-02,  ..., -5.2330e-02,\n",
       "              -8.8497e-03, -3.6166e-02],\n",
       "             [ 3.0384e-03,  9.7844e-03,  1.9395e-02,  ...,  1.6410e-01,\n",
       "              -2.1198e-02,  2.2550e-02]],\n",
       "  \n",
       "            [[-3.8660e-02, -1.9084e-02, -4.5845e-03,  ..., -4.2062e-03,\n",
       "               1.2585e-02,  4.7612e-03],\n",
       "             [ 6.1396e-02,  4.5043e-02, -1.5445e-02,  ...,  3.3933e-02,\n",
       "              -2.8724e-02, -1.4793e-02],\n",
       "             [ 9.2317e-03, -1.5910e-02,  5.7461e-03,  ...,  4.7116e-02,\n",
       "              -6.7413e-03,  3.8151e-02],\n",
       "             ...,\n",
       "             [-6.6746e-03, -5.7703e-03,  4.2490e-03,  ...,  2.6396e-02,\n",
       "              -9.8569e-03,  3.3953e-02],\n",
       "             [ 5.5540e-02,  2.8859e-02, -2.8222e-02,  ...,  3.0147e-02,\n",
       "              -3.4354e-02, -2.3551e-02],\n",
       "             [-6.1915e-03, -1.4374e-02,  7.6163e-03,  ...,  2.7397e-02,\n",
       "              -1.7698e-02,  3.3610e-02]],\n",
       "  \n",
       "            [[ 1.0614e-01, -6.2515e-03,  8.8402e-03,  ...,  1.5647e-03,\n",
       "              -7.9393e-03, -3.1664e-04],\n",
       "             [-1.0708e-01, -3.1211e-03,  3.6196e-03,  ..., -7.2911e-03,\n",
       "               1.2847e-02, -4.6337e-02],\n",
       "             [ 1.8343e-01, -9.3105e-03,  1.3973e-02,  ..., -2.7889e-02,\n",
       "              -1.3634e-02,  1.4880e-03],\n",
       "             ...,\n",
       "             [ 1.6527e-01, -8.2843e-03,  5.8837e-03,  ..., -1.3642e-02,\n",
       "              -1.5869e-02,  1.7887e-03],\n",
       "             [-1.3140e-01, -1.1849e-02,  2.6250e-03,  ..., -5.2022e-03,\n",
       "               2.2451e-02, -6.0746e-02],\n",
       "             [ 1.5053e-01, -8.6654e-03,  6.2439e-03,  ..., -1.6795e-02,\n",
       "              -2.0212e-02,  5.8278e-03]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 1.3732e-03, -3.1152e-02, -2.1452e-01,  ..., -2.7631e-01,\n",
       "              -1.2909e+00,  7.3533e-01],\n",
       "             [ 5.5356e-01,  5.9802e-02,  7.7254e-01,  ...,  3.8367e-01,\n",
       "               6.7550e-01, -4.6682e-01],\n",
       "             [ 1.0180e-01,  6.6716e-02, -1.2580e-01,  ..., -5.1118e-01,\n",
       "              -6.9886e-01,  9.8184e-01],\n",
       "             ...,\n",
       "             [ 2.1958e-01,  1.2745e-01, -3.7242e-01,  ..., -5.6320e-01,\n",
       "              -7.5294e-01,  1.1791e+00],\n",
       "             [ 8.4037e-01, -3.2573e-02,  4.0821e-01,  ...,  2.3323e-01,\n",
       "               1.2273e-01,  4.4319e-02],\n",
       "             [ 2.1496e-01,  1.1876e-01, -4.4507e-01,  ..., -5.5489e-01,\n",
       "              -8.4894e-01,  1.1979e+00]],\n",
       "  \n",
       "            [[-1.1132e+00, -1.2448e-01,  1.0983e+00,  ..., -7.3489e-03,\n",
       "               6.9657e-02, -1.6341e-01],\n",
       "             [-2.6266e-01, -3.5057e-01,  1.0390e+00,  ...,  1.2706e+00,\n",
       "               1.6491e-02, -8.8436e-01],\n",
       "             [-1.7826e-01, -2.5279e-01,  2.9990e-01,  ...,  4.5925e-01,\n",
       "               6.1034e-01, -1.4961e-01],\n",
       "             ...,\n",
       "             [-4.8965e-02, -6.2697e-01, -1.8539e+00,  ..., -2.2442e-01,\n",
       "              -1.4169e-01,  1.9390e-01],\n",
       "             [-1.7084e-01, -6.4219e-01, -1.0467e+00,  ...,  4.3814e-01,\n",
       "              -6.7040e-01, -3.0298e-01],\n",
       "             [-4.8870e-02, -6.4088e-01, -2.0001e+00,  ..., -2.8450e-01,\n",
       "              -2.0127e-01,  2.0114e-01]],\n",
       "  \n",
       "            [[ 1.3171e+00,  6.7066e-01,  1.0201e+00,  ...,  1.4822e+00,\n",
       "              -6.5354e-04, -1.2782e+00],\n",
       "             [-4.9257e-01,  7.0507e-01,  2.8585e-01,  ..., -1.0026e+00,\n",
       "               3.3309e-01,  1.0703e+00],\n",
       "             [ 8.1321e-01, -1.3244e-01,  2.2641e-01,  ..., -2.8384e-01,\n",
       "               1.8885e-01, -1.3899e+00],\n",
       "             ...,\n",
       "             [-1.6844e-01, -4.6495e-01, -3.3195e-01,  ...,  3.2054e-01,\n",
       "               1.3388e+00, -2.3499e+00],\n",
       "             [-9.5213e-01,  4.4838e-01, -2.2329e-01,  ...,  1.0145e-01,\n",
       "               1.4386e+00, -5.5737e-01],\n",
       "             [-2.6512e-01, -4.4866e-01, -3.9866e-01,  ...,  3.9018e-01,\n",
       "               1.4138e+00, -2.3916e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.9582e-01,  9.0748e-02,  4.6948e-01,  ...,  2.0914e-01,\n",
       "              -1.9690e-01,  1.7281e-01],\n",
       "             [ 3.9708e-01,  4.9278e-01,  3.4358e-01,  ..., -5.7817e-01,\n",
       "              -1.1119e+00, -3.5681e-01],\n",
       "             [-5.3029e-01,  1.0232e+00,  2.6085e-01,  ...,  6.2739e-02,\n",
       "              -4.8667e-01, -5.2726e-01],\n",
       "             ...,\n",
       "             [ 4.9742e-02,  1.6388e-01,  5.5877e-01,  ...,  1.0970e+00,\n",
       "               3.0226e-01, -4.3555e-01],\n",
       "             [ 7.5735e-01, -5.1173e-01,  2.7250e-01,  ...,  1.0058e+00,\n",
       "               1.2645e-02, -4.5818e-01],\n",
       "             [ 1.0384e-01,  8.5821e-02,  6.2418e-01,  ...,  1.1076e+00,\n",
       "               3.4843e-01, -4.3180e-01]],\n",
       "  \n",
       "            [[-2.1836e-02, -1.6478e-02,  3.3250e-01,  ...,  4.6523e-01,\n",
       "              -3.0216e-01, -5.4917e-01],\n",
       "             [-7.5696e-01, -9.0302e-01,  3.9400e-02,  ...,  4.5685e-02,\n",
       "              -1.3434e-01, -1.3074e+00],\n",
       "             [ 4.3539e-02,  4.6468e-01,  1.2926e-02,  ..., -7.1159e-01,\n",
       "              -4.3663e-01, -2.5163e-01],\n",
       "             ...,\n",
       "             [ 1.8335e+00,  1.3168e+00,  1.2520e+00,  ..., -1.0992e+00,\n",
       "              -1.6982e+00, -2.4647e+00],\n",
       "             [ 1.6050e+00,  2.8709e-01,  7.1577e-01,  ..., -6.1914e-01,\n",
       "              -1.6414e+00, -2.9707e+00],\n",
       "             [ 1.9613e+00,  1.3047e+00,  1.2215e+00,  ..., -9.9180e-01,\n",
       "              -1.9706e+00, -2.5699e+00]],\n",
       "  \n",
       "            [[ 2.2117e-01, -2.2352e-01, -2.7293e-01,  ...,  1.2287e-01,\n",
       "               1.7066e+00,  4.3141e-02],\n",
       "             [-3.4082e-01, -2.3486e-01, -7.1640e-02,  ..., -5.6265e-01,\n",
       "              -8.6947e-01, -1.7060e-01],\n",
       "             [-6.1464e-02,  1.2267e-01, -1.9044e-01,  ...,  1.3128e-01,\n",
       "               1.2613e-01,  1.2517e-02],\n",
       "             ...,\n",
       "             [ 7.2369e-02,  5.6791e-02, -2.0905e-01,  ..., -1.4716e-01,\n",
       "               3.8101e-01,  1.8978e-02],\n",
       "             [-7.8229e-02, -1.7727e-01, -2.1226e-01,  ..., -3.4204e-01,\n",
       "               4.7143e-02, -2.3802e-01],\n",
       "             [ 9.2552e-02,  6.0483e-02, -2.2751e-01,  ..., -1.6088e-01,\n",
       "               3.3967e-01,  1.0776e-02]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.1288e-01, -7.3756e-02,  4.1562e-01,  ...,  1.0891e-01,\n",
       "              -2.2000e-01,  2.7641e-01],\n",
       "             [ 8.4596e-02, -3.1537e-01, -3.6905e-01,  ..., -8.2744e-03,\n",
       "               1.9836e-02, -8.6060e-04],\n",
       "             [ 2.1927e-01,  1.0642e-01,  7.3121e-04,  ...,  6.8869e-02,\n",
       "              -1.7593e-01,  2.3871e-01],\n",
       "             ...,\n",
       "             [ 5.9715e-01,  5.4864e-01,  4.9133e-01,  ..., -3.1126e-01,\n",
       "              -3.1610e-01,  3.2728e-01],\n",
       "             [-7.5342e-02, -1.2938e-01,  4.5588e-01,  ..., -4.2842e-01,\n",
       "              -1.6973e-01,  1.6444e-01],\n",
       "             [ 5.6355e-01,  5.7384e-01,  5.4991e-01,  ..., -3.3279e-01,\n",
       "              -3.2332e-01,  3.0293e-01]],\n",
       "  \n",
       "            [[ 1.7196e-01, -1.1144e-01,  1.4478e-03,  ...,  4.6665e-03,\n",
       "               1.4802e-01, -1.1413e-01],\n",
       "             [-8.7649e-01, -7.2703e-02,  4.7985e-01,  ..., -3.3779e-01,\n",
       "               3.2150e-01,  2.1270e-01],\n",
       "             [ 4.3443e-01,  1.9312e-01,  1.4849e-01,  ...,  6.1159e-02,\n",
       "              -9.9687e-02, -2.0709e-01],\n",
       "             ...,\n",
       "             [ 3.7974e-01,  1.0961e+00,  2.9356e-01,  ..., -1.1159e-01,\n",
       "              -9.1351e-01, -1.2655e-01],\n",
       "             [-9.5393e-01,  1.1897e+00,  3.8126e-01,  ..., -5.4444e-01,\n",
       "              -5.6157e-01,  2.5204e-01],\n",
       "             [ 3.9494e-01,  1.2013e+00,  2.6462e-01,  ..., -1.0423e-01,\n",
       "              -9.5901e-01, -1.1632e-01]],\n",
       "  \n",
       "            [[ 8.0207e-02, -6.9696e-03, -2.6643e-01,  ..., -2.5784e-02,\n",
       "               2.9343e-01, -1.4394e-02],\n",
       "             [ 7.5280e-01,  4.0011e-02, -6.5069e-02,  ...,  8.8561e-01,\n",
       "              -5.1950e-01,  1.6396e-01],\n",
       "             [ 1.4365e-01, -2.5928e-01, -1.1437e-01,  ..., -1.7281e-02,\n",
       "               7.2640e-02,  1.6000e-02],\n",
       "             ...,\n",
       "             [ 2.9043e-01, -2.3284e-01,  3.1093e-01,  ...,  8.2343e-02,\n",
       "               7.9434e-02, -2.0749e-01],\n",
       "             [ 6.4281e-01,  2.2744e-01,  3.1879e-01,  ...,  7.3648e-01,\n",
       "              -3.9788e-01, -1.0599e-01],\n",
       "             [ 3.0557e-01, -2.6229e-01,  3.0262e-01,  ...,  1.0792e-01,\n",
       "               5.6345e-02, -2.1503e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.9911e-01,  1.4074e-01, -7.1719e-02,  ..., -1.5074e-01,\n",
       "               3.8447e-02, -3.9748e-01],\n",
       "             [ 9.7150e-02, -4.8043e-01, -1.1247e-01,  ...,  1.7712e-01,\n",
       "               1.8198e-01,  5.7814e-01],\n",
       "             [ 1.6426e-01,  7.7734e-02,  1.6053e-01,  ..., -2.7912e-01,\n",
       "               6.3470e-02, -3.0118e-01],\n",
       "             ...,\n",
       "             [ 1.9972e-01, -3.9443e-02, -8.0196e-02,  ..., -5.4356e-01,\n",
       "               7.7398e-02,  1.7048e-01],\n",
       "             [-1.6864e-02, -4.0871e-01, -2.1529e-02,  ..., -8.4738e-02,\n",
       "               2.1150e-01,  7.0404e-01],\n",
       "             [ 1.8359e-01, -5.5178e-02, -6.8768e-02,  ..., -5.4374e-01,\n",
       "               7.6699e-02,  1.9276e-01]],\n",
       "  \n",
       "            [[ 4.5376e-01, -9.5503e-02, -2.1041e-01,  ...,  3.5804e-01,\n",
       "              -1.3702e-01, -4.7131e-01],\n",
       "             [ 6.1372e-02, -2.5000e-01,  4.7806e-01,  ...,  1.5363e-01,\n",
       "              -3.8773e-01, -5.7048e-02],\n",
       "             [ 3.0118e-01, -6.9409e-02, -2.2144e-01,  ...,  2.6856e-01,\n",
       "              -1.4035e-01, -3.5713e-01],\n",
       "             ...,\n",
       "             [ 6.7400e-02, -2.8573e-01, -8.7119e-02,  ..., -9.8326e-02,\n",
       "              -9.4396e-02, -1.4109e-01],\n",
       "             [-7.3351e-02, -1.8733e-01,  4.8566e-01,  ...,  9.9767e-02,\n",
       "              -2.3151e-01,  2.6291e-01],\n",
       "             [ 8.1810e-02, -2.6022e-01, -5.2111e-02,  ..., -1.2480e-01,\n",
       "              -7.0141e-02, -1.4968e-01]],\n",
       "  \n",
       "            [[ 5.9382e-02, -3.5986e-01, -5.5193e-02,  ...,  2.0033e-01,\n",
       "              -1.6054e-01, -4.1664e-03],\n",
       "             [-2.6004e-01,  5.2948e-01,  3.0210e-01,  ...,  1.3766e-01,\n",
       "              -6.0209e-01, -2.2138e-01],\n",
       "             [-1.4559e-02, -7.8340e-02, -5.4997e-03,  ...,  5.8090e-02,\n",
       "              -3.5198e-01, -1.0430e-01],\n",
       "             ...,\n",
       "             [-3.6104e-02, -4.7305e-01,  1.0073e-02,  ...,  5.2401e-01,\n",
       "              -2.3104e+00,  1.7670e-01],\n",
       "             [-2.4976e-01,  5.3703e-02,  9.7487e-02,  ...,  4.0168e-01,\n",
       "              -2.7093e+00,  1.2379e-01],\n",
       "             [-3.3083e-02, -5.4230e-01,  3.8988e-03,  ...,  5.4442e-01,\n",
       "              -2.3365e+00,  2.0276e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 1.9054e-01, -1.0591e-01, -4.6353e-01,  ..., -9.0642e-01,\n",
       "               3.1063e-01,  5.7120e-01],\n",
       "             [-1.1171e-01, -3.0458e-01, -2.0842e-01,  ..., -5.6840e-01,\n",
       "              -1.2728e-01, -1.4252e-02],\n",
       "             [ 2.4394e-02, -1.2025e-01, -6.0032e-01,  ..., -2.2887e-01,\n",
       "              -8.0994e-02,  3.8038e-01],\n",
       "             ...,\n",
       "             [ 3.7199e-01, -1.4595e-01, -1.6711e+00,  ...,  6.6729e-01,\n",
       "              -1.8593e-01,  1.6283e-01],\n",
       "             [ 3.0604e-01, -3.8023e-01, -1.5408e+00,  ...,  6.8192e-01,\n",
       "               2.2499e-02,  9.7974e-02],\n",
       "             [ 3.7747e-01, -1.3802e-01, -1.7531e+00,  ...,  5.8435e-01,\n",
       "              -1.8760e-01,  1.3263e-01]],\n",
       "  \n",
       "            [[ 1.4559e-01, -1.5670e-01, -4.9808e-01,  ...,  2.3234e-01,\n",
       "              -5.5468e-01, -2.4019e-01],\n",
       "             [ 2.2048e-01, -1.8740e-01,  1.5918e-01,  ...,  3.0774e-01,\n",
       "              -1.0063e+00,  2.5774e-01],\n",
       "             [ 4.2587e-02, -1.8807e-01, -1.2804e-01,  ..., -4.9654e-02,\n",
       "               8.0500e-01, -2.3177e-01],\n",
       "             ...,\n",
       "             [ 5.5299e-02, -3.4687e-03,  9.7126e-02,  ..., -1.0889e-01,\n",
       "               1.6101e+00, -1.3396e-01],\n",
       "             [ 2.1951e-01,  1.0742e-01,  3.2421e-01,  ...,  2.6101e-01,\n",
       "               6.4505e-01,  9.2614e-02],\n",
       "             [ 4.8023e-02,  1.6621e-02,  1.0357e-01,  ..., -8.9844e-02,\n",
       "               1.5801e+00, -1.3042e-01]],\n",
       "  \n",
       "            [[-3.5510e-01, -1.4094e-01, -5.2819e-01,  ...,  4.5299e-01,\n",
       "              -6.5512e-01, -7.8750e-01],\n",
       "             [ 7.9614e-01, -1.6137e-02, -1.3484e+00,  ...,  1.0741e+00,\n",
       "               1.1378e+00, -6.0276e-01],\n",
       "             [ 2.4603e-02,  1.4563e-01, -2.1560e-01,  ..., -2.8729e-01,\n",
       "               2.2414e-01, -1.7944e-01],\n",
       "             ...,\n",
       "             [-7.0532e-01, -1.3299e+00,  7.0482e-02,  ..., -1.6577e+00,\n",
       "               1.0023e+00,  2.7428e+00],\n",
       "             [-2.6476e-01, -1.5248e+00, -8.9148e-01,  ..., -7.3778e-01,\n",
       "               1.8105e+00,  2.0857e+00],\n",
       "             [-8.7015e-01, -1.4125e+00,  5.2351e-02,  ..., -1.5908e+00,\n",
       "               9.7487e-01,  2.8582e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-6.4292e-01,  3.7202e-02, -2.9920e-01,  ...,  3.4284e-01,\n",
       "               2.2034e-01,  5.4896e-01],\n",
       "             [-2.6560e-01,  4.2992e-01, -2.9731e-01,  ...,  3.0372e-03,\n",
       "              -7.4193e-02,  4.2945e-01],\n",
       "             [-3.9789e-01, -9.7989e-02, -2.5294e-01,  ...,  4.2359e-01,\n",
       "               3.9511e-02,  2.8348e-01],\n",
       "             ...,\n",
       "             [ 1.4876e+00,  2.6357e-01,  8.4809e-01,  ..., -1.0977e+00,\n",
       "              -9.3810e-02, -1.5059e+00],\n",
       "             [ 1.6310e+00,  6.9003e-01,  9.0988e-01,  ..., -1.4293e+00,\n",
       "               1.4535e-02, -1.0727e+00],\n",
       "             [ 1.5956e+00,  3.1386e-01,  9.2419e-01,  ..., -1.1977e+00,\n",
       "              -7.1769e-02, -1.5956e+00]],\n",
       "  \n",
       "            [[ 4.7137e-01, -5.3984e-01, -3.4725e-01,  ..., -4.3685e-01,\n",
       "               8.5513e-01, -2.2945e-01],\n",
       "             [ 8.7712e-01, -1.9372e-02, -8.7122e-02,  ..., -1.5379e-01,\n",
       "              -7.8581e-02, -1.0645e+00],\n",
       "             [-4.9247e-01,  3.9556e-01,  1.6823e-01,  ..., -6.1454e-01,\n",
       "               2.9115e-01, -3.8398e-01],\n",
       "             ...,\n",
       "             [ 2.7144e-01,  1.8478e+00,  3.5846e-01,  ..., -3.3485e+00,\n",
       "               3.0667e-01,  8.5043e-01],\n",
       "             [ 1.0158e+00,  1.6955e+00,  5.2189e-01,  ..., -3.1719e+00,\n",
       "              -6.8707e-02,  4.8756e-01],\n",
       "             [ 3.8996e-01,  1.8734e+00,  3.2702e-01,  ..., -3.4005e+00,\n",
       "               3.0370e-01,  8.8831e-01]],\n",
       "  \n",
       "            [[ 2.6854e-01,  5.7007e-02,  2.7600e-01,  ...,  2.7626e-01,\n",
       "              -2.6608e-01,  8.5073e-02],\n",
       "             [ 1.3142e-01,  4.8065e-01, -1.3366e+00,  ...,  1.2941e+00,\n",
       "               7.9773e-01, -7.2365e-01],\n",
       "             [-4.3432e-01,  2.4347e-02, -1.3807e-01,  ...,  6.7102e-01,\n",
       "               4.0416e-01,  1.6151e-01],\n",
       "             ...,\n",
       "             [-4.5139e+00,  2.8216e-01, -1.2896e+00,  ...,  1.0030e+00,\n",
       "              -2.3359e-01,  2.3094e+00],\n",
       "             [-4.1916e+00,  4.3797e-01, -2.4180e+00,  ...,  8.3489e-01,\n",
       "              -1.9207e-01,  1.9308e+00],\n",
       "             [-4.6746e+00,  3.8080e-01, -1.2599e+00,  ...,  1.0072e+00,\n",
       "              -3.0726e-01,  2.6478e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-2.8984e-01, -9.5053e-01, -4.2101e-01,  ...,  2.6560e-01,\n",
       "              -4.4052e-02,  2.6516e-01],\n",
       "             [-1.4658e-01,  3.2608e-01, -6.0178e-01,  ...,  4.3249e-01,\n",
       "              -2.7029e-01, -6.7224e-02],\n",
       "             [-1.7531e-01, -1.1327e-01,  7.2336e-01,  ...,  4.1022e-02,\n",
       "              -9.7736e-02,  1.3922e-02],\n",
       "             ...,\n",
       "             [-1.4306e-01,  3.6944e-02,  2.5615e+00,  ..., -3.1224e-01,\n",
       "              -1.7184e-01, -3.8713e-01],\n",
       "             [-2.9149e-01,  1.1917e-01,  2.5551e+00,  ...,  4.2880e-02,\n",
       "              -1.7940e-01, -4.1340e-01],\n",
       "             [-1.2743e-01,  3.1615e-02,  2.5359e+00,  ..., -3.2899e-01,\n",
       "              -1.4861e-01, -4.1738e-01]],\n",
       "  \n",
       "            [[ 1.6713e-01,  2.3165e-01,  3.0481e-01,  ...,  1.8356e-01,\n",
       "              -1.8613e-01,  3.7517e-01],\n",
       "             [-4.1503e-02,  2.6801e-01, -9.8477e-03,  ...,  3.7615e-01,\n",
       "              -7.9453e-02,  1.3847e-01],\n",
       "             [-9.6029e-02, -6.3760e-02,  7.4975e-02,  ...,  1.1340e-01,\n",
       "              -2.1548e-02,  7.4171e-03],\n",
       "             ...,\n",
       "             [-2.3708e-02, -7.6344e-02, -2.0201e-01,  ...,  1.3697e-01,\n",
       "               4.9620e-02,  4.1098e-02],\n",
       "             [ 1.4721e-01,  2.4555e-01, -1.9471e-01,  ...,  3.7734e-01,\n",
       "               1.9247e-02,  9.8152e-02],\n",
       "             [-1.1669e-02, -8.5673e-02, -2.1044e-01,  ...,  1.3666e-01,\n",
       "               6.7921e-02,  4.0517e-02]],\n",
       "  \n",
       "            [[ 3.9783e-01, -2.7834e-01, -2.9279e-01,  ..., -2.1629e-01,\n",
       "              -4.5279e-01,  1.4681e-01],\n",
       "             [-6.7982e-01,  4.9688e-01,  4.3375e-01,  ..., -4.7558e-01,\n",
       "              -1.1380e-01,  6.4052e-01],\n",
       "             [ 3.2737e-01, -1.1600e+00, -2.9227e-02,  ..., -1.1916e-01,\n",
       "              -2.7516e-01,  1.2488e-02],\n",
       "             ...,\n",
       "             [ 2.4549e-01, -1.2891e+00, -5.1070e-02,  ...,  1.8678e-02,\n",
       "              -1.9584e-01, -3.1466e-01],\n",
       "             [-7.5442e-01,  5.1603e-01,  3.1397e-01,  ..., -5.4113e-01,\n",
       "               4.7700e-01, -4.0424e-01],\n",
       "             [ 2.4675e-01, -1.2790e+00, -6.7882e-02,  ...,  4.0275e-02,\n",
       "              -2.0008e-01, -2.8999e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-4.5116e-02,  1.7099e-01, -6.1685e-02,  ..., -7.5759e-02,\n",
       "               1.6197e-01, -6.9073e-02],\n",
       "             [ 1.5362e-01, -3.1335e-01, -1.8791e-01,  ...,  8.0334e-01,\n",
       "               2.9655e-01,  4.4419e-01],\n",
       "             [-2.9417e-02,  1.2834e-01, -7.8101e-02,  ..., -7.4429e-01,\n",
       "               2.5614e-03,  2.5955e-02],\n",
       "             ...,\n",
       "             [ 1.4462e-01, -3.7819e-02, -1.7253e-01,  ..., -2.3780e-01,\n",
       "               9.1400e-02,  1.2483e-01],\n",
       "             [ 8.9699e-02, -1.9563e-01, -1.7455e-01,  ...,  1.9868e-01,\n",
       "               7.7451e-02,  3.6947e-01],\n",
       "             [ 1.6891e-01, -5.0240e-02, -1.2973e-01,  ..., -2.1291e-01,\n",
       "               8.8717e-02,  1.2839e-01]],\n",
       "  \n",
       "            [[ 1.2768e-01,  7.3946e-02,  7.6204e-01,  ..., -1.0533e+00,\n",
       "               8.6982e-01, -3.7628e-01],\n",
       "             [-3.4573e-01, -6.5017e-01, -8.0730e-01,  ...,  3.5180e-01,\n",
       "               8.0292e-01,  3.6796e-01],\n",
       "             [ 1.0631e-01,  4.1224e-01,  8.8968e-01,  ..., -6.1037e-01,\n",
       "               6.9314e-01,  4.0451e-02],\n",
       "             ...,\n",
       "             [ 4.7435e-02,  1.4579e-01, -1.1626e-02,  ..., -6.3331e-01,\n",
       "               4.7573e-01,  1.0259e-02],\n",
       "             [-6.3796e-01, -3.6450e-01, -7.6878e-01,  ...,  3.8392e-01,\n",
       "               9.1132e-02,  5.9173e-01],\n",
       "             [ 5.5140e-02,  1.0602e-01, -7.1952e-02,  ..., -6.3976e-01,\n",
       "               4.5596e-01, -2.5325e-03]],\n",
       "  \n",
       "            [[-8.5043e-01, -2.4333e-01, -4.2240e-01,  ...,  2.6253e-01,\n",
       "              -1.2320e-01, -8.8310e-02],\n",
       "             [ 3.1755e-02,  3.1480e-01,  8.9462e-02,  ...,  1.5860e-01,\n",
       "               2.6110e-01, -9.5993e-01],\n",
       "             [-9.3306e-02,  7.9739e-03,  4.9194e-02,  ...,  1.3967e-01,\n",
       "               1.8511e-02, -6.3664e-02],\n",
       "             ...,\n",
       "             [ 2.5211e-01, -8.7274e-02,  2.3610e-01,  ...,  2.0613e-01,\n",
       "              -4.5992e-02, -5.6887e-02],\n",
       "             [-3.2330e-01,  3.4576e-01, -2.3071e-02,  ...,  2.5203e-01,\n",
       "               1.8238e-01, -2.1287e-01],\n",
       "             [ 2.5353e-01, -9.7441e-02,  2.4608e-01,  ...,  2.1098e-01,\n",
       "              -5.0427e-02, -5.1211e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 2.8918e-01,  1.2644e+00,  3.2592e-01,  ..., -8.0289e-02,\n",
       "              -1.6458e+00,  2.1959e+00],\n",
       "             [ 9.1457e-01, -5.9631e-01, -1.5752e+00,  ...,  5.4293e-02,\n",
       "              -3.7180e-01, -3.6848e-01],\n",
       "             [-8.5443e-02,  4.9928e-01,  1.9010e-03,  ..., -1.3677e-01,\n",
       "              -1.5002e-01,  3.7018e-01],\n",
       "             ...,\n",
       "             [ 1.2450e-01,  3.2955e+00, -1.6791e-01,  ..., -3.3784e+00,\n",
       "              -9.2105e-01, -2.1060e-01],\n",
       "             [ 1.6267e+00,  2.7565e+00, -1.0007e+00,  ..., -3.6766e+00,\n",
       "              -5.2225e-01, -1.2959e+00],\n",
       "             [ 1.0742e-01,  3.3835e+00, -1.5965e-01,  ..., -3.4897e+00,\n",
       "              -1.0027e+00, -2.1723e-01]],\n",
       "  \n",
       "            [[ 7.0905e-01, -1.6613e+00, -4.2812e-01,  ..., -1.6996e+00,\n",
       "               6.3429e-01,  7.1628e-02],\n",
       "             [ 1.4047e+00,  8.8538e-01, -9.8983e-02,  ..., -2.7486e-02,\n",
       "               1.8568e-01, -1.0226e+00],\n",
       "             [-1.1055e+00, -1.3358e+00,  4.9133e-01,  ...,  1.7235e-02,\n",
       "               3.8130e-01,  5.7154e-01],\n",
       "             ...,\n",
       "             [-6.1291e+00, -4.4223e+00,  1.8581e+00,  ...,  1.7797e+00,\n",
       "               3.2886e-01,  3.0593e+00],\n",
       "             [-4.1021e+00, -2.9515e+00,  1.8637e+00,  ...,  1.7410e+00,\n",
       "               3.9948e-01,  2.7388e+00],\n",
       "             [-6.1482e+00, -4.5917e+00,  1.8784e+00,  ...,  1.8406e+00,\n",
       "               3.2767e-01,  3.1094e+00]],\n",
       "  \n",
       "            [[-6.6846e-01,  1.7176e-01, -7.1971e-01,  ...,  3.0749e-01,\n",
       "              -5.1775e-01,  2.2710e+00],\n",
       "             [-7.2725e-01, -1.7903e+00, -2.5658e-01,  ...,  3.4214e-01,\n",
       "               5.3023e-01,  6.1467e-01],\n",
       "             [ 1.0476e+00, -5.9777e-02, -5.9343e-01,  ...,  4.2200e-01,\n",
       "               4.4247e-01, -2.2999e-01],\n",
       "             ...,\n",
       "             [ 2.9605e+00,  4.0557e+00,  7.3473e+00,  ...,  4.1034e+00,\n",
       "              -9.4784e-01, -1.9909e+00],\n",
       "             [ 1.8999e+00,  3.4891e+00,  8.1249e+00,  ...,  3.8013e+00,\n",
       "              -6.2681e-01, -1.5564e+00],\n",
       "             [ 2.9621e+00,  4.5328e+00,  7.4465e+00,  ...,  4.1889e+00,\n",
       "              -1.0214e+00, -2.1078e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.5119e+00, -3.5413e-01, -9.7055e-01,  ..., -2.7067e-01,\n",
       "               5.3213e-01,  8.0726e-02],\n",
       "             [-1.9718e-01,  4.4353e-01, -6.1901e-01,  ...,  2.2208e+00,\n",
       "              -9.6678e-01,  1.6465e-01],\n",
       "             [ 3.0909e-01, -9.3570e-01, -5.2592e-01,  ...,  9.2744e-02,\n",
       "               1.0825e+00,  8.7890e-01],\n",
       "             ...,\n",
       "             [ 6.6495e-02, -4.7285e-01, -4.4333e+00,  ..., -4.1169e+00,\n",
       "               4.5144e-01, -2.9160e+00],\n",
       "             [-8.5149e-01,  4.1586e-01, -4.3870e+00,  ..., -3.2010e+00,\n",
       "              -1.0747e+00, -3.2399e+00],\n",
       "             [ 9.1686e-02, -7.0371e-01, -4.4745e+00,  ..., -4.5097e+00,\n",
       "               3.0333e-01, -3.0811e+00]],\n",
       "  \n",
       "            [[ 1.2214e+00, -6.1433e-01,  7.3578e-01,  ...,  1.0523e+00,\n",
       "              -7.2978e-01,  8.5789e-02],\n",
       "             [ 1.6784e+00, -3.5812e-01,  5.7494e-01,  ...,  9.6930e-01,\n",
       "               4.6297e-01,  1.6093e+00],\n",
       "             [-3.6772e-01,  2.6426e-01,  5.1815e-01,  ...,  6.0338e-02,\n",
       "               5.1054e-01,  5.7864e-01],\n",
       "             ...,\n",
       "             [ 5.4237e-01,  2.1640e+00,  5.8478e-01,  ..., -8.5628e-01,\n",
       "               5.6154e+00, -6.1026e-01],\n",
       "             [ 2.1409e+00,  1.8291e+00,  1.6437e-01,  ..., -7.4168e-01,\n",
       "               5.6343e+00, -3.9523e-02],\n",
       "             [ 5.9729e-01,  2.2197e+00,  5.6205e-01,  ..., -8.7712e-01,\n",
       "               5.6763e+00, -7.4367e-01]],\n",
       "  \n",
       "            [[ 1.0824e+00, -8.8322e-01, -5.8215e-01,  ...,  9.8842e-02,\n",
       "              -7.9274e-01, -9.6895e-03],\n",
       "             [ 3.4742e-01, -9.5856e-01,  1.0344e-01,  ..., -5.1646e-01,\n",
       "              -3.1679e-01, -1.0867e+00],\n",
       "             [ 1.6602e+00, -5.5901e-01,  4.2316e-01,  ...,  3.5425e-02,\n",
       "               7.4290e-01, -7.3806e-01],\n",
       "             ...,\n",
       "             [ 8.7255e+00, -4.2076e+00,  9.5962e-01,  ..., -7.4126e-01,\n",
       "               4.1605e+00, -6.1550e-01],\n",
       "             [ 8.0094e+00, -4.2375e+00,  4.7914e-01,  ..., -1.0832e+00,\n",
       "               4.3223e+00, -1.0895e+00],\n",
       "             [ 8.9928e+00, -4.2666e+00,  7.4117e-01,  ..., -8.4989e-01,\n",
       "               4.5812e+00, -4.6102e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-6.6852e-02, -5.6592e-01,  4.2532e-01,  ..., -7.0091e-01,\n",
       "               3.8756e-01, -6.1264e-01],\n",
       "             [-1.9859e-01, -8.7832e-01, -1.9238e-01,  ...,  5.8986e-01,\n",
       "              -7.1951e-01,  1.2023e-01],\n",
       "             [-7.3895e-02,  1.5089e-01, -1.6994e-01,  ...,  2.5684e-01,\n",
       "               8.8383e-02, -4.5007e-01],\n",
       "             ...,\n",
       "             [-3.4077e-01, -9.1102e-02,  2.4719e-02,  ...,  3.1956e-01,\n",
       "              -1.8878e-01, -3.4889e-01],\n",
       "             [-7.8042e-01, -1.6842e-01,  2.9399e-01,  ...,  5.2441e-01,\n",
       "              -4.1002e-01,  2.9431e-01],\n",
       "             [-3.5606e-01, -8.4383e-02,  3.4986e-02,  ...,  3.3102e-01,\n",
       "              -1.8385e-01, -3.4531e-01]],\n",
       "  \n",
       "            [[ 8.2340e-01,  1.4297e-01,  2.9584e-01,  ..., -7.8567e-01,\n",
       "              -2.5546e-01, -2.4159e-01],\n",
       "             [ 1.5664e-01,  3.6113e-01, -4.1939e-01,  ..., -9.2128e-01,\n",
       "              -5.1178e-01, -5.5919e-02],\n",
       "             [ 3.5955e-01,  1.9441e-01, -1.8975e-01,  ..., -1.0018e-02,\n",
       "               3.9915e-02, -1.1263e-01],\n",
       "             ...,\n",
       "             [ 9.5230e-02,  6.3742e-02, -3.8110e-01,  ...,  1.6581e-01,\n",
       "              -2.9900e-02, -2.9628e-02],\n",
       "             [ 5.4784e-02,  1.9885e-01, -2.4651e-01,  ..., -6.0623e-01,\n",
       "              -2.0140e-01,  1.5841e-01],\n",
       "             [ 9.6416e-02,  4.8562e-02, -3.7818e-01,  ...,  1.5322e-01,\n",
       "              -2.9755e-02, -2.2827e-02]],\n",
       "  \n",
       "            [[-2.9850e-01, -7.9912e-02,  1.1419e-01,  ..., -5.4689e-01,\n",
       "               1.1660e-01,  3.3313e-01],\n",
       "             [ 5.9552e-01, -4.6070e-02, -7.1615e-01,  ...,  2.4028e-02,\n",
       "              -3.9326e-02, -2.5013e-01],\n",
       "             [-1.1187e-01,  6.3909e-03,  2.8814e-02,  ...,  5.0684e-02,\n",
       "               1.7826e-03,  1.5778e-02],\n",
       "             ...,\n",
       "             [-1.2377e-01, -1.0111e-01,  6.1354e-03,  ...,  1.1384e-01,\n",
       "               2.5782e-02, -6.1261e-02],\n",
       "             [ 6.5164e-03,  3.9157e-01, -5.8301e-01,  ..., -4.2655e-02,\n",
       "              -3.2794e-01, -2.4056e-01],\n",
       "             [-1.3216e-01, -1.1875e-01,  1.1836e-02,  ...,  1.0380e-01,\n",
       "               2.5231e-02, -6.9330e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.3784e-01,  2.3087e-01,  2.9162e-01,  ...,  4.1505e-01,\n",
       "              -4.9935e-01, -1.4532e-02],\n",
       "             [ 8.9929e-03, -4.3563e-01, -2.1139e-01,  ..., -1.4202e-01,\n",
       "               2.8848e-01,  6.4669e-02],\n",
       "             [-2.4237e-01,  5.2177e-01,  1.6602e-01,  ..., -5.7325e-03,\n",
       "              -6.3978e-01, -1.0185e-01],\n",
       "             ...,\n",
       "             [-2.0690e-02,  2.4675e-01,  1.8040e-01,  ..., -5.5178e-02,\n",
       "              -5.7811e-01,  2.8422e-02],\n",
       "             [-5.6921e-02, -2.6193e-01, -7.2066e-02,  ..., -2.2721e-01,\n",
       "               3.2617e-01, -1.0868e-01],\n",
       "             [-1.1236e-02,  2.3373e-01,  1.8179e-01,  ..., -7.4333e-02,\n",
       "              -5.5246e-01,  1.8711e-02]],\n",
       "  \n",
       "            [[-2.4285e-01,  5.7736e-01,  3.2711e-01,  ...,  2.5097e-01,\n",
       "              -3.5418e-01,  2.3419e-01],\n",
       "             [-6.3471e-02, -1.6851e-01, -8.1014e-01,  ..., -5.7526e-01,\n",
       "               1.9905e-01,  5.3377e-01],\n",
       "             [ 1.4993e-01,  2.3217e-01,  9.3562e-02,  ..., -1.9085e-01,\n",
       "               1.7783e-01, -4.2146e-03],\n",
       "             ...,\n",
       "             [-1.1577e-01,  3.2358e-01,  3.3604e-01,  ..., -1.0065e-01,\n",
       "               2.0470e-01, -8.4269e-02],\n",
       "             [-2.5959e-01, -1.2849e-01, -6.1569e-01,  ...,  3.7953e-01,\n",
       "               2.2843e-01,  6.9070e-01],\n",
       "             [-1.2440e-01,  3.3724e-01,  3.2618e-01,  ..., -8.2896e-02,\n",
       "               2.1031e-01, -8.6497e-02]],\n",
       "  \n",
       "            [[ 6.8262e-01,  5.9938e-02, -7.9621e-01,  ...,  8.9056e-02,\n",
       "               9.6512e-02,  3.0698e-01],\n",
       "             [ 4.0905e-01,  3.1792e-01, -2.6229e-01,  ..., -3.6171e-01,\n",
       "              -2.7358e-03,  1.5832e-01],\n",
       "             [ 4.5659e-01,  1.7325e-01, -6.3922e-01,  ...,  4.3049e-01,\n",
       "               6.2543e-01,  1.9892e-01],\n",
       "             ...,\n",
       "             [ 1.8475e-01,  1.4191e-01, -4.6684e-01,  ...,  2.4161e-01,\n",
       "               4.6827e-01,  3.2062e-01],\n",
       "             [ 4.0275e-01,  2.5731e-01,  2.6473e-01,  ...,  8.8358e-03,\n",
       "               1.0509e-01,  2.5707e-01],\n",
       "             [ 1.6854e-01,  1.4154e-01, -4.5306e-01,  ...,  2.3733e-01,\n",
       "               4.6155e-01,  3.3401e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-6.3325e-01,  3.9469e-01,  2.9316e-01,  ...,  6.4813e-02,\n",
       "              -9.1779e-01, -4.2052e-02],\n",
       "             [-4.5004e-02, -1.8257e+00,  1.7290e+00,  ...,  9.2967e-01,\n",
       "               1.7760e+00,  1.1929e+00],\n",
       "             [ 5.7945e-01, -2.4468e+00,  1.0202e+00,  ..., -4.1458e-01,\n",
       "               2.5667e-01,  6.5768e-01],\n",
       "             ...,\n",
       "             [ 5.7077e-01, -1.2703e+00,  1.2887e+00,  ...,  4.6652e-01,\n",
       "              -3.8547e+00,  8.7635e-01],\n",
       "             [-5.8669e-02, -9.1068e-01,  1.7302e+00,  ...,  1.4910e+00,\n",
       "              -3.3909e+00,  2.5928e-01],\n",
       "             [ 5.5127e-01, -1.1525e+00,  1.2543e+00,  ...,  5.1223e-01,\n",
       "              -4.0491e+00,  8.4678e-01]],\n",
       "  \n",
       "            [[-4.3842e-01, -5.9148e-01, -2.7844e-01,  ..., -2.2067e-01,\n",
       "              -4.7638e-01,  5.8577e-01],\n",
       "             [ 1.2357e+00, -7.4975e-01,  2.6301e-02,  ..., -5.0183e-01,\n",
       "               9.2459e-02, -6.7021e-01],\n",
       "             [-5.9259e-01,  1.4132e-02,  8.0689e-01,  ..., -7.2636e-02,\n",
       "              -2.7348e-01, -3.1937e-01],\n",
       "             ...,\n",
       "             [ 1.0297e+00,  6.8606e-01, -2.3024e-01,  ...,  5.9897e-01,\n",
       "               2.2278e-01,  2.2106e+00],\n",
       "             [ 2.6319e+00,  2.7007e-01, -5.6663e-01,  ...,  6.9342e-01,\n",
       "               2.1320e-01,  2.3100e+00],\n",
       "             [ 9.8669e-01,  6.4093e-01, -1.1399e-01,  ...,  6.5037e-01,\n",
       "               7.5651e-02,  2.3170e+00]],\n",
       "  \n",
       "            [[ 1.6223e-01,  5.1118e-01, -2.0861e-01,  ...,  9.5185e-01,\n",
       "              -3.0350e-01, -1.0133e-02],\n",
       "             [-5.3412e-01,  1.4999e+00, -9.6452e-01,  ...,  7.6231e-01,\n",
       "              -1.3834e-01, -2.8390e+00],\n",
       "             [ 1.0632e+00,  5.6889e-01, -9.1059e-01,  ..., -1.6277e+00,\n",
       "              -1.8745e+00,  7.3168e-02],\n",
       "             ...,\n",
       "             [-4.7926e+00,  2.8693e-01, -1.5259e+00,  ...,  7.9731e-02,\n",
       "              -4.7079e+00, -9.4559e-01],\n",
       "             [-5.5974e+00,  7.4334e-01, -1.5003e+00,  ...,  1.1226e+00,\n",
       "              -3.0924e+00, -3.3718e+00],\n",
       "             [-4.9517e+00,  2.0994e-01, -1.2985e+00,  ...,  1.7235e-01,\n",
       "              -4.7512e+00, -9.2952e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.9460e+00,  1.6198e+00, -2.2637e-01,  ...,  8.5561e-01,\n",
       "               1.5478e+00, -2.0620e+00],\n",
       "             [ 1.3899e-01,  1.6465e+00,  2.1241e+00,  ...,  2.0562e+00,\n",
       "               1.2509e+00, -8.2310e-01],\n",
       "             [-1.3150e+00,  4.2455e-01, -6.8421e-01,  ..., -4.7261e-01,\n",
       "               1.4553e-01, -9.8936e-01],\n",
       "             ...,\n",
       "             [-1.5762e+01,  1.1767e+01, -3.2362e+00,  ...,  2.4840e+00,\n",
       "               1.2166e+01, -8.4330e+00],\n",
       "             [-1.5866e+01,  1.2999e+01, -8.5682e-01,  ...,  5.1198e+00,\n",
       "               1.4119e+01, -9.2889e+00],\n",
       "             [-1.6218e+01,  1.1830e+01, -3.4768e+00,  ...,  2.2817e+00,\n",
       "               1.2677e+01, -8.6229e+00]],\n",
       "  \n",
       "            [[ 4.0023e-01, -4.7454e-01,  3.7902e-02,  ...,  3.6929e-01,\n",
       "               2.0590e-01, -2.5502e-01],\n",
       "             [ 1.7048e+00,  1.2144e-01,  8.7871e-01,  ..., -6.6316e-01,\n",
       "               5.0351e-01,  2.3513e+00],\n",
       "             [ 4.2953e-01,  2.3597e-01,  8.4505e-01,  ...,  5.1996e-01,\n",
       "              -3.1822e-01, -4.3976e-01],\n",
       "             ...,\n",
       "             [-1.2560e+00, -2.3782e+00, -1.1954e+00,  ..., -1.1961e+00,\n",
       "              -2.1249e+00, -2.2535e+00],\n",
       "             [-2.7344e-01, -2.2317e+00, -9.4684e-01,  ..., -1.3955e+00,\n",
       "              -1.7475e+00, -5.8950e-01],\n",
       "             [-1.4261e+00, -2.4795e+00, -1.1940e+00,  ..., -1.2528e+00,\n",
       "              -2.3218e+00, -2.2929e+00]],\n",
       "  \n",
       "            [[ 1.6767e-01, -6.3861e-02,  2.8639e-01,  ...,  9.1864e-02,\n",
       "              -3.9977e-01, -1.8771e-01],\n",
       "             [-1.9732e+00, -7.8003e-01,  6.9140e-01,  ..., -2.2954e+00,\n",
       "              -2.7288e-01, -9.5027e-01],\n",
       "             [ 3.1338e-02,  4.9833e-02,  3.7996e-01,  ..., -2.0243e-01,\n",
       "              -3.0730e-01, -3.8437e-01],\n",
       "             ...,\n",
       "             [-5.2304e-01,  9.8854e-01, -6.6637e-01,  ..., -7.2729e-01,\n",
       "               6.1644e-01,  8.7698e-01],\n",
       "             [-1.2670e+00,  8.9094e-01, -2.3781e-01,  ..., -1.9714e+00,\n",
       "               1.3418e+00,  4.7336e-01],\n",
       "             [-5.4655e-01,  1.0230e+00, -7.3006e-01,  ..., -7.4941e-01,\n",
       "               6.7928e-01,  9.2925e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-7.9187e-02, -3.1501e-02,  4.9325e-02,  ...,  1.0304e-01,\n",
       "              -9.0569e-02,  2.0801e-02],\n",
       "             [-7.3204e-01, -4.4449e-02,  2.3747e-01,  ..., -4.6206e-01,\n",
       "               5.8424e-01,  1.0133e+00],\n",
       "             [-7.6069e-02,  4.8222e-01,  3.1537e-03,  ...,  5.0171e-01,\n",
       "              -7.3100e-02, -2.9966e-01],\n",
       "             ...,\n",
       "             [ 2.2420e-01,  3.6184e-01,  5.1837e-02,  ...,  4.5890e-01,\n",
       "               2.0513e-01, -4.6064e-01],\n",
       "             [ 2.4331e-01,  6.1725e-01,  1.9288e-01,  ..., -3.0622e-03,\n",
       "               9.2698e-01,  2.3394e-01],\n",
       "             [ 2.3159e-01,  3.5013e-01,  4.3568e-02,  ...,  4.5835e-01,\n",
       "               2.0230e-01, -4.5020e-01]],\n",
       "  \n",
       "            [[ 1.8976e-02,  1.2167e-02, -7.1562e-02,  ...,  3.4018e-01,\n",
       "              -2.2299e-02, -1.6386e-01],\n",
       "             [-5.5225e-01, -4.4769e-01, -3.1093e-01,  ..., -1.4474e-01,\n",
       "              -4.7709e-01,  1.2398e+00],\n",
       "             [ 4.8762e-01,  5.1955e-01,  2.5512e-01,  ...,  6.6379e-01,\n",
       "              -7.6514e-01, -2.7496e-01],\n",
       "             ...,\n",
       "             [ 2.5473e-01,  3.4666e-01,  1.3168e-01,  ...,  1.4664e-01,\n",
       "              -3.8548e-01, -4.6793e-01],\n",
       "             [-6.2654e-01, -1.7804e-01,  2.0550e-01,  ..., -3.5974e-02,\n",
       "               5.2182e-01,  4.5127e-01],\n",
       "             [ 2.5811e-01,  3.3385e-01,  1.2555e-01,  ...,  1.4417e-01,\n",
       "              -3.1794e-01, -4.6807e-01]],\n",
       "  \n",
       "            [[ 4.6790e-02, -1.3087e-01,  4.9169e-02,  ..., -3.1279e-02,\n",
       "              -1.6421e-01,  1.5845e-01],\n",
       "             [ 1.7891e-01,  2.9642e-02, -1.0641e+00,  ..., -4.1416e-01,\n",
       "               3.8544e-01, -7.6640e-01],\n",
       "             [ 8.1145e-02,  9.4949e-02,  7.5022e-01,  ..., -1.5809e-01,\n",
       "               8.5609e-02,  5.2451e-01],\n",
       "             ...,\n",
       "             [ 8.9220e-03,  6.5013e-02,  5.3820e-01,  ..., -5.9273e-02,\n",
       "               1.7857e-01,  1.6612e-01],\n",
       "             [ 1.7468e-01,  1.7579e-01, -6.5151e-01,  ..., -2.4798e-01,\n",
       "               2.5008e-01, -6.1831e-01],\n",
       "             [ 5.7972e-03,  4.6068e-02,  5.5280e-01,  ..., -8.8765e-02,\n",
       "               1.8200e-01,  1.8204e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.0552e-01, -3.1239e-02, -2.2913e-02,  ...,  9.4098e-03,\n",
       "               3.1498e-02,  2.6320e-01],\n",
       "             [ 8.1381e-02, -4.2269e-01,  5.0452e-01,  ..., -4.2982e-02,\n",
       "               2.9911e-01,  5.1423e-01],\n",
       "             [ 3.7543e-02, -6.1714e-01, -2.3438e-01,  ...,  2.3281e-01,\n",
       "              -4.8434e-03,  9.7607e-02],\n",
       "             ...,\n",
       "             [-2.1548e-01, -3.6638e-01,  9.0460e-02,  ...,  3.9202e-01,\n",
       "               1.8590e-02,  1.8929e-01],\n",
       "             [-2.3925e-01, -3.3439e-01,  4.0127e-01,  ..., -2.1146e-01,\n",
       "               1.0109e-01,  3.9606e-01],\n",
       "             [-2.1557e-01, -3.4411e-01,  9.0680e-02,  ...,  3.9539e-01,\n",
       "               2.8538e-02,  1.6579e-01]],\n",
       "  \n",
       "            [[ 1.7947e-01, -3.5917e-03, -1.7183e-01,  ...,  4.9090e-02,\n",
       "               2.9142e-02,  3.9662e-02],\n",
       "             [ 5.3916e-01, -1.2580e+00, -5.2479e-02,  ...,  1.9864e-01,\n",
       "               6.5587e-02,  6.7887e-01],\n",
       "             [ 5.7233e-02,  3.9852e-01, -1.0671e-01,  ...,  5.6947e-02,\n",
       "              -9.3032e-03, -4.4979e-01],\n",
       "             ...,\n",
       "             [ 3.6108e-02,  4.5078e-01,  1.0899e-01,  ..., -1.2599e-01,\n",
       "               1.8311e-01, -4.7433e-01],\n",
       "             [ 7.3815e-01, -5.6228e-01,  1.5581e-01,  ...,  2.6655e-01,\n",
       "               4.7017e-01,  1.4620e-01],\n",
       "             [ 4.3145e-02,  4.5767e-01,  1.1392e-01,  ..., -1.2423e-01,\n",
       "               2.0611e-01, -4.9023e-01]],\n",
       "  \n",
       "            [[ 2.1530e-01,  1.5696e-01, -9.2665e-02,  ...,  2.6955e-01,\n",
       "              -8.6116e-02,  2.6278e-02],\n",
       "             [ 2.9228e-01,  4.1495e-01,  1.5488e+00,  ...,  4.1444e-01,\n",
       "              -2.3215e-01,  6.1795e-02],\n",
       "             [ 1.4042e+00, -2.7485e-01, -2.1201e-01,  ...,  1.1163e-02,\n",
       "               1.8750e-01, -1.1495e-02],\n",
       "             ...,\n",
       "             [ 2.9736e-01, -8.4980e-01,  3.9279e-01,  ..., -4.5134e-01,\n",
       "              -1.9227e-01, -4.2966e-01],\n",
       "             [-4.6369e-01, -1.2587e+00,  1.9488e+00,  ..., -2.1268e-01,\n",
       "              -3.7608e-01,  1.9360e-01],\n",
       "             [ 2.3984e-01, -8.9690e-01,  4.0535e-01,  ..., -4.4959e-01,\n",
       "              -2.0263e-01, -4.3026e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-1.2052e-01,  3.1460e-01, -1.2498e-01,  ..., -5.7691e-01,\n",
       "              -1.0106e-01,  5.1160e-01],\n",
       "             [ 8.8265e-01,  4.4766e-01,  3.4790e-02,  ..., -2.4390e-01,\n",
       "              -2.1853e+00, -2.0706e+00],\n",
       "             [-2.3373e-01,  4.9361e-02, -9.1293e-02,  ..., -1.1603e+00,\n",
       "              -1.3555e-01,  1.3860e-01],\n",
       "             ...,\n",
       "             [ 8.0619e-01,  2.9996e-01,  3.9072e-01,  ..., -2.3891e-01,\n",
       "              -1.0860e+00,  3.4973e+00],\n",
       "             [ 1.8534e+00,  2.5182e-01,  6.7582e-01,  ...,  1.1078e-01,\n",
       "              -2.3131e+00,  1.5638e+00],\n",
       "             [ 8.5917e-01,  2.9573e-01,  4.0553e-01,  ..., -2.3097e-01,\n",
       "              -1.0892e+00,  3.5896e+00]],\n",
       "  \n",
       "            [[-8.9517e-02,  4.9057e-01,  1.4619e-01,  ...,  3.7974e-01,\n",
       "              -2.5649e-02, -2.7030e-02],\n",
       "             [ 1.0619e+00, -7.4962e-01, -2.7398e-01,  ..., -1.1415e+00,\n",
       "              -4.3345e-02, -1.0186e+00],\n",
       "             [ 7.8154e-01,  1.1212e-01, -1.9386e-01,  ..., -4.0771e-03,\n",
       "               1.0709e+00, -5.0827e-01],\n",
       "             ...,\n",
       "             [-1.1508e+00,  6.3215e+00,  1.3684e+00,  ...,  4.3259e+00,\n",
       "               7.8122e-01, -2.0161e+00],\n",
       "             [-8.8067e-01,  6.4905e+00,  1.1133e+00,  ...,  4.0546e+00,\n",
       "               6.1298e-01, -2.8505e+00],\n",
       "             [-9.1681e-01,  6.6029e+00,  1.2692e+00,  ...,  4.5555e+00,\n",
       "               7.2940e-01, -2.0970e+00]],\n",
       "  \n",
       "            [[-3.3719e-02,  1.2957e-01, -5.7693e-01,  ...,  1.2116e-01,\n",
       "              -2.3101e-02,  8.2890e-01],\n",
       "             [-2.5057e-01,  1.2633e+00,  1.0270e+00,  ...,  5.1710e-01,\n",
       "              -1.2780e+00, -7.3460e-01],\n",
       "             [-8.3250e-01, -1.0980e-01,  1.1351e+00,  ...,  6.6763e-01,\n",
       "              -1.2242e+00, -3.3540e-01],\n",
       "             ...,\n",
       "             [ 4.2551e-01, -1.4327e+00,  1.1612e+00,  ..., -2.3588e+00,\n",
       "              -1.0415e+00,  7.6158e+00],\n",
       "             [ 1.4797e+00, -8.2905e-02,  1.1546e+00,  ..., -2.7280e+00,\n",
       "              -1.4252e+00,  8.0833e+00],\n",
       "             [ 6.5094e-01, -1.4681e+00,  1.1309e+00,  ..., -2.5426e+00,\n",
       "              -9.6533e-01,  7.6542e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-2.1414e-01,  4.7462e-02, -1.5474e-01,  ..., -8.3162e-02,\n",
       "              -1.1102e+00,  1.9495e-01],\n",
       "             [ 4.5022e-01, -2.3045e+00,  2.3217e+00,  ..., -3.9795e-01,\n",
       "               1.3822e+00,  1.4771e-01],\n",
       "             [ 5.5677e-01, -1.2439e+00,  1.7905e+00,  ..., -3.9029e-02,\n",
       "               1.0830e+00, -1.2510e+00],\n",
       "             ...,\n",
       "             [ 1.3848e+00, -3.9311e+00,  9.7458e-01,  ..., -4.3478e-01,\n",
       "              -4.0477e+00, -1.6007e-01],\n",
       "             [ 1.2519e+00, -4.1817e+00,  2.3294e+00,  ..., -6.6730e-01,\n",
       "              -3.9034e+00,  6.9753e-01],\n",
       "             [ 1.4027e+00, -4.0292e+00,  8.6477e-01,  ..., -4.2729e-01,\n",
       "              -4.1051e+00, -1.1145e-01]],\n",
       "  \n",
       "            [[ 2.4719e-01, -7.1770e-03,  1.7221e-02,  ..., -2.0889e-01,\n",
       "               1.0311e-02, -1.1938e-01],\n",
       "             [ 2.6888e+00,  4.0968e-01,  4.9493e-01,  ...,  5.7549e-01,\n",
       "               1.4951e+00,  2.6204e-01],\n",
       "             [ 7.0993e-01, -8.1806e-01,  8.7712e-01,  ...,  2.9560e-01,\n",
       "               7.3689e-01, -5.6554e-01],\n",
       "             ...,\n",
       "             [ 1.7369e+00, -1.6013e+00,  1.2524e+00,  ..., -7.3715e-02,\n",
       "               7.1026e-01, -1.0380e+00],\n",
       "             [ 2.7488e+00, -1.1873e+00,  1.3597e+00,  ..., -3.1033e-01,\n",
       "               2.1820e+00, -3.4525e-01],\n",
       "             [ 1.7638e+00, -1.6432e+00,  1.2377e+00,  ..., -1.4097e-01,\n",
       "               7.4573e-01, -1.0845e+00]],\n",
       "  \n",
       "            [[-8.3548e-01,  4.1693e-02, -2.6349e-01,  ...,  2.7683e-01,\n",
       "              -2.3358e-01, -4.7644e-01],\n",
       "             [ 1.1163e+00, -1.9889e+00,  4.0046e-02,  ..., -8.8493e-01,\n",
       "              -1.9877e+00,  1.6819e+00],\n",
       "             [ 4.9914e-01, -3.2179e-02, -2.8286e-01,  ..., -9.6201e-01,\n",
       "              -9.1476e-02, -4.0798e-01],\n",
       "             ...,\n",
       "             [-3.2654e+00, -1.3647e+00, -1.0656e+00,  ..., -1.4477e-01,\n",
       "               1.4681e+00,  5.2390e-01],\n",
       "             [-2.3891e+00, -2.5547e+00, -6.8467e-01,  ..., -6.8380e-01,\n",
       "              -3.6610e-01,  8.2402e-01],\n",
       "             [-3.4756e+00, -1.3652e+00, -1.1184e+00,  ..., -8.8397e-02,\n",
       "               1.6425e+00,  5.7475e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.0710e-01, -3.8192e-02, -5.6153e-02,  ...,  7.6919e-02,\n",
       "              -2.3796e-02,  1.4593e-02],\n",
       "             [ 2.3329e-01,  1.0652e-01,  8.2068e-01,  ...,  2.8625e-01,\n",
       "               7.3824e-01,  5.1752e-01],\n",
       "             [ 4.6713e-01,  9.5628e-02,  1.8415e-01,  ...,  4.3346e-01,\n",
       "               1.5455e-01, -1.9398e-01],\n",
       "             ...,\n",
       "             [ 1.4668e+00,  2.4883e-01,  7.0544e-01,  ...,  1.0487e-01,\n",
       "              -2.1463e-01, -6.4136e-01],\n",
       "             [ 1.7038e+00,  4.3160e-01,  6.9455e-01,  ...,  7.3743e-02,\n",
       "              -8.7207e-02, -2.9821e-01],\n",
       "             [ 1.4859e+00,  2.4740e-01,  7.3056e-01,  ...,  1.0831e-01,\n",
       "              -2.1551e-01, -6.3957e-01]],\n",
       "  \n",
       "            [[-8.0627e-02, -4.6858e-02,  1.3376e-03,  ..., -2.3709e-03,\n",
       "              -2.2702e-04, -5.5303e-02],\n",
       "             [-1.3234e+00, -5.9427e-01, -5.8242e-01,  ...,  5.1768e-01,\n",
       "              -3.0003e-01,  2.1547e-01],\n",
       "             [-3.8883e-01,  1.3008e-01,  4.3000e-01,  ...,  2.3015e-01,\n",
       "               4.6659e-01, -3.7167e-01],\n",
       "             ...,\n",
       "             [ 3.2133e-02,  4.7576e-01,  5.4518e-01,  ...,  1.9310e-01,\n",
       "               6.1286e-02,  3.8637e-01],\n",
       "             [-6.2409e-01, -3.2735e-01, -2.3400e-01,  ...,  7.0215e-01,\n",
       "               5.8598e-03,  5.2216e-01],\n",
       "             [ 5.6396e-02,  4.5940e-01,  5.5989e-01,  ...,  2.0900e-01,\n",
       "               5.2629e-02,  3.7191e-01]],\n",
       "  \n",
       "            [[ 4.4798e-02, -1.3215e-01,  8.4773e-02,  ..., -1.5579e-01,\n",
       "               5.5140e-02,  1.4401e-01],\n",
       "             [-9.7926e-02,  8.6342e-01, -3.8702e-01,  ...,  1.8498e-01,\n",
       "               1.6992e-01, -5.4536e-02],\n",
       "             [-2.1782e-01, -1.8004e-01,  2.6145e-01,  ..., -4.0524e-01,\n",
       "              -4.4305e-01,  8.6285e-01],\n",
       "             ...,\n",
       "             [-2.4447e-02, -2.0777e-01,  4.9620e-02,  ..., -3.0636e-01,\n",
       "              -2.5961e-01,  5.1677e-01],\n",
       "             [ 3.2635e-02,  4.6856e-01, -1.9789e-01,  ...,  4.4220e-01,\n",
       "               1.8311e-01,  1.6280e-02],\n",
       "             [-4.9732e-02, -1.9359e-01,  3.8774e-02,  ..., -2.9885e-01,\n",
       "              -2.4444e-01,  5.0236e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.0042e-02, -1.0485e-02,  1.6918e-01,  ..., -7.4782e-02,\n",
       "              -7.1054e-02, -5.4051e-02],\n",
       "             [-2.7242e-01,  6.4058e-02,  1.0032e+00,  ..., -2.6584e-02,\n",
       "              -2.5675e-01,  4.9826e-01],\n",
       "             [-1.8478e-02,  2.5151e-01, -6.4204e-01,  ..., -3.9094e-01,\n",
       "               7.0915e-01,  3.8277e-01],\n",
       "             ...,\n",
       "             [-4.5560e-01, -2.1959e-01,  5.4481e-02,  ..., -6.3666e-01,\n",
       "              -5.4701e-01, -7.2765e-01],\n",
       "             [-6.8903e-01,  5.7498e-02,  2.0126e-01,  ..., -5.4965e-01,\n",
       "              -6.2776e-01, -6.8481e-01],\n",
       "             [-4.6340e-01, -2.1821e-01,  4.2120e-02,  ..., -6.3281e-01,\n",
       "              -5.6399e-01, -7.1893e-01]],\n",
       "  \n",
       "            [[ 3.1571e-02, -2.4925e-02,  1.2156e-01,  ..., -9.6619e-02,\n",
       "              -1.8544e-01, -9.2648e-02],\n",
       "             [ 4.5478e-01, -1.1751e-01, -3.2476e-01,  ..., -1.6675e-01,\n",
       "              -4.4801e-01, -9.4666e-01],\n",
       "             [ 6.9083e-01, -2.0501e-01,  8.8175e-01,  ...,  5.0497e-01,\n",
       "              -1.7642e-01, -3.1971e-01],\n",
       "             ...,\n",
       "             [-3.1124e-01, -2.5737e-01,  1.0384e-01,  ...,  5.7330e-01,\n",
       "              -7.7170e-02,  1.1473e-01],\n",
       "             [-3.1404e-01, -4.7380e-01, -3.4186e-02,  ...,  2.3507e-01,\n",
       "              -1.0089e+00,  1.4769e-01],\n",
       "             [-3.0170e-01, -2.7659e-01,  8.7204e-02,  ...,  5.7619e-01,\n",
       "              -4.2394e-02,  1.6308e-01]],\n",
       "  \n",
       "            [[-2.0394e-01,  4.8224e-03, -1.5186e-01,  ...,  1.0724e-02,\n",
       "              -2.8669e-02, -2.4235e-02],\n",
       "             [ 3.7194e-01, -3.2409e-01,  1.2554e-01,  ...,  1.2304e-01,\n",
       "               5.2175e-01,  7.7896e-03],\n",
       "             [ 1.6817e-01, -3.2303e-01, -8.3657e-01,  ...,  3.4013e-01,\n",
       "              -5.8837e-01,  7.5414e-01],\n",
       "             ...,\n",
       "             [ 3.2087e-01, -2.2216e-01, -5.2580e-01,  ..., -2.4853e-01,\n",
       "              -4.3614e-02,  4.2875e-01],\n",
       "             [ 9.1567e-01, -6.4019e-01, -9.8221e-02,  ...,  2.6370e-02,\n",
       "               3.2114e-01, -8.2904e-02],\n",
       "             [ 3.1945e-01, -2.0866e-01, -5.1928e-01,  ..., -2.5009e-01,\n",
       "              -3.9465e-02,  4.0865e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 0.1522, -0.1238,  0.0806,  ...,  0.0079,  0.1238,  0.1840],\n",
       "             [-0.4660, -1.2609, -0.1456,  ...,  1.9608, -0.7999,  0.7594],\n",
       "             [-0.5371, -2.2926, -0.3693,  ..., -0.1720, -0.1752,  1.0457],\n",
       "             ...,\n",
       "             [-1.4090, -2.2825, -0.7236,  ...,  1.3987, -0.7897,  0.5247],\n",
       "             [-1.3876, -2.0831, -0.0911,  ...,  2.9715, -1.4077, -1.0845],\n",
       "             [-1.3838, -2.2687, -0.6756,  ...,  1.4140, -0.7528,  0.4453]],\n",
       "  \n",
       "            [[ 0.1666, -0.3944, -0.1043,  ...,  1.1979, -0.4242,  0.2155],\n",
       "             [ 0.4579, -1.2979,  0.1309,  ...,  1.7841,  0.7092, -0.4384],\n",
       "             [-0.7685,  0.1752, -1.3169,  ...,  3.5756, -0.7979,  2.9075],\n",
       "             ...,\n",
       "             [-0.4242, -0.9696,  0.0135,  ...,  1.7306,  0.3568,  0.5882],\n",
       "             [-0.2232, -1.3041, -0.9986,  ...,  0.6639,  1.0196, -0.1685],\n",
       "             [-0.4844, -0.9683,  0.0211,  ...,  1.6929,  0.3137,  0.6046]],\n",
       "  \n",
       "            [[ 0.2471, -0.2090,  0.0849,  ..., -0.0971, -0.2162, -0.0145],\n",
       "             [-2.1001, -0.3690,  2.2352,  ..., -0.5417, -1.1098,  2.3830],\n",
       "             [-0.0043, -0.6452, -0.4240,  ...,  0.7181, -0.9739,  1.4241],\n",
       "             ...,\n",
       "             [ 0.6807, -0.3870, -0.6354,  ...,  0.0532, -2.2537,  1.1704],\n",
       "             [-1.1359,  0.2690,  1.1584,  ...,  0.2841, -2.4995,  2.7685],\n",
       "             [ 0.6803, -0.3590, -0.6710,  ...,  0.0700, -2.2370,  1.1229]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-0.1001, -0.1053, -0.0964,  ...,  0.1972,  0.0656,  0.3014],\n",
       "             [-1.4928, -0.5012, -0.5930,  ...,  0.4150,  0.2703,  0.7185],\n",
       "             [-0.1107,  1.0035,  0.7458,  ...,  0.6817,  1.0631,  0.7142],\n",
       "             ...,\n",
       "             [-0.9490,  1.2392,  0.1111,  ...,  0.0168,  0.1435,  0.7578],\n",
       "             [-1.4154, -0.1837, -0.7714,  ...,  0.0888, -0.2381,  0.2331],\n",
       "             [-0.9152,  1.2111,  0.1225,  ..., -0.0385,  0.0925,  0.7444]],\n",
       "  \n",
       "            [[-0.1148,  0.5221,  0.2127,  ...,  0.2002, -0.1479,  0.3012],\n",
       "             [-2.0446, -3.5580, -2.9182,  ...,  0.2825,  1.2641, -1.4347],\n",
       "             [-1.5641, -2.9386, -3.0378,  ..., -0.1576, -0.0808, -0.8935],\n",
       "             ...,\n",
       "             [-0.7796, -0.8852,  3.4144,  ..., -0.8310, -0.4667, -2.1323],\n",
       "             [-0.7379, -1.6652,  3.6758,  ..., -0.9510, -0.0729, -3.1649],\n",
       "             [-0.7528, -0.5006,  3.4325,  ..., -0.8210, -0.5759, -2.1394]],\n",
       "  \n",
       "            [[ 0.1148, -0.4909, -0.0899,  ..., -0.3996,  0.1366, -0.4292],\n",
       "             [ 1.0752, -0.3143,  0.7523,  ...,  1.0655, -0.6817,  0.4163],\n",
       "             [-1.6916, -1.1988,  2.1872,  ...,  1.7348, -0.7664,  0.1665],\n",
       "             ...,\n",
       "             [ 0.0400, -3.0988,  2.4965,  ...,  0.6559, -1.1022, -3.4828],\n",
       "             [ 1.1552, -3.5060,  2.3746,  ...,  1.0693, -0.8055, -3.3478],\n",
       "             [-0.0836, -3.1210,  2.5807,  ...,  0.6501, -1.0899, -3.5258]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-0.0204,  0.0455, -0.1136,  ..., -0.0685, -0.0491, -0.0063],\n",
       "             [-1.5833, -0.1715,  0.8137,  ...,  1.5860, -0.4219,  0.2143],\n",
       "             [-0.0774,  1.2746,  0.3464,  ...,  0.2322, -0.3886, -0.5177],\n",
       "             ...,\n",
       "             [ 1.2403,  0.4966, -0.9015,  ...,  1.0825,  0.0485, -0.4068],\n",
       "             [-0.3811, -0.0931, -0.0660,  ...,  0.8470, -1.0236,  0.4968],\n",
       "             [ 1.2177,  0.4691, -0.8821,  ...,  1.0692,  0.0138, -0.3618]],\n",
       "  \n",
       "            [[ 0.1180,  0.1181,  0.1384,  ..., -0.0786,  0.0879, -0.0900],\n",
       "             [ 0.4230, -0.0881, -1.2667,  ...,  0.6964,  0.2801,  0.9957],\n",
       "             [-0.1096, -0.4304, -0.8970,  ...,  1.3079, -0.0702, -0.0203],\n",
       "             ...,\n",
       "             [ 1.0570,  0.3197,  0.2069,  ..., -3.3632,  0.2860, -0.2088],\n",
       "             [ 1.2921,  1.0605, -0.2923,  ..., -3.7712,  0.5944,  0.5460],\n",
       "             [ 1.0448,  0.3312,  0.2002,  ..., -3.4037,  0.2634, -0.1713]],\n",
       "  \n",
       "            [[ 0.1363,  0.0990,  0.2185,  ..., -0.0363,  0.0923,  0.1448],\n",
       "             [ 0.0458, -0.7376,  0.3980,  ...,  0.3582,  0.1635, -0.3253],\n",
       "             [-0.0984, -0.0613, -0.0065,  ...,  0.3470, -0.0763,  0.3218],\n",
       "             ...,\n",
       "             [-0.2028,  0.2188,  0.0738,  ..., -0.1002,  0.6261,  0.2141],\n",
       "             [-0.5296, -0.3441,  0.4984,  ...,  0.1910,  0.8891, -0.0182],\n",
       "             [-0.2107,  0.1922,  0.0421,  ..., -0.1268,  0.6032,  0.2125]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 0.0251,  0.0863,  0.1066,  ...,  0.0969,  0.0687, -0.0166],\n",
       "             [ 0.7474,  0.6776,  0.0560,  ...,  0.1618,  0.1376,  1.3513],\n",
       "             [ 0.0627,  1.1009,  0.7630,  ..., -0.1159,  0.5759,  0.0866],\n",
       "             ...,\n",
       "             [-0.2568, -0.0754, -0.1326,  ..., -0.9518,  0.5726, -0.1901],\n",
       "             [-0.3014, -0.4887, -1.5597,  ..., -0.4300,  0.0628,  1.3290],\n",
       "             [-0.2783, -0.0800, -0.1557,  ..., -0.9657,  0.5462, -0.1784]],\n",
       "  \n",
       "            [[-0.0421, -0.0243, -0.1207,  ...,  0.1521, -0.0094,  0.0965],\n",
       "             [-0.7639,  0.5166, -0.1799,  ..., -0.1223, -0.1309,  0.1492],\n",
       "             [ 1.2735, -0.3839, -0.8504,  ...,  1.0511, -0.5509,  0.5284],\n",
       "             ...,\n",
       "             [ 0.8194, -0.2286, -1.0354,  ...,  0.4890, -0.2652,  0.2940],\n",
       "             [-1.2244, -0.0647, -0.0435,  ...,  0.0621, -0.3496, -0.1790],\n",
       "             [ 0.7925, -0.2165, -1.0473,  ...,  0.4959, -0.3003,  0.2679]],\n",
       "  \n",
       "            [[-0.0684, -0.0282,  0.1385,  ..., -0.0458, -0.0772,  0.1848],\n",
       "             [-0.9698,  0.3077,  0.7843,  ...,  0.1362, -0.3643, -0.6377],\n",
       "             [ 0.8484, -1.9875, -0.3901,  ..., -0.5127,  0.7504,  0.3240],\n",
       "             ...,\n",
       "             [ 0.2670, -0.6692,  1.3751,  ..., -0.1892, -0.7515,  0.1590],\n",
       "             [-0.6329,  0.0805,  1.8714,  ...,  0.2167, -1.0237,  0.0263],\n",
       "             [ 0.2379, -0.6431,  1.3933,  ..., -0.1740, -0.7878,  0.1467]]]]],\n",
       "         grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 4.5990e-01, -1.6423e-01, -7.0473e-02,  ...,  1.2789e-02,\n",
       "               3.3595e-01, -3.0549e-01],\n",
       "             [ 1.2482e+00,  3.7890e-02, -1.9409e+00,  ..., -8.0578e-01,\n",
       "              -1.2600e-01,  6.0470e-01],\n",
       "             [ 8.8900e-01,  2.4907e-01, -4.4895e-01,  ..., -1.1019e+00,\n",
       "               8.3893e-01,  6.2958e-01],\n",
       "             ...,\n",
       "             [ 1.0981e+00,  1.6426e-01, -1.0801e+00,  ..., -1.6687e-01,\n",
       "               3.7372e-02, -2.3268e+00],\n",
       "             [ 8.1382e-01, -6.7716e-01, -1.4475e+00,  ...,  3.4822e-01,\n",
       "               4.2177e-01, -1.7670e+00],\n",
       "             [ 1.0660e+00,  9.8135e-02, -1.1025e+00,  ..., -2.1228e-01,\n",
       "              -5.9497e-03, -2.3879e+00]],\n",
       "  \n",
       "            [[ 1.1706e-01,  3.4325e-02,  3.3315e-01,  ...,  6.6974e-02,\n",
       "               3.6118e-01, -1.7523e-01],\n",
       "             [-5.3648e-02, -1.2139e+00, -6.2853e-01,  ...,  5.2832e-01,\n",
       "               1.6742e+00,  5.4137e-02],\n",
       "             [-4.6883e-01, -1.1231e-02, -1.2756e+00,  ...,  3.3899e-01,\n",
       "               1.0640e+00, -1.8882e-01],\n",
       "             ...,\n",
       "             [-5.1580e-01,  1.6949e+00, -5.7431e+00,  ...,  3.9008e-01,\n",
       "               5.9018e-01, -1.3713e+00],\n",
       "             [ 3.1070e-01,  6.7545e-01, -5.6964e+00,  ...,  5.7468e-01,\n",
       "               1.3603e+00, -9.8501e-01],\n",
       "             [-5.2418e-01,  1.6924e+00, -5.8958e+00,  ...,  4.2089e-01,\n",
       "               4.8843e-01, -1.3733e+00]],\n",
       "  \n",
       "            [[ 9.6266e-02,  5.3009e-01, -3.6293e-01,  ...,  3.0148e-02,\n",
       "               1.0204e-01,  2.1953e-01],\n",
       "             [ 1.0387e-02, -7.9064e-01, -8.9884e-01,  ..., -2.7221e-01,\n",
       "               1.5673e+00, -1.2077e+00],\n",
       "             [-1.1311e+00, -9.4840e-01, -5.1545e-02,  ...,  3.5841e-01,\n",
       "               1.2506e+00, -2.8423e+00],\n",
       "             ...,\n",
       "             [-7.4123e-02, -1.0736e+00, -1.7238e+00,  ..., -1.1126e+00,\n",
       "               3.7543e-01, -6.6150e-01],\n",
       "             [ 2.7488e-02, -1.5760e+00, -1.9093e+00,  ..., -1.0375e+00,\n",
       "              -8.9292e-02, -4.8788e-01],\n",
       "             [-7.4714e-02, -1.0654e+00, -1.6442e+00,  ..., -1.1032e+00,\n",
       "               3.8112e-01, -6.3468e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-3.4160e-02,  2.7792e-01,  1.9446e-01,  ...,  2.1648e-01,\n",
       "              -4.0505e-01,  2.1871e-01],\n",
       "             [-2.9885e+00, -1.8224e-01,  6.8868e-01,  ..., -3.1841e-01,\n",
       "              -1.9787e-01, -1.2035e-01],\n",
       "             [-1.0867e+00,  2.2213e+00,  4.0476e-02,  ...,  2.8628e-01,\n",
       "              -2.5353e+00,  1.4230e+00],\n",
       "             ...,\n",
       "             [ 6.9197e-01,  3.2871e+00,  3.2218e-01,  ...,  2.0622e+00,\n",
       "              -1.9082e+00,  7.6810e-01],\n",
       "             [-6.0836e-01,  1.9449e+00,  2.4467e+00,  ...,  1.4759e+00,\n",
       "              -8.3232e-01, -2.7693e-01],\n",
       "             [ 8.3263e-01,  3.2847e+00,  3.5998e-01,  ...,  2.1708e+00,\n",
       "              -1.8807e+00,  6.9558e-01]],\n",
       "  \n",
       "            [[-4.4253e-02, -5.1474e-03,  1.1470e-01,  ..., -6.7926e-02,\n",
       "               3.6750e-01,  2.0194e-01],\n",
       "             [ 7.7663e-01,  1.7269e+00, -1.8497e+00,  ..., -1.6134e+00,\n",
       "              -1.6338e+00, -4.3356e-01],\n",
       "             [ 1.3555e+00,  1.3743e+00,  1.1733e+00,  ..., -1.1017e+00,\n",
       "              -2.4731e-01,  1.7001e+00],\n",
       "             ...,\n",
       "             [-1.3996e+00,  2.8939e+00,  1.2424e+00,  ..., -3.8124e-01,\n",
       "              -3.6470e-02,  1.3434e+00],\n",
       "             [-3.0022e+00,  2.7067e+00, -7.0257e-02,  ..., -1.1823e+00,\n",
       "              -9.0575e-01, -1.5187e-01],\n",
       "             [-1.4168e+00,  2.8616e+00,  1.3390e+00,  ..., -3.8588e-01,\n",
       "              -3.8711e-02,  1.3494e+00]],\n",
       "  \n",
       "            [[ 4.9678e-02,  5.1285e-02,  8.7136e-02,  ..., -7.4805e-02,\n",
       "              -2.3733e-01, -1.7542e-01],\n",
       "             [ 3.6371e-02,  1.9350e-01, -1.0161e-02,  ..., -1.0966e+00,\n",
       "              -5.7417e-01, -1.7524e-01],\n",
       "             [-1.8043e+00, -4.1836e-01,  1.1041e+00,  ..., -2.9041e+00,\n",
       "              -2.7024e-01,  7.4560e-01],\n",
       "             ...,\n",
       "             [-2.0449e+00, -1.3430e+00, -1.3380e-01,  ..., -3.9875e+00,\n",
       "               6.8061e-01,  6.3249e-01],\n",
       "             [-1.1337e+00, -1.1366e+00,  5.2844e-01,  ..., -3.6932e+00,\n",
       "              -1.0545e+00, -1.4105e-01],\n",
       "             [-2.0809e+00, -1.3452e+00, -7.8858e-02,  ..., -3.9452e+00,\n",
       "               7.0290e-01,  6.1458e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-5.7782e-02, -4.7315e-02,  2.4928e-02,  ...,  5.5143e-02,\n",
       "               6.4048e-02,  4.7465e-02],\n",
       "             [-1.3786e-01,  6.7696e-01,  7.4004e-01,  ...,  9.2297e-01,\n",
       "               5.6387e-01, -8.7097e-02],\n",
       "             [ 3.1798e-01, -2.2610e-01, -6.8674e-01,  ...,  4.5118e-01,\n",
       "               6.5257e-01, -5.1282e-01],\n",
       "             ...,\n",
       "             [ 3.6494e-02, -4.3679e-01, -1.4050e-01,  ..., -2.1511e+00,\n",
       "              -5.5579e-01,  1.9740e-01],\n",
       "             [ 1.1142e-02,  3.8077e-01, -2.3947e-01,  ..., -7.8761e-01,\n",
       "               5.5888e-01, -1.3959e-01],\n",
       "             [ 5.5540e-02, -3.7554e-01, -2.0669e-01,  ..., -2.1263e+00,\n",
       "              -5.6430e-01,  1.8848e-01]],\n",
       "  \n",
       "            [[-6.3957e-02, -7.9304e-02,  1.5967e-02,  ...,  6.7480e-03,\n",
       "              -1.2040e-01, -2.2468e-01],\n",
       "             [ 2.3844e-02,  1.0196e+00,  1.2122e-01,  ...,  1.3954e+00,\n",
       "              -2.0906e+00, -6.7638e-01],\n",
       "             [ 6.9860e-01,  5.0115e-01,  6.4690e-01,  ...,  1.1850e+00,\n",
       "              -6.9568e-01,  1.3303e-01],\n",
       "             ...,\n",
       "             [ 1.5618e+00, -1.5785e-01,  6.5925e-01,  ...,  1.2683e+00,\n",
       "              -1.2242e+00, -6.0200e-01],\n",
       "             [ 2.9950e-01,  3.6721e-01,  3.3727e-01,  ...,  8.7919e-01,\n",
       "              -1.8889e+00, -1.1078e+00],\n",
       "             [ 1.4817e+00, -1.6266e-01,  6.1728e-01,  ...,  1.1992e+00,\n",
       "              -1.1882e+00, -6.3248e-01]],\n",
       "  \n",
       "            [[ 1.0753e-01, -4.3963e-02, -6.6306e-02,  ...,  4.0179e-01,\n",
       "              -9.0919e-02, -1.4785e-02],\n",
       "             [-2.7449e-01, -3.0073e-01,  3.2270e-01,  ..., -2.4372e+00,\n",
       "              -3.1224e-02, -7.9692e-01],\n",
       "             [-4.3965e-01, -1.3882e+00,  2.5976e-01,  ..., -2.1991e+00,\n",
       "              -1.6639e-01, -1.2122e+00],\n",
       "             ...,\n",
       "             [-9.1309e-01, -2.7926e+00, -2.6798e-01,  ..., -2.8105e+00,\n",
       "              -2.2858e+00,  4.1534e-01],\n",
       "             [-6.0546e-03, -2.2705e+00,  2.7309e-01,  ..., -2.5844e+00,\n",
       "              -1.4688e+00,  1.0231e+00],\n",
       "             [-9.3313e-01, -2.8158e+00, -2.6005e-01,  ..., -2.7976e+00,\n",
       "              -2.2347e+00,  4.3881e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 7.5646e-02,  3.5870e-03, -1.6026e-01,  ..., -3.9409e-02,\n",
       "              -1.7806e-01,  1.5072e-01],\n",
       "             [ 2.7148e-01, -7.3097e-01,  2.0453e-01,  ..., -7.3614e-01,\n",
       "              -1.3660e-01, -4.7905e-01],\n",
       "             [-5.6934e-02, -1.1385e-01,  2.4108e-01,  ...,  1.0072e-01,\n",
       "              -2.1553e-01,  1.0231e+00],\n",
       "             ...,\n",
       "             [-4.6304e-01, -5.3788e-02,  2.9625e-01,  ...,  1.2628e-02,\n",
       "              -4.7854e-01,  1.0911e+00],\n",
       "             [ 9.5285e-01, -2.9438e-01,  7.5982e-01,  ..., -1.7827e-01,\n",
       "              -8.8304e-02,  2.8551e-01],\n",
       "             [-4.4781e-01, -1.5304e-03,  2.7036e-01,  ...,  1.2610e-02,\n",
       "              -4.6309e-01,  1.0847e+00]],\n",
       "  \n",
       "            [[ 1.5349e-01, -8.3581e-03,  1.8578e-02,  ..., -1.0560e-01,\n",
       "               6.0635e-02,  2.1364e-02],\n",
       "             [-2.3644e+00, -3.4632e-02, -1.1961e+00,  ..., -1.2036e+00,\n",
       "               6.7561e-01, -5.9303e-01],\n",
       "             [-3.2115e-02, -4.0962e-01,  9.3737e-01,  ..., -1.0937e+00,\n",
       "              -6.3260e-01,  3.3339e-01],\n",
       "             ...,\n",
       "             [-1.1529e-01,  6.1468e-01,  2.5898e-01,  ..., -5.7044e-01,\n",
       "              -4.6099e-02,  9.0789e-01],\n",
       "             [-1.2440e+00,  8.6880e-01, -8.5127e-01,  ..., -6.7322e-01,\n",
       "               1.4799e+00, -9.1919e-01],\n",
       "             [-1.0191e-01,  6.2414e-01,  2.4962e-01,  ..., -5.3921e-01,\n",
       "              -3.5162e-02,  8.6342e-01]],\n",
       "  \n",
       "            [[ 2.7211e-02, -7.5024e-02, -5.6496e-02,  ..., -3.7664e-03,\n",
       "               1.7206e-02,  1.3883e-03],\n",
       "             [-2.2256e-01,  2.0972e+00,  6.6128e-01,  ..., -8.3051e-01,\n",
       "               5.4045e-01, -1.5901e-02],\n",
       "             [ 1.8208e-01, -3.1738e-01, -3.1187e-02,  ...,  1.2640e+00,\n",
       "               5.1007e-01, -8.3236e-01],\n",
       "             ...,\n",
       "             [-1.5674e-01, -1.0412e+00,  2.9375e-01,  ...,  1.7144e-01,\n",
       "               1.7886e-01, -8.4005e-01],\n",
       "             [-3.7356e-01,  6.1266e-01,  3.6698e-02,  ..., -4.7902e-01,\n",
       "              -1.5491e-01, -2.3358e-01],\n",
       "             [-1.5318e-01, -1.0205e+00,  2.9034e-01,  ...,  1.7920e-01,\n",
       "               1.9913e-01, -7.7656e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 1.3771e-01,  9.0157e-01, -3.5496e-01,  ..., -2.0243e-01,\n",
       "               9.8999e-02,  7.9731e-02],\n",
       "             [ 6.8603e-01, -8.9343e-01,  1.3114e+00,  ..., -1.1600e-01,\n",
       "               5.5447e-01, -8.8110e-01],\n",
       "             [ 7.1423e-01,  2.9217e-01,  1.4583e-02,  ..., -1.1546e+00,\n",
       "               2.3820e-01,  1.0250e+00],\n",
       "             ...,\n",
       "             [ 1.2194e+00,  7.9311e+00,  1.5823e+00,  ...,  5.1556e-01,\n",
       "               1.9357e+00,  2.5451e+00],\n",
       "             [ 1.1668e+00,  7.9978e+00,  2.5361e+00,  ...,  7.6883e-01,\n",
       "               1.9658e+00,  1.1794e+00],\n",
       "             [ 1.2941e+00,  8.0683e+00,  1.5205e+00,  ...,  5.8429e-01,\n",
       "               1.9638e+00,  2.4792e+00]],\n",
       "  \n",
       "            [[ 6.1901e-02,  8.8106e-01, -2.8147e-01,  ..., -2.6773e-01,\n",
       "              -1.8376e-01, -1.1549e-02],\n",
       "             [-8.8878e-01,  5.5974e-01, -3.4638e-01,  ...,  7.9472e-01,\n",
       "              -1.6082e-01,  8.5831e-01],\n",
       "             [ 1.8869e+00,  1.1415e-01, -1.9564e+00,  ..., -1.6116e+00,\n",
       "               7.9366e-01, -8.6390e-01],\n",
       "             ...,\n",
       "             [-1.4537e-01,  2.8966e+00, -4.6524e+00,  ..., -2.7780e+00,\n",
       "               8.6829e-01, -1.1170e+00],\n",
       "             [-2.0415e+00,  2.8823e+00, -2.8646e+00,  ..., -1.3703e+00,\n",
       "               9.7047e-01, -5.9055e-02],\n",
       "             [-2.5966e-01,  3.1442e+00, -4.6484e+00,  ..., -2.7134e+00,\n",
       "               8.0791e-01, -9.9943e-01]],\n",
       "  \n",
       "            [[ 2.1769e-01, -3.8806e-01,  1.8626e-01,  ...,  2.7785e-01,\n",
       "               3.8709e-01,  3.7514e-01],\n",
       "             [-3.6386e-01,  9.5170e-01, -8.2031e-01,  ..., -1.9245e+00,\n",
       "               7.9807e-01, -1.5011e+00],\n",
       "             [ 6.4954e-01, -4.5205e-01,  1.4459e+00,  ...,  5.1824e-01,\n",
       "               1.2267e-01, -3.4894e-01],\n",
       "             ...,\n",
       "             [-1.5725e+00,  1.9465e+00,  1.6578e+00,  ..., -9.3065e-01,\n",
       "               1.0014e+00, -1.8643e-01],\n",
       "             [-1.3059e+00,  2.3995e+00,  5.2118e-02,  ..., -1.3595e+00,\n",
       "               3.1534e+00, -5.7495e-01],\n",
       "             [-1.6305e+00,  2.0022e+00,  1.6790e+00,  ..., -1.0458e+00,\n",
       "               1.0953e+00, -1.9653e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 7.2850e-02, -9.8556e-02,  6.3139e-02,  ...,  9.9210e-02,\n",
       "               5.8900e-02, -1.7060e-01],\n",
       "             [ 5.8704e-01,  1.0792e+00,  7.3844e-01,  ...,  2.3723e+00,\n",
       "               5.5190e-01,  8.6259e-01],\n",
       "             [ 1.6026e+00,  8.4365e-01, -1.4142e+00,  ...,  1.1797e+00,\n",
       "              -5.2442e-01,  1.8882e-02],\n",
       "             ...,\n",
       "             [ 2.1647e+00,  3.9805e-01, -1.2591e+00,  ...,  3.8199e-01,\n",
       "              -2.1057e+00, -9.5578e-02],\n",
       "             [ 2.2274e+00,  1.2014e+00, -2.0953e-01,  ...,  8.7797e-01,\n",
       "              -2.2200e+00,  5.7655e-01],\n",
       "             [ 2.1243e+00,  4.3669e-01, -1.2126e+00,  ...,  3.5034e-01,\n",
       "              -2.1348e+00, -1.6700e-01]],\n",
       "  \n",
       "            [[ 1.3089e-01, -1.3481e-02,  9.4816e-02,  ...,  3.0806e-02,\n",
       "               5.2371e-03, -1.3107e+00],\n",
       "             [ 1.1604e-01,  5.0168e-01,  1.2727e+00,  ..., -1.1964e+00,\n",
       "              -2.5043e-01,  2.5933e+00],\n",
       "             [-1.1752e+00, -6.4684e-02, -4.6941e-01,  ..., -1.4915e+00,\n",
       "               6.2559e-01,  2.9623e+00],\n",
       "             ...,\n",
       "             [-1.1976e+00,  1.1133e+00,  8.7948e-01,  ..., -5.4465e-01,\n",
       "               9.8191e-01, -1.7758e+00],\n",
       "             [-1.0035e+00,  9.2925e-01,  1.8043e+00,  ..., -1.1288e+00,\n",
       "               4.4028e-01, -1.9522e+00],\n",
       "             [-1.2144e+00,  1.1093e+00,  9.0577e-01,  ..., -5.4871e-01,\n",
       "               1.0409e+00, -2.0743e+00]],\n",
       "  \n",
       "            [[-2.7150e-01, -3.4428e-01, -7.1111e-02,  ...,  5.7818e-01,\n",
       "               4.7107e-01, -2.5103e-01],\n",
       "             [-1.9029e-01,  2.2406e+00,  6.1711e-01,  ..., -7.3203e-01,\n",
       "               3.6917e-02, -1.0914e-01],\n",
       "             [-6.8767e-01, -1.1247e+00, -6.2679e-01,  ..., -8.4440e-01,\n",
       "              -7.2531e-01,  6.7224e-01],\n",
       "             ...,\n",
       "             [-2.2645e+00, -2.3166e-01,  5.8330e-01,  ..., -3.9381e-01,\n",
       "              -2.5768e+00,  1.0639e+00],\n",
       "             [-1.5708e+00,  1.0621e+00,  1.7766e-01,  ..., -6.1433e-02,\n",
       "              -1.9710e+00,  9.7734e-01],\n",
       "             [-2.2770e+00, -2.7306e-01,  5.7732e-01,  ..., -2.9944e-01,\n",
       "              -2.6747e+00,  1.0706e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.7769e-01, -1.9868e-02,  3.6486e-02,  ...,  9.6218e-03,\n",
       "               6.7924e-02,  3.1965e-03],\n",
       "             [ 4.3672e-02,  4.0235e-02,  4.7228e-01,  ...,  8.4840e-01,\n",
       "               1.6675e-01,  3.4818e-01],\n",
       "             [-5.6196e-01, -4.6746e-01,  5.8312e-01,  ...,  6.6042e-01,\n",
       "              -5.3383e-01,  3.6734e-01],\n",
       "             ...,\n",
       "             [ 2.9145e-01,  2.3742e-01,  6.9251e-01,  ..., -3.0051e-02,\n",
       "              -6.0954e-01,  4.8869e-02],\n",
       "             [ 2.4541e-01,  4.7130e-01,  4.6727e-01,  ...,  8.7736e-01,\n",
       "               4.5745e-01, -6.9198e-02],\n",
       "             [ 3.2747e-01,  2.8414e-01,  6.3209e-01,  ..., -2.3813e-03,\n",
       "              -5.5888e-01,  7.7983e-02]],\n",
       "  \n",
       "            [[-4.0079e-02,  4.7627e-02, -2.0990e-01,  ..., -1.3484e-01,\n",
       "               3.0816e-02,  6.4082e-02],\n",
       "             [ 4.6453e-01, -4.0604e-01,  8.2549e-01,  ...,  1.5971e-01,\n",
       "               9.2278e-02,  9.9117e-01],\n",
       "             [ 5.3281e-01,  7.3788e-01,  2.8048e-01,  ...,  3.3176e-01,\n",
       "              -1.3099e+00, -2.4246e-01],\n",
       "             ...,\n",
       "             [ 3.0422e-01, -2.4027e-01, -5.5547e-01,  ..., -8.0873e-01,\n",
       "              -2.7658e-01, -2.8836e-02],\n",
       "             [-6.6797e-01,  3.9216e-02,  9.4326e-01,  ..., -6.2509e-02,\n",
       "               3.0423e-01,  4.2278e-01],\n",
       "             [ 3.3224e-01, -2.2553e-01, -5.4199e-01,  ..., -8.0184e-01,\n",
       "              -2.6850e-01, -8.1512e-02]],\n",
       "  \n",
       "            [[ 7.2285e-02, -3.1630e-02, -1.6655e-01,  ..., -8.9160e-02,\n",
       "              -2.0111e-01, -6.5453e-02],\n",
       "             [ 7.7623e-01,  6.3914e-01, -2.2372e-01,  ..., -1.4663e-01,\n",
       "               2.6967e-01, -3.3026e-01],\n",
       "             [ 1.9590e-01,  4.8709e-01, -1.5344e-01,  ..., -5.6191e-01,\n",
       "               1.9368e-02,  5.6774e-02],\n",
       "             ...,\n",
       "             [ 2.8809e-01,  5.4727e-02, -1.7595e-01,  ..., -1.3927e-01,\n",
       "               1.0250e-01, -1.7690e-01],\n",
       "             [ 2.5719e-01,  3.9549e-01,  1.2690e-01,  ...,  7.1759e-01,\n",
       "               6.5449e-01, -7.9504e-01],\n",
       "             [ 2.5784e-01,  2.2483e-02, -1.6551e-01,  ..., -1.5103e-01,\n",
       "               1.4847e-01, -1.6177e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-4.5902e-02, -9.6472e-02, -1.7944e-02,  ...,  6.7100e-02,\n",
       "              -6.8915e-03, -4.4650e-02],\n",
       "             [ 5.2386e-01,  1.1234e-01,  7.9435e-01,  ...,  8.2008e-01,\n",
       "              -1.4411e-02, -6.8194e-01],\n",
       "             [-6.9178e-01, -2.1721e-01, -4.8476e-02,  ..., -1.6245e+00,\n",
       "               5.4425e-01, -1.1310e-01],\n",
       "             ...,\n",
       "             [-9.9717e-01, -6.3572e-01, -5.6292e-01,  ..., -6.4437e-03,\n",
       "               3.7575e-01, -4.7072e-01],\n",
       "             [-6.0714e-01,  7.0789e-02,  3.4317e-01,  ...,  4.4393e-01,\n",
       "               5.5097e-01, -2.8036e-01],\n",
       "             [-1.0006e+00, -5.9933e-01, -5.5422e-01,  ..., -1.7138e-02,\n",
       "               3.6980e-01, -4.7932e-01]],\n",
       "  \n",
       "            [[-9.2612e-02,  1.9121e-02,  4.8481e-02,  ..., -2.0642e-02,\n",
       "              -1.2847e-01,  3.2826e-02],\n",
       "             [-2.6852e-01,  4.9444e-01, -6.7064e-01,  ...,  9.5245e-02,\n",
       "               2.3633e-01, -1.0949e+00],\n",
       "             [ 1.6142e-01,  1.0994e+00, -9.6061e-01,  ...,  1.2240e+00,\n",
       "              -3.3590e-01, -7.3955e-01],\n",
       "             ...,\n",
       "             [ 7.2288e-02, -4.5554e-02, -8.1182e-02,  ..., -6.1590e-01,\n",
       "              -2.8048e-01, -1.2142e+00],\n",
       "             [-2.2214e-01, -1.5382e-01, -6.1776e-01,  ...,  7.5930e-02,\n",
       "              -2.6566e-01, -1.3068e+00],\n",
       "             [ 5.4183e-02, -8.2436e-02, -3.4182e-02,  ..., -5.7980e-01,\n",
       "              -2.7879e-01, -1.2075e+00]],\n",
       "  \n",
       "            [[ 1.3356e-02, -1.4301e-01, -3.2877e-02,  ...,  4.6615e-03,\n",
       "              -4.0957e-02,  1.0125e-02],\n",
       "             [ 4.9277e-01,  1.4792e+00, -1.0851e+00,  ...,  1.6033e+00,\n",
       "              -6.9564e-01, -2.0382e-01],\n",
       "             [-7.9968e-01,  3.1177e-01, -1.1993e+00,  ...,  2.4692e-01,\n",
       "               7.2428e-02,  1.2972e-01],\n",
       "             ...,\n",
       "             [-3.5555e-01, -5.3964e-01, -1.0287e+00,  ..., -2.0806e-01,\n",
       "              -3.9654e-02,  1.2974e+00],\n",
       "             [ 6.7501e-01,  4.1135e-02, -1.1275e+00,  ...,  1.0525e+00,\n",
       "              -2.5639e-01,  1.0310e+00],\n",
       "             [-3.9419e-01, -5.3765e-01, -9.6850e-01,  ..., -2.4740e-01,\n",
       "              -1.8159e-03,  1.2894e+00]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 6.8537e-01,  2.1427e-01, -4.5352e-02,  ..., -3.5849e-03,\n",
       "              -2.8943e-02, -6.6344e-02],\n",
       "             [-1.6954e+00, -2.2446e+00,  8.0909e-01,  ...,  1.0270e+00,\n",
       "              -1.7578e+00, -3.4627e-01],\n",
       "             [ 1.2369e+00,  1.0438e-01,  1.9135e+00,  ..., -8.9543e-01,\n",
       "               1.1045e+00, -2.0674e+00],\n",
       "             ...,\n",
       "             [ 2.2138e-01,  1.4968e+00,  1.6126e+00,  ..., -1.6487e+00,\n",
       "               1.9645e-01, -2.2584e+00],\n",
       "             [-1.7065e+00, -2.3399e-01,  1.5907e+00,  ..., -7.9670e-01,\n",
       "              -9.3064e-01, -1.2596e+00],\n",
       "             [ 2.9130e-01,  1.5144e+00,  1.5056e+00,  ..., -1.6140e+00,\n",
       "               1.7768e-01, -2.1949e+00]],\n",
       "  \n",
       "            [[ 2.1328e-01, -1.8435e-01, -1.6182e-01,  ...,  5.5558e-02,\n",
       "               2.4471e-02,  1.4388e-01],\n",
       "             [ 7.7110e-01,  7.4403e-02, -5.3017e-01,  ..., -3.8544e-01,\n",
       "               1.2777e+00,  4.4977e-01],\n",
       "             [ 7.8479e-01,  2.9403e-01, -1.8430e-01,  ...,  2.9821e-01,\n",
       "               4.1774e-01,  7.2198e-01],\n",
       "             ...,\n",
       "             [ 6.2793e-01,  1.3856e+00, -7.5469e-01,  ...,  8.9061e-01,\n",
       "              -8.9901e-01, -3.8924e-01],\n",
       "             [ 1.1514e+00,  4.7978e-01, -5.7582e-01,  ...,  7.4075e-01,\n",
       "              -1.2570e+00, -9.9033e-01],\n",
       "             [ 7.0615e-01,  1.3269e+00, -8.2562e-01,  ...,  9.2904e-01,\n",
       "              -9.7526e-01, -3.4804e-01]],\n",
       "  \n",
       "            [[-8.6636e-02,  1.2201e-01,  1.5518e-02,  ..., -4.4909e-02,\n",
       "              -1.5601e-01, -1.0241e-01],\n",
       "             [ 8.8407e-01, -1.3988e-01, -3.1171e-01,  ..., -5.3115e-01,\n",
       "               5.9184e-01,  3.0933e+00],\n",
       "             [ 1.3505e+00,  7.0934e-01,  1.1093e+00,  ...,  4.7968e-01,\n",
       "              -7.9301e-02, -1.3391e+00],\n",
       "             ...,\n",
       "             [ 7.1144e-01, -9.2167e-01,  1.3211e+00,  ...,  6.1275e-01,\n",
       "               5.7988e-01, -1.3222e+00],\n",
       "             [ 5.3658e-01, -1.5493e+00,  6.5235e-01,  ...,  1.0666e+00,\n",
       "               5.0489e-01,  1.1325e-01],\n",
       "             [ 7.3646e-01, -1.0215e+00,  1.1981e+00,  ...,  6.8063e-01,\n",
       "               6.5228e-01, -1.3886e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 2.6494e-02,  7.8296e-01,  1.8132e-01,  ...,  7.4352e-02,\n",
       "               4.1801e-02, -1.4314e-01],\n",
       "             [-1.1518e+00, -2.9566e+00,  1.5535e+00,  ...,  7.1298e-01,\n",
       "               1.2990e+00, -1.9996e+00],\n",
       "             [-1.3578e+00, -1.6476e+00, -1.8125e-01,  ...,  1.2472e+00,\n",
       "               6.5089e-01, -1.2741e+00],\n",
       "             ...,\n",
       "             [-1.8210e+00,  8.9778e-01, -1.4465e+00,  ...,  1.1802e-01,\n",
       "              -1.3118e+00, -1.8856e+00],\n",
       "             [-2.3797e+00,  6.0693e-01, -7.0705e-01,  ...,  4.1585e-01,\n",
       "              -2.2993e-01, -2.1793e+00],\n",
       "             [-1.7358e+00,  1.0732e+00, -1.4490e+00,  ...,  6.9380e-02,\n",
       "              -1.3049e+00, -1.8447e+00]],\n",
       "  \n",
       "            [[ 2.0060e-01,  7.5593e-02, -2.8681e-02,  ...,  4.2734e-01,\n",
       "              -2.1390e-02, -7.7349e-02],\n",
       "             [-2.6036e+00, -5.6494e-01,  3.4092e-01,  ..., -1.9044e+00,\n",
       "               6.0452e-01,  7.2233e-01],\n",
       "             [ 8.2164e-01, -7.3673e-01, -5.6234e-01,  ..., -2.9345e+00,\n",
       "               1.5968e-01, -1.6516e+00],\n",
       "             ...,\n",
       "             [-4.9517e-01, -2.2784e-01,  4.8798e-01,  ...,  1.6577e+00,\n",
       "              -9.3673e-01, -1.1740e+00],\n",
       "             [-2.2997e+00, -2.5739e-01,  1.4306e-01,  ...,  2.1128e+00,\n",
       "               4.8050e-01,  9.2496e-01],\n",
       "             [-5.1131e-01, -2.2419e-01,  4.5266e-01,  ...,  1.8985e+00,\n",
       "              -9.4349e-01, -1.1182e+00]],\n",
       "  \n",
       "            [[-2.2082e-01,  2.9831e-01,  3.0861e-02,  ..., -1.0502e-01,\n",
       "              -1.8531e-02,  2.1701e-01],\n",
       "             [ 2.3554e+00, -1.2918e+00, -1.3569e+00,  ...,  6.8881e-01,\n",
       "               1.6159e+00,  9.3151e-01],\n",
       "             [ 9.6836e-01,  9.8888e-01, -1.3195e+00,  ...,  3.7121e-01,\n",
       "              -1.1329e+00, -3.6213e-01],\n",
       "             ...,\n",
       "             [ 7.5807e-01,  1.1804e+00,  1.0688e-01,  ..., -1.4068e+00,\n",
       "              -2.3224e+00, -8.0463e-01],\n",
       "             [ 1.7630e+00, -3.3871e-01,  1.2034e+00,  ..., -6.9985e-01,\n",
       "              -7.2815e-01,  1.8362e-01],\n",
       "             [ 6.9994e-01,  1.2109e+00,  2.3022e-01,  ..., -1.4998e+00,\n",
       "              -2.3277e+00, -7.7729e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.2125e-01,  2.2008e-02, -6.5314e-02,  ...,  9.2584e-02,\n",
       "               3.5623e-02, -3.7969e-04],\n",
       "             [ 2.0111e+00,  5.1528e-01,  4.3825e-01,  ...,  1.8468e+00,\n",
       "               7.3727e-01, -3.9190e-01],\n",
       "             [ 6.8265e-02,  8.6446e-01,  6.6308e-01,  ...,  4.7508e-01,\n",
       "              -7.2122e-01,  7.6963e-01],\n",
       "             ...,\n",
       "             [-3.6802e-01,  3.4177e-01,  7.8910e-01,  ...,  6.6477e-01,\n",
       "              -5.5517e-01,  6.0912e-01],\n",
       "             [ 1.0162e+00,  7.3033e-01,  3.6478e-01,  ...,  1.0292e+00,\n",
       "              -1.2334e-01,  6.9081e-02],\n",
       "             [-2.8647e-01,  3.2836e-01,  7.4716e-01,  ...,  6.4711e-01,\n",
       "              -5.1705e-01,  5.5538e-01]],\n",
       "  \n",
       "            [[-7.2903e-02,  4.9875e-02, -5.0968e-02,  ...,  5.6493e-02,\n",
       "              -7.1445e-02, -9.9216e-02],\n",
       "             [-3.3335e-02,  2.4220e-01,  3.5223e-02,  ...,  1.1298e-01,\n",
       "              -5.1401e-01, -2.3367e-01],\n",
       "             [-3.0075e-01,  8.0762e-01, -2.8344e-01,  ...,  1.5244e-01,\n",
       "              -1.1921e+00,  3.8304e-01],\n",
       "             ...,\n",
       "             [-2.3796e-02,  1.2921e+00, -1.0582e+00,  ...,  1.2896e+00,\n",
       "              -4.9185e-01,  4.8608e-01],\n",
       "             [-1.2282e+00,  5.2326e-01, -7.8570e-01,  ...,  1.9048e+00,\n",
       "              -2.1608e-01,  4.4203e-01],\n",
       "             [-8.1367e-02,  1.2290e+00, -1.0009e+00,  ...,  1.2673e+00,\n",
       "              -3.9385e-01,  4.7337e-01]],\n",
       "  \n",
       "            [[ 8.0475e-03, -1.6137e-02, -1.0294e-01,  ...,  7.2216e-02,\n",
       "              -1.7923e-01,  1.1483e-01],\n",
       "             [ 4.3647e-01, -1.1528e+00,  1.7065e+00,  ..., -4.8328e-01,\n",
       "               4.6387e-02,  5.5228e-01],\n",
       "             [ 2.8434e-01, -5.1202e-01,  2.5652e-01,  ..., -1.3514e+00,\n",
       "              -1.3213e+00, -7.1779e-01],\n",
       "             ...,\n",
       "             [ 4.5747e-01, -1.6742e-02, -1.9834e-01,  ..., -4.8238e-02,\n",
       "              -9.2763e-01, -6.0046e-02],\n",
       "             [-1.9865e-01, -3.8533e-01,  1.0194e+00,  ..., -8.0254e-03,\n",
       "              -1.0806e-01,  2.1529e-01],\n",
       "             [ 4.5575e-01,  3.2244e-02, -2.0221e-01,  ..., -1.0476e-01,\n",
       "              -9.0852e-01, -6.5058e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 9.4708e-02,  4.8268e-02, -1.7377e-01,  ...,  4.2699e-02,\n",
       "               1.0605e-01,  5.5429e-03],\n",
       "             [-4.3943e-01, -3.5992e-01,  1.0120e+00,  ..., -2.1329e-01,\n",
       "              -4.1847e-02,  4.4506e-01],\n",
       "             [ 6.3501e-01, -6.0898e-02, -1.4341e+00,  ...,  5.3269e-01,\n",
       "              -2.5241e-02, -1.1466e+00],\n",
       "             ...,\n",
       "             [-2.6318e-01, -1.2083e+00, -2.5827e+00,  ...,  1.7172e+00,\n",
       "               2.2955e+00, -1.0936e+00],\n",
       "             [-1.6644e+00, -1.1592e+00, -1.3508e+00,  ...,  1.0737e+00,\n",
       "               2.6780e+00, -8.1391e-01],\n",
       "             [-3.6019e-01, -1.1988e+00, -2.5079e+00,  ...,  1.6575e+00,\n",
       "               2.3004e+00, -1.0948e+00]],\n",
       "  \n",
       "            [[-1.6755e-02,  8.8640e-02, -2.5329e-01,  ...,  3.8905e-02,\n",
       "              -2.4743e-01,  1.7618e-02],\n",
       "             [ 8.9692e-01, -1.2612e-01,  1.3151e+00,  ...,  7.0664e-02,\n",
       "              -9.2286e-01, -1.3151e-01],\n",
       "             [ 8.4719e-01,  2.4142e-01,  2.6738e-01,  ..., -3.8943e-01,\n",
       "              -2.7978e-01, -5.1305e-01],\n",
       "             ...,\n",
       "             [ 1.3561e+00,  4.0042e-02,  1.0466e+00,  ..., -5.1884e-01,\n",
       "              -1.0089e+00,  7.1590e-01],\n",
       "             [ 8.0763e-01,  4.0774e-01,  1.5238e+00,  ...,  5.9635e-01,\n",
       "              -1.2650e+00,  7.1216e-01],\n",
       "             [ 1.2497e+00,  4.4024e-02,  1.0708e+00,  ..., -5.1786e-01,\n",
       "              -1.0033e+00,  6.9646e-01]],\n",
       "  \n",
       "            [[-7.2593e-03,  1.8752e-02, -1.1463e-01,  ..., -1.3021e-02,\n",
       "               7.3455e-02,  1.1168e-01],\n",
       "             [ 1.2464e-01, -4.2998e-01,  2.6983e-01,  ..., -3.5254e-01,\n",
       "               1.6719e-01, -6.7581e-01],\n",
       "             [ 7.8095e-01, -9.6077e-01,  4.0577e-01,  ...,  3.1818e-03,\n",
       "              -2.4233e-01,  3.1054e-01],\n",
       "             ...,\n",
       "             [ 1.5630e-01, -3.2900e-01, -8.1370e-02,  ..., -2.8281e-01,\n",
       "              -1.2955e-01,  4.1290e-01],\n",
       "             [ 1.3419e-01, -4.0031e-01, -1.2824e-01,  ...,  1.6867e-01,\n",
       "              -1.1820e-01, -8.9405e-01],\n",
       "             [ 1.2531e-01, -3.6874e-01, -9.4275e-02,  ..., -3.7238e-01,\n",
       "              -1.3620e-01,  5.1232e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-0.1725, -0.1518, -0.0961,  ...,  0.1084, -0.2766, -0.0596],\n",
       "             [ 0.7464, -0.5116, -0.6193,  ...,  1.3030,  0.3052, -0.9409],\n",
       "             [-2.5683,  0.0542, -2.2359,  ..., -0.3944, -1.0062, -0.2594],\n",
       "             ...,\n",
       "             [-3.9871,  0.6364, -0.6240,  ..., -1.3251, -0.6507,  1.5664],\n",
       "             [-3.0463,  0.1919, -0.4736,  ...,  0.2192, -0.3783,  1.0022],\n",
       "             [-4.0613,  0.6211, -0.5828,  ..., -1.3436, -0.6599,  1.5943]],\n",
       "  \n",
       "            [[-0.2496,  0.0091, -0.6572,  ...,  0.6731, -1.0039, -0.4439],\n",
       "             [ 0.6287, -0.6484, -1.1698,  ...,  0.9320, -0.3400,  0.8464],\n",
       "             [ 1.0040, -0.8979, -1.5295,  ...,  0.0955,  1.0207,  0.2944],\n",
       "             ...,\n",
       "             [ 1.4279, -3.2427,  0.1518,  ...,  3.0343,  3.0296,  0.3985],\n",
       "             [ 0.8271, -3.7780,  0.5777,  ...,  2.9330,  2.2817,  1.5809],\n",
       "             [ 1.4319, -3.2761,  0.1365,  ...,  3.0843,  3.0228,  0.3730]],\n",
       "  \n",
       "            [[-0.2305, -1.0570, -0.0190,  ..., -0.9610,  0.0973, -0.1769],\n",
       "             [ 1.1877,  1.6812, -0.0397,  ...,  2.8911,  0.3245,  1.9362],\n",
       "             [ 2.5933, -0.0926,  0.6095,  ...,  2.9049,  0.1403,  0.3236],\n",
       "             ...,\n",
       "             [ 0.6820, -2.9862,  1.4882,  ..., -1.5353, -1.4353,  2.3769],\n",
       "             [ 1.2176, -2.6057,  0.9623,  ..., -1.6224, -1.4099,  3.5245],\n",
       "             [ 0.7311, -3.1263,  1.5489,  ..., -1.6933, -1.4675,  2.4115]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-0.1501, -0.1770,  0.0240,  ..., -0.0088, -0.1996, -0.1223],\n",
       "             [-0.1600, -0.7143,  0.5969,  ..., -0.1437,  0.9807,  0.5207],\n",
       "             [-1.0315, -0.1915, -0.9737,  ..., -0.1807,  2.7774, -0.5854],\n",
       "             ...,\n",
       "             [ 2.5506,  2.5869,  2.4115,  ...,  3.3484, -1.0548, -0.9053],\n",
       "             [ 2.2443,  2.0326,  2.3781,  ...,  2.7347, -1.9070, -0.1328],\n",
       "             [ 2.6559,  2.6714,  2.5148,  ...,  3.4722, -1.2035, -0.9089]],\n",
       "  \n",
       "            [[-0.0109, -0.3856,  0.1653,  ..., -0.0477,  0.0577,  0.1044],\n",
       "             [ 1.6053, -0.7605,  0.1032,  ...,  0.5636, -0.1899,  0.6509],\n",
       "             [ 2.5088, -2.8085, -0.4755,  ..., -0.2166, -0.8767,  0.8165],\n",
       "             ...,\n",
       "             [ 1.6020, -0.7100, -0.6736,  ...,  1.9320, -1.6346,  2.1945],\n",
       "             [ 2.0030,  0.4486, -0.3469,  ...,  1.6738, -1.8228,  2.1408],\n",
       "             [ 1.5387, -0.6330, -0.6183,  ...,  1.9330, -1.7079,  2.2002]],\n",
       "  \n",
       "            [[-0.0486, -0.1727,  0.0658,  ...,  0.0131, -0.0802,  0.3659],\n",
       "             [-0.2701, -0.3370,  1.0234,  ..., -0.0816, -0.0574, -1.3917],\n",
       "             [ 1.1309,  0.0310,  0.8943,  ...,  0.0368,  0.9252,  1.6798],\n",
       "             ...,\n",
       "             [ 0.9999, -1.8376,  0.3742,  ...,  1.1552, -0.9392, -0.5580],\n",
       "             [ 0.3958, -2.2266,  1.0668,  ...,  1.7600, -1.6932, -2.6588],\n",
       "             [ 0.9568, -1.8587,  0.3589,  ...,  1.2013, -0.9659, -0.7194]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 0.0312, -0.0368,  0.0323,  ..., -0.2076, -0.1007,  0.1123],\n",
       "             [ 0.3485,  0.0500, -1.0935,  ..., -1.1667,  0.0831, -1.5754],\n",
       "             [-0.3529,  0.7031, -1.1933,  ..., -1.1075, -0.5890,  0.1130],\n",
       "             ...,\n",
       "             [ 0.2540,  0.0776, -0.8328,  ..., -0.2318,  0.0531, -0.4256],\n",
       "             [-0.3853,  0.2326, -0.9210,  ..., -0.0453,  0.1055, -0.6854],\n",
       "             [ 0.2738,  0.0930, -0.8134,  ..., -0.2573,  0.0633, -0.4171]],\n",
       "  \n",
       "            [[ 0.0123, -0.0266, -0.0128,  ..., -0.0382, -0.0596,  0.0701],\n",
       "             [-0.4253,  1.3090, -1.0143,  ..., -0.1980,  0.4484,  0.7133],\n",
       "             [ 0.5735,  1.3106, -0.2318,  ..., -0.0358,  1.3607, -0.2642],\n",
       "             ...,\n",
       "             [ 0.3378,  0.7209, -0.2407,  ..., -0.0363,  0.4884,  0.2024],\n",
       "             [-0.2335,  0.4285, -0.8415,  ..., -0.0657, -0.2582,  1.2119],\n",
       "             [ 0.3568,  0.6982, -0.2684,  ...,  0.0369,  0.4604,  0.2416]],\n",
       "  \n",
       "            [[ 0.0264,  0.0569, -0.0903,  ...,  0.0139,  0.0220, -0.0556],\n",
       "             [-0.0226,  1.1313, -0.4856,  ...,  0.4479,  0.1301,  0.1747],\n",
       "             [-0.3229,  0.2677,  0.9708,  ..., -1.2685,  1.6110, -1.1742],\n",
       "             ...,\n",
       "             [-1.0428,  0.4100, -0.0278,  ...,  0.1193,  0.4352,  0.0973],\n",
       "             [-0.3195,  0.4140, -0.4357,  ...,  0.5867,  0.2708,  0.0982],\n",
       "             [-1.0422,  0.3663, -0.0104,  ...,  0.1104,  0.4047,  0.0441]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 0.1105,  0.1602,  0.0478,  ...,  0.0070, -0.1864,  0.0194],\n",
       "             [-1.1568,  0.4072,  1.7580,  ..., -0.8772,  0.4214, -1.2068],\n",
       "             [-0.6857,  0.0191,  0.4976,  ..., -0.5413,  0.6075,  0.7398],\n",
       "             ...,\n",
       "             [-0.1869, -0.6568,  0.7816,  ...,  0.0395,  0.2143,  0.5802],\n",
       "             [-1.2585, -0.7074,  1.2800,  ..., -0.2988,  0.5696, -0.3933],\n",
       "             [-0.2174, -0.6372,  0.7504,  ...,  0.0530,  0.2524,  0.6088]],\n",
       "  \n",
       "            [[ 0.0688, -0.0814,  0.1127,  ..., -0.0949,  0.0803, -0.0690],\n",
       "             [-0.8122,  0.0583,  0.6352,  ...,  0.4150, -0.2034,  0.4368],\n",
       "             [ 0.0730, -0.6045,  0.1518,  ...,  0.0512,  0.0130,  0.2126],\n",
       "             ...,\n",
       "             [-0.0592, -1.2808,  0.9065,  ..., -0.2051,  0.4805, -0.5722],\n",
       "             [-0.9348, -0.1863,  0.6156,  ...,  0.7969, -0.4455,  0.7270],\n",
       "             [-0.0547, -1.2175,  0.9086,  ..., -0.2053,  0.4505, -0.5660]],\n",
       "  \n",
       "            [[-0.1646, -0.1855, -0.0153,  ..., -0.1758, -0.0934, -0.1412],\n",
       "             [-0.2879, -0.2852,  0.3780,  ..., -0.8950,  1.0840,  0.0219],\n",
       "             [-0.5403, -0.8192, -0.3513,  ...,  0.0673,  0.3819,  0.3494],\n",
       "             ...,\n",
       "             [-0.5440, -0.7614,  0.0929,  ..., -0.3380,  0.9736,  0.5806],\n",
       "             [-0.5529, -0.5317,  0.1874,  ..., -0.5057,  0.8674, -0.0787],\n",
       "             [-0.5204, -0.7341,  0.0621,  ..., -0.3713,  0.9285,  0.5746]]]]],\n",
       "         grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 5.6166e-02, -4.2002e-01,  3.8002e-01,  ...,  3.8938e-01,\n",
       "              -4.0163e-01,  2.1940e-01],\n",
       "             [-9.0036e-01,  2.5164e-01,  1.0827e+00,  ...,  8.3210e-01,\n",
       "               1.2399e+00, -5.2130e-01],\n",
       "             [-1.2126e+00, -4.3218e-01, -8.0373e-01,  ...,  3.1813e-01,\n",
       "               2.3243e+00, -8.6250e-01],\n",
       "             ...,\n",
       "             [ 1.0634e+00,  3.6366e+00, -4.3412e+00,  ...,  2.6793e+00,\n",
       "              -1.2157e+00,  1.7478e+00],\n",
       "             [ 1.1861e+00,  3.9963e+00, -3.7035e+00,  ...,  2.0344e+00,\n",
       "              -5.5688e-01,  1.3168e+00],\n",
       "             [ 1.1166e+00,  3.7670e+00, -4.3342e+00,  ...,  2.7086e+00,\n",
       "              -1.2816e+00,  1.7340e+00]],\n",
       "  \n",
       "            [[ 1.5011e+00, -2.4253e-01, -1.8437e+00,  ..., -1.6119e+00,\n",
       "              -2.3475e+00,  1.6712e-01],\n",
       "             [ 1.2258e+00,  8.9521e-01,  9.8843e-01,  ...,  3.5756e-01,\n",
       "               1.7873e-01, -6.6019e-01],\n",
       "             [-1.1977e-01, -1.6766e+00,  1.5651e-01,  ..., -2.2401e+00,\n",
       "               2.1953e+00,  7.0043e-01],\n",
       "             ...,\n",
       "             [ 5.7594e-01, -3.2278e+00, -8.8773e-01,  ..., -2.5146e+00,\n",
       "              -1.4448e-01, -7.8484e-01],\n",
       "             [ 1.0864e+00, -1.9657e+00, -1.2011e-02,  ..., -9.0885e-01,\n",
       "              -7.2953e-01, -2.3621e+00],\n",
       "             [ 6.5725e-01, -3.2337e+00, -9.7704e-01,  ..., -2.4551e+00,\n",
       "              -3.2943e-01, -9.6910e-01]],\n",
       "  \n",
       "            [[ 1.2856e+00, -1.9217e-01, -9.8805e-01,  ..., -2.8358e-01,\n",
       "              -7.0646e-01, -5.0923e-02],\n",
       "             [ 2.4959e-01, -7.2976e-01,  1.9933e+00,  ...,  6.2721e-01,\n",
       "               4.9795e-01,  1.4856e+00],\n",
       "             [ 1.2986e+00, -2.7844e+00, -9.0845e-01,  ...,  6.6660e-01,\n",
       "               3.2374e-02,  9.0445e-01],\n",
       "             ...,\n",
       "             [ 6.4543e-01, -1.5075e+00, -2.7834e+00,  ...,  3.0820e+00,\n",
       "              -5.0923e+00, -2.9048e+00],\n",
       "             [ 5.0992e-01, -1.7386e+00, -1.8178e+00,  ...,  3.2099e+00,\n",
       "              -5.4081e+00, -3.0420e+00],\n",
       "             [ 6.7985e-01, -1.4265e+00, -2.8677e+00,  ...,  3.2350e+00,\n",
       "              -5.1615e+00, -3.0517e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 5.9247e-01, -8.0191e-02, -4.8320e-01,  ..., -4.2196e-02,\n",
       "               1.2568e-01, -1.1414e-01],\n",
       "             [ 1.4345e-01, -1.2341e-01, -2.9809e-01,  ..., -2.7742e-01,\n",
       "              -1.0967e+00,  1.4368e+00],\n",
       "             [-1.3090e+00, -7.5311e-01, -8.4933e-01,  ..., -3.0142e-01,\n",
       "              -5.3921e-01, -9.8285e-01],\n",
       "             ...,\n",
       "             [-2.0666e+00,  3.3036e-01, -3.5907e-01,  ...,  1.8929e-01,\n",
       "              -3.3404e+00, -1.5453e+00],\n",
       "             [-1.3719e+00,  3.4992e-01, -5.9277e-01,  ..., -4.4082e-01,\n",
       "              -3.1663e+00, -1.3159e+00],\n",
       "             [-1.9634e+00,  4.2107e-01, -3.5189e-01,  ...,  1.6480e-01,\n",
       "              -3.4214e+00, -1.5606e+00]],\n",
       "  \n",
       "            [[ 2.7973e-01,  6.7818e-01, -1.7939e-01,  ..., -2.2796e-01,\n",
       "              -7.6827e-02, -4.5045e-01],\n",
       "             [ 8.6182e-01, -2.2256e+00,  1.8621e+00,  ...,  1.5628e+00,\n",
       "              -1.3158e+00,  1.3275e+00],\n",
       "             [ 2.3336e+00, -2.0955e-01,  1.7138e-01,  ...,  1.7505e+00,\n",
       "               5.6696e-02,  1.0674e+00],\n",
       "             ...,\n",
       "             [-4.1930e+00, -7.0871e-01,  2.0013e+00,  ...,  1.5869e+00,\n",
       "               2.0522e+00, -4.4835e-01],\n",
       "             [-4.8349e+00, -1.9820e+00,  1.4516e+00,  ...,  1.1793e+00,\n",
       "               1.2066e+00, -5.4100e-01],\n",
       "             [-4.3638e+00, -7.4093e-01,  2.0279e+00,  ...,  1.6074e+00,\n",
       "               2.0619e+00, -5.4973e-01]],\n",
       "  \n",
       "            [[-2.1772e-01, -1.0921e-01, -3.6384e-02,  ...,  1.1472e-01,\n",
       "               1.4872e-01,  7.3530e-02],\n",
       "             [-1.8979e-01,  5.0915e-02, -1.9807e-01,  ..., -1.1196e+00,\n",
       "               1.6558e-01, -3.7173e-01],\n",
       "             [-4.4602e-01,  6.2886e-01,  1.0505e+00,  ...,  3.5230e-01,\n",
       "               1.0677e+00,  1.1299e+00],\n",
       "             ...,\n",
       "             [-1.7302e-02, -6.5697e-01, -1.4642e+00,  ...,  3.7024e-01,\n",
       "              -1.2113e+00,  1.9589e+00],\n",
       "             [ 1.8845e-01, -2.6722e-01, -1.1788e+00,  ...,  8.1768e-01,\n",
       "              -7.9566e-01,  1.1179e+00],\n",
       "             [-4.7589e-03, -7.2274e-01, -1.4505e+00,  ...,  4.2071e-01,\n",
       "              -1.1965e+00,  1.8555e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 2.8610e-02,  1.2853e-02, -1.2269e-01,  ..., -1.1257e-02,\n",
       "               2.9263e-02, -1.5723e-01],\n",
       "             [-2.0106e-01,  2.7768e-01,  2.5367e+00,  ...,  3.7636e-01,\n",
       "              -5.3303e-02, -7.3146e-02],\n",
       "             [-7.5599e-02, -1.8415e-02,  5.8910e-01,  ...,  3.6737e-01,\n",
       "              -3.0556e-01,  3.4870e-01],\n",
       "             ...,\n",
       "             [-2.5798e-01,  6.6433e-01,  4.4798e-02,  ...,  4.2006e-01,\n",
       "               2.4894e-01,  2.7327e-02],\n",
       "             [ 2.0591e-01, -5.9180e-02,  6.9254e-01,  ...,  8.0513e-01,\n",
       "               1.4813e-01, -2.2537e-01],\n",
       "             [-2.3338e-01,  7.0667e-01,  4.6292e-02,  ...,  4.4014e-01,\n",
       "               2.7583e-01,  5.9266e-03]],\n",
       "  \n",
       "            [[ 4.5970e-02, -7.6100e-02, -3.1406e-02,  ...,  4.2137e-03,\n",
       "               2.9127e-02,  8.3232e-02],\n",
       "             [-6.6416e-01,  1.1792e+00,  7.2355e-01,  ...,  6.1842e-01,\n",
       "               1.3291e+00,  1.3557e-01],\n",
       "             [-1.0069e-01,  3.1926e-01,  3.5223e-01,  ..., -3.6035e-01,\n",
       "               6.9251e-01, -4.2601e-01],\n",
       "             ...,\n",
       "             [-6.4514e-03,  4.0228e-01,  6.0551e-01,  ...,  4.1727e-01,\n",
       "              -3.4731e-01, -7.8465e-01],\n",
       "             [-6.6201e-01,  8.0433e-01,  5.1797e-01,  ...,  6.3021e-01,\n",
       "               4.6219e-01,  1.2468e-01],\n",
       "             [ 4.2583e-02,  4.0989e-01,  6.0239e-01,  ...,  3.7964e-01,\n",
       "              -3.5404e-01, -7.1969e-01]],\n",
       "  \n",
       "            [[ 4.0437e-02, -3.9120e-03, -1.8649e-01,  ...,  1.9926e-02,\n",
       "               1.0219e-01,  2.2396e-02],\n",
       "             [ 4.3508e-01,  1.3748e+00, -1.8874e-02,  ...,  7.6127e-01,\n",
       "              -2.5055e-02,  7.8726e-01],\n",
       "             [ 5.1185e-01,  1.2991e+00, -6.2457e-03,  ...,  5.4653e-01,\n",
       "               5.6407e-01, -9.0313e-01],\n",
       "             ...,\n",
       "             [-2.9639e-01,  4.4766e-01, -8.5618e-01,  ..., -4.7889e-01,\n",
       "               4.4166e-01,  9.8398e-02],\n",
       "             [ 6.7280e-02,  9.1599e-02, -3.8354e-01,  ...,  7.7066e-01,\n",
       "              -1.1416e-02,  7.9639e-01],\n",
       "             [-2.6635e-01,  4.1709e-01, -8.4446e-01,  ..., -4.8175e-01,\n",
       "               4.1025e-01,  7.1735e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.9750e-01,  6.8529e-03, -1.4536e-02,  ...,  3.4890e-03,\n",
       "               1.0463e-01,  7.3523e-02],\n",
       "             [ 1.1149e+00,  8.2626e-01,  1.5518e-02,  ...,  9.0221e-01,\n",
       "              -4.6150e-01, -7.2491e-01],\n",
       "             [-7.0829e-01,  3.8576e-02,  4.5917e-01,  ...,  1.3060e-01,\n",
       "              -4.5200e-01,  6.5450e-02],\n",
       "             ...,\n",
       "             [ 1.6055e-01, -4.4959e-02, -6.3658e-01,  ..., -3.9343e-02,\n",
       "               7.7898e-02,  4.1651e-02],\n",
       "             [ 7.6647e-01,  3.1331e-01, -7.0777e-01,  ...,  2.7662e-01,\n",
       "              -3.3727e-01, -7.9312e-01],\n",
       "             [ 2.2596e-01,  2.5328e-02, -6.5446e-01,  ..., -3.9717e-02,\n",
       "               6.9850e-02,  4.4686e-02]],\n",
       "  \n",
       "            [[-9.8877e-02, -4.6599e-03, -3.8561e-03,  ...,  1.1805e-01,\n",
       "               9.6648e-02, -5.6808e-02],\n",
       "             [ 5.3670e-01, -5.6381e-01,  4.5461e-01,  ...,  5.7934e-01,\n",
       "               8.2111e-02, -4.6666e-01],\n",
       "             [-9.4565e-01, -5.2629e-02, -2.8324e-02,  ...,  6.6512e-01,\n",
       "               2.9557e-01, -4.9475e-01],\n",
       "             ...,\n",
       "             [ 2.4102e-01, -9.1359e-01,  1.8441e-01,  ...,  4.5317e-01,\n",
       "              -1.4818e-01, -7.8914e-01],\n",
       "             [ 4.9549e-01, -1.6623e-01,  3.3844e-01,  ...,  4.1715e-01,\n",
       "               2.2420e-01, -3.4012e-01],\n",
       "             [ 2.2019e-01, -9.0551e-01,  1.9570e-01,  ...,  4.5624e-01,\n",
       "              -1.2058e-01, -7.7331e-01]],\n",
       "  \n",
       "            [[ 1.3056e-01,  2.2470e-02,  5.5132e-02,  ..., -9.6777e-03,\n",
       "               4.2867e-02,  8.0464e-02],\n",
       "             [-7.1081e-01, -5.3793e-01,  7.0893e-02,  ...,  1.6059e+00,\n",
       "               8.8559e-01,  1.6009e+00],\n",
       "             [-7.5900e-01,  3.2864e-01,  2.9079e-01,  ...,  6.1201e-01,\n",
       "               1.7177e-01, -4.9661e-01],\n",
       "             ...,\n",
       "             [ 2.3875e-01,  7.7463e-01, -8.4165e-01,  ..., -3.9675e-01,\n",
       "              -4.2066e-01, -5.9187e-02],\n",
       "             [ 6.4349e-02,  3.0666e-01, -4.1727e-01,  ...,  6.6901e-01,\n",
       "               3.8666e-01,  4.8330e-01],\n",
       "             [ 1.9610e-01,  7.6599e-01, -8.8106e-01,  ..., -3.4469e-01,\n",
       "              -4.2299e-01, -3.2146e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-8.0509e-01, -1.5786e-01,  4.0455e-01,  ...,  5.1511e-02,\n",
       "               7.3780e-01, -2.3081e-01],\n",
       "             [ 2.0069e+00, -1.2103e+00, -3.2134e-01,  ...,  2.0463e+00,\n",
       "              -1.7248e+00, -8.9961e-02],\n",
       "             [ 1.1574e+00, -1.6836e+00,  2.9710e-03,  ...,  1.5643e+00,\n",
       "              -8.6848e-01, -2.4166e-01],\n",
       "             ...,\n",
       "             [-2.2699e+00, -1.2972e+00, -4.7365e+00,  ..., -1.1557e+00,\n",
       "              -1.4084e+00,  4.0186e+00],\n",
       "             [-2.7211e+00, -1.4570e+00, -4.5784e+00,  ..., -8.5334e-02,\n",
       "              -2.4154e+00,  3.2588e+00],\n",
       "             [-2.3536e+00, -1.3064e+00, -4.8190e+00,  ..., -1.1959e+00,\n",
       "              -1.4213e+00,  4.0587e+00]],\n",
       "  \n",
       "            [[-9.3736e-01, -5.2172e-02,  3.7902e-01,  ...,  2.6934e-01,\n",
       "              -7.0688e-01,  4.3571e-01],\n",
       "             [-4.7712e-01, -1.7614e+00,  1.4042e+00,  ..., -1.9707e+00,\n",
       "               1.1611e+00, -1.2010e+00],\n",
       "             [ 1.8771e+00,  1.2277e+00, -8.7057e-01,  ..., -1.0569e-01,\n",
       "               2.4207e-01, -1.4343e+00],\n",
       "             ...,\n",
       "             [ 2.3636e+00,  1.5779e+00,  1.3397e+00,  ...,  3.4857e+00,\n",
       "               7.2268e-01,  1.8681e+00],\n",
       "             [ 1.8394e+00,  4.1946e-01,  1.4512e+00,  ...,  1.6969e+00,\n",
       "               1.3930e+00,  1.2559e+00],\n",
       "             [ 2.3054e+00,  1.4767e+00,  1.3321e+00,  ...,  3.3702e+00,\n",
       "               7.6097e-01,  1.8429e+00]],\n",
       "  \n",
       "            [[ 1.2431e-01, -1.9596e-01, -3.7100e-01,  ..., -2.9573e-01,\n",
       "               1.2071e-01, -1.8707e-01],\n",
       "             [-6.1152e-01, -1.1212e+00,  7.7419e-01,  ..., -7.6331e-02,\n",
       "              -1.2396e+00,  2.1420e+00],\n",
       "             [ 1.0026e+00, -8.8863e-01,  1.1224e+00,  ...,  4.6487e-01,\n",
       "               1.1094e+00,  1.5170e+00],\n",
       "             ...,\n",
       "             [ 2.7676e+00,  9.1408e-01,  4.2194e-01,  ...,  2.1513e+00,\n",
       "              -1.1351e+00,  4.1803e+00],\n",
       "             [ 2.0050e+00,  6.5823e-01,  5.1451e-01,  ...,  2.4423e+00,\n",
       "              -2.2873e+00,  4.5584e+00],\n",
       "             [ 2.7651e+00,  9.9362e-01,  3.5207e-01,  ...,  2.1813e+00,\n",
       "              -1.2712e+00,  4.2558e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.1101e+00, -1.4262e+00,  1.3988e+00,  ...,  1.5434e+00,\n",
       "               4.4440e-01,  1.8507e+00],\n",
       "             [ 4.2952e-01,  6.6493e-01, -4.2849e-01,  ...,  1.0792e+00,\n",
       "               1.2027e+00,  1.5726e+00],\n",
       "             [-1.9389e-01, -8.9660e-01,  1.8397e+00,  ..., -1.0483e+00,\n",
       "              -7.0499e-01,  1.8053e+00],\n",
       "             ...,\n",
       "             [-5.1135e+00, -7.6571e-01,  1.1407e+00,  ..., -2.9861e+00,\n",
       "               2.8615e+00,  1.0116e+00],\n",
       "             [-6.4364e+00,  2.7259e-01,  6.3638e-01,  ..., -1.7919e+00,\n",
       "               4.2762e+00,  7.6588e-01],\n",
       "             [-5.3074e+00, -7.0848e-01,  1.2337e+00,  ..., -2.9743e+00,\n",
       "               2.9812e+00,  9.4407e-01]],\n",
       "  \n",
       "            [[-2.6173e-01,  1.5671e-01, -2.8757e-01,  ..., -3.8101e-01,\n",
       "              -2.0463e-01,  9.5139e-02],\n",
       "             [-1.8710e+00, -7.0214e-01,  1.0967e+00,  ...,  3.2663e-01,\n",
       "              -1.6948e-02,  9.2062e-01],\n",
       "             [-1.9617e+00, -4.0355e-01, -1.0796e-01,  ..., -5.0139e-01,\n",
       "              -1.1405e-01,  1.2661e-01],\n",
       "             ...,\n",
       "             [ 1.1409e+00, -2.0893e+00, -2.8737e+00,  ..., -4.1695e+00,\n",
       "              -5.0880e+00, -3.1322e+00],\n",
       "             [ 4.7062e-01, -1.8036e+00, -1.9398e+00,  ..., -3.6469e+00,\n",
       "              -4.8252e+00, -2.7708e+00],\n",
       "             [ 1.1975e+00, -2.1957e+00, -2.9622e+00,  ..., -4.2747e+00,\n",
       "              -5.1553e+00, -3.2145e+00]],\n",
       "  \n",
       "            [[-1.7156e-01, -5.8267e-02,  7.7460e-01,  ...,  3.0813e-01,\n",
       "               7.6626e-01, -1.3414e-01],\n",
       "             [-1.4913e+00,  4.0281e-01, -1.0599e+00,  ...,  1.0718e+00,\n",
       "              -1.2053e+00,  1.2962e-02],\n",
       "             [-1.0439e+00, -1.8174e+00,  1.0110e+00,  ...,  1.6480e+00,\n",
       "              -2.0945e+00, -1.0982e+00],\n",
       "             ...,\n",
       "             [-2.2487e+00,  2.8088e+00,  8.0010e+00,  ...,  6.3947e-02,\n",
       "              -4.6936e+00,  1.1263e+00],\n",
       "             [-2.5354e+00,  3.3772e+00,  7.4754e+00,  ...,  5.1553e-01,\n",
       "              -4.7355e+00,  1.6568e+00],\n",
       "             [-2.3555e+00,  2.9145e+00,  8.1140e+00,  ..., -7.9245e-02,\n",
       "              -4.6512e+00,  1.2580e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 5.8372e-02,  3.1311e-02, -1.4783e-01,  ...,  1.1438e-01,\n",
       "               1.3060e-02,  2.3378e-01],\n",
       "             [ 8.4837e-01,  2.4797e-01, -1.5988e+00,  ..., -1.0958e+00,\n",
       "               5.3335e-01, -8.2253e-02],\n",
       "             [-1.1586e-01, -1.2235e-01, -8.2173e-01,  ..., -8.7066e-01,\n",
       "               5.5435e-01,  3.5810e-01],\n",
       "             ...,\n",
       "             [ 1.4167e-01,  5.4759e-01, -2.4479e-01,  ..., -5.1462e-01,\n",
       "               3.6379e-01,  5.7067e-01],\n",
       "             [ 4.0622e-01,  5.5799e-01, -4.2934e-01,  ..., -8.4903e-01,\n",
       "               4.0601e-01,  3.4820e-01],\n",
       "             [ 1.3251e-01,  5.3892e-01, -1.9960e-01,  ..., -4.7376e-01,\n",
       "               3.4650e-01,  5.9987e-01]],\n",
       "  \n",
       "            [[ 5.3258e-02,  6.8870e-02,  1.0893e-01,  ...,  5.2471e-02,\n",
       "               2.4778e-02, -1.1068e-01],\n",
       "             [-4.8206e-01, -7.2946e-01,  3.7010e-01,  ..., -1.4647e-01,\n",
       "               1.0994e+00, -5.5253e-01],\n",
       "             [ 1.0664e-01,  6.6453e-01, -1.1115e-01,  ...,  1.1596e+00,\n",
       "              -1.2741e+00, -5.4519e-01],\n",
       "             ...,\n",
       "             [-2.2164e-01,  1.0101e+00,  1.4202e-01,  ...,  3.0003e-01,\n",
       "               5.4102e-01, -1.6095e-01],\n",
       "             [-4.7768e-01,  3.5226e-01,  6.7886e-01,  ..., -3.2422e-01,\n",
       "               6.7535e-01, -1.3981e+00],\n",
       "             [-2.1656e-01,  9.7024e-01,  1.8375e-01,  ...,  2.6772e-01,\n",
       "               5.7848e-01, -1.5512e-01]],\n",
       "  \n",
       "            [[-3.3564e-02, -1.6812e-02, -2.7630e-02,  ..., -2.0661e-01,\n",
       "              -2.0624e-02,  1.5071e-01],\n",
       "             [-1.8632e-02,  2.6415e+00, -9.8896e-01,  ..., -2.5421e-01,\n",
       "              -2.5654e-01, -1.0942e+00],\n",
       "             [ 4.3388e-01,  1.3108e+00, -8.4434e-01,  ..., -9.1371e-01,\n",
       "               6.9896e-01, -4.4035e-01],\n",
       "             ...,\n",
       "             [-2.0192e-01,  4.9667e-01, -5.9729e-02,  ..., -2.8124e-01,\n",
       "               4.8397e-01, -1.0883e+00],\n",
       "             [-4.9207e-01,  8.5241e-01,  2.2433e-01,  ..., -1.7091e-01,\n",
       "              -8.6071e-02, -1.4243e+00],\n",
       "             [-2.1454e-01,  4.5218e-01, -6.6088e-02,  ..., -2.8687e-01,\n",
       "               4.1840e-01, -1.0410e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 3.5601e-02, -8.6612e-02,  4.3746e-02,  ..., -1.2505e-01,\n",
       "               1.2904e-02, -6.3012e-02],\n",
       "             [ 2.0843e-01,  1.2784e+00, -1.0727e-01,  ...,  4.7901e-03,\n",
       "              -2.2344e-01, -8.6769e-01],\n",
       "             [ 2.0866e-01,  2.9216e-01,  1.1828e+00,  ...,  1.3029e-01,\n",
       "              -7.2860e-01, -5.2975e-01],\n",
       "             ...,\n",
       "             [ 8.6252e-01,  1.8769e-01, -3.4279e-02,  ...,  2.3206e-01,\n",
       "              -1.0320e-01, -2.3436e-01],\n",
       "             [-5.9651e-03,  3.8795e-01,  4.9396e-01,  ..., -6.1235e-01,\n",
       "               5.2938e-01, -1.1389e+00],\n",
       "             [ 7.7963e-01,  2.0020e-01, -3.7951e-02,  ...,  2.3512e-01,\n",
       "              -1.3809e-01, -2.2619e-01]],\n",
       "  \n",
       "            [[-8.3317e-02, -1.1641e-01,  1.3257e-01,  ..., -2.0688e-02,\n",
       "              -4.3591e-02,  1.5613e-01],\n",
       "             [-8.7765e-01, -1.8110e-01,  9.0772e-04,  ...,  3.4550e-01,\n",
       "               4.3784e-01, -8.5332e-01],\n",
       "             [-5.8751e-01,  4.5552e-01, -1.4623e-01,  ..., -3.3811e-01,\n",
       "               7.7644e-01, -1.4031e-02],\n",
       "             ...,\n",
       "             [-7.8987e-01,  2.7637e-01, -1.8619e-01,  ...,  7.2958e-01,\n",
       "               3.9757e-01, -2.3940e-01],\n",
       "             [-8.4212e-01,  2.0331e-02,  1.6109e-01,  ..., -9.0122e-02,\n",
       "               8.0954e-01, -2.9008e-01],\n",
       "             [-7.9814e-01,  3.0385e-01, -1.7667e-01,  ...,  7.3262e-01,\n",
       "               3.8308e-01, -1.7138e-01]],\n",
       "  \n",
       "            [[-1.0493e-01, -6.0311e-02, -1.7198e-02,  ...,  1.2304e-01,\n",
       "              -1.2854e-01,  2.3725e-03],\n",
       "             [ 1.2170e-02,  8.6749e-01,  1.5740e+00,  ...,  1.1157e+00,\n",
       "               3.6348e-01,  2.1335e-01],\n",
       "             [-4.7504e-01, -3.1139e-01, -2.4286e-02,  ...,  2.8995e-01,\n",
       "               9.6717e-01, -8.7367e-02],\n",
       "             ...,\n",
       "             [-1.6668e-01, -3.2424e-01,  5.3034e-02,  ..., -1.2974e-01,\n",
       "               1.0413e-01,  2.8462e-01],\n",
       "             [-1.8066e-01,  7.1741e-01,  7.3482e-01,  ...,  3.4216e-01,\n",
       "              -5.0389e-01, -6.7674e-01],\n",
       "             [-1.5682e-01, -3.5008e-01,  2.5355e-02,  ..., -9.4031e-02,\n",
       "               7.2551e-02,  1.9553e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-3.5626e-02,  9.6058e-02,  2.6860e-02,  ..., -8.9990e-02,\n",
       "              -1.9404e-01,  1.8616e-01],\n",
       "             [-1.9478e-01,  1.2086e+00,  2.5259e+00,  ..., -1.0809e+00,\n",
       "              -2.8474e+00,  1.1295e+00],\n",
       "             [-6.7777e-01,  2.0095e+00,  1.1494e+00,  ..., -6.2736e-01,\n",
       "              -7.5870e-01,  1.4799e+00],\n",
       "             ...,\n",
       "             [-1.7186e+00,  3.9500e+00, -1.8548e+00,  ..., -1.7138e+00,\n",
       "               8.2255e-01,  1.2757e+00],\n",
       "             [-9.1280e-01,  3.4560e+00, -1.8048e-01,  ..., -2.4396e+00,\n",
       "               7.2674e-01,  2.0220e+00],\n",
       "             [-1.6321e+00,  4.0120e+00, -1.9003e+00,  ..., -1.7738e+00,\n",
       "               7.9802e-01,  1.2192e+00]],\n",
       "  \n",
       "            [[ 1.4859e-01,  4.1946e-01, -2.2613e+00,  ..., -5.9651e-01,\n",
       "              -1.5599e-02, -9.8328e-02],\n",
       "             [ 8.3303e-02,  1.3943e+00,  3.4867e+00,  ...,  4.4353e-01,\n",
       "              -1.2919e+00,  8.0335e-01],\n",
       "             [ 1.5714e+00,  1.1583e+00,  2.1803e+00,  ...,  1.0743e+00,\n",
       "              -6.1733e-01,  7.0874e-01],\n",
       "             ...,\n",
       "             [ 5.2559e-01, -1.1066e+00, -4.1979e+00,  ...,  1.3285e+00,\n",
       "              -1.4407e+00, -1.0478e+00],\n",
       "             [ 3.3856e-01, -1.2271e+00, -3.6175e+00,  ...,  1.3964e+00,\n",
       "              -1.5940e+00,  1.1369e-01],\n",
       "             [ 5.3394e-01, -1.1370e+00, -4.4529e+00,  ...,  1.3289e+00,\n",
       "              -1.4031e+00, -1.0683e+00]],\n",
       "  \n",
       "            [[-1.0476e+00,  7.8033e-01,  3.7009e-01,  ..., -7.8949e-01,\n",
       "              -1.7861e-01, -3.5614e-01],\n",
       "             [-4.4819e-01, -2.3335e+00, -3.8445e-01,  ...,  3.4558e-01,\n",
       "               8.7486e-01,  1.2523e+00],\n",
       "             [ 3.9366e-01, -2.0292e+00,  2.0745e-01,  ...,  1.0650e+00,\n",
       "              -1.4602e-01,  1.7951e+00],\n",
       "             ...,\n",
       "             [-1.4020e+00, -4.2545e+00,  2.2487e+00,  ..., -1.4094e+00,\n",
       "              -4.9603e-01, -3.9276e+00],\n",
       "             [-1.7254e+00, -4.2003e+00,  1.7347e+00,  ..., -2.0224e+00,\n",
       "               1.0840e-02, -3.5232e+00],\n",
       "             [-1.4327e+00, -4.3681e+00,  2.2557e+00,  ..., -1.5592e+00,\n",
       "              -4.9671e-01, -4.0285e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-4.5795e-01, -1.7472e-01, -7.6552e-01,  ..., -2.3013e-02,\n",
       "               4.5836e-01,  3.8976e-01],\n",
       "             [-1.4109e-01, -1.3885e+00,  1.5742e+00,  ..., -1.4984e+00,\n",
       "              -1.7863e-01,  1.8931e+00],\n",
       "             [ 3.5257e-02,  7.6608e-01,  1.1566e+00,  ..., -2.7326e+00,\n",
       "               7.7622e-01,  1.4166e+00],\n",
       "             ...,\n",
       "             [-2.4759e+00, -2.0726e+00,  1.4003e+00,  ..., -4.5185e+00,\n",
       "               1.4408e-01, -6.7974e-01],\n",
       "             [-1.8249e+00, -3.9657e+00,  4.7548e-01,  ..., -4.5437e+00,\n",
       "              -1.1691e+00, -5.9599e-01],\n",
       "             [-2.5894e+00, -2.2503e+00,  1.3842e+00,  ..., -4.4890e+00,\n",
       "               1.0650e-01, -6.8354e-01]],\n",
       "  \n",
       "            [[ 2.8074e-01,  9.7224e-01,  2.6496e-01,  ...,  1.9854e-02,\n",
       "              -1.1354e-01,  1.5440e-01],\n",
       "             [ 2.9735e-01, -8.5662e-01, -1.7143e-01,  ..., -4.2318e-01,\n",
       "               2.3457e+00,  1.4826e+00],\n",
       "             [ 4.0542e-01, -1.6285e-01, -1.6692e+00,  ...,  1.7143e+00,\n",
       "              -9.8580e-01,  2.0312e+00],\n",
       "             ...,\n",
       "             [-9.2772e-01, -1.4200e+00,  2.5189e-01,  ..., -7.2397e-01,\n",
       "              -1.5358e+00,  4.7808e-01],\n",
       "             [-2.3484e-01, -7.2803e-01,  9.8886e-02,  ..., -1.3927e+00,\n",
       "               4.9278e-01,  3.0268e-01],\n",
       "             [-9.3088e-01, -1.3284e+00,  3.6368e-01,  ..., -7.9778e-01,\n",
       "              -1.5207e+00,  4.1118e-01]],\n",
       "  \n",
       "            [[-8.6930e-02,  2.1569e-02,  7.8588e-02,  ..., -8.8409e-02,\n",
       "               2.9754e-01,  2.5058e-01],\n",
       "             [-7.8535e-01,  1.4004e+00, -7.1586e-02,  ...,  5.8438e-01,\n",
       "              -1.3186e+00, -3.3546e-01],\n",
       "             [ 3.1227e-01,  2.2924e-01,  3.0289e-01,  ...,  3.2061e-01,\n",
       "              -5.5615e-01,  1.3075e+00],\n",
       "             ...,\n",
       "             [ 1.0487e+00, -5.8908e-01, -9.7855e-01,  ...,  2.8311e+00,\n",
       "               2.3205e+00,  3.5746e+00],\n",
       "             [ 2.9843e-01,  5.6715e-01, -7.6179e-01,  ...,  2.3176e+00,\n",
       "               2.0353e+00,  3.0026e+00],\n",
       "             [ 1.0540e+00, -5.5265e-01, -8.9185e-01,  ...,  2.8961e+00,\n",
       "               2.4416e+00,  3.6135e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.8299e-01, -7.4142e-02, -7.0574e-02,  ...,  5.6379e-02,\n",
       "              -7.3365e-02, -4.6098e-02],\n",
       "             [ 1.3737e+00,  1.5504e+00,  4.2807e-01,  ..., -6.1071e-01,\n",
       "               6.7113e-01,  6.9169e-01],\n",
       "             [ 1.9625e+00, -4.4112e-01, -9.7198e-01,  ..., -9.5132e-01,\n",
       "              -1.0951e+00, -5.1565e-01],\n",
       "             ...,\n",
       "             [ 5.5925e-01, -3.1237e-02, -9.9782e-01,  ...,  1.0609e-01,\n",
       "              -1.6642e+00, -5.4093e-01],\n",
       "             [ 2.9720e-01,  9.5041e-01,  6.8391e-03,  ..., -5.8683e-02,\n",
       "              -1.4329e-01,  1.0249e-01],\n",
       "             [ 5.0838e-01,  2.2538e-02, -9.5318e-01,  ...,  9.3157e-02,\n",
       "              -1.6114e+00, -4.9090e-01]],\n",
       "  \n",
       "            [[-9.6329e-02,  1.6889e-02,  3.2881e-02,  ..., -4.6500e-02,\n",
       "               1.3689e-01,  1.4687e-02],\n",
       "             [ 1.9450e+00, -4.7742e-02,  1.2742e+00,  ...,  4.0864e-02,\n",
       "              -1.5111e+00,  2.9228e-02],\n",
       "             [ 9.9490e-01, -2.9075e-01,  2.7348e-01,  ...,  1.2490e+00,\n",
       "              -1.4511e+00, -8.1816e-01],\n",
       "             ...,\n",
       "             [ 1.3516e+00, -2.2480e-02,  2.8711e-01,  ..., -2.5484e-01,\n",
       "              -9.3909e-01, -7.5213e-01],\n",
       "             [ 1.7167e+00, -6.5455e-01,  5.1284e-01,  ...,  6.2249e-02,\n",
       "              -7.6691e-01, -1.0805e+00],\n",
       "             [ 1.3261e+00, -2.6576e-02,  2.4561e-01,  ..., -2.9411e-01,\n",
       "              -9.1086e-01, -7.8877e-01]],\n",
       "  \n",
       "            [[ 8.6372e-02, -1.3211e-01,  9.9665e-02,  ...,  1.7509e-03,\n",
       "              -1.4730e-02, -4.9049e-02],\n",
       "             [-7.9739e-01,  9.1485e-02, -1.3586e-01,  ...,  6.1312e-01,\n",
       "              -7.3886e-01, -2.3035e+00],\n",
       "             [-4.8863e-01,  6.2138e-01,  3.5179e-01,  ..., -4.8970e-01,\n",
       "              -6.8810e-01, -1.2448e+00],\n",
       "             ...,\n",
       "             [ 7.0990e-02, -3.7396e-02,  4.5078e-01,  ..., -6.8112e-01,\n",
       "              -2.5030e-01, -6.7158e-01],\n",
       "             [-2.6501e-01, -1.5887e-01, -3.6186e-01,  ..., -4.9099e-01,\n",
       "              -5.7055e-01, -1.5924e+00],\n",
       "             [ 9.8731e-02, -2.6620e-02,  4.2697e-01,  ..., -6.7852e-01,\n",
       "              -3.0273e-01, -6.7067e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.1563e-01,  7.7200e-02,  2.8498e-02,  ..., -9.3503e-02,\n",
       "              -1.6608e-02,  8.3871e-02],\n",
       "             [ 2.7667e-01,  2.0680e-01, -4.1773e-01,  ...,  1.9115e-01,\n",
       "              -1.1667e+00, -1.3154e+00],\n",
       "             [ 7.5924e-01, -2.7966e-01, -9.2384e-02,  ..., -1.0054e+00,\n",
       "              -4.3723e-01, -4.4194e-01],\n",
       "             ...,\n",
       "             [ 9.6144e-01,  4.1668e-01, -6.2466e-01,  ..., -4.5936e-01,\n",
       "              -5.4238e-01, -5.5113e-01],\n",
       "             [ 3.8808e-01,  3.5090e-03, -1.8062e+00,  ...,  4.4019e-01,\n",
       "              -4.4628e-01, -7.7932e-01],\n",
       "             [ 8.9202e-01,  3.8933e-01, -6.4758e-01,  ..., -4.9424e-01,\n",
       "              -4.9389e-01, -5.1038e-01]],\n",
       "  \n",
       "            [[-7.9168e-02,  5.1150e-02,  7.2856e-02,  ...,  1.0386e-01,\n",
       "               8.3135e-02, -1.1139e-01],\n",
       "             [-1.1810e+00, -5.0970e-01, -4.6497e-01,  ..., -3.2378e+00,\n",
       "              -4.2474e-01, -1.1595e-01],\n",
       "             [ 4.7672e-02, -3.7796e-01,  5.4111e-01,  ...,  7.2553e-01,\n",
       "               7.5427e-01, -1.9289e-01],\n",
       "             ...,\n",
       "             [-3.7523e-02,  3.5921e-01,  6.7582e-01,  ...,  7.2582e-01,\n",
       "               4.6708e-01, -3.8831e-01],\n",
       "             [-2.4542e-01, -4.6032e-01,  3.3361e-01,  ..., -1.9231e+00,\n",
       "              -3.2129e-01, -7.4452e-02],\n",
       "             [ 1.3230e-02,  3.5396e-01,  6.9046e-01,  ...,  6.3652e-01,\n",
       "               4.6656e-01, -3.6635e-01]],\n",
       "  \n",
       "            [[ 7.2860e-02,  1.9324e-01,  1.8858e-01,  ...,  1.1595e-02,\n",
       "               1.3806e-02, -1.3101e-01],\n",
       "             [ 9.3098e-02,  3.1130e-01,  7.3523e-01,  ..., -1.0186e+00,\n",
       "              -6.8469e-02,  5.8171e-01],\n",
       "             [-9.7061e-02,  4.9559e-01,  8.4866e-01,  ...,  6.7414e-02,\n",
       "              -1.7660e+00,  9.1924e-02],\n",
       "             ...,\n",
       "             [-3.2793e-01,  6.8008e-01,  9.2097e-01,  ...,  1.2371e-01,\n",
       "              -2.8955e-01,  4.2327e-02],\n",
       "             [-5.7163e-01,  4.5604e-01,  4.4431e-01,  ...,  4.0308e-01,\n",
       "               7.0040e-02, -7.2576e-01],\n",
       "             [-2.9994e-01,  7.0878e-01,  9.1150e-01,  ...,  1.3040e-01,\n",
       "              -3.1020e-01,  7.5951e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 8.9367e-02, -7.8190e-01,  4.0781e-03,  ..., -6.3994e-02,\n",
       "              -3.4035e-01,  1.1557e-04],\n",
       "             [ 4.8697e-01,  8.7834e-01, -5.9861e-01,  ..., -1.1025e+00,\n",
       "               8.5854e-01,  1.7138e+00],\n",
       "             [-1.2371e-01,  6.2749e-01, -1.7620e-01,  ..., -3.3778e-01,\n",
       "              -6.9913e-01,  2.1432e-01],\n",
       "             ...,\n",
       "             [-1.1898e+00, -1.2330e+00,  1.2196e-01,  ..., -1.4832e+00,\n",
       "               1.3773e+00,  1.3300e+00],\n",
       "             [-1.1495e+00, -9.4264e-01, -6.8237e-01,  ..., -2.1637e+00,\n",
       "               1.5807e+00,  2.3811e+00],\n",
       "             [-1.1984e+00, -1.3661e+00,  1.2195e-01,  ..., -1.4987e+00,\n",
       "               1.3976e+00,  1.3283e+00]],\n",
       "  \n",
       "            [[-1.1463e-01,  1.5414e-01, -3.3556e-01,  ..., -1.2091e-01,\n",
       "              -6.0446e-02,  1.5057e+00],\n",
       "             [-2.0503e+00, -1.6268e+00, -8.0584e-03,  ...,  5.7306e-01,\n",
       "              -2.2473e-02, -2.4654e+00],\n",
       "             [-1.1604e+00, -8.0109e-02,  1.2182e+00,  ..., -2.7711e-01,\n",
       "               2.9322e-01, -3.7471e+00],\n",
       "             ...,\n",
       "             [-2.2172e+00,  4.4815e-01,  3.4076e+00,  ...,  3.1115e-01,\n",
       "              -4.0088e-01,  5.4946e+00],\n",
       "             [-2.7808e+00, -1.3333e+00,  2.5807e+00,  ...,  5.9998e-01,\n",
       "              -1.3772e-01,  5.6201e+00],\n",
       "             [-2.1908e+00,  4.5444e-01,  3.4168e+00,  ...,  2.7999e-01,\n",
       "              -4.5920e-01,  5.8262e+00]],\n",
       "  \n",
       "            [[ 7.0791e-02, -5.5965e-01, -2.2243e-02,  ...,  4.8049e-01,\n",
       "               5.3726e-01, -1.5731e-01],\n",
       "             [-8.5409e-01,  1.7755e+00, -2.9613e-01,  ..., -1.0768e+00,\n",
       "               1.1004e-01,  6.1195e-01],\n",
       "             [-5.3527e-01, -7.5270e-01, -1.5838e-01,  ...,  6.5029e-04,\n",
       "               5.7236e-01, -4.0013e-01],\n",
       "             ...,\n",
       "             [-3.7295e+00,  5.0293e-01, -1.8564e+00,  ...,  4.3107e+00,\n",
       "               7.7906e+00, -1.5311e+00],\n",
       "             [-4.3253e+00,  1.8817e+00, -1.8383e+00,  ...,  1.9279e+00,\n",
       "               7.9243e+00, -1.8689e+00],\n",
       "             [-3.6699e+00,  5.5439e-01, -1.8270e+00,  ...,  4.3574e+00,\n",
       "               7.9080e+00, -1.6615e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.3915e-01,  2.1767e-01, -6.5029e-01,  ...,  9.7640e-01,\n",
       "               6.4497e-01, -1.0495e+00],\n",
       "             [ 9.5624e-01,  1.6763e+00,  1.1208e+00,  ..., -1.3697e+00,\n",
       "              -8.4024e-01,  3.0501e+00],\n",
       "             [-7.7095e-01, -4.2066e-01,  2.7154e-01,  ..., -2.9740e+00,\n",
       "              -6.2394e-01,  2.0342e+00],\n",
       "             ...,\n",
       "             [ 1.2427e+00, -6.2246e+00, -1.7313e+00,  ...,  2.9262e+00,\n",
       "              -5.5176e-01,  1.9014e+00],\n",
       "             [ 2.4950e+00, -5.2072e+00, -2.0803e+00,  ...,  3.2605e+00,\n",
       "              -1.2203e+00,  3.4013e+00],\n",
       "             [ 1.2940e+00, -6.3190e+00, -1.7960e+00,  ...,  3.1776e+00,\n",
       "              -5.6973e-01,  1.8997e+00]],\n",
       "  \n",
       "            [[ 5.7570e-01,  7.4366e-01,  6.8049e-01,  ...,  1.1685e+00,\n",
       "              -4.2434e-01,  7.9872e-01],\n",
       "             [ 1.6935e+00, -1.6617e+00, -1.2794e+00,  ..., -6.9484e-01,\n",
       "              -2.1966e-01, -5.1784e-01],\n",
       "             [ 2.1669e+00, -7.9123e-01, -3.3049e-01,  ...,  9.4472e-01,\n",
       "               4.2394e-01, -1.8480e-01],\n",
       "             ...,\n",
       "             [ 1.9234e+00, -2.4876e+00, -3.0990e+00,  ...,  6.9780e-01,\n",
       "              -1.1071e+00, -2.2631e+00],\n",
       "             [ 1.5725e+00, -3.5509e+00, -3.8835e+00,  ..., -7.6856e-01,\n",
       "              -1.8001e-01, -2.1097e+00],\n",
       "             [ 1.8032e+00, -2.5010e+00, -3.1748e+00,  ...,  6.4680e-01,\n",
       "              -1.1083e+00, -2.2558e+00]],\n",
       "  \n",
       "            [[ 1.0457e-01, -1.8363e-01,  1.3462e-01,  ..., -1.2287e-01,\n",
       "               1.0313e-01, -2.4325e-01],\n",
       "             [ 1.9624e-02,  6.7755e-01,  9.9019e-01,  ..., -4.9596e-01,\n",
       "              -4.3477e-01,  8.3797e-01],\n",
       "             [-4.9421e-01, -1.6213e-01,  6.3992e-01,  ...,  2.0407e-01,\n",
       "              -6.4433e-01, -1.7984e-01],\n",
       "             ...,\n",
       "             [-5.2600e-01, -1.1804e-01,  8.1786e-02,  ...,  6.4444e+00,\n",
       "              -2.6129e+00, -5.5552e+00],\n",
       "             [-4.7832e-02,  9.1389e-01, -9.5729e-02,  ...,  6.6711e+00,\n",
       "              -2.5463e+00, -5.3890e+00],\n",
       "             [-5.1681e-01, -1.5662e-01,  5.9885e-02,  ...,  6.5897e+00,\n",
       "              -2.6515e+00, -5.5742e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.7617e-02,  1.9100e-02,  7.4215e-02,  ...,  5.5277e-03,\n",
       "              -3.7850e-02,  7.7476e-02],\n",
       "             [-7.0967e-01,  7.4358e-01,  1.7536e+00,  ...,  9.0167e-01,\n",
       "               6.8327e-01, -1.9166e+00],\n",
       "             [-5.1703e-01,  1.5444e+00, -1.0815e+00,  ...,  5.8523e-01,\n",
       "               7.1184e-01, -6.0517e-01],\n",
       "             ...,\n",
       "             [-5.0766e-01,  3.9992e-01, -6.2626e-01,  ...,  5.6122e-01,\n",
       "               2.6277e-01,  3.5103e-01],\n",
       "             [-8.5739e-01,  2.7689e-01, -1.8926e-01,  ...,  1.0571e+00,\n",
       "               2.1564e-01, -1.1946e-01],\n",
       "             [-4.8577e-01,  3.5587e-01, -6.6658e-01,  ...,  5.6549e-01,\n",
       "               2.4234e-01,  3.8590e-01]],\n",
       "  \n",
       "            [[ 3.3914e-02, -8.8856e-02, -5.5313e-03,  ...,  1.1858e-01,\n",
       "               1.3372e-01,  4.0809e-02],\n",
       "             [-4.7111e-01,  7.0224e-01,  4.9681e-01,  ...,  1.3935e-01,\n",
       "              -7.9133e-01,  1.1294e+00],\n",
       "             [-8.0564e-01,  5.3137e-01,  2.7531e-01,  ..., -5.9608e-01,\n",
       "               3.3773e-02, -7.8056e-01],\n",
       "             ...,\n",
       "             [-2.2093e-01,  2.4333e-01, -4.2353e-01,  ..., -3.3910e-01,\n",
       "               6.4202e-01, -3.8438e-01],\n",
       "             [-6.4428e-01,  2.7128e-01, -1.1813e-01,  ..., -1.7804e-01,\n",
       "              -2.8194e-02,  3.4588e-01],\n",
       "             [-2.6635e-01,  2.7081e-01, -4.3918e-01,  ..., -3.1688e-01,\n",
       "               6.7675e-01, -3.7627e-01]],\n",
       "  \n",
       "            [[-2.5022e-02,  4.6746e-04,  7.1227e-02,  ..., -2.1691e-02,\n",
       "              -1.4388e-01,  1.2917e-01],\n",
       "             [ 1.3207e+00, -9.7167e-02, -4.3254e-02,  ..., -1.1794e-01,\n",
       "               4.7581e-01, -6.0767e-01],\n",
       "             [-5.9027e-01,  5.4489e-02,  4.0488e-01,  ...,  4.8344e-01,\n",
       "               4.6009e-01,  1.9037e-02],\n",
       "             ...,\n",
       "             [-6.4645e-01,  5.0527e-03, -9.9323e-02,  ...,  3.4828e-01,\n",
       "              -3.6676e-01, -7.5016e-01],\n",
       "             [ 5.8888e-01,  1.7997e-01,  3.4016e-01,  ..., -2.4735e-01,\n",
       "              -4.2223e-01, -5.4837e-01],\n",
       "             [-6.2072e-01,  6.2121e-03, -5.1855e-02,  ...,  3.6348e-01,\n",
       "              -3.7332e-01, -7.2578e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.2634e-01, -9.0111e-03,  6.1170e-02,  ..., -2.8844e-02,\n",
       "               1.1346e-02,  1.3515e-01],\n",
       "             [-4.6222e-01, -7.3574e-01,  7.6296e-01,  ..., -3.4225e-01,\n",
       "               9.4332e-01, -2.9572e-01],\n",
       "             [-6.2965e-01,  4.1410e-01,  6.0440e-01,  ...,  3.3087e-02,\n",
       "               8.8669e-01, -4.3701e-01],\n",
       "             ...,\n",
       "             [-4.1360e-01,  4.2841e-01,  3.4588e-01,  ..., -1.7670e-01,\n",
       "               2.7978e-01, -1.8215e-01],\n",
       "             [-8.1077e-01,  2.0147e-01,  5.1268e-01,  ..., -6.9632e-01,\n",
       "               5.9417e-01,  5.2836e-02],\n",
       "             [-4.2159e-01,  4.2881e-01,  3.4142e-01,  ..., -1.9776e-01,\n",
       "               2.7369e-01, -1.9171e-01]],\n",
       "  \n",
       "            [[-2.8028e-02,  8.4329e-02, -7.4562e-02,  ...,  1.1567e-01,\n",
       "               4.5594e-02,  5.4924e-02],\n",
       "             [-1.5705e-01, -1.3401e+00, -1.5046e+00,  ..., -1.4752e+00,\n",
       "               5.2599e-01,  1.6321e+00],\n",
       "             [ 4.3184e-01,  2.3969e-01, -8.8045e-01,  ..., -2.0772e+00,\n",
       "               1.4693e+00,  8.0424e-01],\n",
       "             ...,\n",
       "             [-1.1475e-01, -3.9556e-02, -2.5399e-01,  ..., -8.1381e-01,\n",
       "               2.5289e-01,  5.5467e-01],\n",
       "             [ 2.7709e-02, -2.2001e+00, -1.2571e+00,  ..., -1.8843e+00,\n",
       "               2.2824e-01,  1.2075e+00],\n",
       "             [-1.0162e-01, -5.9535e-02, -2.6836e-01,  ..., -7.9802e-01,\n",
       "               1.9247e-01,  5.9190e-01]],\n",
       "  \n",
       "            [[-1.1343e-01, -2.1909e-02,  1.3382e-01,  ...,  5.6986e-02,\n",
       "              -2.1418e-01, -6.8748e-02],\n",
       "             [ 6.5334e-01,  1.3428e+00, -1.5310e-01,  ..., -2.3468e-01,\n",
       "               2.0447e-01,  3.7732e-01],\n",
       "             [ 6.7185e-01,  3.5975e-01,  2.5317e-01,  ...,  5.9677e-01,\n",
       "              -1.3562e+00,  7.8783e-01],\n",
       "             ...,\n",
       "             [ 7.2587e-01, -1.9175e-02, -1.8541e-01,  ...,  4.8094e-01,\n",
       "              -4.2995e-01,  7.1530e-01],\n",
       "             [ 5.5944e-01,  6.2292e-01,  1.6546e-01,  ...,  8.0500e-02,\n",
       "               1.5836e-01,  1.7326e-01],\n",
       "             [ 6.9656e-01, -7.5633e-02, -2.3236e-01,  ...,  4.6187e-01,\n",
       "              -4.0555e-01,  7.0178e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 2.5721e-01,  1.2138e+00,  8.1850e-02,  ..., -1.5436e-02,\n",
       "              -2.6535e-02, -3.3984e-01],\n",
       "             [ 5.7023e-01, -1.6326e+00, -1.3452e+00,  ..., -9.7856e-01,\n",
       "              -9.3806e-02,  1.1103e-01],\n",
       "             [-6.5884e-01, -7.3669e-01,  5.5879e-01,  ..., -1.6449e+00,\n",
       "               1.3863e+00,  5.7571e-01],\n",
       "             ...,\n",
       "             [-2.5891e+00,  3.6271e+00,  7.8342e-01,  ..., -2.4252e+00,\n",
       "               3.6595e+00,  1.6286e+00],\n",
       "             [-1.9184e+00,  2.8134e+00, -1.8229e-01,  ..., -3.1005e+00,\n",
       "               2.8074e+00,  1.3658e+00],\n",
       "             [-2.6316e+00,  3.7973e+00,  7.7992e-01,  ..., -2.4313e+00,\n",
       "               3.6154e+00,  1.5645e+00]],\n",
       "  \n",
       "            [[-3.5678e-01, -2.6492e-01, -1.1649e-01,  ..., -1.0741e-01,\n",
       "               4.2998e-01, -9.8164e-02],\n",
       "             [ 3.8823e-01, -1.8031e+00, -1.3167e+00,  ...,  1.5703e+00,\n",
       "              -7.4182e-01,  2.3385e-01],\n",
       "             [ 3.9244e-01, -1.6642e+00, -7.6806e-01,  ...,  1.1689e+00,\n",
       "               4.5848e-02, -7.8316e-01],\n",
       "             ...,\n",
       "             [-1.3631e+00, -2.9359e+00,  9.6263e-01,  ..., -3.9056e-01,\n",
       "               5.3526e+00, -2.1709e+00],\n",
       "             [-1.0622e+00, -4.5258e+00,  6.2185e-01,  ...,  7.7345e-02,\n",
       "               4.8630e+00, -1.9212e+00],\n",
       "             [-1.3845e+00, -2.9444e+00,  1.0412e+00,  ..., -4.3046e-01,\n",
       "               5.4469e+00, -2.1500e+00]],\n",
       "  \n",
       "            [[-7.6571e-02, -2.1862e-02,  3.1526e-01,  ...,  4.8836e-01,\n",
       "               5.6518e-02, -2.0227e+00],\n",
       "             [-8.5462e-01,  7.1048e-01, -1.4530e+00,  ...,  5.4351e-01,\n",
       "              -3.4837e-01,  3.8102e+00],\n",
       "             [ 1.6520e+00, -7.6158e-01, -7.2883e-01,  ...,  3.7667e-01,\n",
       "              -8.7408e-02,  2.4233e+00],\n",
       "             ...,\n",
       "             [ 2.1690e+00, -1.6134e+00, -1.6237e+00,  ..., -1.6497e+00,\n",
       "              -8.1387e-02, -1.5496e+00],\n",
       "             [ 2.0887e+00, -3.2867e-01, -2.6876e+00,  ..., -1.8665e+00,\n",
       "               1.4759e-01, -6.2026e-01],\n",
       "             [ 2.1724e+00, -1.6319e+00, -1.6827e+00,  ..., -1.6649e+00,\n",
       "              -1.2454e-01, -1.6946e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-4.9549e-01, -9.6223e-01, -1.5773e+00,  ..., -8.9447e-01,\n",
       "              -1.6752e+00,  7.5425e-01],\n",
       "             [ 1.8472e+00,  1.4729e+00, -1.0867e+00,  ...,  1.3627e+00,\n",
       "              -1.8153e+00,  1.2332e+00],\n",
       "             [ 1.2498e+00,  2.6905e-01, -5.3599e-01,  ...,  7.9664e-01,\n",
       "              -2.8643e+00,  9.6770e-01],\n",
       "             ...,\n",
       "             [-4.3781e-01,  7.7877e-03, -5.2059e-01,  ..., -2.9902e+00,\n",
       "              -7.1555e+00, -3.6680e+00],\n",
       "             [ 7.1942e-01,  8.8740e-01, -8.9328e-01,  ..., -1.6693e+00,\n",
       "              -6.5624e+00, -2.7816e+00],\n",
       "             [-4.9307e-01, -4.5331e-02, -5.8609e-01,  ..., -3.1443e+00,\n",
       "              -7.1759e+00, -3.7997e+00]],\n",
       "  \n",
       "            [[-4.7654e-01, -3.9439e-01, -3.6832e-02,  ..., -7.6317e-02,\n",
       "              -2.8420e-01,  1.1539e+00],\n",
       "             [-1.6546e-01, -3.9656e-01, -2.0579e-01,  ..., -8.3005e-01,\n",
       "               1.1140e-01, -2.6167e+00],\n",
       "             [-1.1353e-01, -3.3726e-01, -6.2611e-01,  ...,  6.2819e-01,\n",
       "              -2.3303e-02, -9.2785e-01],\n",
       "             ...,\n",
       "             [-6.1267e+00,  1.4838e-01,  3.1597e+00,  ...,  8.6293e+00,\n",
       "               3.6374e-01,  4.1481e+00],\n",
       "             [-6.3406e+00,  5.6825e-01,  4.0743e+00,  ...,  7.0162e+00,\n",
       "               4.4845e-01,  3.9556e+00],\n",
       "             [-6.2856e+00,  1.6311e-01,  3.2931e+00,  ...,  8.7034e+00,\n",
       "               3.0326e-01,  4.2933e+00]],\n",
       "  \n",
       "            [[ 7.7467e-02, -2.6303e-01, -5.2029e-01,  ...,  2.1443e+00,\n",
       "               2.2853e+00,  4.4737e-01],\n",
       "             [ 1.7687e+00, -1.7020e-01, -2.1599e+00,  ..., -3.6347e-01,\n",
       "              -2.1461e+00, -8.9899e-01],\n",
       "             [-1.1482e-02, -1.4947e+00, -5.2686e-01,  ...,  1.7061e+00,\n",
       "              -1.1591e+00,  2.6533e-01],\n",
       "             ...,\n",
       "             [ 3.1832e+00, -2.3699e+00,  7.2115e-01,  ...,  1.0088e+01,\n",
       "               6.8950e+00,  1.1676e+00],\n",
       "             [ 4.6007e+00, -1.9037e+00,  1.9926e-01,  ...,  9.2790e+00,\n",
       "               6.8701e+00,  1.2638e+00],\n",
       "             [ 3.2946e+00, -2.3977e+00,  7.5841e-01,  ...,  1.0198e+01,\n",
       "               7.1239e+00,  1.1269e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.6332e-01,  1.4786e-01, -1.1422e-01,  ...,  3.8804e-02,\n",
       "               1.7195e-01, -1.0548e-01],\n",
       "             [-1.6032e-01,  5.5673e-01,  1.0013e+00,  ..., -8.0335e-01,\n",
       "               1.1870e+00, -3.0828e-01],\n",
       "             [ 1.3168e-01,  8.9118e-01,  9.7710e-01,  ..., -2.6267e-01,\n",
       "               9.1514e-01,  4.1614e-01],\n",
       "             ...,\n",
       "             [ 1.2225e-01,  5.3133e-01, -2.5466e-01,  ..., -9.4634e-01,\n",
       "               5.2956e-01,  1.7132e-01],\n",
       "             [-5.8868e-01,  4.4613e-01,  1.3970e-01,  ..., -5.0140e-01,\n",
       "               3.5854e-01,  5.0789e-02],\n",
       "             [ 8.7806e-02,  5.1828e-01, -2.8527e-01,  ..., -9.0446e-01,\n",
       "               4.7059e-01,  2.1138e-01]],\n",
       "  \n",
       "            [[ 1.1702e-01, -6.4699e-02,  3.1676e-02,  ..., -5.7561e-02,\n",
       "               1.1061e-01,  6.0477e-02],\n",
       "             [-1.8498e+00, -1.4362e+00,  2.8411e+00,  ..., -8.4311e-01,\n",
       "               4.4487e-02,  2.3439e+00],\n",
       "             [-9.9192e-01, -1.3068e+00,  1.3063e+00,  ..., -2.5021e-01,\n",
       "               1.6060e+00,  9.6410e-01],\n",
       "             ...,\n",
       "             [-3.5784e-01, -9.1374e-01,  6.8249e-01,  ...,  9.1868e-01,\n",
       "               6.2099e-01,  4.3478e-01],\n",
       "             [-9.0948e-01, -1.7387e+00,  2.6020e+00,  ...,  4.5886e-01,\n",
       "               8.4674e-01,  1.6683e+00],\n",
       "             [-3.9481e-01, -8.7358e-01,  6.8256e-01,  ...,  9.3054e-01,\n",
       "               6.1870e-01,  4.1275e-01]],\n",
       "  \n",
       "            [[ 1.0699e-01, -8.6197e-02, -1.5626e-01,  ..., -3.6686e-02,\n",
       "              -2.8451e-02, -1.8200e-01],\n",
       "             [ 2.0919e+00, -5.7443e-01,  5.0261e-01,  ...,  5.0879e-01,\n",
       "              -4.4538e-01,  1.1994e+00],\n",
       "             [ 1.1740e+00,  1.1131e+00, -1.0803e-01,  ...,  1.5733e+00,\n",
       "               5.6335e-01,  4.2996e-01],\n",
       "             ...,\n",
       "             [ 7.4576e-01,  3.7459e-01,  5.1748e-02,  ...,  5.9791e-01,\n",
       "               6.2805e-01, -2.7986e-03],\n",
       "             [ 1.1941e+00, -6.3472e-01,  4.1449e-01,  ...,  4.0538e-02,\n",
       "              -2.7813e-01,  5.5665e-01],\n",
       "             [ 7.5119e-01,  3.0822e-01,  4.3934e-02,  ...,  6.2068e-01,\n",
       "               6.9509e-01, -1.4949e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 7.0213e-02, -4.6690e-03, -1.3244e-02,  ..., -1.9181e-01,\n",
       "              -5.8565e-02, -1.1433e-01],\n",
       "             [-1.9068e-01,  6.4706e-01,  1.7624e+00,  ..., -1.2610e+00,\n",
       "              -6.0742e-01, -1.6792e-01],\n",
       "             [-2.5184e-01, -1.1926e-01,  3.5495e-02,  ..., -1.5271e+00,\n",
       "              -4.9171e-01,  1.1398e+00],\n",
       "             ...,\n",
       "             [ 1.5809e-01, -1.4623e+00,  2.1308e-01,  ..., -3.6758e-01,\n",
       "              -4.1551e-01, -2.6188e-02],\n",
       "             [-2.4769e-01, -1.0237e+00,  1.2874e+00,  ..., -4.7997e-01,\n",
       "               2.9049e-02, -4.7527e-01],\n",
       "             [ 1.6794e-01, -1.4549e+00,  1.7829e-01,  ..., -3.6329e-01,\n",
       "              -4.1272e-01, -3.8104e-02]],\n",
       "  \n",
       "            [[-1.8465e-01, -1.0772e-01, -6.3472e-02,  ..., -4.8459e-02,\n",
       "              -9.3733e-02,  7.8508e-03],\n",
       "             [-6.5891e-01, -7.6872e-01,  2.0198e+00,  ...,  4.1450e-01,\n",
       "              -1.1445e+00, -4.7673e-01],\n",
       "             [-1.2836e-01, -1.2783e+00,  9.8167e-01,  ..., -5.0068e-01,\n",
       "              -9.8449e-01,  1.7445e+00],\n",
       "             ...,\n",
       "             [-2.9627e-01, -1.3340e+00,  4.8251e-01,  ..., -5.8301e-01,\n",
       "              -6.2550e-01,  1.6966e+00],\n",
       "             [-1.3742e+00, -8.0175e-01,  5.1382e-01,  ..., -1.7461e-01,\n",
       "              -9.7751e-01,  1.4339e-01],\n",
       "             [-2.8782e-01, -1.3493e+00,  4.9810e-01,  ..., -5.6421e-01,\n",
       "              -5.4099e-01,  1.7088e+00]],\n",
       "  \n",
       "            [[ 1.5993e-02, -8.2934e-02, -1.0345e-01,  ...,  6.5070e-02,\n",
       "               2.6188e-02,  3.8959e-02],\n",
       "             [ 4.2417e-01, -1.5099e+00,  1.4649e-02,  ...,  1.4629e-01,\n",
       "              -1.0355e+00, -1.3556e+00],\n",
       "             [ 7.3402e-01, -2.0612e-01, -7.6275e-01,  ...,  1.2663e-01,\n",
       "              -6.5220e-01, -1.2646e+00],\n",
       "             ...,\n",
       "             [ 2.8900e-01, -1.4638e-01, -4.8337e-01,  ...,  6.8739e-01,\n",
       "              -1.4610e+00,  1.6385e-02],\n",
       "             [ 1.2888e-01, -1.1009e+00,  3.7273e-01,  ...,  9.4664e-01,\n",
       "              -1.8511e+00,  3.8415e-01],\n",
       "             [ 2.8724e-01, -1.4473e-01, -4.4987e-01,  ...,  6.7078e-01,\n",
       "              -1.4032e+00,  7.5681e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-1.7468e-01,  1.0717e-01, -7.6040e-01,  ...,  3.0821e-01,\n",
       "               2.8741e-01,  2.9048e-02],\n",
       "             [ 4.2890e-01,  5.4284e-01,  4.4602e+00,  ...,  1.9793e-01,\n",
       "               1.5736e+00, -2.1584e+00],\n",
       "             [-1.5036e+00,  7.6909e-01,  1.0537e+00,  ..., -8.4576e-02,\n",
       "              -3.2861e-02, -7.8621e-01],\n",
       "             ...,\n",
       "             [ 2.4971e-01, -2.6549e-01, -1.8247e+01,  ...,  6.3037e-01,\n",
       "              -3.0734e-01,  1.1628e-01],\n",
       "             [ 1.6194e+00,  2.1027e-01, -1.7676e+01,  ...,  6.1824e-01,\n",
       "               3.2983e-01, -1.0848e+00],\n",
       "             [ 3.0269e-01, -3.2883e-01, -1.8575e+01,  ...,  5.9535e-01,\n",
       "              -2.6633e-01,  1.9165e-01]],\n",
       "  \n",
       "            [[ 5.6240e-01, -6.3630e-01,  1.1905e-02,  ...,  2.0326e-01,\n",
       "               1.9875e-01, -7.6223e-02],\n",
       "             [ 1.6348e+00, -1.4077e-01,  1.3047e-01,  ...,  8.6383e-01,\n",
       "               1.0218e+00,  2.5608e-01],\n",
       "             [ 6.7032e-01, -7.2540e-01, -9.9685e-01,  ...,  7.3853e-01,\n",
       "               4.6462e-02, -3.0084e-01],\n",
       "             ...,\n",
       "             [ 1.0973e+00, -3.2247e-01, -1.3315e+00,  ..., -2.5628e+00,\n",
       "               1.9588e+00,  1.6561e-01],\n",
       "             [ 2.2223e+00,  5.5571e-01, -2.0431e+00,  ..., -2.3944e+00,\n",
       "               1.9723e+00,  4.7768e-01],\n",
       "             [ 1.1568e+00, -3.1824e-01, -1.3313e+00,  ..., -2.6206e+00,\n",
       "               1.9909e+00,  1.3412e-01]],\n",
       "  \n",
       "            [[-1.7560e+00,  1.5315e+00,  1.0415e+00,  ...,  3.5970e-01,\n",
       "               1.6668e+00, -1.1792e+00],\n",
       "             [-1.1854e+00,  1.8038e-01,  8.0481e-01,  ...,  2.2626e-01,\n",
       "              -4.3112e-01, -1.7047e+00],\n",
       "             [ 5.1965e-01,  4.9645e-01, -2.7751e-02,  ...,  1.6743e+00,\n",
       "              -7.3849e-01, -1.1344e+00],\n",
       "             ...,\n",
       "             [ 1.1806e+00, -1.1148e+00, -1.1892e+00,  ...,  3.7135e+00,\n",
       "              -2.4685e+00,  8.7146e-01],\n",
       "             [ 2.7237e-02, -3.8074e-01, -4.3562e-01,  ...,  3.4326e+00,\n",
       "              -1.9947e+00,  7.7859e-01],\n",
       "             [ 1.1604e+00, -1.1115e+00, -1.1292e+00,  ...,  3.6589e+00,\n",
       "              -2.4985e+00,  9.7956e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 2.3085e-01,  5.2260e-02, -2.6409e-01,  ...,  1.0213e-01,\n",
       "               9.6440e-01,  3.3343e-01],\n",
       "             [-5.5340e-01,  4.6812e-02, -3.1486e-01,  ...,  4.3484e-02,\n",
       "              -9.7888e-01,  1.2114e+00],\n",
       "             [-8.7279e-01, -7.8645e-01, -7.8899e-01,  ..., -1.8146e+00,\n",
       "              -1.5181e+00,  2.3942e+00],\n",
       "             ...,\n",
       "             [ 1.1691e+00, -1.0570e+00,  1.2454e+00,  ..., -2.0210e+00,\n",
       "               1.8224e-01,  2.4187e+00],\n",
       "             [ 6.9002e-01, -1.3524e+00,  2.5004e+00,  ..., -1.9812e+00,\n",
       "               7.3888e-01,  2.0485e+00],\n",
       "             [ 1.2013e+00, -1.1386e+00,  1.3503e+00,  ..., -2.0165e+00,\n",
       "               2.3174e-01,  2.4157e+00]],\n",
       "  \n",
       "            [[ 2.1764e-01,  9.4057e-01,  5.6683e-01,  ...,  2.8146e-01,\n",
       "              -6.7593e-02,  9.5767e-01],\n",
       "             [ 5.8316e-01,  1.9273e+00,  2.3725e+00,  ...,  3.3895e-01,\n",
       "              -5.4782e-01,  2.5123e+00],\n",
       "             [ 1.6383e+00,  1.2497e-01,  1.7635e+00,  ..., -6.8835e-01,\n",
       "               1.2507e+00,  1.0928e+00],\n",
       "             ...,\n",
       "             [ 2.7377e+00, -2.4009e+00,  3.7117e+00,  ...,  1.6957e-01,\n",
       "               2.4561e+00, -1.6149e+00],\n",
       "             [ 1.6675e+00, -2.6092e+00,  4.3211e+00,  ...,  1.0568e+00,\n",
       "               1.3674e+00, -6.8008e-01],\n",
       "             [ 2.7063e+00, -2.4350e+00,  3.7069e+00,  ...,  1.7959e-01,\n",
       "               2.4409e+00, -1.6400e+00]],\n",
       "  \n",
       "            [[-1.1778e-01, -2.5513e-01, -1.5417e-01,  ...,  2.8240e-01,\n",
       "               5.9684e-01, -2.1728e-01],\n",
       "             [-8.0560e-01,  5.4791e-02,  5.7660e-01,  ..., -1.6531e+00,\n",
       "               2.5050e-01,  1.4666e+00],\n",
       "             [ 8.1632e-01,  1.5964e+00, -1.2875e+00,  ...,  2.1482e-01,\n",
       "              -1.6551e+00, -1.0226e-01],\n",
       "             ...,\n",
       "             [ 1.9715e+00,  2.5392e+00, -2.0742e+00,  ..., -2.0154e+00,\n",
       "              -1.0214e+00, -3.0341e+00],\n",
       "             [ 6.0310e-01,  2.2108e+00, -2.0675e+00,  ..., -2.1962e+00,\n",
       "              -5.8974e-01, -2.5049e+00],\n",
       "             [ 2.0665e+00,  2.5266e+00, -2.0451e+00,  ..., -2.1100e+00,\n",
       "              -1.0499e+00, -3.0856e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-4.5566e-02, -1.7480e-02, -3.8891e-02,  ...,  3.6865e-02,\n",
       "              -5.5307e-02, -7.1500e-02],\n",
       "             [ 6.2637e-01,  2.5595e-01,  6.6446e-01,  ..., -1.7559e+00,\n",
       "              -1.8878e-01,  5.3419e-01],\n",
       "             [-7.7922e-01,  1.3548e-01,  8.6319e-01,  ..., -6.4873e-01,\n",
       "              -2.8578e-01, -3.3432e-01],\n",
       "             ...,\n",
       "             [-1.0011e+00,  1.6430e-01, -2.5699e-01,  ..., -3.6857e-01,\n",
       "              -3.2400e-01, -4.7606e-01],\n",
       "             [ 9.6577e-02,  5.4291e-01,  2.0008e-01,  ..., -8.8246e-01,\n",
       "               5.1083e-01, -2.2739e-01],\n",
       "             [-9.7745e-01,  1.7431e-01, -2.9558e-01,  ..., -3.2513e-01,\n",
       "              -2.4526e-01, -4.8195e-01]],\n",
       "  \n",
       "            [[-1.2290e-01,  1.1081e-01, -4.3613e-02,  ...,  1.5664e-01,\n",
       "              -1.3631e-01,  3.4497e-02],\n",
       "             [-5.2788e-01, -7.9282e-01,  1.1273e+00,  ..., -1.0951e+00,\n",
       "               3.4573e-01, -6.2041e-01],\n",
       "             [ 2.0018e-02, -1.5128e+00,  1.2531e+00,  ...,  3.4519e-01,\n",
       "               2.3076e+00, -1.0036e+00],\n",
       "             ...,\n",
       "             [ 7.1103e-01, -1.4989e+00,  3.9438e-01,  ..., -8.2604e-02,\n",
       "               1.0878e+00, -1.1895e+00],\n",
       "             [-4.7197e-01, -6.9099e-01,  8.4547e-01,  ..., -1.1704e+00,\n",
       "               2.9250e-01, -9.6097e-01],\n",
       "             [ 6.9305e-01, -1.4659e+00,  4.1487e-01,  ..., -1.2832e-01,\n",
       "               9.6341e-01, -1.1758e+00]],\n",
       "  \n",
       "            [[-4.0915e-02, -2.5827e-02, -3.8340e-02,  ...,  6.5657e-02,\n",
       "              -6.5066e-02, -7.1902e-02],\n",
       "             [ 9.2164e-01, -1.4168e+00, -4.8031e-01,  ...,  6.4627e-01,\n",
       "              -9.3983e-01,  1.5531e+00],\n",
       "             [ 3.2302e-01,  6.6319e-01,  5.3836e-02,  ..., -9.4950e-01,\n",
       "               7.1307e-01, -2.3200e-01],\n",
       "             ...,\n",
       "             [ 9.8054e-02,  4.0679e-01,  4.1275e-01,  ..., -1.6196e-01,\n",
       "               9.0045e-01,  8.5608e-02],\n",
       "             [ 9.1775e-01, -1.7935e-01, -4.4064e-01,  ...,  1.0792e+00,\n",
       "              -2.4329e-01,  2.4545e-01],\n",
       "             [ 1.1315e-01,  4.2112e-01,  4.0122e-01,  ..., -1.0363e-01,\n",
       "               9.1427e-01,  1.2911e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-2.0744e-02,  6.6681e-02,  4.2876e-02,  ...,  6.3183e-02,\n",
       "               7.4517e-02, -2.1804e-02],\n",
       "             [ 1.2956e+00, -6.0599e-01, -7.3705e-01,  ..., -1.3554e+00,\n",
       "               1.1951e+00,  7.5260e-01],\n",
       "             [ 5.7595e-01, -6.3402e-01, -1.0337e+00,  ..., -1.4194e+00,\n",
       "              -3.7618e-01, -3.3896e-01],\n",
       "             ...,\n",
       "             [ 1.8955e-01, -8.5672e-01, -1.2462e+00,  ..., -7.5994e-01,\n",
       "              -4.3447e-01, -6.0162e-01],\n",
       "             [ 1.1331e+00, -3.4510e-01, -1.1935e+00,  ..., -1.7561e+00,\n",
       "               7.0557e-01,  2.1363e-01],\n",
       "             [ 2.3032e-01, -8.7259e-01, -1.2628e+00,  ..., -7.7210e-01,\n",
       "              -4.1047e-01, -5.7558e-01]],\n",
       "  \n",
       "            [[ 3.2518e-04,  3.7154e-02,  1.2617e-01,  ..., -3.2091e-02,\n",
       "               7.7207e-02,  1.2766e-01],\n",
       "             [ 9.3514e-01, -1.7814e-01, -2.8198e+00,  ...,  7.3082e-01,\n",
       "              -3.8584e-01, -1.1399e+00],\n",
       "             [ 3.0442e-01,  9.3584e-01,  8.9384e-02,  ...,  4.6791e-01,\n",
       "               4.5719e-01, -2.7641e-01],\n",
       "             ...,\n",
       "             [ 1.9988e-01,  9.2302e-01,  2.7621e-01,  ..., -4.0096e-01,\n",
       "               1.0985e+00,  2.7633e-01],\n",
       "             [ 1.3093e+00,  3.3545e-01, -1.9330e+00,  ..., -3.2209e-01,\n",
       "               2.5876e-01, -2.9921e-01],\n",
       "             [ 2.4153e-01,  9.2163e-01,  2.8477e-01,  ..., -3.7422e-01,\n",
       "               1.1135e+00,  2.6796e-01]],\n",
       "  \n",
       "            [[-1.4468e-02,  1.3328e-01,  2.9911e-02,  ..., -4.7124e-03,\n",
       "              -4.0540e-02, -2.9560e-02],\n",
       "             [-1.0652e+00,  1.2824e+00,  4.1322e-01,  ...,  8.1307e-01,\n",
       "               2.6433e-01, -4.2133e-01],\n",
       "             [-7.7034e-01,  5.4305e-01, -5.1909e-01,  ...,  1.3205e+00,\n",
       "               1.2389e+00, -1.8216e-01],\n",
       "             ...,\n",
       "             [-3.3312e-01,  6.6690e-01,  1.0034e-01,  ...,  7.7545e-01,\n",
       "               1.4768e-01,  1.3035e-01],\n",
       "             [-1.3296e+00,  1.1827e+00,  8.3366e-01,  ..., -7.6596e-02,\n",
       "               5.9457e-01,  1.6917e-01],\n",
       "             [-4.0216e-01,  6.6990e-01,  1.4997e-01,  ...,  7.6484e-01,\n",
       "               1.2988e-01,  9.3710e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-6.8363e-02,  2.3473e-01, -1.8097e-01,  ...,  2.3013e-01,\n",
       "              -1.4967e-01, -5.4951e-02],\n",
       "             [ 3.0134e-02, -2.0588e-01,  8.5890e-01,  ..., -5.5731e-01,\n",
       "              -2.0551e+00, -4.1907e-01],\n",
       "             [-6.3715e-01,  6.3762e-03,  1.2009e+00,  ...,  1.3735e+00,\n",
       "               3.4252e-02,  2.2617e-01],\n",
       "             ...,\n",
       "             [-5.0931e-01,  1.2689e+00,  6.6942e-01,  ...,  1.5946e+00,\n",
       "              -1.1770e+00, -5.1137e-01],\n",
       "             [-4.7522e-01,  1.2451e+00,  7.3215e-01,  ...,  3.7181e-01,\n",
       "              -2.7636e+00, -1.2014e+00],\n",
       "             [-6.0890e-01,  1.2834e+00,  6.5942e-01,  ...,  1.5900e+00,\n",
       "              -1.2238e+00, -4.8055e-01]],\n",
       "  \n",
       "            [[-2.0398e-01, -4.6946e-02, -6.9316e-02,  ..., -1.3456e-01,\n",
       "              -2.3902e-01,  6.6880e-01],\n",
       "             [-1.2970e+00, -2.2308e-01, -4.1568e-01,  ..., -1.7620e-01,\n",
       "              -6.2372e-01, -1.8557e+00],\n",
       "             [-1.0259e+00,  3.8145e-02, -5.1221e-02,  ..., -3.6907e+00,\n",
       "              -1.4507e+00, -1.5562e+00],\n",
       "             ...,\n",
       "             [-3.7403e+00, -1.2280e+00, -1.4350e+00,  ..., -3.2937e+00,\n",
       "              -1.3203e+00, -2.4295e+00],\n",
       "             [-4.4497e+00, -8.6610e-01, -2.1866e+00,  ..., -1.6010e+00,\n",
       "              -6.3435e-01, -3.3133e+00],\n",
       "             [-3.7603e+00, -1.2771e+00, -1.4538e+00,  ..., -3.1839e+00,\n",
       "              -1.3174e+00, -2.4027e+00]],\n",
       "  \n",
       "            [[ 1.2101e-01, -3.3775e-01, -7.5342e-01,  ...,  1.4288e-01,\n",
       "              -5.7473e-02, -2.2517e-01],\n",
       "             [ 7.1858e-01,  1.0671e+00,  2.5207e+00,  ..., -7.8073e-01,\n",
       "               1.3278e+00,  1.7128e+00],\n",
       "             [-5.5515e-01,  4.5155e-01,  1.2876e+00,  ...,  9.0296e-02,\n",
       "               1.1994e+00,  1.3098e+00],\n",
       "             ...,\n",
       "             [-7.2239e-01,  1.0309e+00, -2.5305e+00,  ...,  3.5632e-01,\n",
       "               1.8742e+00,  2.6916e+00],\n",
       "             [ 9.3721e-03,  2.0874e+00, -2.2025e+00,  ..., -1.8252e-01,\n",
       "               3.1287e+00,  3.2005e+00],\n",
       "             [-6.3847e-01,  1.0943e+00, -2.6169e+00,  ...,  3.9455e-01,\n",
       "               1.9324e+00,  2.7169e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-3.1846e-01, -2.2966e-01, -4.1549e-01,  ...,  2.8118e-01,\n",
       "              -9.1376e-01, -1.3885e-01],\n",
       "             [ 2.2987e+00, -8.6459e-01,  2.8000e+00,  ..., -8.0268e-01,\n",
       "               2.8388e+00,  5.8557e-01],\n",
       "             [ 1.5848e-01, -8.9317e-01,  1.2131e+00,  ...,  3.5174e-02,\n",
       "               1.9402e+00,  7.1297e-01],\n",
       "             ...,\n",
       "             [-3.7386e+00,  3.4965e+00, -6.2242e+00,  ...,  7.6135e-01,\n",
       "              -1.0431e+00,  1.0505e+00],\n",
       "             [-2.5247e+00,  4.0209e+00, -5.4806e+00,  ...,  3.6015e-01,\n",
       "              -3.2000e-01,  7.0123e-01],\n",
       "             [-3.8224e+00,  3.5692e+00, -6.4203e+00,  ...,  7.5984e-01,\n",
       "              -1.2126e+00,  1.0081e+00]],\n",
       "  \n",
       "            [[ 8.2211e-01,  9.1275e-02,  4.2697e-02,  ..., -6.7359e-01,\n",
       "               1.0167e-01,  1.2876e+00],\n",
       "             [-8.9089e-01,  8.4156e-01,  1.2123e+00,  ..., -8.7723e-01,\n",
       "               5.6888e-01,  2.3910e-01],\n",
       "             [-5.4239e-01,  9.3615e-01,  1.0040e-01,  ..., -2.1924e+00,\n",
       "               4.9205e-02, -5.1112e-01],\n",
       "             ...,\n",
       "             [ 3.7273e+00,  1.4250e-01, -5.9669e+00,  ..., -1.0485e+00,\n",
       "               9.4365e-01, -1.1212e-01],\n",
       "             [ 3.9569e+00, -4.9953e-01, -6.4824e+00,  ..., -1.4632e+00,\n",
       "               1.2777e+00, -3.2002e-01],\n",
       "             [ 3.8552e+00,  1.0124e-01, -6.0035e+00,  ..., -1.0735e+00,\n",
       "               9.6882e-01, -1.1187e-01]],\n",
       "  \n",
       "            [[-3.7398e-01,  2.5305e-02,  9.7201e-01,  ...,  2.3895e-01,\n",
       "              -5.1968e-01,  6.8140e-01],\n",
       "             [ 1.1778e-01,  4.4421e-01, -2.7052e-01,  ...,  2.0774e+00,\n",
       "              -7.1972e-01,  1.1630e-01],\n",
       "             [ 1.0886e-01, -1.1758e+00, -1.5168e-01,  ...,  1.3644e+00,\n",
       "              -1.7472e+00,  4.0572e-01],\n",
       "             ...,\n",
       "             [ 5.7748e+00,  6.8894e+00,  9.0955e+00,  ..., -3.7789e+00,\n",
       "              -3.3661e+00, -6.2968e-01],\n",
       "             [ 6.8790e+00,  8.0774e+00,  1.0206e+01,  ..., -3.0138e+00,\n",
       "              -3.8751e+00, -9.1797e-01],\n",
       "             [ 5.9551e+00,  7.1900e+00,  9.2815e+00,  ..., -4.0185e+00,\n",
       "              -3.4386e+00, -6.5133e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-4.2885e-02, -1.2107e-01, -1.5820e-01,  ...,  2.0636e-01,\n",
       "               2.8759e-01,  7.4576e-02],\n",
       "             [ 1.1971e-01, -6.6895e-01, -1.8416e+00,  ...,  5.7289e-01,\n",
       "              -2.0339e-01,  1.3873e-02],\n",
       "             [-1.2138e+00,  3.6421e-01, -1.3385e+00,  ...,  4.9920e-01,\n",
       "               7.7398e-01, -7.5725e-01],\n",
       "             ...,\n",
       "             [-7.6551e-01,  1.4908e+00, -1.0417e+00,  ...,  9.3507e-01,\n",
       "               1.6497e+00,  4.3018e-02],\n",
       "             [-7.0337e-01,  1.1566e+00, -1.0160e+00,  ...,  1.4911e+00,\n",
       "               1.0859e+00,  6.0557e-01],\n",
       "             [-7.1998e-01,  1.4543e+00, -9.9271e-01,  ...,  9.9563e-01,\n",
       "               1.6108e+00,  3.3358e-02]],\n",
       "  \n",
       "            [[ 4.7294e-02,  1.2589e-02,  1.3605e-01,  ...,  7.8787e-03,\n",
       "               2.9382e-02, -2.9296e-02],\n",
       "             [-2.4300e-01,  3.3368e-01,  1.4025e-01,  ..., -1.6096e+00,\n",
       "               8.4775e-01,  1.0206e+00],\n",
       "             [ 2.5166e-01, -2.8205e-01, -4.3210e-01,  ..., -1.9428e+00,\n",
       "               2.0017e+00, -1.9764e-01],\n",
       "             ...,\n",
       "             [ 8.7309e-01,  1.3881e-01, -2.1979e-01,  ..., -1.5756e+00,\n",
       "               8.6083e-01, -7.9376e-01],\n",
       "             [-4.2063e-01,  3.9164e-01,  1.1048e-01,  ..., -1.2903e+00,\n",
       "               6.9103e-01,  8.6336e-01],\n",
       "             [ 8.5124e-01,  1.1466e-01, -1.6801e-01,  ..., -1.5125e+00,\n",
       "               8.3840e-01, -7.4542e-01]],\n",
       "  \n",
       "            [[ 1.2611e-01,  3.1437e-03, -7.3591e-02,  ...,  1.3742e-01,\n",
       "              -3.6719e-02, -9.5853e-02],\n",
       "             [ 1.2321e+00, -1.1449e+00, -3.8663e-01,  ...,  8.7898e-01,\n",
       "              -1.2717e+00,  1.0307e+00],\n",
       "             [ 8.4025e-01,  3.0522e-01, -7.7022e-01,  ...,  3.0005e-01,\n",
       "              -5.1376e-01,  1.0424e-01],\n",
       "             ...,\n",
       "             [ 7.1224e-01,  1.7528e-01, -3.9135e-01,  ...,  3.4713e-01,\n",
       "              -3.3522e-01,  2.7083e-01],\n",
       "             [ 4.6691e-01, -7.9861e-01, -5.7115e-01,  ...,  5.0911e-01,\n",
       "               1.2945e-01,  1.1278e+00],\n",
       "             [ 7.2042e-01,  1.2726e-01, -4.5077e-01,  ...,  4.2308e-01,\n",
       "              -2.6290e-01,  2.8119e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 4.6765e-02, -5.6109e-02, -1.3412e-01,  ..., -9.7240e-02,\n",
       "              -5.3328e-02, -3.9770e-02],\n",
       "             [-2.9042e-01,  1.0353e+00,  3.4273e-01,  ..., -6.2273e-01,\n",
       "               7.4122e-01, -1.0529e+00],\n",
       "             [ 3.9952e-02,  1.3833e-01,  6.6181e-02,  ...,  2.2065e-01,\n",
       "              -7.6734e-01, -3.8463e-01],\n",
       "             ...,\n",
       "             [-1.6303e-01,  9.8397e-02,  8.5066e-02,  ...,  8.9085e-01,\n",
       "              -1.0727e-01, -7.3128e-01],\n",
       "             [ 4.0338e-01,  1.1190e+00, -7.2316e-01,  ..., -4.1705e-01,\n",
       "              -4.1264e-01, -7.4593e-01],\n",
       "             [-1.4650e-01,  1.2129e-01,  7.5668e-02,  ...,  8.2638e-01,\n",
       "              -1.1043e-01, -7.1499e-01]],\n",
       "  \n",
       "            [[-5.0889e-02, -4.9232e-03,  3.7780e-02,  ..., -3.1797e-01,\n",
       "              -2.4316e-01,  1.4987e-02],\n",
       "             [-2.5397e-01,  6.5921e-01,  1.3070e+00,  ...,  4.6241e-01,\n",
       "               9.0882e-02,  2.8398e-02],\n",
       "             [-1.3102e+00,  1.0008e+00,  5.2654e-01,  ..., -1.5409e-01,\n",
       "              -1.7296e+00, -2.4269e-01],\n",
       "             ...,\n",
       "             [-7.4463e-01,  8.6569e-02,  3.1618e-02,  ..., -7.7343e-01,\n",
       "              -3.2690e-01, -2.0179e-02],\n",
       "             [ 5.9176e-01,  3.0533e-01,  5.2555e-01,  ..., -3.2570e-01,\n",
       "               1.1459e-01,  2.0796e-01],\n",
       "             [-7.0952e-01,  3.7049e-02,  2.2360e-02,  ..., -7.7559e-01,\n",
       "              -3.0874e-01,  1.1578e-02]],\n",
       "  \n",
       "            [[ 2.9618e-02,  3.8360e-02,  8.3317e-03,  ..., -2.7286e-01,\n",
       "              -4.2066e-02, -3.7188e-02],\n",
       "             [ 5.3378e-01,  1.7853e+00, -8.6738e-01,  ...,  2.3777e-01,\n",
       "               1.1519e+00, -2.4273e-02],\n",
       "             [ 3.9251e-01,  2.1904e-01, -1.6148e-01,  ...,  5.8887e-02,\n",
       "              -3.5234e-01,  1.0769e+00],\n",
       "             ...,\n",
       "             [ 4.3078e-01,  1.1279e-01, -1.4636e-01,  ...,  3.1902e-01,\n",
       "              -2.0811e-01,  8.7018e-01],\n",
       "             [ 1.5142e-01,  5.7969e-01, -1.6673e-01,  ...,  4.2616e-01,\n",
       "               8.8396e-01,  1.0264e+00],\n",
       "             [ 4.7118e-01,  5.4779e-02, -1.4001e-01,  ...,  3.0940e-01,\n",
       "              -1.9915e-01,  8.0427e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-2.4955e-02,  3.8577e-01,  2.8015e-01,  ...,  3.6721e-01,\n",
       "               1.9064e-01, -2.3876e-01],\n",
       "             [ 2.5125e-01, -1.2733e-01, -8.0235e-01,  ..., -4.6622e-01,\n",
       "               1.9686e+00,  1.0569e+00],\n",
       "             [ 2.8510e-01,  5.1489e-02, -1.5954e+00,  ..., -1.7207e-01,\n",
       "               1.2692e+00,  1.1976e-01],\n",
       "             ...,\n",
       "             [-2.5456e-01,  5.9838e-01, -5.5159e-01,  ..., -1.2533e+00,\n",
       "              -7.3917e-02,  4.2924e+00],\n",
       "             [-1.4242e-01,  1.3811e+00, -5.4571e-01,  ..., -8.9925e-01,\n",
       "              -3.9785e-01,  5.4730e+00],\n",
       "             [-2.4730e-01,  6.3387e-01, -4.7063e-01,  ..., -1.2184e+00,\n",
       "              -3.8992e-02,  4.4595e+00]],\n",
       "  \n",
       "            [[-1.9131e-01, -1.1398e-01, -1.6757e-01,  ...,  4.0200e-02,\n",
       "              -1.8549e-01,  9.0757e-02],\n",
       "             [ 4.1804e-01,  9.7727e-01,  7.1425e-01,  ..., -5.6789e-01,\n",
       "              -5.7342e-01,  9.7889e-01],\n",
       "             [-9.6520e-01, -4.1238e-01,  8.1408e-01,  ..., -1.3623e-01,\n",
       "               7.9233e-01,  9.6695e-01],\n",
       "             ...,\n",
       "             [ 7.2722e-03, -1.4795e+00,  1.7848e+00,  ...,  1.2893e+00,\n",
       "               7.8675e-01,  4.8717e-02],\n",
       "             [ 1.4567e-02, -1.5633e+00,  1.6778e+00,  ...,  7.0404e-01,\n",
       "               7.2698e-02,  1.8317e-01],\n",
       "             [ 4.7297e-02, -1.5337e+00,  1.7674e+00,  ...,  1.2655e+00,\n",
       "               8.3135e-01,  5.1514e-02]],\n",
       "  \n",
       "            [[ 3.2747e-01, -8.6707e-02, -1.4488e-01,  ...,  4.4925e-01,\n",
       "              -3.4146e-01,  3.6310e-02],\n",
       "             [ 8.1195e-01,  4.8323e-01, -7.2059e-01,  ..., -4.6087e-01,\n",
       "               1.4376e+00,  2.2213e-01],\n",
       "             [ 3.6785e-01,  3.3558e-01, -3.1029e-01,  ..., -4.0883e-01,\n",
       "               2.5137e+00,  3.6423e-01],\n",
       "             ...,\n",
       "             [ 1.8962e+00,  3.7996e+00, -1.4433e-01,  ...,  3.7024e+00,\n",
       "              -2.5669e+00,  2.5543e+00],\n",
       "             [ 2.4319e+00,  4.4623e+00, -6.1962e-01,  ...,  3.6510e+00,\n",
       "              -3.5980e+00,  3.2528e+00],\n",
       "             [ 1.9951e+00,  3.8396e+00, -2.1976e-01,  ...,  3.8463e+00,\n",
       "              -2.8782e+00,  2.5936e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.1725e-01, -2.1779e-01, -1.8960e-01,  ...,  3.1861e-01,\n",
       "               3.1671e-01,  1.5524e-02],\n",
       "             [-1.2444e+00,  2.4231e-01,  5.5073e-01,  ..., -5.8774e-01,\n",
       "              -8.5408e-01, -1.7633e+00],\n",
       "             [-4.7743e-01, -3.8582e-01,  1.0976e+00,  ..., -2.4307e-01,\n",
       "              -5.0690e-01, -9.9650e-01],\n",
       "             ...,\n",
       "             [-1.0695e+00,  1.0245e+00,  1.7452e+00,  ...,  5.2326e-01,\n",
       "              -8.4779e-01, -1.8184e+00],\n",
       "             [-1.1765e+00,  1.4705e+00,  1.6807e+00,  ..., -7.6910e-01,\n",
       "              -1.3749e+00, -2.8614e+00],\n",
       "             [-1.1527e+00,  1.0473e+00,  1.7507e+00,  ...,  5.2847e-01,\n",
       "              -7.8102e-01, -1.8488e+00]],\n",
       "  \n",
       "            [[-2.1762e-01,  3.3568e-01, -1.6233e-01,  ..., -6.5765e-01,\n",
       "               4.2922e-01, -7.0302e-01],\n",
       "             [-1.7727e+00, -5.9688e-01, -1.4605e+00,  ..., -2.4516e+00,\n",
       "               7.4791e-01,  9.4136e-02],\n",
       "             [-1.1862e+00,  1.9440e+00, -3.6245e-01,  ..., -1.5809e+00,\n",
       "               4.9827e-01,  6.7005e-01],\n",
       "             ...,\n",
       "             [-2.5242e+00,  3.4597e+00,  4.7155e-01,  ..., -8.3066e-01,\n",
       "               1.2267e+00,  1.3677e+00],\n",
       "             [-1.9195e+00,  1.7770e+00, -9.2155e-01,  ..., -1.9264e+00,\n",
       "               1.6124e+00,  9.0136e-01],\n",
       "             [-2.4809e+00,  3.4660e+00,  4.7123e-01,  ..., -8.4369e-01,\n",
       "               1.2412e+00,  1.3494e+00]],\n",
       "  \n",
       "            [[-3.1883e-01, -1.7511e-01, -1.6445e-01,  ...,  9.8513e-02,\n",
       "               2.0126e-01,  3.1801e-01],\n",
       "             [ 1.1070e+00, -1.5935e+00, -2.4602e-01,  ..., -8.2626e-01,\n",
       "               8.4036e-01, -1.6332e+00],\n",
       "             [ 2.8565e-01, -4.2543e-01, -9.1148e-01,  ...,  3.5443e-01,\n",
       "               9.5425e-01,  3.4728e-01],\n",
       "             ...,\n",
       "             [ 1.2397e-01, -6.4325e-01,  2.9638e-01,  ..., -2.2534e-01,\n",
       "               2.2002e+00,  5.0860e+00],\n",
       "             [ 7.1293e-01, -2.1270e+00,  2.6220e-01,  ...,  1.7734e-02,\n",
       "               1.7432e+00,  4.6476e+00],\n",
       "             [ 9.4910e-02, -6.2242e-01,  3.6751e-01,  ..., -1.8507e-01,\n",
       "               2.1614e+00,  5.2033e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 4.2250e-02,  5.0168e-02,  1.8583e-01,  ..., -1.2491e-01,\n",
       "              -1.2075e-01, -9.9351e-02],\n",
       "             [ 8.9135e-01, -3.7804e-01, -7.4224e-02,  ...,  1.8145e+00,\n",
       "              -9.0233e-02,  3.3136e-01],\n",
       "             [ 8.3002e-01, -1.5926e-01,  8.7375e-01,  ..., -2.1030e-02,\n",
       "              -6.1785e-01, -2.1124e-01],\n",
       "             ...,\n",
       "             [ 9.0745e-01, -8.4917e-01,  7.9817e-01,  ..., -3.3964e-01,\n",
       "              -4.9278e-01, -6.9301e-01],\n",
       "             [ 8.6314e-01, -5.3071e-01,  7.0246e-01,  ...,  1.5704e+00,\n",
       "              -6.0517e-01,  4.2361e-01],\n",
       "             [ 9.0642e-01, -8.4196e-01,  8.4113e-01,  ..., -3.4844e-01,\n",
       "              -4.5786e-01, -6.5748e-01]],\n",
       "  \n",
       "            [[ 6.8843e-02, -3.4312e-02,  1.1653e-01,  ...,  2.8305e-03,\n",
       "               1.8918e-01,  1.6803e-01],\n",
       "             [ 7.9128e-01,  5.6126e-01,  3.2284e-01,  ...,  1.2917e+00,\n",
       "               1.0787e+00, -5.7739e-01],\n",
       "             [ 1.7619e-01,  1.7284e-01,  5.3417e-02,  ..., -8.9633e-01,\n",
       "               1.2142e+00,  1.5870e-02],\n",
       "             ...,\n",
       "             [ 6.3668e-01,  9.8275e-01, -1.7126e-01,  ..., -1.4113e-01,\n",
       "               1.7819e+00,  2.6439e-02],\n",
       "             [-1.7387e-01,  1.0414e+00, -2.5323e-01,  ...,  7.7625e-01,\n",
       "               1.6442e+00, -3.3496e-01],\n",
       "             [ 6.5011e-01,  9.4777e-01, -1.7463e-01,  ..., -1.3352e-01,\n",
       "               1.7757e+00,  6.0550e-02]],\n",
       "  \n",
       "            [[ 4.8726e-02, -7.4730e-03,  1.2723e-01,  ..., -4.8515e-02,\n",
       "               8.2777e-02, -9.4125e-02],\n",
       "             [-7.5361e-01,  5.9208e-01,  3.8427e-01,  ...,  8.1735e-01,\n",
       "              -6.6898e-01, -1.0737e-01],\n",
       "             [-7.0942e-01,  7.7838e-01,  5.4821e-01,  ...,  1.1840e-01,\n",
       "               4.2942e-01,  3.2433e-01],\n",
       "             ...,\n",
       "             [-4.4041e-01, -3.7385e-01,  5.3134e-02,  ...,  1.3888e-01,\n",
       "               2.8167e-01,  9.5426e-01],\n",
       "             [-6.0928e-01, -4.4753e-01, -4.8937e-02,  ...,  9.0892e-02,\n",
       "              -5.0845e-01,  4.8503e-01],\n",
       "             [-4.2209e-01, -3.9506e-01,  5.1358e-02,  ...,  1.1986e-01,\n",
       "               2.4777e-01,  9.8372e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-5.2235e-03, -1.2553e-01,  8.3080e-03,  ..., -5.1718e-02,\n",
       "              -1.1923e-02,  2.9005e-02],\n",
       "             [-1.1340e+00, -2.3374e-01, -2.1158e+00,  ...,  1.3871e-01,\n",
       "              -2.7347e+00, -1.5221e+00],\n",
       "             [-1.0410e+00, -5.7328e-01,  4.0415e-01,  ...,  1.9808e-01,\n",
       "               5.3024e-01, -9.3553e-01],\n",
       "             ...,\n",
       "             [-1.5851e-02, -6.9414e-01,  1.0032e+00,  ..., -1.0471e-01,\n",
       "               7.6869e-01,  1.7194e-01],\n",
       "             [-2.5266e-01, -3.1722e-02, -6.0867e-01,  ..., -3.0899e-01,\n",
       "              -2.3465e+00,  1.1645e-01],\n",
       "             [-5.2057e-02, -7.3095e-01,  1.0170e+00,  ..., -1.3583e-01,\n",
       "               7.5799e-01,  2.1820e-01]],\n",
       "  \n",
       "            [[-9.5237e-02,  1.0166e-01, -4.5621e-02,  ..., -1.3682e-01,\n",
       "              -4.5252e-02, -7.4323e-02],\n",
       "             [-1.0420e+00, -2.3487e+00, -2.4052e+00,  ..., -2.1206e+00,\n",
       "               1.6993e+00, -5.3463e-01],\n",
       "             [ 7.7381e-01, -1.5026e+00, -2.3097e-01,  ..., -1.1356e+00,\n",
       "               7.5040e-01, -6.3723e-01],\n",
       "             ...,\n",
       "             [-6.7290e-02, -4.9291e-01,  5.6384e-01,  ...,  5.7656e-03,\n",
       "               3.1572e-01, -1.4450e+00],\n",
       "             [ 4.6952e-01, -1.1270e+00, -1.1987e+00,  ..., -1.0248e+00,\n",
       "               1.3965e+00, -8.3618e-01],\n",
       "             [-2.6378e-02, -4.3790e-01,  5.4692e-01,  ..., -5.2463e-03,\n",
       "               2.5328e-01, -1.4716e+00]],\n",
       "  \n",
       "            [[ 1.4156e-01,  1.0304e-01,  5.9696e-02,  ..., -4.3525e-02,\n",
       "               2.4092e-02, -3.3962e-02],\n",
       "             [ 6.8187e-02,  5.5612e-01, -7.5028e-01,  ..., -3.4026e-01,\n",
       "               2.9871e-01, -1.4040e+00],\n",
       "             [ 4.5204e-01,  3.0772e-01, -1.2906e-01,  ..., -1.0082e+00,\n",
       "              -2.6068e-01, -8.4508e-01],\n",
       "             ...,\n",
       "             [ 8.5006e-01,  1.0708e-01, -4.5580e-01,  ..., -5.0894e-01,\n",
       "              -8.9236e-02, -7.4427e-01],\n",
       "             [-6.1613e-01,  3.1678e-01, -7.9129e-01,  ..., -3.8556e-01,\n",
       "               8.8199e-04, -1.3910e+00],\n",
       "             [ 8.0914e-01,  1.1730e-01, -4.7282e-01,  ..., -5.1120e-01,\n",
       "              -1.0140e-01, -7.3145e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 1.6141e-02,  4.0214e-01, -2.0166e-01,  ...,  1.6615e-01,\n",
       "               2.5353e-01, -6.4479e-01],\n",
       "             [ 8.0857e-01, -3.6461e-02, -1.1835e+00,  ..., -1.9934e-01,\n",
       "              -1.7127e+00,  4.0425e-01],\n",
       "             [ 9.6605e-01, -8.8255e-01,  4.7908e-01,  ...,  5.2032e-01,\n",
       "              -1.9165e+00, -1.3385e+00],\n",
       "             ...,\n",
       "             [ 4.2081e+00, -4.3530e-01,  1.4359e+00,  ...,  3.9579e+00,\n",
       "               4.7798e+00, -1.0570e+00],\n",
       "             [ 4.5705e+00,  4.0026e-01,  7.7374e-01,  ...,  3.6120e+00,\n",
       "               5.2667e+00, -1.3971e-01],\n",
       "             [ 4.3024e+00, -3.5679e-01,  1.4794e+00,  ...,  3.9988e+00,\n",
       "               5.0204e+00, -1.1465e+00]],\n",
       "  \n",
       "            [[-1.1129e-01, -5.0358e-01,  3.5406e-01,  ..., -2.7672e-01,\n",
       "              -4.6886e-01,  1.9271e-01],\n",
       "             [-3.0500e-01,  5.2277e+00,  5.3263e-01,  ...,  1.9336e+00,\n",
       "               1.1235e+00,  7.0536e-01],\n",
       "             [ 3.4710e-01,  2.8968e+00,  1.6316e+00,  ...,  6.5483e-01,\n",
       "               8.1731e-01,  3.8100e-03],\n",
       "             ...,\n",
       "             [-2.4028e+00, -5.6856e+00,  5.9516e+00,  ..., -9.8585e-02,\n",
       "               3.7800e+00, -6.2792e-01],\n",
       "             [-3.3216e+00, -4.8009e+00,  6.5393e+00,  ...,  1.1598e+00,\n",
       "               3.9386e+00,  1.3036e-01],\n",
       "             [-2.5365e+00, -5.9112e+00,  5.9930e+00,  ..., -1.2175e-01,\n",
       "               3.7828e+00, -5.7390e-01]],\n",
       "  \n",
       "            [[ 1.5179e-01, -4.6314e-02, -1.6434e-01,  ..., -1.9313e-01,\n",
       "              -5.5654e-01, -3.4469e-01],\n",
       "             [-1.1374e-02, -2.2429e+00,  1.1760e-01,  ...,  3.0295e-01,\n",
       "              -6.4599e-01, -1.5921e+00],\n",
       "             [-7.9938e-01, -1.3096e+00,  8.3456e-02,  ..., -1.8451e+00,\n",
       "              -1.5635e+00, -1.3109e+00],\n",
       "             ...,\n",
       "             [-7.1534e-01, -3.3939e+00, -2.6312e-01,  ..., -1.7791e+00,\n",
       "              -3.6649e+00, -2.8745e+00],\n",
       "             [ 1.4202e-02, -4.1120e+00,  4.3337e-01,  ..., -1.2172e+00,\n",
       "              -2.8369e+00, -2.2511e+00],\n",
       "             [-6.5960e-01, -3.4302e+00, -2.5048e-01,  ..., -1.7801e+00,\n",
       "              -3.7233e+00, -2.8359e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 9.5145e-02, -1.4019e-02,  1.6208e-01,  ...,  1.4838e-01,\n",
       "              -6.9859e-02, -2.1973e-01],\n",
       "             [ 5.1006e-01, -1.0189e+00,  1.6536e+00,  ..., -2.2259e-02,\n",
       "              -5.9242e-01,  2.5183e-01],\n",
       "             [ 7.2814e-01, -5.6520e-01,  1.0891e+00,  ..., -3.2481e-01,\n",
       "              -7.0000e-01,  5.2532e-01],\n",
       "             ...,\n",
       "             [ 3.6993e+00, -2.8455e+00, -3.3613e-02,  ..., -4.1317e-01,\n",
       "              -5.0132e-01, -1.8119e+00],\n",
       "             [ 5.1440e+00, -3.5246e+00, -4.3941e-01,  ...,  3.9153e-01,\n",
       "              -7.9707e-01, -2.3939e+00],\n",
       "             [ 3.8572e+00, -2.8988e+00, -2.0321e-02,  ..., -4.0340e-01,\n",
       "              -5.2071e-01, -1.8964e+00]],\n",
       "  \n",
       "            [[ 2.2533e-01, -1.1276e-01,  2.4039e-01,  ...,  2.4186e-01,\n",
       "               3.9230e-03,  1.3308e-01],\n",
       "             [ 1.8568e+00, -7.0363e-01,  5.6584e-01,  ..., -9.5466e-01,\n",
       "              -7.0394e-01,  7.9250e-01],\n",
       "             [ 7.9223e-01, -5.1518e-01,  1.4123e-01,  ...,  3.0214e-01,\n",
       "              -2.0003e+00, -1.3828e-01],\n",
       "             ...,\n",
       "             [ 4.9774e+00, -1.0434e+00, -6.5068e-01,  ..., -2.6522e-01,\n",
       "              -1.9447e+00,  1.3932e+00],\n",
       "             [ 7.0939e+00, -4.5766e-01, -5.8808e-01,  ..., -1.1504e+00,\n",
       "              -1.2180e+00,  1.2815e+00],\n",
       "             [ 5.1196e+00, -1.0972e+00, -6.2979e-01,  ..., -4.3470e-01,\n",
       "              -1.9564e+00,  1.4618e+00]],\n",
       "  \n",
       "            [[ 1.9628e-01, -2.1743e-01, -5.4668e-01,  ..., -1.5320e-01,\n",
       "              -2.7920e-01,  2.3376e-01],\n",
       "             [ 1.2563e+00,  3.3390e+00, -7.0119e-01,  ..., -6.6875e-01,\n",
       "              -9.8511e-01, -3.8920e-01],\n",
       "             [ 5.3804e-01,  2.1276e+00, -8.1373e-01,  ..., -7.7831e-01,\n",
       "               8.3867e-01,  1.0519e+00],\n",
       "             ...,\n",
       "             [-1.4767e+00,  6.1488e-01, -1.5700e+00,  ...,  1.3528e+00,\n",
       "               1.8489e-01,  2.0690e+00],\n",
       "             [-1.2938e+00,  1.5394e+00, -9.2237e-01,  ...,  4.5599e-01,\n",
       "              -3.9254e-01,  6.7409e-01],\n",
       "             [-1.5100e+00,  5.1334e-01, -1.5493e+00,  ...,  1.3725e+00,\n",
       "               2.2794e-01,  2.0244e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.4793e-02,  7.3524e-02,  4.5829e-02,  ..., -1.1554e-02,\n",
       "              -5.7882e-02,  5.2907e-02],\n",
       "             [-1.2772e+00, -3.3786e-01, -1.1363e+00,  ...,  1.0080e+00,\n",
       "              -6.9762e-01, -1.7991e-01],\n",
       "             [-9.8204e-01, -3.0691e-01, -3.8778e-01,  ...,  1.8543e-01,\n",
       "              -1.0096e-01,  2.8559e-01],\n",
       "             ...,\n",
       "             [-7.6848e-01, -8.7848e-01, -7.2359e-01,  ..., -7.1192e-01,\n",
       "              -1.1538e-01, -2.3633e-01],\n",
       "             [-1.3124e+00, -9.9143e-01, -1.5553e+00,  ...,  3.7022e-01,\n",
       "              -5.0282e-01, -3.2339e-01],\n",
       "             [-7.5191e-01, -8.9060e-01, -7.4888e-01,  ..., -7.5845e-01,\n",
       "              -9.6685e-02, -2.3739e-01]],\n",
       "  \n",
       "            [[-1.1834e-01, -5.5375e-02,  8.5329e-02,  ..., -1.4903e-01,\n",
       "               2.6376e-02,  1.6399e-01],\n",
       "             [ 6.3696e-01,  1.5603e+00, -6.8002e-01,  ...,  4.9880e-01,\n",
       "              -1.2674e+00, -6.9325e-01],\n",
       "             [ 6.1338e-02,  6.6575e-01, -3.0962e-01,  ...,  1.4828e-01,\n",
       "               8.7651e-01,  1.8279e-01],\n",
       "             ...,\n",
       "             [ 1.6080e-01, -5.2305e-01, -3.2931e-01,  ...,  1.4840e-01,\n",
       "               1.4074e-01,  4.7458e-03],\n",
       "             [-6.3594e-01,  1.3913e-02, -3.1687e-03,  ...,  7.6394e-02,\n",
       "              -3.9832e-01, -3.6468e-01],\n",
       "             [ 4.6908e-02, -5.3697e-01, -3.0798e-01,  ...,  1.4127e-01,\n",
       "               1.6072e-01, -4.2524e-02]],\n",
       "  \n",
       "            [[-9.6596e-02, -2.2499e-01,  2.0475e-01,  ...,  6.6423e-02,\n",
       "              -3.0584e-02,  2.2477e-01],\n",
       "             [-4.7936e-01, -1.1253e+00, -1.0839e+00,  ..., -4.5152e-01,\n",
       "              -9.4806e-02,  5.9853e-02],\n",
       "             [ 6.1400e-01, -6.7186e-01,  4.9245e-01,  ..., -6.7523e-01,\n",
       "               2.2928e-01,  1.5224e+00],\n",
       "             ...,\n",
       "             [ 6.1487e-01, -8.2942e-01,  4.3423e-01,  ..., -3.0143e-01,\n",
       "               4.6173e-01,  7.8557e-01],\n",
       "             [-1.4434e+00, -1.7917e-01, -5.9628e-01,  ..., -1.2410e-01,\n",
       "               3.3434e-01, -2.2182e-02],\n",
       "             [ 5.7284e-01, -7.9262e-01,  3.9897e-01,  ..., -3.0192e-01,\n",
       "               5.2859e-01,  7.6397e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.2443e-03,  8.5336e-02, -1.9872e-01,  ...,  4.0273e-02,\n",
       "              -1.5836e-01, -2.1388e-01],\n",
       "             [-4.1405e-01, -7.2114e-01, -3.8220e-01,  ..., -1.9422e-01,\n",
       "               5.5711e-01, -1.1581e-01],\n",
       "             [-5.1784e-01, -1.0053e-01, -2.1552e+00,  ...,  1.0807e+00,\n",
       "              -1.6824e+00, -1.3177e+00],\n",
       "             ...,\n",
       "             [-6.9235e-01, -6.1264e-01, -9.7350e-01,  ..., -6.7548e-03,\n",
       "              -1.1592e+00, -1.8305e+00],\n",
       "             [-7.5757e-01, -3.3887e-01, -6.8633e-01,  ..., -3.2268e-01,\n",
       "               1.2986e+00,  1.8509e-01],\n",
       "             [-6.9719e-01, -5.5009e-01, -9.4186e-01,  ..., -1.0114e-02,\n",
       "              -1.1904e+00, -1.7452e+00]],\n",
       "  \n",
       "            [[-8.8972e-03,  4.0978e-02, -1.3444e-01,  ...,  7.5752e-02,\n",
       "              -2.2658e-01,  3.1502e-03],\n",
       "             [ 4.1815e-01, -5.8090e-01, -2.9797e-01,  ...,  7.1130e-01,\n",
       "               7.8117e-01,  1.2556e+00],\n",
       "             [ 8.4496e-01, -7.0487e-01, -5.1064e-01,  ..., -7.1248e-01,\n",
       "               1.2750e+00,  6.7227e-01],\n",
       "             ...,\n",
       "             [ 5.5512e-01, -1.8391e+00, -9.0667e-01,  ..., -5.9074e-01,\n",
       "               8.6677e-01,  1.5167e-01],\n",
       "             [-1.0410e-01, -9.6551e-01, -7.8450e-01,  ...,  1.7369e-01,\n",
       "               2.4163e-01,  5.1076e-01],\n",
       "             [ 5.6207e-01, -1.8085e+00, -8.5340e-01,  ..., -5.7552e-01,\n",
       "               7.6965e-01,  1.8303e-01]],\n",
       "  \n",
       "            [[-5.1970e-02, -4.6209e-02,  1.6716e-01,  ...,  1.0012e-01,\n",
       "              -2.4189e-02, -3.5561e-02],\n",
       "             [ 1.2953e+00,  4.1384e-01, -3.6409e-01,  ...,  1.2637e-01,\n",
       "              -1.8758e+00,  3.0507e-01],\n",
       "             [ 3.4642e-01, -6.4915e-01,  8.6135e-01,  ..., -7.9244e-01,\n",
       "               8.5907e-01, -1.3510e+00],\n",
       "             ...,\n",
       "             [-1.3831e-01,  8.3662e-02,  7.0042e-01,  ...,  3.8570e-01,\n",
       "               7.4740e-01, -1.0022e+00],\n",
       "             [ 9.8044e-01,  1.2741e+00,  3.7253e-02,  ...,  8.5164e-01,\n",
       "              -1.0858e+00, -1.0824e-01],\n",
       "             [-1.2115e-01,  1.0846e-01,  7.2400e-01,  ...,  3.6335e-01,\n",
       "               7.2299e-01, -9.2417e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-1.7704e-01,  2.5098e-01, -1.3918e-01,  ...,  1.0624e-01,\n",
       "              -3.9388e-01, -3.4023e-01],\n",
       "             [-1.6987e-01,  1.4030e-01,  1.0399e-01,  ...,  3.1858e-01,\n",
       "              -3.9741e-01,  1.9997e+00],\n",
       "             [-8.0378e-01,  2.6730e-01, -2.9187e-01,  ...,  9.7025e-01,\n",
       "              -5.4433e-01,  2.3530e-01],\n",
       "             ...,\n",
       "             [ 2.3442e-01,  2.5107e+00, -3.5300e+00,  ...,  1.4958e+00,\n",
       "               1.1240e+00, -2.7029e-01],\n",
       "             [ 7.3228e-01,  2.2478e+00, -3.0260e+00,  ...,  1.3465e+00,\n",
       "               1.1869e+00,  1.4907e+00],\n",
       "             [ 3.0713e-01,  2.5970e+00, -3.7267e+00,  ...,  1.4601e+00,\n",
       "               1.1870e+00, -3.0428e-01]],\n",
       "  \n",
       "            [[-4.5692e-01, -4.5598e-01,  4.6643e-01,  ..., -6.5904e-01,\n",
       "              -1.9306e-01, -5.6085e-01],\n",
       "             [ 3.4918e-01, -5.3679e-02, -1.2179e+00,  ..., -4.9807e-01,\n",
       "              -2.1204e-01,  9.1124e-01],\n",
       "             [ 7.9751e-01,  5.2607e-01, -3.4294e-01,  ..., -3.7007e-01,\n",
       "               2.8444e-01, -9.3577e-01],\n",
       "             ...,\n",
       "             [ 2.4496e+00,  1.1858e+00, -3.1055e-01,  ...,  1.0241e+00,\n",
       "              -2.8110e+00, -5.0356e+00],\n",
       "             [ 2.2789e+00,  4.5656e-02, -4.5705e-01,  ...,  1.0229e+00,\n",
       "              -1.8912e+00, -4.4007e+00],\n",
       "             [ 2.4304e+00,  1.1487e+00, -3.6415e-01,  ...,  9.8561e-01,\n",
       "              -2.8631e+00, -5.1554e+00]],\n",
       "  \n",
       "            [[ 1.8130e-01,  2.0221e+00,  1.3832e+00,  ...,  5.1169e-01,\n",
       "               2.4475e-01,  7.3984e-02],\n",
       "             [-7.8292e-01, -2.1030e+00, -1.4412e+00,  ...,  1.3658e+00,\n",
       "              -2.3080e+00,  1.2692e+00],\n",
       "             [-3.3811e-01, -5.7479e-01, -9.9980e-01,  ...,  3.0638e-01,\n",
       "              -1.5366e+00,  1.5604e+00],\n",
       "             ...,\n",
       "             [-2.7012e+00,  1.1177e+01, -6.1279e-02,  ...,  9.2151e-01,\n",
       "              -1.1434e+00,  1.0019e-01],\n",
       "             [-4.1771e+00,  1.0677e+01, -5.1034e-01,  ...,  1.9042e+00,\n",
       "              -2.4349e+00,  1.3552e-01],\n",
       "             [-2.8427e+00,  1.1470e+01, -1.4490e-02,  ...,  9.7658e-01,\n",
       "              -1.1251e+00,  2.8623e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 3.7110e-02,  3.0914e-01,  4.5760e-01,  ...,  1.7316e-01,\n",
       "               8.9155e-03,  7.0790e-02],\n",
       "             [-2.8040e-01,  8.4698e-02,  1.1572e+00,  ...,  3.7928e-01,\n",
       "               7.9117e-01,  1.3659e+00],\n",
       "             [-4.2214e-01,  5.1926e-01,  8.5266e-01,  ...,  1.1217e+00,\n",
       "               4.2534e-01,  1.9072e+00],\n",
       "             ...,\n",
       "             [-3.4201e+00,  3.6615e-01,  3.6774e+00,  ...,  1.3953e+00,\n",
       "              -1.9797e+00,  2.0195e+00],\n",
       "             [-3.7788e+00,  2.4771e-01,  4.0974e+00,  ...,  1.1594e+00,\n",
       "              -2.7271e+00,  2.7430e+00],\n",
       "             [-3.4812e+00,  3.9650e-01,  3.7584e+00,  ...,  1.4194e+00,\n",
       "              -2.0235e+00,  2.0380e+00]],\n",
       "  \n",
       "            [[ 1.8872e-01,  4.7173e-02, -4.8206e-02,  ...,  9.8904e-02,\n",
       "              -9.0675e-03,  3.8710e-02],\n",
       "             [-7.4598e-01,  2.2388e+00,  4.8148e-01,  ...,  1.0424e+00,\n",
       "               1.7593e-01, -5.6965e-01],\n",
       "             [ 1.3636e+00,  2.3075e+00,  1.1324e+00,  ...,  1.4751e+00,\n",
       "               1.5005e+00, -1.4745e-01],\n",
       "             ...,\n",
       "             [ 1.0379e+00,  4.3442e-01,  9.4968e-01,  ...,  6.0330e-01,\n",
       "               1.1024e+00, -1.0083e+00],\n",
       "             [-7.8777e-01,  1.1156e+00,  1.2716e+00,  ...,  5.6302e-02,\n",
       "              -1.4833e-01, -9.6032e-01],\n",
       "             [ 1.0270e+00,  4.1547e-01,  1.0022e+00,  ...,  5.2029e-01,\n",
       "               1.0537e+00, -1.0053e+00]],\n",
       "  \n",
       "            [[ 7.9454e-02,  7.0977e-02,  3.5175e-02,  ...,  5.5455e-02,\n",
       "               3.2942e-01,  2.7173e-01],\n",
       "             [-1.5891e+00,  6.4638e-01,  3.0005e-01,  ..., -1.8071e-01,\n",
       "               1.1370e+00, -1.0484e+00],\n",
       "             [-1.3361e+00,  1.3833e+00, -9.3750e-01,  ...,  5.2912e-02,\n",
       "               2.0330e+00, -1.2787e+00],\n",
       "             ...,\n",
       "             [-4.0762e+00,  8.7766e-01, -2.0543e-01,  ...,  8.0790e-01,\n",
       "               2.6155e+00,  7.3779e-02],\n",
       "             [-4.4705e+00,  1.4958e+00, -2.5387e-01,  ...,  4.4849e-01,\n",
       "               1.4788e+00,  6.9613e-01],\n",
       "             [-4.1150e+00,  9.0303e-01, -2.1573e-01,  ...,  8.5942e-01,\n",
       "               2.6103e+00,  1.9477e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-2.4876e-02,  6.3550e-02,  2.7732e-02,  ...,  1.2231e-03,\n",
       "               2.5960e-01,  8.1726e-03],\n",
       "             [ 1.0898e+00,  2.0889e+00,  9.9452e-01,  ...,  5.2285e-01,\n",
       "              -1.7416e+00,  6.1093e-01],\n",
       "             [ 1.8767e-01,  9.9919e-01, -1.4214e+00,  ..., -8.6920e-01,\n",
       "               2.8190e-01,  4.3446e-01],\n",
       "             ...,\n",
       "             [-3.2562e-01,  1.2323e+00, -1.5686e+00,  ..., -1.9024e-01,\n",
       "               6.0371e-01,  9.4988e-02],\n",
       "             [-3.4477e-01,  2.4342e+00,  1.4290e+00,  ...,  6.3836e-01,\n",
       "              -1.7070e+00,  7.1635e-02],\n",
       "             [-2.8222e-01,  1.2455e+00, -1.5270e+00,  ..., -1.3148e-01,\n",
       "               5.9510e-01,  9.1886e-02]],\n",
       "  \n",
       "            [[ 1.5006e-01,  8.6397e-02, -2.8647e-01,  ..., -7.7012e-02,\n",
       "               9.6815e-02, -1.4891e-01],\n",
       "             [ 1.7671e+00,  1.8874e-02,  4.0821e-01,  ...,  7.5981e-01,\n",
       "               6.7134e-01,  1.3102e+00],\n",
       "             [ 1.0771e+00, -3.3804e-01, -1.2949e+00,  ...,  3.2510e-01,\n",
       "               1.1067e+00, -1.0542e+00],\n",
       "             ...,\n",
       "             [ 1.9251e+00, -1.4540e+00, -6.8589e-01,  ...,  4.9009e-01,\n",
       "               2.9731e-01, -1.1636e+00],\n",
       "             [ 2.6139e+00, -1.1586e+00, -9.8465e-02,  ...,  9.2550e-01,\n",
       "               4.5506e-01,  1.0919e+00],\n",
       "             [ 2.0306e+00, -1.4759e+00, -7.1596e-01,  ...,  5.8672e-01,\n",
       "               3.2487e-01, -1.1108e+00]],\n",
       "  \n",
       "            [[ 1.7615e-01, -7.7676e-02,  7.6348e-03,  ..., -7.3023e-02,\n",
       "               1.6742e-03,  9.7209e-03],\n",
       "             [-1.2699e+00,  2.3622e+00,  2.3304e-01,  ...,  1.2093e+00,\n",
       "              -1.1019e+00,  2.9163e-02],\n",
       "             [-1.5788e-01,  2.2549e+00,  6.3066e-01,  ..., -1.9863e+00,\n",
       "              -4.3600e-01, -7.6353e-02],\n",
       "             ...,\n",
       "             [-6.0184e-01,  8.1608e-01,  4.3826e-01,  ..., -1.9377e+00,\n",
       "              -8.2105e-01,  2.5787e-01],\n",
       "             [-1.8052e+00,  3.0268e+00,  3.5748e-02,  ..., -6.3478e-01,\n",
       "              -1.2507e-01,  2.0221e-01],\n",
       "             [-6.6504e-01,  7.2733e-01,  5.0961e-01,  ..., -1.9192e+00,\n",
       "              -7.7049e-01,  2.6718e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-9.1487e-02, -1.1333e-01,  1.7586e-01,  ..., -1.1592e-01,\n",
       "               1.1683e-01,  1.9515e-01],\n",
       "             [-1.7625e+00, -6.8811e-01, -1.1842e+00,  ...,  1.1516e+00,\n",
       "               5.2354e-01,  2.1580e+00],\n",
       "             [-1.5248e+00,  2.5224e-01, -4.5799e-01,  ..., -7.6002e-01,\n",
       "              -7.3545e-01,  1.8108e+00],\n",
       "             ...,\n",
       "             [-1.3440e+00,  7.2174e-01,  5.9245e-01,  ..., -6.7168e-01,\n",
       "              -3.8330e-01,  5.0656e-01],\n",
       "             [-1.8809e+00, -2.2718e-01, -6.3792e-01,  ...,  5.5448e-01,\n",
       "               8.4136e-01,  1.6922e+00],\n",
       "             [-1.3130e+00,  6.7752e-01,  5.9598e-01,  ..., -7.0757e-01,\n",
       "              -3.8928e-01,  5.3699e-01]],\n",
       "  \n",
       "            [[ 1.5977e-01, -2.4339e-03,  1.7304e-01,  ...,  1.5837e-01,\n",
       "              -5.6212e-02,  7.2709e-02],\n",
       "             [ 7.0068e-01, -2.7764e-01,  1.3608e+00,  ...,  1.6692e+00,\n",
       "               1.2503e+00, -1.0444e+00],\n",
       "             [ 1.6338e-01,  9.1919e-01,  1.7184e+00,  ...,  4.8779e-01,\n",
       "               1.6966e+00, -1.6504e-01],\n",
       "             ...,\n",
       "             [ 5.4991e-01,  6.3887e-01,  1.7825e-01,  ...,  1.0669e+00,\n",
       "               6.7639e-01, -3.3838e-01],\n",
       "             [ 7.1695e-01,  3.6230e-01,  1.4782e+00,  ...,  1.4439e+00,\n",
       "               2.8586e-01, -8.2015e-01],\n",
       "             [ 5.8005e-01,  5.8963e-01,  1.7634e-01,  ...,  1.1358e+00,\n",
       "               6.3790e-01, -3.1256e-01]],\n",
       "  \n",
       "            [[-1.3735e-01, -5.0504e-02,  7.0306e-02,  ...,  5.5682e-02,\n",
       "               8.5924e-02, -1.5147e-02],\n",
       "             [-1.1011e+00,  1.2676e-01, -1.0486e+00,  ..., -7.0738e-03,\n",
       "               1.1977e+00, -7.8149e-01],\n",
       "             [-4.9343e-01, -1.2560e+00, -5.2777e-02,  ...,  7.2532e-01,\n",
       "               7.7925e-01,  3.7413e-01],\n",
       "             ...,\n",
       "             [ 1.4137e-01, -2.3489e-01,  3.3385e-01,  ..., -2.7325e-02,\n",
       "               1.3163e-01,  9.3181e-02],\n",
       "             [-5.4350e-01, -9.1463e-01, -7.8626e-01,  ...,  4.5531e-01,\n",
       "               1.3796e-01, -3.2892e-01],\n",
       "             [ 1.1929e-01, -2.4079e-01,  3.7288e-01,  ..., -2.8434e-02,\n",
       "               4.0973e-02,  8.1618e-02]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[-5.4882e-01, -4.6021e-01,  2.0816e-01,  ...,  3.2185e-02,\n",
       "               1.9677e-01, -4.0632e-01],\n",
       "             [-1.0208e+00,  3.4483e-01, -5.4078e+00,  ...,  1.0608e+00,\n",
       "              -8.1824e-01,  1.1844e-01],\n",
       "             [-1.2334e+00,  4.0289e-01, -4.1039e+00,  ...,  2.7255e-01,\n",
       "              -9.4773e-01, -7.6409e-01],\n",
       "             ...,\n",
       "             [-9.0423e-01,  1.4264e+00, -2.3019e-01,  ..., -8.1958e-01,\n",
       "               1.2976e-01, -1.0081e+00],\n",
       "             [ 2.7279e-01,  1.6665e+00, -1.7681e+00,  ..., -5.6377e-01,\n",
       "              -1.2213e-02, -4.4814e-01],\n",
       "             [-8.7353e-01,  1.4625e+00, -7.5520e-02,  ..., -8.5398e-01,\n",
       "               1.3444e-01, -1.0402e+00]],\n",
       "  \n",
       "            [[ 1.7843e+00,  1.7307e-01,  1.8474e+00,  ...,  1.3269e+00,\n",
       "              -8.6536e-01, -1.1275e+00],\n",
       "             [-1.7347e+00, -4.2126e-01,  1.8031e+00,  ..., -9.7250e-01,\n",
       "              -1.2086e-02, -8.2845e-03],\n",
       "             [ 1.2622e+00, -8.0226e-01,  1.9230e+00,  ...,  1.0388e+00,\n",
       "               9.7922e-01, -3.4361e-01],\n",
       "             ...,\n",
       "             [ 6.4515e+00, -2.5691e+00,  7.3559e+00,  ...,  7.6330e+00,\n",
       "              -3.2111e+00, -3.2274e+00],\n",
       "             [ 5.9927e+00, -2.9345e+00,  8.1582e+00,  ...,  6.6971e+00,\n",
       "              -4.7485e+00, -2.6457e+00],\n",
       "             [ 6.6104e+00, -2.6805e+00,  7.5273e+00,  ...,  7.8273e+00,\n",
       "              -3.3536e+00, -3.2021e+00]],\n",
       "  \n",
       "            [[ 1.3848e-01,  1.3382e-01, -1.0545e-01,  ...,  1.8984e-01,\n",
       "              -3.4012e-01, -2.5155e-02],\n",
       "             [-9.5574e-01, -2.9557e-01,  1.5038e+00,  ...,  4.4021e-01,\n",
       "              -1.8121e-01,  1.2305e+00],\n",
       "             [-1.1769e-01,  1.5981e-01, -2.7390e-01,  ...,  5.8114e-02,\n",
       "               8.0108e-01, -7.8723e-02],\n",
       "             ...,\n",
       "             [ 2.5359e+00, -1.1967e+00,  4.8737e-01,  ...,  1.0169e+00,\n",
       "               3.1231e+00,  1.3402e-01],\n",
       "             [ 2.0860e+00, -1.3404e+00,  1.4930e+00,  ...,  1.6625e+00,\n",
       "               3.3391e+00,  6.2623e-01],\n",
       "             [ 2.5595e+00, -1.2567e+00,  4.8819e-01,  ...,  1.1011e+00,\n",
       "               3.1878e+00,  1.1695e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.4330e-01, -1.1125e+00,  1.2784e-01,  ..., -9.6856e-02,\n",
       "               3.9662e-02,  7.5653e-02],\n",
       "             [-4.6940e-01,  3.0301e+00, -1.8223e+00,  ..., -5.6182e-01,\n",
       "              -1.9719e+00, -4.3371e-01],\n",
       "             [-1.3592e+00,  7.8946e-01, -6.9511e-01,  ...,  8.3361e-01,\n",
       "              -1.0995e+00,  1.5486e-01],\n",
       "             ...,\n",
       "             [-1.4273e+00, -3.0889e+00, -1.7460e-01,  ...,  2.0498e+00,\n",
       "              -2.1883e+00, -1.8069e+00],\n",
       "             [-1.3390e+00, -2.2423e+00, -3.2350e-01,  ...,  1.6105e+00,\n",
       "              -3.9416e+00, -2.6857e+00],\n",
       "             [-1.3849e+00, -3.2182e+00, -1.4738e-01,  ...,  2.0622e+00,\n",
       "              -2.2773e+00, -1.8409e+00]],\n",
       "  \n",
       "            [[ 1.3482e-01, -2.9507e-01,  5.6703e-01,  ...,  1.0898e+00,\n",
       "               3.2482e-01, -2.3599e-02],\n",
       "             [-5.6551e-01, -6.4587e-01, -1.2605e+00,  ..., -4.7155e+00,\n",
       "              -2.9846e-01, -8.6159e-01],\n",
       "             [-1.1860e-02, -1.5711e+00, -1.3479e+00,  ..., -1.2150e+00,\n",
       "               4.4109e-01, -1.5147e+00],\n",
       "             ...,\n",
       "             [ 1.4615e+00, -1.3878e+00,  1.8757e+00,  ...,  3.5135e+00,\n",
       "              -6.5171e-01, -4.9758e-01],\n",
       "             [ 4.3581e-01, -8.9862e-01,  1.8466e+00,  ...,  2.4336e+00,\n",
       "              -9.1073e-01, -8.0294e-02],\n",
       "             [ 1.5089e+00, -1.4183e+00,  1.9243e+00,  ...,  3.7652e+00,\n",
       "              -6.5864e-01, -3.8773e-01]],\n",
       "  \n",
       "            [[ 9.2106e-01, -6.0047e-01,  8.7529e-02,  ...,  4.1618e-01,\n",
       "               4.3836e-01,  1.6913e-01],\n",
       "             [ 1.4848e+00, -1.8421e+00,  1.2808e+00,  ...,  1.0000e+00,\n",
       "              -1.1346e+00,  1.2150e+00],\n",
       "             [ 1.4640e+00, -3.7169e-01, -1.2154e-02,  ...,  1.1695e+00,\n",
       "               4.9029e-01,  5.4550e-01],\n",
       "             ...,\n",
       "             [ 1.2602e+00, -1.8831e+00, -1.4602e+00,  ...,  2.8330e+00,\n",
       "               1.6484e+00, -1.4097e+00],\n",
       "             [ 1.7661e+00, -2.6651e+00, -1.0273e+00,  ...,  2.1976e+00,\n",
       "              -5.0749e-02, -1.7200e+00],\n",
       "             [ 1.2591e+00, -1.8880e+00, -1.4761e+00,  ...,  2.8063e+00,\n",
       "               1.5843e+00, -1.4621e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-1.4193e-01,  2.1976e-01,  1.2551e-01,  ..., -9.5327e-02,\n",
       "              -1.0484e-01, -8.7670e-02],\n",
       "             [ 1.7174e+00,  2.0334e+00, -9.2068e-01,  ...,  1.2619e-01,\n",
       "               1.9880e+00, -1.7541e+00],\n",
       "             [ 3.2213e-01,  9.6757e-01,  4.8397e-01,  ...,  6.8499e-01,\n",
       "               4.6540e-01,  1.1371e-01],\n",
       "             ...,\n",
       "             [ 3.8857e-01,  6.7228e-01,  1.9031e+00,  ...,  8.2911e-01,\n",
       "              -6.1086e-02,  3.0047e-01],\n",
       "             [ 1.4374e+00,  1.8598e+00,  3.8459e-01,  ...,  1.3647e+00,\n",
       "               1.0759e+00, -1.5020e+00],\n",
       "             [ 4.4441e-01,  6.4935e-01,  1.8172e+00,  ...,  7.1834e-01,\n",
       "              -9.0189e-02,  2.0138e-01]],\n",
       "  \n",
       "            [[-1.6054e-01, -2.9684e-01, -1.8202e-01,  ..., -8.9942e-02,\n",
       "              -4.9850e-02, -7.4437e-02],\n",
       "             [ 1.2724e+00,  2.4158e+00,  8.4902e-01,  ..., -7.9608e-03,\n",
       "              -7.3562e-01, -2.3337e-01],\n",
       "             [ 2.9652e-01, -2.7902e-01, -4.7435e-01,  ..., -1.2875e+00,\n",
       "               5.5154e-01, -1.1449e-02],\n",
       "             ...,\n",
       "             [-7.9831e-01, -1.1952e-01, -7.7449e-01,  ..., -1.9535e+00,\n",
       "              -1.6713e-01, -4.9686e-01],\n",
       "             [-2.8111e-01,  8.3772e-01, -9.8066e-01,  ..., -1.9979e+00,\n",
       "              -7.4465e-01, -1.7014e-01],\n",
       "             [-8.3804e-01, -1.5263e-01, -7.6826e-01,  ..., -1.9346e+00,\n",
       "              -1.5150e-01, -4.9915e-01]],\n",
       "  \n",
       "            [[-1.7407e-01, -3.7663e-02,  1.0152e-01,  ...,  6.1656e-02,\n",
       "               1.8936e-01,  1.3889e-01],\n",
       "             [ 2.5385e-01,  5.5175e-01,  3.8710e-01,  ..., -4.9093e-01,\n",
       "              -7.3466e-01,  1.0957e+00],\n",
       "             [ 1.1181e-01, -2.1531e-01, -8.0064e-01,  ...,  2.3635e-02,\n",
       "              -2.8929e-01, -6.5819e-01],\n",
       "             ...,\n",
       "             [-8.4514e-02,  2.8505e-01, -5.6647e-01,  ...,  9.9958e-02,\n",
       "               1.1791e+00,  9.2019e-02],\n",
       "             [ 1.9857e-01,  9.6409e-01, -6.8282e-01,  ..., -3.1281e-01,\n",
       "               3.3856e-01,  1.5680e+00],\n",
       "             [-4.2736e-02,  3.1813e-01, -5.7075e-01,  ...,  9.7042e-02,\n",
       "               1.1830e+00,  9.7430e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-6.1854e-02,  1.5219e-01,  3.8176e-02,  ...,  1.1879e-01,\n",
       "              -1.0173e-01,  2.5631e-01],\n",
       "             [ 2.5597e-01, -1.5963e+00, -3.8434e-01,  ..., -9.2291e-01,\n",
       "              -1.6733e-01, -1.0866e+00],\n",
       "             [ 4.3841e-01,  6.9563e-01,  7.5351e-01,  ...,  1.5627e-01,\n",
       "               1.3347e+00,  1.0270e+00],\n",
       "             ...,\n",
       "             [ 1.2977e+00, -6.3770e-01,  1.2925e+00,  ...,  4.2165e-01,\n",
       "               6.1576e-01,  1.3251e+00],\n",
       "             [ 4.9071e-01, -2.2035e+00,  8.9428e-02,  ..., -1.0772e-01,\n",
       "              -8.1806e-01, -1.1161e-01],\n",
       "             [ 1.3188e+00, -6.5788e-01,  1.2972e+00,  ...,  4.6899e-01,\n",
       "               5.2662e-01,  1.3232e+00]],\n",
       "  \n",
       "            [[ 8.0342e-02,  3.1236e-02,  1.5771e-01,  ...,  1.8027e-01,\n",
       "               2.7733e-02,  1.5062e-01],\n",
       "             [-4.8490e-01, -2.1014e-01,  1.5100e-01,  ...,  1.6893e+00,\n",
       "               1.5314e+00, -3.8153e-01],\n",
       "             [-1.4744e+00,  3.7450e-01,  8.2778e-01,  ...,  1.0125e+00,\n",
       "               1.3094e+00,  1.6447e-01],\n",
       "             ...,\n",
       "             [-6.0433e-01,  1.4829e-01,  3.6789e-01,  ...,  1.0004e+00,\n",
       "               2.1375e+00, -6.7600e-01],\n",
       "             [-5.0285e-01,  1.5441e-01,  9.8772e-01,  ...,  1.7075e+00,\n",
       "               1.1775e+00, -3.1753e-01],\n",
       "             [-5.2505e-01,  1.3058e-01,  4.1900e-01,  ...,  9.7927e-01,\n",
       "               2.0930e+00, -6.5377e-01]],\n",
       "  \n",
       "            [[-1.0647e-01, -1.0394e-01, -1.2336e-01,  ...,  2.2990e-01,\n",
       "              -7.5569e-02, -8.2221e-02],\n",
       "             [-1.5905e-01,  3.1457e-01,  3.1631e-01,  ..., -5.9599e-01,\n",
       "              -6.2033e-01,  1.9923e-01],\n",
       "             [-6.1743e-01, -6.5234e-02, -1.3838e-01,  ..., -2.1462e-01,\n",
       "              -9.4081e-01, -1.0362e+00],\n",
       "             ...,\n",
       "             [-5.5370e-01,  2.1646e-01, -1.1931e-01,  ...,  3.3600e-01,\n",
       "              -9.0798e-01, -3.7384e-01],\n",
       "             [-1.5450e-01, -3.3756e-01,  1.2874e+00,  ..., -3.5643e-01,\n",
       "               1.3048e-01,  5.9807e-01],\n",
       "             [-5.1705e-01,  2.3171e-01, -6.3643e-02,  ...,  3.3825e-01,\n",
       "              -8.8192e-01, -3.9846e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 1.8027e-01,  7.5461e-04,  2.3850e-01,  ...,  1.3871e+00,\n",
       "               2.9911e-01,  2.1594e-01],\n",
       "             [-7.8824e-01,  4.3092e-01,  1.8194e+00,  ..., -2.6896e+00,\n",
       "              -2.5671e+00, -1.7007e-01],\n",
       "             [-2.8774e-01,  1.2918e+00,  6.2638e-01,  ..., -2.5072e+00,\n",
       "              -1.9606e-01, -7.8911e-01],\n",
       "             ...,\n",
       "             [-8.7987e-01,  1.4322e-01,  7.0794e-01,  ..., -3.2964e-02,\n",
       "              -5.0382e-01, -6.6921e-01],\n",
       "             [-1.0716e+00, -3.4049e-01,  1.6845e+00,  ...,  5.7890e-01,\n",
       "              -2.2676e+00, -2.7539e-01],\n",
       "             [-8.6890e-01,  4.8599e-02,  7.3749e-01,  ...,  1.3483e-01,\n",
       "              -5.3672e-01, -6.7282e-01]],\n",
       "  \n",
       "            [[ 5.4798e-02, -2.1423e-01,  7.4569e-01,  ...,  2.2229e-01,\n",
       "              -8.7351e-02,  2.0732e-01],\n",
       "             [ 1.8219e+00,  5.8821e-01, -2.0124e+00,  ...,  5.6362e-01,\n",
       "               2.5628e-01,  1.3906e+00],\n",
       "             [ 2.5506e-01, -1.2909e+00, -2.3909e+00,  ..., -2.7489e-01,\n",
       "               1.6423e+00,  1.2155e+00],\n",
       "             ...,\n",
       "             [ 1.7150e+00, -1.7978e+00, -4.7017e-01,  ...,  3.4562e-01,\n",
       "               2.1228e+00,  2.1023e+00],\n",
       "             [ 2.7706e+00, -1.7052e+00,  3.2495e-01,  ...,  5.4775e-01,\n",
       "               2.3870e+00,  2.2331e+00],\n",
       "             [ 1.7369e+00, -1.8217e+00, -3.1760e-01,  ...,  3.6189e-01,\n",
       "               2.1813e+00,  2.1321e+00]],\n",
       "  \n",
       "            [[ 8.7318e-02,  3.3052e-01,  6.2967e-01,  ...,  1.4984e-01,\n",
       "               1.8454e-01,  1.2409e-01],\n",
       "             [-1.2808e+00,  6.0221e-01, -2.0623e-01,  ...,  3.7366e-01,\n",
       "               1.2254e+00, -7.6948e-01],\n",
       "             [-1.7421e-01,  7.9473e-01,  3.3923e-01,  ..., -1.2332e+00,\n",
       "               7.6260e-01, -1.6328e-01],\n",
       "             ...,\n",
       "             [-1.6184e-01,  8.6737e-01,  5.7822e-01,  ..., -4.6709e-01,\n",
       "               6.6804e-01,  8.0891e-02],\n",
       "             [-9.6585e-01,  9.0728e-01, -5.2769e-01,  ...,  2.7699e-01,\n",
       "              -2.2544e-01,  3.0169e-01],\n",
       "             [-1.9067e-01,  8.4514e-01,  5.8380e-01,  ..., -4.6943e-01,\n",
       "               6.6226e-01,  5.1599e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 2.6856e-01,  8.8726e-02,  3.2200e-01,  ..., -5.2333e-01,\n",
       "               1.2339e-02, -1.2732e-01],\n",
       "             [-4.1138e-01,  8.1252e-01, -9.5610e-01,  ...,  2.4976e-01,\n",
       "              -1.6647e+00,  4.8598e-01],\n",
       "             [ 9.8685e-01, -1.7914e+00, -9.0734e-01,  ..., -9.0234e-01,\n",
       "               1.2767e+00,  4.7515e-01],\n",
       "             ...,\n",
       "             [ 2.7181e-01, -3.6437e+00,  7.1021e-01,  ..., -1.3013e+00,\n",
       "               7.3182e-01, -2.0994e-01],\n",
       "             [ 1.7475e-01, -2.7206e+00,  4.8408e-01,  ..., -1.1127e+00,\n",
       "              -8.7733e-01,  2.6706e-01],\n",
       "             [ 2.0927e-01, -3.6462e+00,  7.6479e-01,  ..., -1.2971e+00,\n",
       "               7.2158e-01, -2.3324e-01]],\n",
       "  \n",
       "            [[-2.9320e-01,  6.2091e-02,  8.8453e-02,  ..., -3.6115e-01,\n",
       "              -3.5452e-02,  7.3534e-03],\n",
       "             [ 1.4868e+00,  2.2568e-01, -8.0983e-01,  ...,  1.8122e+00,\n",
       "               1.6197e+00,  2.5910e+00],\n",
       "             [ 8.1656e-01,  7.0976e-01, -6.3347e-02,  ...,  5.5968e-01,\n",
       "               1.3582e-01,  2.0041e-01],\n",
       "             ...,\n",
       "             [ 5.2555e-01,  2.6536e-01,  8.2882e-02,  ..., -2.1166e+00,\n",
       "               8.9868e-01, -2.3135e+00],\n",
       "             [ 2.1523e+00, -1.3651e-01, -1.6191e-01,  ..., -1.6805e+00,\n",
       "               1.3857e+00, -1.2237e+00],\n",
       "             [ 5.6323e-01,  2.4931e-01,  1.1835e-01,  ..., -2.2247e+00,\n",
       "               9.1748e-01, -2.4350e+00]],\n",
       "  \n",
       "            [[ 2.1357e-02, -2.3502e-01,  5.3432e-02,  ...,  1.2665e-01,\n",
       "               1.0988e-01, -1.8252e-01],\n",
       "             [ 1.1956e+00,  7.2363e-01,  6.2911e-02,  ..., -6.1963e-01,\n",
       "               1.1160e-01, -1.3090e-01],\n",
       "             [-3.1462e-01,  1.1621e+00,  2.3795e-01,  ...,  1.1620e+00,\n",
       "              -3.5170e-01,  5.7834e-01],\n",
       "             ...,\n",
       "             [-2.3509e+00,  1.0813e+00,  7.5645e-01,  ...,  8.9207e-01,\n",
       "              -4.9020e-01,  5.0270e-01],\n",
       "             [-2.1497e+00,  4.0503e-01,  4.1496e-01,  ..., -3.4130e-02,\n",
       "               5.1769e-01, -8.0151e-01],\n",
       "             [-2.4305e+00,  1.0686e+00,  7.1002e-01,  ...,  8.6243e-01,\n",
       "              -4.3973e-01,  5.0854e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.6860e-01,  9.3417e-02, -1.3401e-01,  ...,  1.6013e-01,\n",
       "              -2.1127e-01,  6.0922e-02],\n",
       "             [-6.9370e-01, -1.1658e+00, -6.6914e-01,  ...,  7.5296e-01,\n",
       "              -1.2386e-01,  3.1232e-01],\n",
       "             [ 1.6283e+00, -3.0457e-01,  6.4167e-01,  ...,  9.8505e-01,\n",
       "               7.1228e-01,  3.8351e-01],\n",
       "             ...,\n",
       "             [ 1.5811e+00, -6.7422e-01,  3.0336e-01,  ...,  9.9743e-01,\n",
       "               7.3817e-01, -8.3021e-01],\n",
       "             [ 7.1862e-01, -7.5777e-01, -6.8733e-01,  ...,  9.8309e-01,\n",
       "               6.5858e-01, -1.0394e+00],\n",
       "             [ 1.6077e+00, -6.2839e-01,  2.7645e-01,  ...,  9.4632e-01,\n",
       "               8.1335e-01, -9.0022e-01]],\n",
       "  \n",
       "            [[-1.1954e-02, -1.1543e-01, -3.0793e-01,  ...,  5.6343e-02,\n",
       "              -3.3205e-01,  1.9663e-01],\n",
       "             [ 1.1990e+00, -7.0437e-01,  1.4361e+00,  ..., -1.3195e+00,\n",
       "              -1.2408e-01, -1.5006e+00],\n",
       "             [ 4.9311e-01,  5.4443e-01,  1.0154e+00,  ...,  8.1392e-01,\n",
       "              -6.9691e-01, -1.3208e-01],\n",
       "             ...,\n",
       "             [ 6.0459e-01,  3.8829e-03, -2.1965e-01,  ...,  9.2987e-01,\n",
       "              -4.0680e-01, -3.6630e-01],\n",
       "             [ 1.6519e+00, -6.8339e-01,  6.8179e-02,  ..., -9.6331e-01,\n",
       "               9.5155e-01, -1.5415e+00],\n",
       "             [ 5.4861e-01, -5.9308e-02, -2.2522e-01,  ...,  9.2706e-01,\n",
       "              -3.3390e-01, -3.9962e-01]],\n",
       "  \n",
       "            [[-5.1941e-02, -2.2396e-01, -2.0413e-01,  ..., -8.7052e-02,\n",
       "               5.6029e-02, -1.4984e-01],\n",
       "             [ 3.3276e-01,  1.6351e-01,  1.9216e-01,  ...,  1.4765e+00,\n",
       "              -9.2817e-01,  1.8998e+00],\n",
       "             [-1.7456e+00,  3.6567e-01, -1.2842e+00,  ..., -4.3035e-01,\n",
       "              -8.0880e-01,  5.2751e+00],\n",
       "             ...,\n",
       "             [-1.1211e+00,  6.4422e-01, -1.6814e+00,  ...,  2.0298e-01,\n",
       "              -1.7585e-01,  3.6025e+00],\n",
       "             [ 1.2902e+00, -4.3128e-01, -8.1505e-02,  ...,  1.0756e+00,\n",
       "              -3.6664e-01,  7.2480e-02],\n",
       "             [-1.0806e+00,  6.2305e-01, -1.6903e+00,  ...,  2.0071e-01,\n",
       "              -1.8220e-01,  3.4788e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-3.8027e-01, -4.0654e-01,  3.1190e-01,  ...,  4.7975e-01,\n",
       "               2.1680e-01, -3.0893e-01],\n",
       "             [-1.2741e-01,  1.9662e-01,  1.2317e-02,  ..., -6.7248e-01,\n",
       "              -1.8503e+00, -9.4523e-01],\n",
       "             [-2.2417e-01, -2.0096e-01,  1.0359e+00,  ...,  3.3461e-01,\n",
       "              -3.9151e-01, -4.2620e-01],\n",
       "             ...,\n",
       "             [ 3.2101e-01, -2.0099e-01,  4.2574e-01,  ...,  1.8685e-01,\n",
       "              -6.1960e-01,  1.8035e-01],\n",
       "             [ 1.6138e-01,  4.5141e-01, -2.6567e-01,  ..., -4.4470e-01,\n",
       "              -2.2374e+00, -3.6056e-02],\n",
       "             [ 2.7775e-01, -1.6329e-01,  3.8470e-01,  ...,  1.4558e-01,\n",
       "              -6.3315e-01,  1.4248e-01]],\n",
       "  \n",
       "            [[ 1.1950e-01, -6.1611e-02, -1.8663e-01,  ...,  6.6358e-02,\n",
       "               7.8154e-02, -1.0299e-01],\n",
       "             [-2.8338e+00, -1.1946e+00,  5.1238e-01,  ..., -1.5235e+00,\n",
       "               5.0046e-02,  2.6793e-01],\n",
       "             [-6.8270e-01,  4.2171e-01, -2.9975e-01,  ...,  2.3492e-01,\n",
       "               9.1121e-01, -1.8729e-01],\n",
       "             ...,\n",
       "             [ 7.9067e-01,  4.7576e-01,  3.3231e-02,  ...,  6.5831e-01,\n",
       "               8.6210e-01,  1.8020e-01],\n",
       "             [-1.3089e+00, -1.7519e+00,  5.0876e-01,  ..., -5.0022e-02,\n",
       "               5.2008e-01,  7.4356e-01],\n",
       "             [ 8.2782e-01,  4.4182e-01,  8.7032e-03,  ...,  6.9404e-01,\n",
       "               9.0272e-01,  1.4671e-01]],\n",
       "  \n",
       "            [[-7.7069e-02,  1.0782e-01,  1.1658e-02,  ...,  6.1299e-02,\n",
       "              -9.2770e-02, -1.4468e-01],\n",
       "             [ 5.9941e-01,  1.4788e-01, -4.8524e-01,  ..., -1.5537e+00,\n",
       "              -8.7137e-01,  1.2707e-02],\n",
       "             [ 5.9306e-01,  2.6453e-02,  5.0147e-01,  ...,  2.2775e-01,\n",
       "               6.1684e-01,  3.9077e-01],\n",
       "             ...,\n",
       "             [ 4.6960e-01,  9.4719e-01,  2.9457e-01,  ..., -6.7474e-01,\n",
       "               8.0134e-01,  7.1939e-01],\n",
       "             [ 8.7411e-01,  6.4449e-01, -1.1855e+00,  ..., -2.1342e+00,\n",
       "              -7.4908e-01, -9.9778e-02],\n",
       "             [ 4.9481e-01,  9.4906e-01,  3.2488e-01,  ..., -6.4252e-01,\n",
       "               7.3193e-01,  7.3225e-01]]]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[[[ 6.6615e-02,  6.0832e-01, -4.7964e-01,  ...,  1.3632e-01,\n",
       "              -9.9073e-02, -9.0911e-01],\n",
       "             [ 3.6406e-01, -4.9409e-01, -2.9283e-01,  ...,  5.3283e-01,\n",
       "               1.8498e-02,  5.7925e-03],\n",
       "             [ 7.3907e-01, -1.7766e+00, -8.5893e-01,  ..., -1.2064e-02,\n",
       "              -3.8492e-02, -7.3187e-01],\n",
       "             ...,\n",
       "             [ 1.1354e+00, -2.1696e+00, -9.5136e-01,  ...,  1.1017e+00,\n",
       "               4.1215e-01, -8.2494e-01],\n",
       "             [ 1.2213e+00, -1.1367e+00, -2.2582e-01,  ...,  2.1398e+00,\n",
       "               5.6479e-01, -1.1099e+00],\n",
       "             [ 1.1778e+00, -2.1122e+00, -9.5004e-01,  ...,  1.1893e+00,\n",
       "               3.7140e-01, -8.9399e-01]],\n",
       "  \n",
       "            [[ 1.2187e-02,  7.8845e-01,  4.9964e-01,  ...,  5.8986e-02,\n",
       "               2.7161e-01, -4.4144e-01],\n",
       "             [ 7.8673e-01,  1.1204e+00,  3.5772e-01,  ..., -4.7365e-01,\n",
       "               3.2460e-01, -1.1671e+00],\n",
       "             [ 5.4521e-01,  1.2924e+00, -1.9031e-01,  ...,  4.7603e-02,\n",
       "               1.7241e+00, -1.0002e+00],\n",
       "             ...,\n",
       "             [ 4.9768e-02,  1.6369e+00, -1.8572e-01,  ..., -7.5291e-02,\n",
       "               3.6897e+00, -1.1238e+00],\n",
       "             [-9.6341e-02,  1.3252e+00, -1.1345e-01,  ..., -9.0504e-01,\n",
       "               3.9211e+00, -1.0618e+00],\n",
       "             [ 3.9368e-02,  1.6338e+00, -1.7518e-01,  ..., -3.9679e-02,\n",
       "               3.7395e+00, -1.1432e+00]],\n",
       "  \n",
       "            [[-8.5318e-02, -5.0549e-03,  1.8199e+00,  ...,  3.3701e-01,\n",
       "              -1.2126e+00, -7.9893e-02],\n",
       "             [ 5.0266e-01, -4.3630e-01, -1.7187e+00,  ...,  1.6472e-01,\n",
       "               4.6963e-01,  1.2524e+00],\n",
       "             [ 1.9592e-01,  1.5726e-03,  1.1578e+00,  ...,  6.4496e-01,\n",
       "              -6.1938e-01,  1.2030e-01],\n",
       "             ...,\n",
       "             [ 6.2853e-01, -7.6749e-01,  3.8992e+00,  ...,  7.2322e-01,\n",
       "              -2.1454e+00,  2.1041e-01],\n",
       "             [ 9.9720e-01, -1.0300e+00,  2.0191e+00,  ...,  3.2456e-01,\n",
       "              -1.1709e+00,  6.0874e-02],\n",
       "             [ 6.5969e-01, -8.0843e-01,  4.0804e+00,  ...,  7.6266e-01,\n",
       "              -2.2430e+00,  1.7994e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 3.6574e-01,  1.1903e+00,  9.8930e-01,  ..., -3.6188e-01,\n",
       "              -6.4226e-01,  4.6684e-01],\n",
       "             [ 2.4320e+00, -4.2003e-01,  5.5116e-01,  ..., -2.1063e+00,\n",
       "              -2.5617e-01, -8.3429e-01],\n",
       "             [ 1.0009e+00,  4.1185e-01,  1.8455e+00,  ..., -2.2559e-01,\n",
       "              -3.6371e-01,  4.9991e-01],\n",
       "             ...,\n",
       "             [ 1.3961e+00,  5.7823e-01,  3.3300e+00,  ...,  5.7331e+00,\n",
       "               1.2755e-01, -2.1673e+00],\n",
       "             [ 2.7557e+00,  2.1018e-01,  3.1832e+00,  ...,  5.2571e+00,\n",
       "              -4.7276e-01, -2.9170e+00],\n",
       "             [ 1.3755e+00,  5.1930e-01,  3.3370e+00,  ...,  5.9363e+00,\n",
       "               1.1298e-01, -2.2010e+00]],\n",
       "  \n",
       "            [[ 5.2429e-02, -1.4332e-01,  8.8792e-02,  ..., -2.7514e-01,\n",
       "              -2.6421e-01, -3.7105e-01],\n",
       "             [ 3.1488e-01, -6.8475e-01, -2.4824e-01,  ..., -9.7153e-01,\n",
       "              -9.3588e-01, -1.6398e+00],\n",
       "             [ 7.3513e-01,  4.5702e-01, -9.7447e-01,  ..., -7.1012e-01,\n",
       "              -9.8893e-01, -3.9196e-01],\n",
       "             ...,\n",
       "             [-2.2036e-01,  7.8090e-01, -9.4945e-01,  ..., -1.1649e+00,\n",
       "              -4.0440e+00, -5.5184e-01],\n",
       "             [-1.1075e+00,  2.4947e-01, -6.5430e-01,  ..., -1.7041e+00,\n",
       "              -4.9874e+00, -1.0262e+00],\n",
       "             [-2.7656e-01,  8.4039e-01, -9.3745e-01,  ..., -1.2238e+00,\n",
       "              -4.1358e+00, -5.8057e-01]],\n",
       "  \n",
       "            [[-1.9041e-01, -1.0983e+00, -1.3844e-01,  ..., -1.7704e-01,\n",
       "              -1.6084e+00, -1.6774e+00],\n",
       "             [-8.3762e-01, -1.4886e+00, -4.6962e-01,  ...,  1.7815e-01,\n",
       "              -1.3161e+00, -6.0492e-01],\n",
       "             [-1.0768e-01, -8.0412e-01, -1.3242e+00,  ..., -4.3617e-01,\n",
       "              -2.0145e+00, -8.9839e-01],\n",
       "             ...,\n",
       "             [ 7.9296e-01, -3.6966e-01,  1.2761e-01,  ..., -5.1042e-01,\n",
       "              -1.4039e+00, -1.4803e+00],\n",
       "             [ 1.5778e-01, -9.9760e-01,  3.2951e-01,  ...,  2.6292e-01,\n",
       "              -1.2221e+00, -1.6887e+00],\n",
       "             [ 8.4111e-01, -3.8233e-01,  2.3182e-01,  ..., -5.1156e-01,\n",
       "              -1.3926e+00, -1.5235e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-4.0222e-01, -1.3492e-01,  2.3634e-01,  ...,  6.6472e-02,\n",
       "               3.5365e-01,  1.7240e-02],\n",
       "             [ 9.9387e-01,  1.4693e+00,  1.7769e+00,  ..., -1.1020e+00,\n",
       "               5.5229e-01, -2.3767e-01],\n",
       "             [-6.0168e-01, -6.5283e-02,  2.0450e-01,  ..., -4.3109e-02,\n",
       "               3.8749e-01,  5.2931e-01],\n",
       "             ...,\n",
       "             [-9.7931e-01, -5.7004e-01,  9.1523e-01,  ..., -5.6859e-02,\n",
       "               8.1573e-01,  1.2169e+00],\n",
       "             [ 2.3384e-01,  9.2300e-01,  2.3591e+00,  ..., -1.4308e+00,\n",
       "               8.9592e-01,  8.2579e-01],\n",
       "             [-9.9361e-01, -5.7807e-01,  9.2539e-01,  ..., -8.7061e-02,\n",
       "               7.7379e-01,  1.1757e+00]],\n",
       "  \n",
       "            [[-3.2203e-01,  2.2255e-01, -3.0696e-02,  ..., -1.0983e-01,\n",
       "              -1.5164e-01, -1.3908e-01],\n",
       "             [-5.7625e-01,  1.3223e-01,  5.5197e-01,  ...,  1.2983e+00,\n",
       "               1.6463e-01,  1.6416e+00],\n",
       "             [-8.8620e-04,  1.3972e-01, -1.0652e+00,  ...,  7.9735e-01,\n",
       "              -4.8895e-01, -5.7817e-01],\n",
       "             ...,\n",
       "             [-2.9517e-01,  3.9489e-01, -4.7385e-01,  ...,  1.5720e-01,\n",
       "              -4.0356e-01, -8.1057e-01],\n",
       "             [-7.6714e-02,  4.5322e-01,  8.6148e-01,  ...,  6.5187e-01,\n",
       "              -3.1327e-01,  7.1030e-01],\n",
       "             [-2.3619e-01,  3.7388e-01, -4.7233e-01,  ...,  1.4813e-01,\n",
       "              -4.2750e-01, -8.3750e-01]],\n",
       "  \n",
       "            [[-3.4737e-01, -6.6538e-01, -1.4102e-01,  ..., -3.7922e-01,\n",
       "               7.7607e-02, -3.1144e-01],\n",
       "             [ 4.1450e-01, -1.2975e+00,  8.3287e-02,  ...,  1.1104e+00,\n",
       "               1.5150e+00,  1.5179e+00],\n",
       "             [-4.3630e-02, -1.9480e+00, -3.4169e-01,  ..., -1.9637e-01,\n",
       "               7.5193e-02, -1.2153e-01],\n",
       "             ...,\n",
       "             [-9.5914e-02, -4.2690e-01, -4.3369e-01,  ..., -7.2699e-02,\n",
       "               9.6740e-02, -3.9675e-01],\n",
       "             [-3.1023e-02, -5.7642e-01,  3.6555e-01,  ...,  6.7368e-01,\n",
       "               1.3400e+00,  8.5771e-01],\n",
       "             [-5.4967e-02, -3.6839e-01, -4.1169e-01,  ..., -6.9794e-02,\n",
       "               1.0722e-01, -4.1704e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-4.7797e-02, -2.0053e-01,  1.6933e-01,  ..., -3.2388e-01,\n",
       "              -1.0444e-01, -3.7925e-02],\n",
       "             [-2.8723e-01, -7.0007e-02,  5.4297e-01,  ..., -7.1863e-01,\n",
       "               6.3360e-02,  1.5822e-01],\n",
       "             [-6.5045e-01, -2.5599e-01,  9.9382e-01,  ..., -4.8836e-01,\n",
       "               8.2334e-01,  4.3500e-02],\n",
       "             ...,\n",
       "             [-1.7043e-01, -6.8230e-01,  7.3170e-01,  ...,  2.6212e-01,\n",
       "               8.2788e-01, -3.0503e-01],\n",
       "             [-4.2758e-01, -1.6562e-01,  3.4579e-01,  ..., -1.8357e-01,\n",
       "               4.3252e-01, -3.0873e-01],\n",
       "             [-1.6493e-01, -6.7484e-01,  6.8031e-01,  ...,  2.5228e-01,\n",
       "               8.2553e-01, -3.1823e-01]],\n",
       "  \n",
       "            [[ 8.3323e-02,  3.0383e-01, -6.9427e-02,  ...,  4.5188e-02,\n",
       "              -6.4996e-02,  7.5110e-02],\n",
       "             [ 2.9699e-01, -9.5230e-01, -7.1017e-01,  ..., -7.6028e-01,\n",
       "              -9.2141e-01, -1.4632e+00],\n",
       "             [-2.8251e-01, -3.9354e-01, -8.7663e-01,  ...,  2.3163e-01,\n",
       "              -2.4260e-01,  2.0104e-01],\n",
       "             ...,\n",
       "             [-3.9468e-01, -1.3828e-01,  6.3829e-01,  ...,  8.4154e-01,\n",
       "              -8.1455e-01,  4.0797e-01],\n",
       "             [-6.9137e-02, -5.6917e-01,  4.7718e-02,  ..., -3.1876e-01,\n",
       "              -1.0225e+00, -4.3917e-01],\n",
       "             [-4.0118e-01, -1.0799e-01,  6.8332e-01,  ...,  8.2821e-01,\n",
       "              -8.1812e-01,  3.9673e-01]],\n",
       "  \n",
       "            [[-1.1143e-01, -3.3076e-02, -6.2504e-02,  ..., -5.3652e-02,\n",
       "               1.4412e-01, -1.1772e-01],\n",
       "             [ 6.3368e-01,  5.2622e-01, -8.3218e-01,  ..., -3.6903e-01,\n",
       "              -2.9545e-01, -2.1842e-01],\n",
       "             [ 1.0448e-01,  8.1367e-01,  5.6495e-01,  ...,  2.1679e-01,\n",
       "              -1.7677e+00, -6.6624e-02],\n",
       "             ...,\n",
       "             [ 1.9913e-01,  4.0581e-01,  9.2101e-01,  ...,  6.9523e-01,\n",
       "              -9.0900e-01,  5.6784e-01],\n",
       "             [ 5.1563e-01,  6.7310e-01,  4.6081e-01,  ...,  1.4200e-01,\n",
       "              -2.2363e-01,  8.0402e-01],\n",
       "             [ 1.6800e-01,  4.1659e-01,  9.6482e-01,  ...,  7.0922e-01,\n",
       "              -8.6311e-01,  5.3320e-01]]]]], grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.forward(chat_history_ids)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(chat_history_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = answer - context\n",
    "if len(answer) < 2:\n",
    "    r2 = 0\n",
    "else:\n",
    "    vec_a, vec_b = answer, answer\n",
    "    r2 = sum(vec_a*vec_b) / sum(abs(vec_a)*abs(vec_b))\n",
    "    r2 = -F.logsigmoid(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'zerograd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-67e55e3af91e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzerograd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'zerograd'"
     ]
    }
   ],
   "source": [
    "optimizer.zerograd()\n",
    "r2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = context_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = q\n",
    "v2 = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50256, 15496, 50256, 15496, 50256, 15496,  5145, 50256, 15496,  5145,\n",
       "         50256, 17250,  5145, 50256]),\n",
       " tensor([15496,  5145,  1058,    35, 50256]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1,v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0057,  0.0238, -0.0812,  ..., -0.0227, -0.0378, -0.0031],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings()(v2).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(size=(3,tokenizer.vocab_size))\n",
    "x[:,-1] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[103.3320,  96.6074,  96.4836,  ..., 109.7336, 112.1754, 125.7009],\n",
       "         [107.1582,  98.9198,  98.5507,  ..., 115.2873, 114.8348, 128.2074],\n",
       "         [116.1806, 104.2458, 106.2476,  ..., 122.1931, 125.4122, 139.5822]],\n",
       "        grad_fn=<MmBackward>),\n",
       " tensor([[ -11.4564,  -17.4578,  -19.1987,  ...,  -16.9864,  -16.7421,\n",
       "            -7.3800],\n",
       "         [-206.5140, -198.9877, -200.6138,  ..., -230.4619, -229.1432,\n",
       "          -207.2097],\n",
       "         [-180.3867, -184.7284, -181.1404,  ..., -203.2211, -201.3414,\n",
       "          -167.4208],\n",
       "         [-157.9265, -160.9077, -163.2302,  ..., -188.6371, -188.0802,\n",
       "          -162.3012],\n",
       "         [-200.9722, -208.1657, -210.0039,  ..., -236.2414, -233.3469,\n",
       "          -213.2841],\n",
       "         [-179.1016, -196.8122, -194.7751,  ..., -215.5321, -212.9505,\n",
       "          -185.1048]], grad_fn=<MmBackward>))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = model(v1)[0]\n",
    "B = model(v2)[0]\n",
    "A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.1308, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "A = model(v1)[0]\n",
    "B = model(v2)[0]\n",
    "max_len = np.max([len(A.detach().numpy()),len(B.detach().numpy())])\n",
    "print(max_len)\n",
    "extra = torch.zeros(size=(max_len-len(A.detach().numpy()),tokenizer.vocab_size))\n",
    "extra[:,-1] = 1\n",
    "# A = torch.cat([A , extra ])\n",
    "B = torch.cat((B , torch.tensor([torch.ones(tokenizer.vocab_size)]*(max_len-len(B.detach().numpy()))) ))\n",
    "A, B\n",
    "\n",
    "A , B = torch.cat([torch.softmax(A, dim=-1), extra]), torch.softmax(B, dim=-1)\n",
    "A , B\n",
    "# loss = F.cosine_similarity(A,B, dim=-2)\n",
    "loss = -torch.mm(A, B.transpose(1, 0)).sum()\n",
    "\n",
    "# loss = -F.cosine_similarity(torch.softmax(A, dim=-1),torch.softmax(B, dim=-1))\n",
    "# loss = 0\n",
    "# for i,j in zip(v1,v2):\n",
    "#     loss += i*j\n",
    "# # loss = -model(v1, past=None)[0].sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' shore Term marine'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "logits = model(v1)[0]\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "prev_input = torch.multinomial(probs, num_samples=1)\n",
    "decode(prev_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[75.3702, 73.6392, 72.8180,  ..., 81.0872, 82.3673, 87.0727],\n",
       "        [74.3895, 72.5374, 71.8523,  ..., 80.4320, 81.0682, 86.7291],\n",
       "        [73.9969, 72.2922, 71.6807,  ..., 80.3298, 80.4573, 86.1744]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! :D'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9997, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.get_output_embeddings()(model.get_input_embeddings()(v1)).mean(dim=0)\n",
    "y = model.get_output_embeddings()(model.get_input_embeddings()(v2)).mean(dim=0)\n",
    "-torch.log(F.cosine_similarity(x,y, dim=-1))\n",
    "F.cosine_similarity(x,y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-122.8433, -150.5232, -149.6123,  ..., -168.9333, -161.6223,\n",
       "         -133.7793],\n",
       "        [-204.0837, -205.4568, -208.4964,  ..., -240.3041, -233.0705,\n",
       "         -217.4363],\n",
       "        [-205.8837, -210.4453, -214.1883,  ..., -246.4192, -239.3104,\n",
       "         -219.0015]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(v1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-6ee6c6e0f6f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-10d376e69163>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(token_ids)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces)\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[0mcurrent_sub_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurrent_sub_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[0msub_texts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_sub_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_gpt2.py\u001b[0m in \u001b[0;36mconvert_tokens_to_string\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert_tokens_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;34m\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyte_decoder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<pad>'])\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check learned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-e5569e72ff68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# generated a response while limiting the total chat history to 1000 tokens,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     chat_history_ids = B.generate(input_ids, max_length=1000, \n\u001b[1;32m---> 24\u001b[1;33m                                       \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#                                       num_beams=3,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#                                       early_stopping=True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, **model_kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             )\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36m_generate_no_beam_search\u001b[1;34m(self, input_ids, cur_len, max_length, min_length, do_sample, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, attention_mask, use_cache, model_kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             )\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         )\n\u001b[0;32m    733\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             )\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add cross attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;31m# residual connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "A = model\n",
    "B = model\n",
    "chat_history_ids = tokenizer.encode(tokenizer.bos_token + \"Hello\" + tokenizer.eos_token, return_tensors='pt')\n",
    "for frame in range(15):\n",
    "    epsilon = epsilon_by_frame(frame)\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "#     new_user_input_ids = tokenizer.encode(tokenizer.eos_token, return_tensors='pt')\n",
    "    input_ids = chat_history_ids\n",
    "    chat_history_ids = A.generate(input_ids, max_length=1000, \n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "#                              num_beams=3,\n",
    "# #                              num_return_sequences=1,\n",
    "#                              early_stopping=True,\n",
    "#                              no_repeat_ngram_size=3\n",
    "                            ) if frame > 0 else input_ids\n",
    "    question = chat_history_ids[:, input_ids.shape[-1]:][0] if frame > 0 else input_ids[0]\n",
    "    print(\"User: {}\".format(decode(question)))\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    input_ids = chat_history_ids # if step > 0 else new_user_input_ids\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = B.generate(input_ids, max_length=1000, \n",
    "                                      pad_token_id=tokenizer.eos_token_id,\n",
    "#                                       num_beams=3,\n",
    "#                                       early_stopping=True,\n",
    "#                                       num_return_sequences=3,\n",
    "#                                       no_repeat_ngram_size=3\n",
    "                                     )\n",
    "\n",
    "    # pretty print last output tokens from bot\n",
    "    answer = chat_history_ids[:, input_ids.shape[-1]:][0]\n",
    "    print(\"DialoGPT: {}\".format(decode(answer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 292)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.base_model.parameters())), len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-5168ea7c7dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "model.get_head_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
