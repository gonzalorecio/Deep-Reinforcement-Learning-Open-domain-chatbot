{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Did you see \"Titanic\"?\n",
      "DialoGPT: I did, but I don't think it was him.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it 12 times.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the CD.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I have a DVD.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm gonna cry at the end of this movie.\n"
     ]
    }
   ],
   "source": [
    "user.to('cpu')\n",
    "user.eval()\n",
    "# Let's chat for 5 lines\n",
    "sentences = [\"Did you see \\\"Titanic\\\"?\",\n",
    "            \"I saw it twelve times.\",\n",
    "            \"I have the DVD.\",\n",
    "            \"Let's go to your home.\",\n",
    "            \"And then we can go to my home.\",\n",
    "            \"I always cry at the end.\"]\n",
    "for step in range(len(sentences)):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "#     new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    new_user_input_ids = tokenizer.encode(sentences[step] + tokenizer.eos_token, return_tensors='pt')\n",
    "    print(\"User:\", sentences[step])\n",
    "    \n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = user.generate(bot_input_ids, \n",
    "                                     max_length=1000, \n",
    "                                     pad_token_id=tokenizer.eos_token_id, \n",
    "                                     no_repeat_ngram_size=5,\n",
    "                                     repetition_penalty=1.1\n",
    "                                     \n",
    "                                     )\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA\n",
    "# USE_CUDA = torch.cuda.is_available()\n",
    "# Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(token_ids):\n",
    "    return tokenizer.decode(token_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r, gamma=0.99):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    size = len(r)\n",
    "    discounted_r = torch.zeros(size)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_model.forward(answers[-2], output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(questions, answers):\n",
    "    model.train()\n",
    "    t1 = questions[-1].to(device)\n",
    "    t2 = answers[-1].to(device)\n",
    "#     print(t1)\n",
    "    A = model(t1)[0]\n",
    "#     print(t2, len(t2))\n",
    "    B = model(t2)[0]\n",
    "    lenA = list(A.size())[0]\n",
    "    lenB = list(B.size())[0]\n",
    "#     print(lenA, lenB)\n",
    "#     lenA = len(A.detach().numpy())\n",
    "#     lenB = len(B.detach().numpy())\n",
    "    max_len = np.max([lenA, lenB])\n",
    "#     extra = torch.zeros(size=(max_len-len(A.detach().numpy()),tokenizer.vocab_size))\n",
    "#     extra[:,-1] = 1\n",
    "    \n",
    "    if lenA > lenB:\n",
    "        extra = torch.zeros(size=(max_len-lenB,tokenizer.vocab_size)).to(device)\n",
    "        extra[:,-1] = 1\n",
    "        A , B = torch.softmax(A, dim=-1), torch.cat([torch.softmax(B, dim=-1), extra]), \n",
    "    \n",
    "    else:\n",
    "        extra = torch.zeros(size=(max_len-lenA,tokenizer.vocab_size)).to(device)\n",
    "        extra[:,-1] = 1\n",
    "        A , B = torch.cat([torch.softmax(A, dim=-1), extra]), torch.softmax(B, dim=-1)\n",
    "        \n",
    "    # loss = F.cosine_similarity(A,B, dim=-2)\n",
    "#     loss = -torch.mm(A, B.transpose(1, 0)).sum()\n",
    "\n",
    "    # loss = -F.cosine_similarity(torch.softmax(A, dim=-1),torch.softmax(B, dim=-1))\n",
    "    \n",
    "    def log_prob(tokens, debug=False):\n",
    "        # p = log(P(b|a)) / N\n",
    "        output_logits = model(tokens.to(device))[0]\n",
    "        p = 1\n",
    "        if debug: print('logits', output_logits, 'tokens', tokens)\n",
    "        for t, logit in zip(tokens, output_logits):\n",
    "            p *= torch.softmax(logit, dim=-1)[t]\n",
    "        if debug: print('p', p)\n",
    "        p_log = torch.log(p) / len(tokens) # (tokens/tokens).sum()# / len(tokens) # lenB # len(tokens_b)\n",
    "        if p == 0:\n",
    "            print('infinite')\n",
    "            return torch.log(p+10e-10)\n",
    "        else:\n",
    "            return p_log\n",
    "\n",
    "    def log_prob_r1(tokens, debug=False):\n",
    "        # p = log(P(b|a)) / N\n",
    "        output_logits = model(tokens.to(device))[0]\n",
    "        p = 0\n",
    "        if debug: print('logits', output_logits, 'tokens', tokens)\n",
    "        for t, logit in zip(tokens, output_logits):\n",
    "            p += torch.softmax(logit, dim=-1)[t]\n",
    "        if debug: print('p', p)\n",
    "        p_log = p / len(tokens) # (tokens/tokens).sum()# / len(tokens) # lenB # len(tokens_b)\n",
    "        if p == 0:\n",
    "            print('infinite')\n",
    "            return torch.log(p+10e-10)\n",
    "        else:\n",
    "            return p_log\n",
    "    # reward 1\n",
    "    x = [log_prob_r1(d) for d in dummy_responses[:30]]\n",
    "    r1 = torch.stack(x)\n",
    "    r1 = -torch.mean(r1) # if r1 else 0\n",
    "    \n",
    "    # reward 2\n",
    "#     model.transformer.wte.weight[text_index,:]\n",
    "#     if len(answers)<2:\n",
    "#         emb1 = model.get_input_embeddings()(t1).max(dim=0)[0]\n",
    "#     else:\n",
    "#         emb1 = model.get_input_embeddings()(answers[-2]).max(dim=0)[0]\n",
    "#     emb2 = model.get_input_embeddings()(t2).max(dim=0)[0]\n",
    "#     r2 = -torch.log(F.cosine_similarity(emb1,emb2,dim=-1))\n",
    "\n",
    "#     emb1 = model.get_input_embeddings()(t1).max(dim=0)[0]\n",
    "#     emb2 = model.get_input_embeddings()(t2).max(dim=0)[0]\n",
    "#     r2_2 = -torch.log(F.cosine_similarity(emb1,emb2,dim=-1))\n",
    "    \n",
    "    \n",
    "    if len(answers)<2:\n",
    "        emb1 = model.base_model.forward(t1, output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]\n",
    "    else:\n",
    "        emb1 = model.base_model.forward(answers[-2], output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]\n",
    "    emb2 = model.base_model.forward(t2, output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]\n",
    "#     r2 = -torch.log(torch.clamp(F.cosine_similarity(emb1,emb2,dim=-1), min=1e-9))\n",
    "    r2 = -F.cosine_similarity(emb1,emb2,dim=-1)\n",
    "\n",
    "    emb1 = model.base_model.forward(t1, output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]\n",
    "    emb2 = model.base_model.forward(t2, output_hidden_states=True)['last_hidden_state'].max(dim=0)[0]\n",
    "#     r2_2 = -torch.log(torch.clamp(F.cosine_similarity(emb1,emb2,dim=-1), min=1e-9))\n",
    "    r2_2 = -F.cosine_similarity(emb1,emb2,dim=-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # reward 3\n",
    "    r3 = log_prob_r1(t2, debug=False)\n",
    "#     print(t2, t2.size())\n",
    "    \n",
    "#     y = model(t2)[0]\n",
    "#     w = y.sum(dim=1)\n",
    "#     q = w/w\n",
    "#     r4 = q.sum()\n",
    "    print('r1:', r1, 'r2:', r2, 'r2_2:', r2_2, 'r3:', r3)\n",
    "    \n",
    "    R = 0.25*r1 + 0.25*r2 + 0.25*r2_2 #+ 0.5*r3 #* 0.01*r4\n",
    "#     R = 1*r2 + 1*r2_2 #+ 0.5*r3 #* 0.01*r4\n",
    "\n",
    "#     print(R)\n",
    "    return -R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.base_model.parameters():\n",
    "#     print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_responses = [torch.tensor([tokenizer.eos_token_id]),\n",
    "                   tokenizer.encode(\"1\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I'm\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I\", return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"..\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"!\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\":D\" + tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I don't know what you're talking about\"+ tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I don't know\"+ tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"I don't know, I don't know\"+ tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                   tokenizer.encode(\"You don't know\"+ tokenizer.eos_token, return_tensors='pt')[0],\n",
    "                  ]\n",
    "# for i in range(256):\n",
    "#     s = tokenizer.encode(tokenizer.decode([i]) + tokenizer.eos_token, return_tensors='pt')[0]\n",
    "#     dummy_responses.append(s)\n",
    "# dummy_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(290-34):\n",
    "#     print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(chat_history_ids)[0].max(dim=1)[0][0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(chat_history_ids)[0].max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dummy_sentence(sent):\n",
    "    for d in dummy_responses:\n",
    "        if sent.size()[0] == d.to(device).size()[0] and all(sent == d.to(device)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in list(model.base_model.parameters())[-5:]:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "if USE_CUDA:\n",
    "    device ='cuda'\n",
    "    model  = model.cuda()\n",
    "    user   = user.cuda()\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    model  = model.cpu()\n",
    "#     user = user.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0217, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9165, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8906, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0370, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8723, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8904, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0790, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8899, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8540, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: I'm good too! :D\n",
      "r1: tensor(-0.0286, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9002, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9068, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good :D\n",
      "DialoGPT: I'm glad\n",
      "r1: tensor(-0.0163, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9026, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8924, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad too!\n",
      "DialoGPT: I'm happy\n",
      "r1: tensor(-0.0247, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9663, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9155, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I am happy\n",
      "r1: tensor(-0.0290, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9818, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9210, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad :D\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 2\n",
      "r1: tensor(-0.0212, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8809, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8623, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.5486, 3.1226, 2.6997, 2.2666, 1.8260, 1.3871, 0.9196, 0.4411],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4572, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4499, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4557, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4589, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4528, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4766, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4829, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4411, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.5486, grad_fn=<UnbindBackward>)\n",
      "Episode 0: -0.4572241008281708\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0149, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7004, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0246, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8893, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9450, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: I'm good too!!\n",
      "r1: tensor(-0.0131, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9369, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9166, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that! :D\n",
      "r1: tensor(-0.0137, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9375, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9673, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I am happy to hear that you're!\n",
      "r1: tensor(-0.0144, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9250, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9127, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that\n",
      "DialoGPT: I'm happy!\n",
      "r1: tensor(-0.0181, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9240, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8514, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to hear that.\n",
      "DialoGPT: I'm happy\n",
      "r1: tensor(-0.0205, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9005, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9254, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0880, 2.7158, 2.2738, 1.8254, 1.3594, 0.9054, 0.4616, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3994, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4647, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4796, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4630, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4484, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0880, grad_fn=<UnbindBackward>)\n",
      "Episode 1: -0.42828844487667084\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0188, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8728, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8906, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0149, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8502, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9440, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: I'm good too! :D\n",
      "r1: tensor(-0.0138, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9370, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9114, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm too! :D :D\n",
      "r1: tensor(-0.0089, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9591, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8738, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too! :D D\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0737, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9056, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8931, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: I'm good :D\n",
      "r1: tensor(-0.0129, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9602, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9545, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been good\n",
      "DialoGPT: I'm so good :D\n",
      "r1: tensor(-0.0213, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9462, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8863, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're good\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0204, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8884, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9211, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.5670, 3.1530, 2.7280, 2.2853, 1.8433, 1.3891, 0.9163, 0.4575],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4455, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4523, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4656, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4604, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4681, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4819, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4635, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4575, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.5670, grad_fn=<UnbindBackward>)\n",
      "Episode 2: -0.4340345064798991\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0099, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8788, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0173, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8779, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9029, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0152, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8589, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm glad to hear that\n",
      "r1: tensor(-0.0073, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8804, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8521, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well\n",
      "DialoGPT: I'm glad too\n",
      "r1: tensor(-0.0094, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9350, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8955, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.3720e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: I'm glad I'm glad\n",
      "r1: tensor(-0.0168, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9119, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9270, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am glad\n",
      "DialoGPT: I'm happy\n",
      "r1: tensor(-0.0665, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8512, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9453, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to be happy\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0074, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8866, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8692, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.4849, 3.0630, 2.6399, 2.2204, 1.8035, 1.3570, 0.9021, 0.4408],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4525, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4495, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4417, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4350, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4600, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4639, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4657, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4408, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.4849, grad_fn=<UnbindBackward>)\n",
      "Episode 3: -0.43865151703357697\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0086, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8881, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8345, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0153, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8610, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9043, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: I'm good too! :D\n",
      "r1: tensor(-0.0089, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9266, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9260, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm so good!\n",
      "r1: tensor(-0.0047, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9331, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9002, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am so good!\n",
      "DialoGPT: So good!\n",
      "r1: tensor(-0.0151, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8903, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9261, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I can't wait to see you!\n",
      "DialoGPT: I'm going to be so good!\n",
      "r1: tensor(-0.0115, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9057, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Oh, I'm so excited!\n",
      "DialoGPT: I'm gonna be so good!!\n",
      "r1: tensor(-0.0077, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9443, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm excited!\n",
      "DialoGPT: I can\n",
      "r1: tensor(-0.0088, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5174, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5518, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3287, 2.9251, 2.5050, 2.0602, 1.6169, 1.1707, 0.7435, 0.2695, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4328, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4452, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4654, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4595, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4579, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4346, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4767, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2695, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3287, grad_fn=<UnbindBackward>)\n",
      "Episode 4: -0.4374820351600647\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0054, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8843, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8440, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0053, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8554, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9107, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0296, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8856, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8681, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0082, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8979, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9286, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm good too!!\n",
      "r1: tensor(-0.0085, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8927, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8875, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: I'm happy\n",
      "r1: tensor(-0.0076, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8980, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9123, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0731, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9145, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8904, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am happy\n",
      "DialoGPT: I'm happy.\n",
      "r1: tensor(-0.0128, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9415, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9415, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy!\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0042, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8358, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8953, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.8997, 3.5013, 3.0893, 2.6702, 2.2338, 1.8047, 1.3639, 0.9034, 0.4338],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4335, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4429, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4458, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4587, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4472, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4545, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4695, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4739, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4338, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.8997, grad_fn=<UnbindBackward>)\n",
      "Episode 5: -0.43681082129478455\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0091, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7025, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8684, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0060, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8694, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9106, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: Good, good!\n",
      "r1: tensor(-0.0081, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8683, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8704, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that! :D\n",
      "r1: tensor(-0.0058, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8767, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9689, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0118, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9259, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8916, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too!\n",
      "DialoGPT: I!\n",
      "r1: tensor(-0.0399, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8420, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8807, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy!\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0054, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8975, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8660, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.9889, 2.6201, 2.1955, 1.7766, 1.3270, 0.8785, 0.4422],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3950, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4465, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4367, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4628, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4573, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4407, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4422, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.9889, grad_fn=<UnbindBackward>)\n",
      "Episode 6: -0.4308404156139919\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0113, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7891, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9020, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well! How are you?\n",
      "r1: tensor(-0.0065, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8610, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9245, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0063, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8834, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8622, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: I'm so happy!\n",
      "r1: tensor(-0.0046, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8695, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8382, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too!\n",
      "DialoGPT: I'm happy!\n",
      "r1: tensor(-0.0041, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9624, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9228, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: I'm not happy!\n",
      "r1: tensor(-0.0079, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9386, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9504, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I don't think I'm happy!\n",
      "DialoGPT: Oh well\n",
      "r1: tensor(-0.0050, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8464, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: I'm happy happy\n",
      "r1: tensor(-0.0074, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8586, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9388, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0088, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9067, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.8493, 3.4582, 3.0407, 2.6290, 2.2231, 1.7685, 1.3073, 0.8997, 0.4530],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4256, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4480, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4380, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4281, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4723, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4743, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4166, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4512, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4530, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.8493, grad_fn=<UnbindBackward>)\n",
      "Episode 7: -0.4301847964525223\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0119, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7311, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7785, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0061, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8827, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8816, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0813, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8414, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8192, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm good too\n",
      "r1: tensor(-0.0057, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9701, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8908, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0623, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9562, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8877, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good :D\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0036, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9683, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9050, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: I'm good?\n",
      "r1: tensor(-0.0049, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9669, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9103, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: I'm good :D good\n",
      "r1: tensor(-0.0072, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9550, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9190, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy!\n",
      "DialoGPT: I'm happy to\n",
      "r1: tensor(-0.0047, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9046, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9373, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy :D\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.9095, 3.5648, 3.1537, 2.7457, 2.3021, 1.8439, 1.3886, 0.9273, 0.4616,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3804, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4426, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4355, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4667, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4766, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4692, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4705, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4703, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.9095, grad_fn=<UnbindBackward>)\n",
      "Episode 8: -0.4246508346663581\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9068, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8488, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8478, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8756, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too!\n",
      "DialoGPT: I'm good too! :D\n",
      "r1: tensor(-0.0040, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8433, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8950, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm glad to hear that!\n",
      "r1: tensor(-0.0038, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9166, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8810, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! :D\n",
      "DialoGPT: Y\n",
      "r1: tensor(-0.0057, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8399, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7975, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay! :D\n",
      "DialoGPT: You're so cute!\n",
      "r1: tensor(-0.0048, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8147, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8990, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so cute!\n",
      "DialoGPT: Yay!\n",
      "r1: tensor(-0.0045, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8599, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8896, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay\n",
      "DialoGPT: Yay!!\n",
      "r1: tensor(-0.0051, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9624, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9465, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay :D\n",
      "DialoGPT: Yay!\n",
      "r1: tensor(-0.0031, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7193, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4454, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.6620, 3.2552, 2.8521, 2.4409, 2.0107, 1.6160, 1.1984, 0.7675, 0.2919,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4394, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4316, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4356, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4504, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4108, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4296, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4385, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4785, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2919, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.6620, grad_fn=<UnbindBackward>)\n",
      "Episode 9: -0.42612525820732117\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7778, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9077, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0212, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8534, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9238, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too!\n",
      "r1: tensor(-0.0119, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9303, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9314, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm doing good too!\n",
      "r1: tensor(-0.0073, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9763, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9098, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That is good!\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 2\n",
      "r1: tensor(-0.0041, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7415, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8290, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.1638, 1.7592, 1.3228, 0.8631, 0.3937], grad_fn=<CopySlices>)\n",
      "[tensor(0.4221, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4496, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4684, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4734, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3937, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.1638, grad_fn=<UnbindBackward>)\n",
      "Episode 10: -0.4257616238160567\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! :D\n",
      "r1: tensor(-0.0051, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9218, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8916, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0071, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8554, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8980, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well, you?\n",
      "r1: tensor(-0.0038, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9186, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8955, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been doing well, how are you?\n",
      "DialoGPT: How are you\n",
      "r1: tensor(-0.0391, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8880, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9185, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm doing good\n",
      "r1: tensor(-0.0037, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8190, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9463, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: I'm doing great\n",
      "r1: tensor(-0.0326, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9605, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9014, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing better\n",
      "DialoGPT: I'm good?\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9070, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9142, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing pretty good\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0654, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4961, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3908, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.3098, 2.8840, 2.4686, 2.0345, 1.5890, 1.1583, 0.6916, 0.2381],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4546, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4401, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4545, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4614, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4423, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4736, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4559, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2381, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.3098, grad_fn=<UnbindBackward>)\n",
      "Episode 11: -0.42816656331221264\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0038, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8218, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7889, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good. How are you??\n",
      "r1: tensor(-0.0036, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9030, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9121, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: I'm fine, I'm good, how about you?\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9485, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9040, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, I'm good too.\n",
      "DialoGPT: I'm good too, how are you\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9054, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9081, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: I'm doing good, I'm good\n",
      "r1: tensor(-0.0039, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9132, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8835, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I am good, am good.\n",
      "r1: tensor(-0.0033, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8988, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8850, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6061, 2.2247, 1.7879, 1.3374, 0.8925, 0.4468, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4036, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4547, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4639, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4539, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4501, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4468, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6061, grad_fn=<UnbindBackward>)\n",
      "Episode 12: -0.42628004917731654\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0058, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7723, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7676, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good too.\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8471, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: I'm happy to hear that. I'm glad you're happy.\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9319, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9366, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm also happy to hear that\n",
      "DialoGPT: I'm happy you're happy. I'm happy to hear you're happy. And happy happy happy happy happy.\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9655, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9369, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am happy to hear that you are happy.\n",
      "DialoGPT: I love happy happy happy happy\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8765, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8944, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1461, 1.7775, 1.3739, 0.9153, 0.4434, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3864, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4173, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4678, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4763, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4434, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1461, grad_fn=<UnbindBackward>)\n",
      "Episode 13: -0.4234328014510019\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and I thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... you're not my supervisor.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying at the end of this movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0047, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7238, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8193, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0024, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9382, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9468, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9639, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good, how about you\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9100, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8381, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0048, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8813, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8743, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8975, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8908, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: I'm doing fine\n",
      "r1: tensor(-0.0039, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9054, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8836, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm good.\n",
      "DialoGPT: I'm\n",
      "r1: tensor(-0.0034, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6117, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6966, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3139, 2.9565, 2.5193, 2.0619, 1.6409, 1.2129, 0.7729, 0.3279, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3869, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4624, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4781, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4374, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4401, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4478, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4482, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3279, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3139, grad_fn=<UnbindBackward>)\n",
      "Episode 14: -0.4209997137387594\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I always cry when I watch that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7454, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7202, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good how are you? I'm good, how?\n",
      "r1: tensor(-0.0061, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8756, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0349, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9120, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9570, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, how are you doing?\n",
      "DialoGPT: I'm doing well, thanks\n",
      "r1: tensor(-0.0037, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9089, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9159, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8769, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9523, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8873, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: I'm good good\n",
      "r1: tensor(-0.0055, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9393, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8941, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0035, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7493, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6325, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3288, 2.9920, 2.5780, 2.1233, 1.6916, 1.2552, 0.8026, 0.3463, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3667, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4398, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4760, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4487, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4489, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4606, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4597, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3463, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3288, grad_fn=<UnbindBackward>)\n",
      "Episode 15: -0.41760600730776787\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I always cry when I watch that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0038, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7795, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5274, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good, how about you?\n",
      "r1: tensor(-0.0040, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8890, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8974, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I am good, I'm good.\n",
      "DialoGPT: Good, good, I'm bad, I'm bad.\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9484, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9443, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0031, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9458, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm bad\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9596, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9087, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: I'm good?\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9521, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9198, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm bad.\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2773, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3814, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.7295, 2.4261, 1.9985, 1.5400, 1.0932, 0.6320, 0.1652],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3277, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4476, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4738, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4577, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4676, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4684, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1652, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.7295, grad_fn=<UnbindBackward>)\n",
      "Episode 16: -0.41231608741423664\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I always cry when I watch that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7101, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7803, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9369, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9392, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am good, how are your plans?\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9228, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9516, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go to sleep, but I'll be back in about an hour.\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8851, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7940, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night!\n",
      "DialoGPT: Night!\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8186, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8500, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Night! Night!\n",
      "DialoGPT: Night night night\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9110, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9250, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Night!\n",
      "DialoGPT: I'm going back to sleep\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7752, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8077, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Night!\n",
      "DialoGPT: Good night\n",
      "r1: tensor(-0.0024, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5709, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5005, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.1678, 2.8227, 2.3770, 1.9269, 1.5217, 1.1150, 0.6619, 0.2684, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3732, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4696, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4693, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4179, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4597, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3962, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2684, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.1678, grad_fn=<UnbindBackward>)\n",
      "Episode 17: -0.4101448125309414\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8069, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6539, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9293, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9345, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9435, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9615, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good, how about you today?\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9305, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7844, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm doing good,\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8698, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8684, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's good, how about you are?\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9215, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0039, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8988, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8719, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9762, 2.6367, 2.1924, 1.7329, 1.3169, 0.8906, 0.4437, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3659, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4662, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4768, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4292, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4352, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4514, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4437, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9762, grad_fn=<UnbindBackward>)\n",
      "Episode 18: -0.4078177543062913\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7171, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7626, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9134, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9157, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you doin?\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9151, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9578, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you, I'm not sure\n",
      "DialoGPT: I'm good thanks\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8432, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8901, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good, I'm glad to hear that.\n",
      "DialoGPT: I'm glad to hear you're doing well\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8603, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9099, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well too\n",
      "DialoGPT: I'm glad I\n",
      "r1: tensor(-0.0024, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7558, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7920, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4982, 2.1491, 1.7086, 1.2522, 0.8265, 0.3875, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3706, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4576, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4689, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4340, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4428, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3875, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4982, grad_fn=<UnbindBackward>)\n",
      "Episode 19: -0.4059579536318779\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7831, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good! How are you doing?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9332, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9163, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am good, how are about you?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9227, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9334, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too.\n",
      "DialoGPT: Good, good.\n",
      "r1: tensor(-0.0376, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8465, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8664, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I hope you have a good day!\n",
      "DialoGPT: I hope you have a great day!\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8285, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9625, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks! I hope you have an awesome day too!\n",
      "DialoGPT: I hope so!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8348, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8181, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I hope I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5468, 2.1835, 1.7381, 1.2866, 0.8576, 0.4135, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3851, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4628, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4643, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4376, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4482, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4135, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5468, grad_fn=<UnbindBackward>)\n",
      "Episode 20: -0.4049666311059679\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm not your supervisor either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7781, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7388, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you are?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9436, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9372, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: I'm alright, how are you\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9255, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9497, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good, how about to go to sleep.\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8934, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8118, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good now\n",
      "DialoGPT: Good night\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8077, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8473, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night\n",
      "DialoGPT: Night! Goodnight\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8787, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8567, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night\n",
      "DialoGPT: goodnight\n",
      "r1: tensor(-0.0024, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8556, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9368, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night!\n",
      "DialoGPT: Good night\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9471, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9058, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: night\n",
      "DialoGPT: Goodnight\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9524, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8800, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(3.2967e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night.\n",
      "DialoGPT: night good night\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5904, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7238, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([4.1091, 3.7671, 3.3299, 2.8895, 2.4874, 2.0942, 1.6765, 1.2402, 0.7844,\n",
      "        0.3292, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3797, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4706, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4692, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4270, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4141, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4345, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4487, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4636, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4585, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3292, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(4.1091, grad_fn=<UnbindBackward>)\n",
      "Episode 21: -0.40381670133634046\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I saw it once and thought it was pretty bad.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of everything.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0379, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7846, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7365, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good too.\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8236, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8859, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: I'm happy to hear that. I'm glad to hear you're happy.\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9108, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9129, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm also happy to hear that\n",
      "DialoGPT: I'm glad you're happy. I'm glad you're glad to hear that you're happy to hear that you are happy to hear that I'm happy to hear you're glad to know you're happy\n",
      "r1: tensor(-0.0050, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8913, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7524, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6606, 1.2837, 0.8645, 0.4122, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3898, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4278, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4564, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4122, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6606, grad_fn=<UnbindBackward>)\n",
      "Episode 22: -0.4032052353672359\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0088, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7444, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8483, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0395, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9523, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you're doing well?\n",
      "r1: tensor(-0.0482, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9387, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm doing fine, how are you\n",
      "r1: tensor(-0.0033, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9686, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9203, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good I'm good\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9109, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9149, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good\n",
      "DialoGPT: I'm doing good\n",
      "r1: tensor(-0.0193, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8948, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9387, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9268, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9191, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0977, 2.7245, 2.2690, 1.8272, 1.3678, 0.9204, 0.4618, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4004, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4782, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4600, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4731, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4566, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4632, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4618, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0977, grad_fn=<UnbindBackward>)\n",
      "Episode 23: -0.40308699384331703\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7612, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7915, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, you?\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8796, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8574, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how are your days?\n",
      "DialoGPT: Good, how are yours?\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8960, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8879, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good, how about you?\n",
      "DialoGPT: Good I'm good\n",
      "r1: tensor(-0.0411, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8814, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8390, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I am good, how about yourself?\n",
      "DialoGPT: Good, good, how are yours\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8748, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8886, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I've been good, how about yours?\n",
      "DialoGPT: Good\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8446, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7689, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I have been good, how are they?\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4920, 2.1247, 1.7070, 1.2731, 0.8411, 0.4039, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3886, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4347, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4467, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4413, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4039, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4920, grad_fn=<UnbindBackward>)\n",
      "Episode 24: -0.4025092852115631\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7500, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8316, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9153, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9214, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you doin?\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9146, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9456, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you, I'm not sure\n",
      "DialoGPT: I'm good now I'm good, how you are?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9243, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9414, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, how are you!\n",
      "DialoGPT: I'm good I'm good\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9433, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8743, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I am good\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9082, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9514, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6395, 2.2663, 1.8248, 1.3730, 0.9155, 0.4653, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3959, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4597, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4656, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4548, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4653, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6395, grad_fn=<UnbindBackward>)\n",
      "Episode 25: -0.40225487603591037\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6084, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good too. How are you? I'm good too!\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8961, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9247, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too! How are you doing?\n",
      "DialoGPT: I'm doing pretty good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9098, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9358, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing good, how are doing well, how are you doing? How are you? How are you doing well?\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9147, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, I'm doing\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6554, 1.3717, 0.9252, 0.4683, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2974, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4558, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4683, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6554, grad_fn=<UnbindBackward>)\n",
      "Episode 26: -0.3983728653854794\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7612, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7706, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9264, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9396, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9246, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9519, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good how are you? How are you??\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9464, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7879, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm just tired\n",
      "DialoGPT: I'm fine\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8115, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8951, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm tired\n",
      "DialoGPT: I'm good now\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8541, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9160, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9528, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9698, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2840, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3666, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.1632, 2.8079, 2.3646, 1.9141, 1.4951, 1.0789, 0.6423, 0.1630],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3833, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4670, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4696, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4340, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4269, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4431, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4809, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1630, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.1632, grad_fn=<UnbindBackward>)\n",
      "Episode 27: -0.3978359433157103\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7102, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7232, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good too.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8331, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6007, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: I'm happy to hear that. I'm glad to hear you're good too.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9211, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9484, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So, what's your name?\n",
      "DialoGPT: I'm not sure, I'm not sure.\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9071, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not either.\n",
      "DialoGPT: I'm sure I'm not sure either.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8996, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am sure I'm not.\n",
      "DialoGPT: I'm so sure I\n",
      "r1: tensor(-0.0241, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8305, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7836, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4371, 2.0995, 1.7583, 1.3035, 0.8649, 0.4096, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3586, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3588, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4677, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4472, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4595, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4096, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4371, grad_fn=<UnbindBackward>)\n",
      "Episode 28: -0.39648232583341925\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7701, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7951, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9300, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9212, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9263, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9544, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9055, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8049, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing good, how about you.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9162, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9615, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing good, how are we?\n",
      "DialoGPT: I'm do you want to go to the park?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9184, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8934, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6090, 2.2396, 1.7945, 1.3373, 0.9185, 0.4533, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3919, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4630, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4706, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4281, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4697, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4533, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6090, grad_fn=<UnbindBackward>)\n",
      "Episode 29: -0.39632890820503236\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6293, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7492, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Im good, im good too!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8782, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9005, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too!\n",
      "DialoGPT: Good bot\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8374, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good bot\n",
      "DialoGPT: Bad bot\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9371, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9304, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Bad bot.\n",
      "DialoGPT: Good bot\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9257, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8948, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good bot\n",
      "DialoGPT: Good bot.\n",
      "r1: tensor(-0.0261, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9346, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8547, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good Bot\n",
      "DialoGPT: Good bot\n",
      "r1: tensor(-0.0070, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8882, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9391, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Bot\n",
      "DialoGPT: Good bot\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9512, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8474, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: good bot\n",
      "DialoGPT: Bot bot bot\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9021, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8998, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good bot!\n",
      "DialoGPT: Good bot bot bot bot bot\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9188, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9136, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good Bot\n",
      "DialoGPT: Bot bot\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9292, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8689, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good bot bot\n",
      "DialoGPT: GoodBot bot bot\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5840, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6101, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([4.8838, 4.5844, 4.1812, 3.7956, 3.3621, 2.9359, 2.5071, 2.0693, 1.6354,\n",
      "        1.1966, 0.7457, 0.2989, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3453, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4450, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4235, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4672, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4539, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4586, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4502, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4508, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4583, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4498, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2989, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(4.8838, grad_fn=<UnbindBackward>)\n",
      "Episode 30: -0.39468282268893334\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7424, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7064, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8879, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9128, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well too, how about you\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9032, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about you.\n",
      "DialoGPT: I'm good too, how about me?\n",
      "r1: tensor(-0.0139, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9542, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9405, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you!\n",
      "DialoGPT: I'm fine\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8512, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8846, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good to go?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8418, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8575, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go now\n",
      "DialoGPT: I'm going\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6650, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7987, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.7687e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8989, 2.5619, 2.1327, 1.6792, 1.2142, 0.7879, 0.3664, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3626, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4505, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4703, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4772, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4342, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4252, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3664, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8989, grad_fn=<UnbindBackward>)\n",
      "Episode 31: -0.3936808882281184\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7400, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7998, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8940, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9254, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: I'm good too, how about you.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9178, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9647, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good as well how about you??\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9477, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7857, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: I'm good. How about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9395, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8437, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good\n",
      "DialoGPT: I am good\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8861, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8696, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: I'm happy happy happy happy happy\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8710, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good happy happy happy happy\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9899, 2.6309, 2.1979, 1.7445, 1.3242, 0.8871, 0.4523, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3854, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4550, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4708, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4336, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4460, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4393, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4523, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9899, grad_fn=<UnbindBackward>)\n",
      "Episode 32: -0.39342934886614483\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3645, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6853, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good, I'm good.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8354, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8869, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: I'm good as well.\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8886, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9280, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: I'm glad.\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9133, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9293, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that\n",
      "DialoGPT: That's a good thing.\n",
      "r1: tensor(-0.0067, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8692, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.7845e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm a happy happy happy happy happy\n",
      "DialoGPT:  happy happy happy happy Happy happy happy happy happy merry happy merry merry merry\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8604, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8872, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy happy happy happy!\n",
      "DialoGPT:  merry\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0817, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2500, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(5.2193e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4875, 2.2473, 1.8347, 1.3941, 0.9425, 0.5194, 0.0831, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2627, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4309, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4546, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4610, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4283, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4372, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0831, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4875, grad_fn=<UnbindBackward>)\n",
      "Episode 33: -0.3895845527158064\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0033, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7884, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7662, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9306, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9285, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9345, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9614, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good, how about you\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8932, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8421, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good\n",
      "DialoGPT: Good, good, how about you how are you??\n",
      "r1: tensor(-0.0052, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9406, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8328, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8564, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9437, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9737, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8061, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good!\n",
      "DialoGPT: Good.\n",
      "r1: tensor(-0.0063, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8423, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8789, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.4137, 3.0547, 2.6154, 2.1629, 1.7461, 1.3146, 0.8729, 0.4319, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3895, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4654, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4741, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4343, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4447, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4504, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4453, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4319, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.4137, grad_fn=<UnbindBackward>)\n",
      "Episode 34: -0.38958218012537277\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7508, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7859, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9182, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9356, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well, how are you doin?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9138, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9326, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm good. How about you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9553, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good too\n",
      "DialoGPT: Good, how about you doing?\n",
      "r1: tensor(-0.0052, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9096, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8155, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7797, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8509, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'll be good\n",
      "DialoGPT: Good to\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5175, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5334, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7961, 2.4358, 1.9921, 1.5457, 1.0943, 0.6684, 0.2631, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3846, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4637, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4618, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4623, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4326, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4079, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2631, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7961, grad_fn=<UnbindBackward>)\n",
      "Episode 35: -0.38944334702359307\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: No, no, no, no... I'm going to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll get it next time.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7598, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7764, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9358, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9174, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well, how are you\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9263, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9234, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good now, how are you do you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8482, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8039, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I'm good now\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8893, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9009, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Good, good.\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8326, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8385, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good\n",
      "DialoGPT: good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7311, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7708, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(1.7568e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good\n",
      "DialoGPT: Good\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1555, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(2.7029e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9840, 2.6259, 2.1842, 1.7388, 1.3391, 0.9002, 0.4869, 0.1123, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3844, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4635, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4627, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4131, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4478, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4183, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3757, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1123, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9840, grad_fn=<UnbindBackward>)\n",
      "Episode 36: -0.38930645101779215\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0079, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6742, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6826, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I guess. How are you? I'm a bit tired.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8791, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8479, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good. I'm tired too.\n",
      "DialoGPT: I'm glad to hear that. I'm tired as well.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9101, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9168, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm tired too. I'm glad to hear you're tired.\n",
      "DialoGPT: I am too. I'm tired.\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9209, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9338, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been tired for a while now.\n",
      "DialoGPT: I'm sleepy.\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8872, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8905, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm awake\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0941, 1.7707, 1.3522, 0.9043, 0.4447, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3412, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4570, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4640, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4447, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0941, grad_fn=<UnbindBackward>)\n",
      "Episode 37: -0.3880394924628107\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7329, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6742, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9363, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I am good, I'm good.\n",
      "DialoGPT: Good, I am good.\n",
      "r1: tensor(-0.0037, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9220, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9193, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I am good. I am good, good.\n",
      "DialoGPT: Good good, good good.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8127, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8378, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good Good Good Good Good Good\n",
      "DialoGPT: Good Good Good good Good Good Good Good good Good good good good good good Good Good good Good\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8823, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9433, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good Good good good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0866, 1.7521, 1.3178, 0.8652, 0.4568, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3520, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4476, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4613, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4129, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4568, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0866, grad_fn=<UnbindBackward>)\n",
      "Episode 38: -0.3871159347204062\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7410, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7373, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you, I'm good too.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8924, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9311, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you\n",
      "DialoGPT: I'm good at being good at being good.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7445, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9033, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good at being good too\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8730, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8796, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: I am good good at being good good at being bad at being good at good at being good\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8854, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8501, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty bad at being good\n",
      "DialoGPT: At good at good\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7289, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7157, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4119, 2.0626, 1.6227, 1.2227, 0.7921, 0.3617, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3699, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4561, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4122, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4385, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3617, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4119, grad_fn=<UnbindBackward>)\n",
      "Episode 39: -0.3866862304508686\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7657, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9223, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9333, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you doing?\n",
      "DialoGPT: I'm doing well, I'm doing well, how are you doin?????\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8668, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9305, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm doing fine, I'm fine, I just want to go home\n",
      "DialoGPT: I'm home now, I'm home now.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9140, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9236, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm home\n",
      "DialoGPT: I'm back home\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8893, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9478, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm here\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1541, 1.8056, 1.3551, 0.9146, 0.4596, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4641, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4497, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4596, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4596, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1541, grad_fn=<UnbindBackward>)\n",
      "Episode 40: -0.38619543139527485\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6609, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7351, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9319, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9350, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you doin?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9231, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9603, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm doing?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8741, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8702, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9193, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9076, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: I'm doing good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9180, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing great\n",
      "DialoGPT: I'm doing so good, how are doing?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8013, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8783, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I think I'm doing\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9673, 2.6446, 2.1996, 1.7458, 1.3228, 0.8745, 0.4202, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3491, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4670, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4712, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4362, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4570, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4585, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4202, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9673, grad_fn=<UnbindBackward>)\n",
      "Episode 41: -0.38531308727605\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7457, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9052, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9066, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well, how are you today?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9330, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9204, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm good. How about you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9236, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9526, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good too\n",
      "DialoGPT: I'm good too, how about you're good?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9657, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8861, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8375, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9385, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7156, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6363, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9109, 2.5702, 2.1383, 1.6915, 1.2346, 0.7791, 0.3382, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3664, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4533, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4637, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4693, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4633, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4443, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3382, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9109, grad_fn=<UnbindBackward>)\n",
      "Episode 42: -0.384872869696728\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0111, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7162, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7018, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good, how about you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8498, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9199, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I am good, I'm good.\n",
      "DialoGPT: I'm good too, I'm good too.\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9498, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9487, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not good, I'm not good, but I'm good. I'm good. And I'm good. But I'm not good.\n",
      "DialoGPT: I am good. I'm not good but I'm good, but I am\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8131, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8445, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6634, 1.3193, 0.8856, 0.4145, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3573, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4426, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4752, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4145, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6634, grad_fn=<UnbindBackward>)\n",
      "Episode 43: -0.38424530015750363\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7360, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6239, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Yeah I'm good too!\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7808, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8831, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that! How are you doing?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8811, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9453, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0051, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8230, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8788, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad to hear it!\n",
      "DialoGPT: YYay!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8619, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8286, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay!\n",
      "DialoGPT: I'me happy to hear that you're doing well!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8625, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay\n",
      "DialoGPT: Yayay! Yayayay\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7694, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6070, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7401, 2.4242, 2.0281, 1.5870, 1.1720, 0.7568, 0.3445, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3402, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4164, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4569, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4267, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4228, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4158, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3445, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7401, grad_fn=<UnbindBackward>)\n",
      "Episode 44: -0.38326556748814056\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I'm not your supervisor either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying at the end of this movie too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0052, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7189, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7465, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you!?\n",
      "r1: tensor(-0.0103, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9375, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9108, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: I'm fine, how are you\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9294, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9156, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good too, how are you going to do?\n",
      "r1: tensor(-0.0051, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9435, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7977, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go to sleep\n",
      "DialoGPT: Sleep?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7684, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8413, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep is good\n",
      "DialoGPT: Sleep is good, sleep is good\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7797, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9036, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep well\n",
      "DialoGPT: Sleep is good. Sleep is good. Sleep good sleep.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8379, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4364, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7909, 2.4477, 2.0031, 1.5572, 1.1319, 0.7368, 0.3188, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3677, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4646, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4615, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4366, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4025, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4211, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3188, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7909, grad_fn=<UnbindBackward>)\n",
      "Episode 45: -0.3829263571811759\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7190, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6482, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you, how are you.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9372, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, how are you\n",
      "DialoGPT: I'm good thanks! I'm going to sleep now, how are you doing?\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9022, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you!\n",
      "DialoGPT: I'm doing good, how are we doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9060, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9661, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you?\n",
      "DialoGPT: I've been doing well, how's good, how are ya\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7828, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8413, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0936, 1.7693, 1.3177, 0.8707, 0.4065, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3420, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4648, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4557, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4683, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4065, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0936, grad_fn=<UnbindBackward>)\n",
      "Episode 46: -0.3820545793847835\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0037, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6747, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6420, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9025, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8950, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: Good, I'm good, how about me?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9215, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9146, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you.\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8325, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8417, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I am good, how are ya?\n",
      "DialoGPT: I'm a good, good, how about?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8709, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8923, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not good, I'm a good, I'm good\n",
      "DialoGPT: I'm good I'm good,\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8019, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4176, 2.1086, 1.6757, 1.2287, 0.8181, 0.3810, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3301, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4497, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4593, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4188, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4409, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3810, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4176, grad_fn=<UnbindBackward>)\n",
      "Episode 47: -0.3809719153990348\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello! How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6125, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9275, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9317, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well, how bout you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9124, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9283, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I have been doing well, I'm doing well, I've been doing well\n",
      "DialoGPT: I'm doing good, well, well, well I'm doing well.\n",
      "r1: tensor(-0.0036, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9301, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9612, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing great, I'm doing great, well, well\n",
      "DialoGPT: I'm going to be doing\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7430, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7320, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0634, 1.7431, 1.2910, 0.8390, 0.3689, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3378, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4651, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4604, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4737, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3689, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0634, grad_fn=<UnbindBackward>)\n",
      "Episode 48: -0.3800900876522064\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi! How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6593, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7614, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, I'm good too. How are you? How are you??\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8782, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9260, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: I'm fine, how are you\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8936, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good. I'm doing well too.\n",
      "DialoGPT: That's good. How are you doing? How are you doing doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9022, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8685, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, I'm doing well.\n",
      "DialoGPT: I'm doing good. How are doing\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8009, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7312, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0533, 1.7150, 1.2766, 0.8223, 0.3832, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3554, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4512, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4625, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4429, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3832, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0533, grad_fn=<UnbindBackward>)\n",
      "Episode 49: -0.3795957499742508\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8428, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8522, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8233, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9064, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9530, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9264, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm well, I'm doing well, I'm good, how you are?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9148, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9340, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm good\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8991, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8347, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, I'm good.\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9055, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9245, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6138, 2.2120, 1.7973, 1.3406, 0.8870, 0.4578, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4239, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4327, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4701, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4625, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4338, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4578, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6138, grad_fn=<UnbindBackward>)\n",
      "Episode 50: -0.38046401855992334\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7647, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8632, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7998, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8994, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9660, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8725, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm pretty good, how about to be good?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9373, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9168, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be good, I'm going to be a good person\n",
      "DialoGPT: I'm going good to be good, how to be good? I'm going to go good good?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9107, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9189, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'll\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1682, 1.7787, 1.3674, 0.9168, 0.4576, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4072, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4250, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4598, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4637, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4576, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1682, grad_fn=<UnbindBackward>)\n",
      "Episode 51: -0.3809785361473377\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9037, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9132, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8044, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8667, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, I'm just tired.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8951, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8401, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm tired too\n",
      "DialoGPT: I'm tired of you too?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9026, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9228, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm tired\n",
      "DialoGPT: I'm tired tired of you too\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9578, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8993, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm sleepy tired of you\n",
      "DialoGPT: I'm tired sleepy tired of you.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9645, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9518, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm sleepy sleepy tired of you too.\n",
      "DialoGPT: I'm sleep tired tired of you\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9258, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9255, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're sleepy tired\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0754, 2.6475, 2.2516, 1.8359, 1.3933, 0.9380, 0.4634, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4544, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4185, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4565, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4646, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4793, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4634, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0754, grad_fn=<UnbindBackward>)\n",
      "Episode 52: -0.38236308885070514\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8751, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8253, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3518, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1778, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([0.5565, 0.1326], grad_fn=<CopySlices>)\n",
      "[tensor(0.4253, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1326, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(0.5565, grad_fn=<UnbindBackward>)\n",
      "Episode 53: -0.3831577819806558\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8969, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8277, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7726, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8497, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's great! How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9219, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8939, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm doing good!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8550, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8307, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That is good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8609, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9432, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That it is!\n",
      "DialoGPT: That's a good!\n",
      "r1: tensor(-0.0039, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9411, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8956, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That was a good one!\n",
      "DialoGPT: That's is good!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9045, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8900, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well!\n",
      "DialoGPT: I'm doing it's good!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8669, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8940, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3914, 2.9899, 2.6102, 2.1778, 1.7739, 1.3361, 0.8848, 0.4404, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4314, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4058, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4542, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4216, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4512, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4601, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4489, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3914, grad_fn=<UnbindBackward>)\n",
      "Episode 54: -0.3840352941643108\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8211, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8610, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8097, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9163, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9660, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9240, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9546, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7842, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad\n",
      "DialoGPT: I'm good then\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7512, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8340, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good.\n",
      "DialoGPT: Good, good, good, good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9379, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good\n",
      "DialoGPT: Good good\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9021, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8387, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Good,\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7869, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good!\n",
      "DialoGPT: Good good good?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8258, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9187, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good good\n",
      "DialoGPT:  good\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1805, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3649, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.8611, 3.4752, 3.0742, 2.6278, 2.2151, 1.8371, 1.4096, 0.9839, 0.5716,\n",
      "        0.1366, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4206, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4317, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4727, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4349, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3964, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4356, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4180, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4364, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1366, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.8611, grad_fn=<UnbindBackward>)\n",
      "Episode 55: -0.3846890346280166\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was one of the best movies ever made.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: You're not my supervisor!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go to your home.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you will cry at the end of the movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8233, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8428, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you. How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7701, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8787, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, you?\n",
      "DialoGPT: Good you, me.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8687, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8939, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, you, me. I'm glad you're doing well.\n",
      "DialoGPT: I'm glad you're well.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7982, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9142, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too.\n",
      "DialoGPT: I am good.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8738, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9293, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am also good.\n",
      "DialoGPT: I'm good you're good.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9197, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9289, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I think I'm good.\n",
      "DialoGPT: I good\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7874, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7327, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: You're good.\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8078, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9263, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3083, 2.9207, 2.5336, 2.1138, 1.7025, 1.2641, 0.8098, 0.4338, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4168, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4124, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4409, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4284, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4510, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4624, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3803, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4338, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3083, grad_fn=<UnbindBackward>)\n",
      "Episode 56: -0.3852523345696299\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8230, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7492, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8314, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8933, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing today?\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9671, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been busy with school, I'm doing well, I'm doing good, I'm doing fine, I'm doing great, I'm doing very good, how are doing well, how are you do?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9122, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9131, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm good,\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7250, 1.3452, 0.9232, 0.4566, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3932, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4313, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4711, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4566, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7250, grad_fn=<UnbindBackward>)\n",
      "Episode 57: -0.3853900293851721\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7910, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8907, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8507, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8603, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8346, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8552, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad.\n",
      "DialoGPT: I'm glad to be able to talk to you're.\n",
      "r1: tensor(-0.0070, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7509, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8190, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to be able to.\n",
      "DialoGPT: I'm so happy to be able.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9356, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9520, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to be able\n",
      "DialoGPT: I'm.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8107, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7419, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm a happy happy happy happy happy\n",
      "DialoGPT: I'm happy happy happy happy to be happy to be happy\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4942, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7263, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7515, 2.3544, 1.9460, 1.5388, 1.1561, 0.6908, 0.3055, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4207, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4279, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4226, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3942, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4722, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3883, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3055, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7515, grad_fn=<UnbindBackward>)\n",
      "Episode 58: -0.3859878142001265\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9065, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8658, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8124, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9044, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: How are we?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8353, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8742, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8492, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9590, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you.\n",
      "DialoGPT: I'm fine too, how are ya?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9630, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9554, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, how are you!\n",
      "DialoGPT: I'm good to hearin'you're good to bein'me good to be good to be\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7466, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7486, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5435, 2.1215, 1.7087, 1.2940, 0.8502, 0.3740, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4432, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4299, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4277, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4523, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4799, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3740, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5435, grad_fn=<UnbindBackward>)\n",
      "Episode 59: -0.38694151838620505\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7787, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8751, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing pretty good, how about you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8271, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8681, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how about you doing?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9497, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9711, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about me?\n",
      "DialoGPT: I'm pretty good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8986, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9168, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good too\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9336, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8468, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm good\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8637, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8803, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good\n",
      "DialoGPT: I good?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7616, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8657, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9708, 2.5830, 2.1807, 1.7175, 1.2763, 0.8392, 0.4071, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4136, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4241, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4804, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4540, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4454, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4362, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4071, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9708, grad_fn=<UnbindBackward>)\n",
      "Episode 60: -0.3873787903394855\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8031, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8120, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7420, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8812, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9669, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8931, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm fine, how are you, how are you going?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9586, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9529, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go to sleep now, I'm going to sleep now.\n",
      "DialoGPT: Sleep is overrated, sleep is overrated. Sleep is overrated.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8655, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8700, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep is the best sleep\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1429, 1.7565, 1.3641, 0.9079, 0.4341, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4040, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4061, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4653, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4781, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1429, grad_fn=<UnbindBackward>)\n",
      "Episode 61: -0.38764639054575273\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8460, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8420, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8893, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good. How are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9590, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9200, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8321, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8234, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad\n",
      "DialoGPT: I'm glad to hear that's good.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9033, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8757, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: I am glad to be glad to hear that you're glad to hear that.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9382, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7883, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that you are happy to hear that. I'm glad to hear you're\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5594, 2.1508, 1.7351, 1.2779, 0.8726, 0.4318, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4302, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4330, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4700, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4140, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4451, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4318, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5594, grad_fn=<UnbindBackward>)\n",
      "Episode 62: -0.38832156147275654\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8776, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8416, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8499, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8897, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9512, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9109, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good. How are we?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9281, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7487, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good\n",
      "DialoGPT: I'm pretty nice too\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8595, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9397, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's nice\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8832, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9235, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm happy to hear that you're happy with you!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8229, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8525, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: I'm happy with you're happy with me\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7856, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7033, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.3280, 2.9270, 2.5170, 2.0720, 1.6694, 1.2317, 0.7876, 0.3724, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4302, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4352, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4657, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4193, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4500, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4519, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4190, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3724, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.3280, grad_fn=<UnbindBackward>)\n",
      "Episode 63: -0.38897632993757725\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: I'll be there in a minute or two.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I'll be there soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8643, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5223, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8210, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8713, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9585, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9018, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm fine, how are you going to school?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9454, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9447, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to school today, I'm going to be a freshman in college\n",
      "DialoGPT: I'm going home to school today, to school to school today?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9048, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9222, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'll be home in a few hours\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1197, 1.7908, 1.3813, 0.9253, 0.4570, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3468, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4233, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4653, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4729, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4570, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1197, grad_fn=<UnbindBackward>)\n",
      "Episode 64: -0.38832764075352594\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9146, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8652, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8494, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8817, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how about you, I'm good at what?\n",
      "r1: tensor(-0.0048, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9174, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9220, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about me?\n",
      "DialoGPT: I'm well, how about me, you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8908, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9494, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been doing well, how bout you?\n",
      "DialoGPT: I have been doing well, I've been doing well lately.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8964, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9279, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing great, how about you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2105, 1.7832, 1.3639, 0.9120, 0.4563, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4451, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4329, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4610, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4602, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4563, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2105, grad_fn=<UnbindBackward>)\n",
      "Episode 65: -0.3891884350415432\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7154, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8944, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8416, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8684, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8877, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8674, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad.\n",
      "DialoGPT: I am too.\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8869, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8399, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So, what's your name?\n",
      "DialoGPT: I'm?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8901, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8109, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not sure.\n",
      "DialoGPT: I'm sure.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9356, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9188, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am sure.\n",
      "DialoGPT: I'll be there.\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8869, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8880, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'll see you there.\n",
      "DialoGPT: I'm there.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9154, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8533, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I will see you there. I'll see you there\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3587, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0607, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.4247, 3.0526, 2.6514, 2.2349, 1.8210, 1.4096, 0.9553, 0.5164, 0.0747],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4026, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4277, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4389, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4321, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4255, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4638, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4440, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4424, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0747, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.4247, grad_fn=<UnbindBackward>)\n",
      "Episode 66: -0.3893891724187936\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8253, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8081, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8038, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8772, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you're good?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9464, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9013, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, how are you doing?\n",
      "DialoGPT: I'm doing fine, just got a little busy at work.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9055, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9141, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: I'm doing well, how are you are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8672, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8501, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, just busy.\n",
      "DialoGPT: I'm good. Good job good, how?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9162, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8615, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5547, 2.1677, 1.7649, 1.3160, 0.8695, 0.4445, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4086, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4621, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4551, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4295, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4445, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5547, grad_fn=<UnbindBackward>)\n",
      "Episode 67: -0.3896724064560497\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7403, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8761, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8188, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8869, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, I'm good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8912, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8905, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I'm good\n",
      "DialoGPT: I'm good too, I'm good too, how are you doing?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9409, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8982, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you\n",
      "DialoGPT: I'm good how are you? How are you doing? How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9127, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9277, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, I'm good.\n",
      "DialoGPT: I'm good. How\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8299, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7460, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5269, 2.1440, 1.7347, 1.3021, 0.8506, 0.3942, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4043, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4267, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4456, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4600, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4603, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3942, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5269, grad_fn=<UnbindBackward>)\n",
      "Episode 68: -0.38988465502642206\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8325, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8087, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8517, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9217, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about how are you??\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9107, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9308, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Good, good, how are your days?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9244, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8231, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good. I'm good, how about you?\n",
      "DialoGPT: Good good, how are good, how are are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9323, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8890, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: good, good, how about me?\n",
      "DialoGPT: Good, How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9149, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9136, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2293, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3391, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.7318, 2.3446, 1.9202, 1.4743, 1.0477, 0.5981, 0.1423],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4106, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4436, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4607, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4371, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4572, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1423, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.7318, grad_fn=<UnbindBackward>)\n",
      "Episode 69: -0.3901802390813828\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7844, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8121, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, thanks for asking. How are you?\n",
      "r1: tensor(-0.0139, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8320, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8638, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Very good, how are you\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8939, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9390, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good.\n",
      "DialoGPT: Good, good, good. How are you doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9163, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8017, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking\n",
      "DialoGPT: I'm doing good.\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8446, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9091, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm glad to hear that.\n",
      "DialoGPT: I'm glad to do good.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8601, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5681, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6034, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8104, 2.4355, 2.0283, 1.5853, 1.1672, 0.7358, 0.2931, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3993, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4274, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4589, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4297, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4388, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4456, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2931, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8104, grad_fn=<UnbindBackward>)\n",
      "Episode 70: -0.3903086416318383\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cry at the end of every movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8319, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8401, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0049, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8797, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8224, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8354, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: It is?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9000, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9418, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!!\n",
      "DialoGPT: It is good!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9405, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9339, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good!\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8924, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8663, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am!\n",
      "DialoGPT: I'm okay!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9408, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9248, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm ok!\n",
      "DialoGPT: I'm alright!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9616, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9617, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine!\n",
      "DialoGPT: I'm OK\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9347, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9136, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay\n",
      "DialoGPT: I'm okay?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9497, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9444, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([4.3116, 3.9327, 3.5402, 3.1566, 2.7232, 2.2772, 1.8556, 1.4030, 0.9313,\n",
      "        0.4738, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4182, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4279, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4151, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4606, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4688, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4402, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4810, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4623, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4738, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(4.3116, grad_fn=<UnbindBackward>)\n",
      "Episode 71: -0.3906960069305367\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8230, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8573, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT:  and how's life?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8974, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good, how about you?\n",
      "DialoGPT: It's going well, how about you, what's your favorite color?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9119, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Blue, I guess.\n",
      "DialoGPT: Blue is my favorite color.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8682, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8737, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Blue is mine too!\n",
      "DialoGPT: Blue is my favourite color too!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9591, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9007, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Blue and blue are my favorite colors!\n",
      "DialoGPT: Blue is blue is my favorite color is blue blue is my favorite colour blue blue blue blue blue is blue blue\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7648, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8396, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5384, 2.1395, 1.7185, 1.2894, 0.8625, 0.4012, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4203, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4382, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4419, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4356, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4652, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4012, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5384, grad_fn=<UnbindBackward>)\n",
      "Episode 72: -0.3911015468917481\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6817, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8781, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7649, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8496, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing great! How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9681, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8954, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: doing great too!\n",
      "DialoGPT: I am doing great! How is your day going?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9338, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8737, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well!\n",
      "DialoGPT: It's going good!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8284, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9692, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm going good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8940, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8826, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I hope you're doing well!\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8451, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8283, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'll\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4384, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3945, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.1285, 2.7659, 2.3859, 1.9392, 1.5021, 1.0631, 0.6251, 0.2083, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3903, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4039, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4661, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4521, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4497, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4443, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4188, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2083, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.1285, grad_fn=<UnbindBackward>)\n",
      "Episode 73: -0.3910901006814596\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8070, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8514, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7978, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8847, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: I'm glad to hear that.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9044, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8863, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that. I'm glad to hear you're doing well.\n",
      "DialoGPT: Thanks for the warm welcome. I'm glad you're doing well too.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6046, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9359, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm sure you are.\n",
      "DialoGPT: I'm doing well.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8749, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8749, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8841, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8948, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too.\n",
      "DialoGPT: I am good. I'm\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6458, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6314, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7887, 2.3979, 1.9969, 1.5646, 1.1911, 0.7611, 0.3194, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4148, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4209, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4479, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3854, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4376, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4449, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3194, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7887, grad_fn=<UnbindBackward>)\n",
      "Episode 74: -0.3914066012700399\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0036, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8158, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8789, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7406, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9136, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9582, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8550, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you doin?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9296, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9415, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well\n",
      "DialoGPT: GoodGoodGoodgoodgoodgoodgoodgood good good good good goodgoodgoodgoodgood Goodgoodgoodgoodgood GOOD GOOD GOOD GOOD GOOD\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7528, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7524, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good\n",
      "DialoGPT: Good\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2246, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3517, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(3.0653e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2316, 1.8253, 1.4258, 0.9821, 0.5193, 0.1443, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4246, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4137, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4535, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4680, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3765, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1443, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2316, grad_fn=<UnbindBackward>)\n",
      "Episode 75: -0.3918429487629941\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8768, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8660, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 2\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7828, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7638, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([0.8191, 0.3872], grad_fn=<CopySlices>)\n",
      "[tensor(0.4358, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3872, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(0.8191, grad_fn=<UnbindBackward>)\n",
      "Episode 76: -0.392414171200294\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8901, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8980, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good thanks. How are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7886, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9062, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Not bad. How are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9447, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8516, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well.\n",
      "DialoGPT: That's good. How are you feeling?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9116, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8641, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm feeling pretty good.\n",
      "DialoGPT: That's great. How are you feelin '?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9545, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8889, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine.\n",
      "DialoGPT: I'm feeling good.\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8840, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8910, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That is good.\n",
      "DialoGPT: That means you're and good.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8429, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8259, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That makes me feel\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9961, 2.5747, 2.1726, 1.7408, 1.3098, 0.8572, 0.4174, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4472, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4239, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4492, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4441, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4612, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4440, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4174, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9961, grad_fn=<UnbindBackward>)\n",
      "Episode 77: -0.39311604851331466\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7522, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7698, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8227, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9123, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing??\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9633, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9044, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well, how are you are you??\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9481, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9474, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I'm doing well, I'm doing good, I'm good, I'm well, I'm good\n",
      "DialoGPT: I'm good. I'm good, doing good, I am\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7377, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8724, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1159, 1.7527, 1.3319, 0.8732, 0.4027, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3807, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4675, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4745, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4027, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1159, grad_fn=<UnbindBackward>)\n",
      "Episode 78: -0.39295884778227985\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7904, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6835, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7605, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8807, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9441, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8729, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you going?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9210, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9430, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be busy for a while, but I'm going to be doing a lot of work today.\n",
      "DialoGPT: I'm work.\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8577, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8105, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm working on a project\n",
      "DialoGPT: I'm working hard to get work on\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6648, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7497, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4112, 2.0627, 1.6690, 1.2269, 0.7684, 0.3542, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3691, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4104, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4544, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4662, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4177, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3542, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4112, grad_fn=<UnbindBackward>)\n",
      "Episode 79: -0.3926605530083179\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8795, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7490, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8346, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8466, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9297, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9429, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too\n",
      "DialoGPT: That's good, how are you doing?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9347, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8254, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, I'm doing good\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7760, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7375, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm doing great, I'm doing great\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8120, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7873, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm doing better than than me\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9199, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8565, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8722, 2.4898, 2.0902, 1.6383, 1.2100, 0.8398, 0.4443, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4074, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4683, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3786, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4000, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4443, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8722, grad_fn=<UnbindBackward>)\n",
      "Episode 80: -0.3928420628294533\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either...\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back soon enough.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8551, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7995, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8974, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, good how are you???\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8965, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: doing well, how are ya?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9508, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm just tired\n",
      "DialoGPT: I'm tired, I'm tired, tired, tired, I'm exhausted, tired, tired tired, tired tired tired tired tired, tired, exhausted tired tired tired\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6821, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8017, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0791, 1.7016, 1.2901, 0.8357, 0.3713, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3945, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4244, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4627, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4682, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3713, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0791, grad_fn=<UnbindBackward>)\n",
      "Episode 81: -0.39286179040990227\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8558, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7484, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7543, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8489, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9637, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8802, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7521, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8928, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great\n",
      "DialoGPT: That's good. How are ya?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8226, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7109, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7602, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8923, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's nice\n",
      "DialoGPT: That's good to hear\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8109, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8483, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good to hear\n",
      "DialoGPT: Good to hear to hear\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9215, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8212, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good to hear\n",
      "DialoGPT: to hear to hear\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8303, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8646, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good\n",
      "DialoGPT: I'm\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5302, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4344, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.8196, 3.4529, 3.0827, 2.6480, 2.2593, 1.8946, 1.4962, 1.0923, 0.6630,\n",
      "        0.2413, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4012, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4011, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4611, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4113, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3836, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4134, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4149, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4359, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4241, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2413, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.8196, grad_fn=<UnbindBackward>)\n",
      "Episode 82: -0.39296255772372324\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8945, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8388, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7823, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8627, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how about you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9201, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9627, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about me?\n",
      "DialoGPT: I'm fine, how about you how about you? How about you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9453, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9269, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's a good question\n",
      "DialoGPT: I'm doing fine, how about how you're doing well? How about how you're do you're doing?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9344, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7804, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am fine\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1685, 1.7526, 1.3547, 0.8928, 0.4289, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4335, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4114, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4708, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4683, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4289, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1685, grad_fn=<UnbindBackward>)\n",
      "Episode 83: -0.3934445721762521\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8598, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7907, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks for asking. How are you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7590, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8481, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, too.\n",
      "DialoGPT: I'm doing better than ever before. How are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9496, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8941, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, thanks for asking!\n",
      "DialoGPT: You're welcome! I'm glad you're doing well!\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8744, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8716, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm doing good!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8428, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8688, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! I'm glad to hear you're doing well.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0979, 1.7021, 1.3132, 0.8607, 0.4281, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4128, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4021, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4610, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4369, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4281, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0979, grad_fn=<UnbindBackward>)\n",
      "Episode 84: -0.39367190108579747\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8030, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8151, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing pretty well, how about you?\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7676, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8317, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8415, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8453, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that!!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9051, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9656, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that.\n",
      "DialoGPT: I'm glad you're happy to hear that too!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9451, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9321, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to hear that you're happy to know that I'm happy to hear you're happy to see me happy to\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1193, 1.7320, 1.3452, 0.9327, 0.4695, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4047, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4003, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4218, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4679, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4695, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1193, grad_fn=<UnbindBackward>)\n",
      "Episode 85: -0.39380004932714063\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7916, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7400, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, thanks. How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7805, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8786, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Pretty good, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9006, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8588, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, thanks.\n",
      "DialoGPT: Good, how about you\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9192, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8491, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too, thanks.\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8385, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8982, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good.\n",
      "DialoGPT: I'm aight\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8816, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8190, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8903, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8236, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good!\n",
      "DialoGPT: I'm good to you, good to me.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8849, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good to you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2854, 2.9316, 2.5421, 2.1234, 1.6981, 1.2764, 0.8591, 0.4349, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3830, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4150, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4400, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4422, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4345, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4258, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4286, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4349, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2854, grad_fn=<UnbindBackward>)\n",
      "Episode 86: -0.3936763419502083\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8347, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6226, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7527, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8648, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing good!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8625, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8825, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That is good!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8734, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9565, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That it is!\n",
      "DialoGPT: That's ok!\n",
      "r1: tensor(-0.0031, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9360, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's okay!\n",
      "DialoGPT: That's alright alright!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9178, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9150, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's fine!\n",
      "DialoGPT: That's a good one\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8380, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8958, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(7.2791e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's a great one!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9373, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9306, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's what I'm saying!\n",
      "DialoGPT: That's awesome!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9124, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8118, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.7606, 3.4304, 3.0564, 2.6463, 2.2107, 1.7643, 1.3192, 0.8946, 0.4312,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3645, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4046, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4365, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4577, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4641, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4583, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4336, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4677, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4312, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.7606, grad_fn=<UnbindBackward>)\n",
      "Episode 87: -0.39334465156901965\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8671, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7407, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7753, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8147, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9620, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8332, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you do you doing?\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9249, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9253, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well, I'm doing good\n",
      "DialoGPT: I'm doing good, how are we doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9462, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8673, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing good, I'm doing great\n",
      "DialoGPT: I'm doing great\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9207, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5370, 2.1564, 1.7765, 1.3408, 0.8867, 0.4375, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4021, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3977, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4491, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4630, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4535, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4375, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5370, grad_fn=<UnbindBackward>)\n",
      "Episode 88: -0.3934435784147027\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8451, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7868, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9046, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how's your day going?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8553, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9110, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about yours?\n",
      "DialoGPT: Good, yours?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8180, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8418, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good too\n",
      "DialoGPT: Good how are you? How's good?\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8661, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7792, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good, how about you?\n",
      "DialoGPT: Good day?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8504, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7818, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good day\n",
      "DialoGPT: Goodday\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8846, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8083, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good day\n",
      "DialoGPT: Good day\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8880, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9425, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Good day\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9593, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8582, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Y\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.6702, 3.3170, 2.9233, 2.5066, 2.1125, 1.7176, 1.3226, 0.9079, 0.4546,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3863, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4230, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4418, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4152, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4121, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4083, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4237, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4579, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4546, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.6702, grad_fn=<UnbindBackward>)\n",
      "Episode 89: -0.39336411721176573\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7775, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8779, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7597, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8757, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9530, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8969, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm well, I'm doing well, I'm good, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9065, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9254, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, I am doing well, how about you\n",
      "DialoGPT: I'm doing good?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8707, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8565, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm good\n",
      "DialoGPT: I'm doing fine, I\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6757, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8551, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4960, 2.1029, 1.7110, 1.2610, 0.8110, 0.3828, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4141, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4091, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4626, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4581, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3828, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4960, grad_fn=<UnbindBackward>)\n",
      "Episode 90: -0.39359157262267647\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8147, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7704, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7923, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8927, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9336, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8931, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: Good, I'm doing well, I'm good, how're you?\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9048, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8945, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, I am doing well, how about you?\n",
      "DialoGPT: I've been doing well, how's you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9236, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9396, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I have been doing well, I have been doing\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1460, 1.7671, 1.3594, 0.9116, 0.4661, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3965, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4214, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4569, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4501, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4661, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1460, grad_fn=<UnbindBackward>)\n",
      "Episode 91: -0.39362352470988815\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and he'll let us watch him there.and we'll watch him there.And we'll watch him here.and we'll all watch him there.AND WE'LL ALL SEE HIM HERE!\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll all be watching him there.and he'll be watching us there.and we will all be watching him here.AND WE WILL ALL BE Watching Him There. AND WE WILL ALL SEE HIM HERE.AND WE WILL SEE HIM HERE.OH MY GOD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I'm crying right now. I'm crying because of you. You're crying because of me. Crying tears of joy. Crying tears for joy. Crying Tears of Joy. Crying Tears Of Joy. Crying tears. Crying Tears. Crying Tears... cries cries cries cries cries sobbing cries cries cries cries. cries cries\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8834, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7611, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7699, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8505, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to be fair to you.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8626, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8882, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: I'm happy to hear that and happy to hear that. I'm glad to hear you're happy to hear that too.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8227, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9072, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to hear that you're happy to be happy to hear that I'm happy to hear you're very happy to hear I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6614, 1.2627, 0.8662, 0.4327, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4113, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4052, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4378, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4327, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6614, grad_fn=<UnbindBackward>)\n",
      "Episode 92: -0.39381306626463447\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: But you're crying for the first time ever.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7329, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8943, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8199, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8261, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you? I'm good too.\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9447, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9010, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you\n",
      "DialoGPT: I'm doing good how are you doing well?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9335, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9479, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doin?\n",
      "DialoGPT: I'm okay, I'm doing well, I'm doing good, how are you good?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9216, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9247, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm ok, I'm doing\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1673, 1.7780, 1.3801, 0.9277, 0.4618, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.4070, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4117, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4705, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4618, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1673, grad_fn=<UnbindBackward>)\n",
      "Episode 93: -0.3939538816822336\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: But you're crying for the first time ever.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8371, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6831, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7750, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8351, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8177, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8524, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: Yeah it is!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8617, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8699, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm doing good too!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8578, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8231, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That is good!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8884, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9487, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! I'm glad to hear you're doing well!\n",
      "DialoGPT: I'm good to the moon!\n",
      "r1: tensor(-0.0013, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8461, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8340, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8451, 2.4898, 2.1081, 1.7074, 1.2872, 0.8757, 0.4204, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3803, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4028, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4177, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4330, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4203, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4595, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8451, grad_fn=<UnbindBackward>)\n",
      "Episode 94: -0.39380981890778793\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a great movie.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: But you're crying for the first time ever.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8278, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6296, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7950, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8024, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8268, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8536, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that you're happy to hear that! :D\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8741, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9055, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy you're happy to be happy!\n",
      "DialoGPT: I'm happiest to be happy happy happy happy happy!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9105, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am happy happy happy happy\n",
      "DialoGPT: I'm happy happy to be happy happy to be happier\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7853, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6115, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3764, 2.0322, 1.6491, 1.2413, 0.8041, 0.3494, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3645, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3996, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4203, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4452, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4583, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3494, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3764, grad_fn=<UnbindBackward>)\n",
      "Episode 95: -0.39350471179932356\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: But you're crying for the first time ever.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8035, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6942, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing great! How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8151, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8544, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well!\n",
      "DialoGPT: I'm doing well! How are you doing?\n",
      "r1: tensor(-0.0027, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9548, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8832, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm good too! How are you feeling?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9337, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8110, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm feeling pretty good!\n",
      "DialoGPT: I am feeling pretty good! How are you feelin?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9154, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7868, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8550, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I feel pretty good!\n",
      "DialoGPT: So good!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8584, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8251, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I love you!\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1521, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2323, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.9837, 2.6355, 2.2404, 1.7982, 1.3755, 0.9219, 0.5164, 0.0964],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3746, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4175, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4602, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4364, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4628, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4107, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4210, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0964, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.9837, grad_fn=<UnbindBackward>)\n",
      "Episode 96: -0.39330946078005524\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: But you're crying for the first time ever.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7853, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8421, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7264, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8890, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing great! How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9527, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8583, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: doing great too!\n",
      "DialoGPT: I am doing well too!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8932, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8558, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8418, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9281, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's a good thing!\n",
      "DialoGPT: It's good!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9106, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8972, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's a good thing.\n",
      "DialoGPT: It's good to you're doing well!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8109, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8744, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's great!\n",
      "DialoGPT: It's very good to you're\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7998, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7174, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2810, 2.9031, 2.5243, 2.0922, 1.6716, 1.2413, 0.7971, 0.3794, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4070, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4040, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4530, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4373, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4427, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4522, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4214, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3794, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2810, grad_fn=<UnbindBackward>)\n",
      "Episode 97: -0.39344886675172924\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7607, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7843, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7800, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8797, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9174, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9482, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how about you!\n",
      "DialoGPT: I'm good how about you??\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9189, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about me?\n",
      "DialoGPT: I'm fine, good how about you how about me??\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9296, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9404, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about u?\n",
      "DialoGPT: I'm not know how about you? I'm good\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8209, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7365, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5110, 2.1460, 1.7484, 1.2947, 0.8533, 0.3895, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3864, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4151, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4499, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4677, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3895, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5110, grad_fn=<UnbindBackward>)\n",
      "Episode 98: -0.393377987724362\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6768, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7884, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7799, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8865, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8412, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8642, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: I'm good too, how are you. How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8853, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9278, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, how about you.\n",
      "DialoGPT: I'm good how about you? How are you??\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9499, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8777, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you!\n",
      "DialoGPT: I'm good?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7454, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8774, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, how about you,\n",
      "DialoGPT: I\n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1180, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1136, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.5170, 2.1722, 1.7732, 1.3602, 0.9159, 0.4635, 0.0581],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3665, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4167, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4265, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4535, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4571, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4059, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0581, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.5170, grad_fn=<UnbindBackward>)\n",
      "Episode 99: -0.39310934513807294\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5687, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8090, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7929, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8603, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: I'm doing good too!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8692, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9266, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm glad you're doing well too!!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8902, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8168, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that!\n",
      "DialoGPT: I'm having a great day!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8590, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8682, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That's a good one!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8964, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9054, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy!\n",
      "DialoGPT: I'm good!\n",
      "r1: tensor(-0.0019, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8100, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8853, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too!\n",
      "DialoGPT: I am a good one\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5854, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5896, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.1253, 2.8087, 2.4194, 1.9902, 1.5790, 1.1587, 0.7153, 0.2939, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3446, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4135, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4491, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4269, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4319, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4506, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4243, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2939, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.1253, grad_fn=<UnbindBackward>)\n",
      "Episode 100: -0.39262946318871905\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8355, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7809, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8160, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you? I'm good how are we?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9402, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8224, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm just tired\n",
      "DialoGPT: I'm tired too tired to be good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7679, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9103, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm tired\n",
      "DialoGPT: I'm good I'm good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8796, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8778, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I am good\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8763, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9095, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great\n",
      "DialoGPT: I'm good to be good\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9061, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8598, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good to be good\n",
      "DialoGPT: good to be good to good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7785, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2386, 2.8648, 2.4902, 2.0700, 1.6669, 1.2398, 0.8012, 0.3633, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.4025, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3994, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4410, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4197, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4395, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4466, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4416, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3633, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2386, grad_fn=<UnbindBackward>)\n",
      "Episode 101: -0.3927258904658112\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7864, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7995, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8002, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8629, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8385, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8446, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8477, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8730, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I am?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7759, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7340, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm good to hear that that's good to hear that?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7891, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8507, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: I'm a good to hear that's good to see that\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7851, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6317, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7252, 2.3518, 1.9554, 1.5499, 1.1310, 0.7609, 0.3543, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3969, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4159, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4210, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4303, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3777, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4101, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3543, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7252, grad_fn=<UnbindBackward>)\n",
      "Episode 102: -0.39276673116730254\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7587, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8145, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7938, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8849, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, I'm good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6894, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7811, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I am too\n",
      "DialoGPT: Good, I too.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9248, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9103, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I as well\n",
      "DialoGPT: I'm good too, I'm good too.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8807, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8948, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good. Good, I'm good. Good. I'm good, too.\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9451, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8365, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good\n",
      "DialoGPT: I'm so good, I'm good, good.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9318, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8290, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8799, 2.5114, 2.1128, 1.7626, 1.3169, 0.8817, 0.4404, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3936, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4198, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3678, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4589, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4440, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4457, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8799, grad_fn=<UnbindBackward>)\n",
      "Episode 103: -0.392774276721936\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7743, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7903, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7725, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8756, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8492, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: So are we!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8648, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8574, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad to hear that.\n",
      "DialoGPT: I'm glad you're glad that's so glad to hear.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8146, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9319, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that! I'm glad to hear you're glad that I'm glad to know that I'm glad that I'm so\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0395, 1.6648, 1.2652, 0.8631, 0.4367, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3913, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4123, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4108, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4307, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4367, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0395, grad_fn=<UnbindBackward>)\n",
      "Episode 104: -0.3927604942094712\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7194, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7958, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7585, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8821, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9415, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9096, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm fine, doing well?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8763, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8974, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well too\n",
      "DialoGPT: That's good, I'm doing good, I'm well, I'm doing fine, I'm doing great, I'm doing ok?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8916, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9230, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm ok, I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1053, 1.7438, 1.3468, 0.8928, 0.4538, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3790, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4104, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4630, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4436, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4538, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1053, grad_fn=<UnbindBackward>)\n",
      "Episode 105: -0.3926304691242722\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7392, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7516, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7724, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8492, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, how about you?\n",
      "DialoGPT: I've been doing well, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9028, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too.\n",
      "DialoGPT: That's good to hear, how are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9073, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8815, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, I'm doing good.\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7799, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7768, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's great to hear!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9364, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4740, 2.1224, 1.7342, 1.2873, 0.8485, 0.4638, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3728, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4055, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4597, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4473, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3893, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4638, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4740, grad_fn=<UnbindBackward>)\n",
      "Episode 106: -0.392445472356315\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: I did, but I didn't think it was that good. It's a shame because it was supposed to be a masterpiece.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his home.and make him watch it twice.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll watch it again! And again! And again... and again... and again! And again.. and again... and Again... and again... And again... and Again.. and Again... and Again... And again... And again.. And again... And Again... And Again... amp nbsp amp nbsp amp Nbsp amp\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7217, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7475, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7621, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8761, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7735, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8710, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: I'm doing good!\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8296, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8300, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: It's been a long time since I've been able to be happy with my life.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7727, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7681, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I know, I'm glad you're doing well!\n",
      "DialoGPT: I'm glad you're happy!\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8518, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9046, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I'm very happy toasty!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8807, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8904, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7844, 2.4413, 2.0521, 1.6574, 1.2546, 0.8781, 0.4430, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3675, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4097, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4112, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4153, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3854, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4395, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4430, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7844, grad_fn=<UnbindBackward>)\n",
      "Episode 107: -0.3922143512301975\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I did see the movie. It was pretty good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go anywhere else.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back in time for Christmas.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5752, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8060, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7967, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8757, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing good, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9646, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are YOU?\n",
      "DialoGPT: I'm great, how are you going?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9267, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9451, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be busy for a while, but I'm going to be doing a lot of work.\n",
      "DialoGPT: I'm going do a lot of work today.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8639, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9315, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm gonna be busy for a few days\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0915, 1.7636, 1.3587, 0.9126, 0.4490, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3455, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4185, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4552, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4681, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4490, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0915, grad_fn=<UnbindBackward>)\n",
      "Episode 108: -0.3917855420790681\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I did see the movie. It was pretty good.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: I watched it once and then never watched it again.\n",
      "User: I have the DVD.\n",
      "DialoGPT: I have the Blu ray.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go anywhere else.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be back in time for Christmas.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0028, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7535, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7870, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7947, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8565, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5674, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6647, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: I'm glad to hear that.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7765, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're happy\n",
      "DialoGPT: I'm glad too.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9039, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8894, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.5384e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that\n",
      "DialoGPT: I'm glad that you're happy.\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8945, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8985, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy\n",
      "DialoGPT: I'm happy that you're happy to hear that happy to hear that. I'm happy to hear you're happy to hearing\n",
      "r1: tensor(-0.0056, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8343, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7213, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6843, 2.3216, 1.9280, 1.6362, 1.2754, 0.8353, 0.3903, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3858, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4129, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3082, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3735, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4485, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4489, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3903, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6843, grad_fn=<UnbindBackward>)\n",
      "Episode 109: -0.3917314662174745\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: I'm not home yet.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: But I don't want to go there either.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you'll be crying for me when you get back home.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8344, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6916, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7631, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, I'm good, how about you?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9095, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8511, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I'm good\n",
      "DialoGPT: Good, how's your day going?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8766, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7904, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about you\n",
      "DialoGPT: I'm?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7199, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7713, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I am good\n",
      "DialoGPT: Good, good, good, good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7285, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8462, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I hope you have a good day\n",
      "DialoGPT: I'm good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7458, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6591, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good! I hope you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6555, 2.2830, 1.9384, 1.5132, 1.1073, 0.7418, 0.3514, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3954, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3640, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4169, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3730, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3939, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3514, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6555, grad_fn=<UnbindBackward>)\n",
      "Episode 110: -0.39176430707579263\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said...\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7735, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6500, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0053, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8078, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8619, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8091, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8139, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that's good to hear that's that's good to say that's that's true to say's that's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8764, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8437, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy that's good to see you're doing well!\n",
      "DialoGPT: I'm good to hear that is that's good to you're\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8730, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8454, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9986, 1.6592, 1.2530, 0.8556, 0.4297, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3560, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4187, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4059, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4302, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4297, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9986, grad_fn=<UnbindBackward>)\n",
      "Episode 111: -0.3914453847599881\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said...\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0050, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7292, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8092, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7624, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8846, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9528, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8633, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you today?\n",
      "DialoGPT: I'm well, I'm doing well, I'm not doing well, but I'm doing well.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8852, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8936, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm doing good, I'm doing good. How are you doing well?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9423, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7650, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm doing fine\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0805, 1.7118, 1.3130, 0.8676, 0.4270, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3858, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4118, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4541, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4449, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4270, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0805, grad_fn=<UnbindBackward>)\n",
      "Episode 112: -0.39139566985906754\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said...\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7929, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7116, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about to go to sleep. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7365, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7852, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep is overrated.\n",
      "DialoGPT: Sleep is over slept. Sleep is overrated. Sleep is over rated. Sleep is over slept.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8870, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9323, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep is sleep is over slept. I sleep is over slept\n",
      "DialoGPT: Sleep is over sleep is over slept? Sleep is over slept is sleep slept slept is over slept. sleep is over slept slept. Sleep is sleep is over sleep\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8629, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8287, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6096, 1.2457, 0.8738, 0.4231, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3763, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3806, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4550, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4231, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6096, grad_fn=<UnbindBackward>)\n",
      "Episode 113: -0.39126351214291755\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said...\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7659, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8043, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7610, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8662, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing great! How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8361, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: doing great too!\n",
      "DialoGPT: I am doing great too! How are you doing?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9730, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8593, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good!\n",
      "DialoGPT: I'm good, I'm doing good?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8324, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8463, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great!\n",
      "DialoGPT: I'm great too!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8543, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9167, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I am good!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8914, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8453, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I think I'm good!\n",
      "DialoGPT: Thanks\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6958, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6654, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.5848e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2284, 2.8643, 2.4822, 2.0568, 1.6147, 1.2069, 0.7717, 0.3408, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3927, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4069, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4459, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4582, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4199, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4429, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4343, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3408, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2284, grad_fn=<UnbindBackward>)\n",
      "Episode 114: -0.3912764380807462\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said...\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6563, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7411, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing fine, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7358, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8661, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, how about you?\n",
      "DialoGPT: I've been doing well, how about yourself?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9095, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: I'm good how are you? How are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8927, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9375, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good, I'm good\n",
      "DialoGPT: I'm good to be good, I'm I'm good, good, I'm doing well, I'm good.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8493, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9271, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0596, 1.7274, 1.3402, 0.8975, 0.4442, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3495, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4006, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4516, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4578, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4442, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0596, grad_fn=<UnbindBackward>)\n",
      "Episode 115: -0.3909165196377656\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6827, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8265, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7692, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8260, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7923, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8436, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: So are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8328, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8700, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm doing well.\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8181, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8180, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I am too.\n",
      "DialoGPT: I'm doing good too.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8519, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8460, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great.\n",
      "DialoGPT: That's a good.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8698, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9080, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: That's fine.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8919, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8534, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2092, 2.8602, 2.4862, 2.0979, 1.6889, 1.2926, 0.8767, 0.4365, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3776, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3989, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4093, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4259, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4092, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4246, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4446, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4365, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2092, grad_fn=<UnbindBackward>)\n",
      "Episode 116: -0.3908023793473203\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6945, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7832, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8364, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how about you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9174, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about me?\n",
      "DialoGPT: I'm pretty good, how about how you're doing?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9121, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9334, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about we do it?\n",
      "DialoGPT: I'm fine, how about you do you do?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9209, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9369, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not good, I'm not good, but I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0814, 1.7720, 1.3808, 0.9215, 0.4645, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3271, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4050, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4685, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4645, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0814, grad_fn=<UnbindBackward>)\n",
      "Episode 117: -0.390262815406767\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7876, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7003, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7562, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8589, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8722, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: Good, I'm good, how about yourself??\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8526, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9073, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you!\n",
      "DialoGPT: I'm good now, how about you're good?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9188, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9384, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, how about you.\n",
      "DialoGPT: I'm good how about you're you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9379, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8883, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'll be good\n",
      "DialoGPT: I'm\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4524, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5893, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7530, 2.4049, 2.0212, 1.6005, 1.1721, 0.7147, 0.2606, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3722, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4039, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4367, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4402, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4645, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4567, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2606, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7530, grad_fn=<UnbindBackward>)\n",
      "Episode 118: -0.3901106146704249\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7515, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6405, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7611, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8533, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9201, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8727, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: That's good, how are ya?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8076, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7661, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you doin the house?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8805, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9331, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not doing too bad, I'm just busy\n",
      "DialoGPT: I'm doing fine.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8813, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: I'm doing good\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9326, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8547, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8346, 2.5115, 2.1291, 1.6977, 1.3173, 0.8725, 0.4471, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3482, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4038, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4484, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3935, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4536, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4298, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4471, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8346, grad_fn=<UnbindBackward>)\n",
      "Episode 119: -0.3897614893813928\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5961, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7114, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8016, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8714, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8560, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8552, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: I'm good how are you??\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8639, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9357, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you.\n",
      "DialoGPT: I'm good too, how are you how are you are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9480, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9100, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Oh, I'm good, I'm good.\n",
      "DialoGPT: I'm fine. I'm good. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9091, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9033, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4747, 2.1694, 1.7687, 1.3542, 0.9133, 0.4532, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3270, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4184, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4280, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4501, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4646, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4532, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4747, grad_fn=<UnbindBackward>)\n",
      "Episode 120: -0.3892427798637674\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5931, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8485, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7937, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7998, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0022, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8952, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9345, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too\n",
      "DialoGPT: That's good, how about yourself?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9040, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8272, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, I'm doing good\n",
      "DialoGPT: I'm doing great\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8093, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8464, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0018, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8242, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: I'm doing doing good, I've been doing good lately lately.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7844, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7920, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7907, 2.4547, 2.0769, 1.6353, 1.2144, 0.8084, 0.3942, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3606, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3985, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4580, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4330, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4141, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4182, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3942, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7907, grad_fn=<UnbindBackward>)\n",
      "Episode 121: -0.3890081087096793\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8021, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6231, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7253, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8663, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you are?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9666, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8821, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you doin?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9162, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9449, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well, I'm doing good, I'm doing great\n",
      "DialoGPT: I'm doing good, how are doing well, I am doing well, I've been doing well, I\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8457, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8700, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0677, 1.7286, 1.3439, 0.8904, 0.4290, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3564, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3981, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4624, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4657, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4290, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0677, grad_fn=<UnbindBackward>)\n",
      "Episode 122: -0.3887429154985319\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6429, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7382, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good! How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6966, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8357, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good! I'm good too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8156, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8231, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: I'm happy to hear that!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8658, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that.\n",
      "DialoGPT: I'm happy for you too!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9087, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to hear that\n",
      "DialoGPT: I'm happy\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9139, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8572, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy too!\n",
      "DialoGPT: I love you too!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7788, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8853, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're so happy!\n",
      "DialoGPT: I'm excited to see\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6179, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6282, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0741, 2.7562, 2.3970, 2.0072, 1.5815, 1.1605, 0.7248, 0.3118, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3454, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3832, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4099, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4326, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4429, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4161, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3118, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0741, grad_fn=<UnbindBackward>)\n",
      "Episode 123: -0.38839375756440625\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6266, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6360, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7771, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7720, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear. How are you?\n",
      "r1: tensor(-0.0044, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8771, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8495, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, just tired.\n",
      "DialoGPT: That's good. How are you doing?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9378, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8249, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, thanks.\n",
      "DialoGPT: That's great. Good to hear.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8589, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8372, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: I'm good to hear that's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8780, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9121, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that. I'm glad\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3844, 2.0895, 1.7192, 1.2995, 0.8673, 0.4477, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3159, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3874, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4328, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4408, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4241, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4477, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3844, grad_fn=<UnbindBackward>)\n",
      "Episode 124: -0.38781343460083006\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7727, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6923, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8018, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you????\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9475, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8804, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you today?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9178, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9406, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, how about you?\n",
      "DialoGPT: I've been busy lately, but I'm doing alright. How are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8958, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8628, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not too bad, I'm doing well.\n",
      "DialoGPT: How are you're doing\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6823, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4111, 2.0492, 1.6925, 1.2478, 0.7909, 0.3546, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3824, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3736, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4572, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4648, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4399, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3546, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4111, grad_fn=<UnbindBackward>)\n",
      "Episode 125: -0.38777075920786175\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7662, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8197, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0035, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7242, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8782, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7815, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8000, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: That's great to hear!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9640, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9188, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: It is indeed!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8593, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9536, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad to hear that.\n",
      "DialoGPT: I'm glad you're glad to hear that I'm hear that I'm glad to hear it's good to hear that's good to hear it's to hear that\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6041, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7105, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3867, 2.0102, 1.6250, 1.2418, 0.7788, 0.3288, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3966, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4015, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3956, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4708, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4533, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3288, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3867, grad_fn=<UnbindBackward>)\n",
      "Episode 126: -0.38783998071678044\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6359, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6454, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7324, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8328, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing great!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9060, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: Yeah, it's great!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8181, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8581, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm feeling better now!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8288, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8819, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That was a great day!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8055, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8668, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It was!\n",
      "DialoGPT: I'm happy to hear that! It's great!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8465, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7728, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It was a great day.\n",
      "DialoGPT: It was a day!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6480, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6797, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0458, 2.7529, 2.3853, 1.9645, 1.5610, 1.1446, 0.7337, 0.3320, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3205, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3914, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4192, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4278, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4182, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4050, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0458, grad_fn=<UnbindBackward>)\n",
      "Episode 127: -0.3873139440547675\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7097, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5552, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6999, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8705, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7504, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8659, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: That's a good thing!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9085, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8008, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is indeed!\n",
      "DialoGPT: It is a good thing!!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9526, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9143, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is.\n",
      "DialoGPT: It's a good thing.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9486, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8625, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(7.0160e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!!\n",
      "DialoGPT: It's a great thing!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9627, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8576, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good!\n",
      "DialoGPT: I'me good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8424, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am!\n",
      "DialoGPT: It's great!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8353, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8946, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.6208, 3.3379, 2.9749, 2.5966, 2.1910, 1.7415, 1.3016, 0.8549, 0.4326,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3163, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3928, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4042, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4275, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4669, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4529, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4553, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4266, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4326, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.6208, grad_fn=<UnbindBackward>)\n",
      "Episode 128: -0.38676353087720944\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6321, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7682, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8137, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good! How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8956, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8041, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm doing great, how are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9176, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8886, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, I'm doing well too!\n",
      "DialoGPT: I'm doing good, how are you doin?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9558, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8571, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm doing good\n",
      "DialoGPT: I'm doing fine, how are you going to be?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9440, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8563, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4222, 2.1315, 1.7534, 1.3418, 0.8991, 0.4502, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3120, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3956, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4250, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4517, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4534, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4502, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4222, grad_fn=<UnbindBackward>)\n",
      "Episode 129: -0.38618857058194966\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys. Then we'll go bowling later on in the evening.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6967, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5657, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7336, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8735, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you? How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9405, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8105, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, how are your days?\n",
      "DialoGPT: They're pretty good, how are yours?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8806, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8776, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8492, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8708, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.8444e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's pretty good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8622, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.6329e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That is pretty good\n",
      "DialoGPT: That's very good.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9305, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9198, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That was pretty good\n",
      "DialoGPT: It's good to see you're going to\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6161, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5694, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.1188, 2.8313, 2.4539, 2.0363, 1.6127, 1.1945, 0.7562, 0.2965, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3158, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4019, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4379, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4397, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4301, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4459, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4626, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2965, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.1188, grad_fn=<UnbindBackward>)\n",
      "Episode 130: -0.38565149584799324\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys. Then we'll go bowling later on in the evening.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6318, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7242, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6949, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8562, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: Good job!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6930, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8506, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks! I'm glad you're doing well!\n",
      "DialoGPT: I'm glad you're enjoying it!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7677, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too!\n",
      "DialoGPT: I'm enjoying it too!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8809, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8872, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am enjoying it too!!\n",
      "DialoGPT: I'm having a good time!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8938, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9093, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy!\n",
      "DialoGPT: I'm loving it!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8974, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9078, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy!\n",
      "DialoGPT: I love me some\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5970, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5696, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0657, 2.7542, 2.3901, 2.0243, 1.6142, 1.1838, 0.7403, 0.2918, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3391, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3880, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3860, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4263, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4422, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4509, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4514, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2918, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0657, grad_fn=<UnbindBackward>)\n",
      "Episode 131: -0.3852987921599186\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys. Then we'll go bowling later on in the evening.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7398, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6193, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7659, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7887, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: That's good. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8464, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8171, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Not bad, just tired.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7969, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7896, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's fine.\n",
      "DialoGPT: I'm tired.\n",
      "r1: tensor(-0.0030, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8917, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8255, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: I'm aaight, aight\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8161, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8348, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too.\n",
      "DialoGPT: I'm okay.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8706, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine.\n",
      "DialoGPT: I'll be good to see you later. Bye bye bye bye\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6230, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5785, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0078, 2.6948, 2.3292, 1.9326, 1.5513, 1.1326, 0.7271, 0.3005, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3399, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3888, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4160, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3968, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4300, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4128, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4296, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3005, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0078, grad_fn=<UnbindBackward>)\n",
      "Episode 132: -0.38495777693009914\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys. Then we'll go bowling later on in the evening.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5567, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6170, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing great, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7249, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8254, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well, how are you doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9326, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9283, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you.\n",
      "DialoGPT: I'm doing good, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9433, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8928, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good, how are ya?\n",
      "DialoGPT: I'm fine, how are you\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9172, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8683, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good how are you? I'm good, I'm good.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8914, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3918, 2.1194, 1.7492, 1.2967, 0.8460, 0.4035, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2936, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3877, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4654, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4592, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4465, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4035, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3918, grad_fn=<UnbindBackward>)\n",
      "Episode 133: -0.3842759695070893\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go to your home and watch some movies with you guys. Then we'll go bowling later on in the evening.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7351, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6661, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: How are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7852, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you?\n",
      "DialoGPT: I'm good, how are you doing??\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8902, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9274, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you\n",
      "DialoGPT: I'm doing fine, how are YOU doing??\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9306, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9134, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well, I'm doing fine, I'm doing good, I'm doing great, I'm doing pretty good, I'm good, I'm pretty good, I think I'm doing\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6491, 1.3118, 0.9111, 0.4611, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3504, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4099, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4545, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4611, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6491, grad_fn=<UnbindBackward>)\n",
      "Episode 134: -0.3840250957895208\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go bowling with you guys later on in the movie theater.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7730, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6536, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8333, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good thanks, how are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8721, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been busy with work, but I'm good now. How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8793, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8877, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, I'm good.\n",
      "DialoGPT: I'm good now I'm good\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8509, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8973, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8505, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.6228e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I am good\n",
      "DialoGPT: I'm\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5073, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6837, 2.3504, 1.9985, 1.5592, 1.1286, 0.6984, 0.2792, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3568, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3719, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4549, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4419, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4372, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4220, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2792, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6837, grad_fn=<UnbindBackward>)\n",
      "Episode 135: -0.3838249565485646\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go bowling with you guys later on in the movie theater.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7139, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7711, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about yourself?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7137, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8354, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you?\n",
      "DialoGPT: Good, good. How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9014, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8618, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good.\n",
      "DialoGPT: Good is good. How are ya?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8811, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7398, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks.\n",
      "DialoGPT: That's good. How are we?\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9137, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7511, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good. How are your days going?\n",
      "DialoGPT: Yeah, yeah.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7878, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3700, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I am good.\n",
      "DialoGPT: Good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8497, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6974, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(4.4870e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.6205, 2.2719, 1.9035, 1.4772, 1.0827, 0.6726, 0.3869, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3713, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3874, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4410, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4053, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4168, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2896, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3869, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.6205, grad_fn=<UnbindBackward>)\n",
      "Episode 136: -0.3837338322705596\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go bowling with you guys later on in the movie theater.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8179, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6563, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7360, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8175, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7629, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7969, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9348, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3074, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is.\n",
      "DialoGPT: That's good?\n",
      "r1: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9336, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8704, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!!\n",
      "DialoGPT: That's a great thing!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9115, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8357, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is\n",
      "DialoGPT: It is a great thing!!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9432, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8111, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is a good thing!\n",
      "DialoGPT: That's is a good thing.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9201, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9468, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is! I'm glad you're doing well!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.1348, 2.7940, 2.4298, 2.0602, 1.7671, 1.3288, 0.9009, 0.4668, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3687, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3885, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3902, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3108, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4515, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4370, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4387, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4668, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.1348, grad_fn=<UnbindBackward>)\n",
      "Episode 137: -0.3836251618205637\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go bowling with you guys later on in the movie theater.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6521, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7534, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7987, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8361, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8476, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: That's good, how about me?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8836, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8926, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you.\n",
      "DialoGPT: That's good. How about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9164, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8685, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good\n",
      "DialoGPT: That's good\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5955, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7541, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.3043e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9470, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9278, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good to hear\n",
      "DialoGPT: That's good how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7277, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6858, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0920, 2.7682, 2.4123, 2.0114, 1.5830, 1.1481, 0.8188, 0.3535, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3516, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3799, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4211, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4442, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4464, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3375, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4688, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3535, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0920, grad_fn=<UnbindBackward>)\n",
      "Episode 138: -0.3833945378553953\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's a lot of movies!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Let's go bowling.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll go bowling together.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then I'll go bowling with you guys later on in the movie theater.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7002, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5730, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7015, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8220, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how's your day?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8280, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9005, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about yours?\n",
      "DialoGPT: It's been alright so far..\n",
      "r1: tensor(-0.0043, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8351, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8784, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: Yeah, yeah. That's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8575, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9240, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: Yeah, I'm good.\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7755, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7534, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too.\n",
      "DialoGPT: So are you.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7921, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: So good\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6164, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8053, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0531, 2.7623, 2.4054, 1.9929, 1.5792, 1.1452, 0.7704, 0.3556, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3184, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3810, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4324, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4295, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4455, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3825, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4184, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3556, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0531, grad_fn=<UnbindBackward>)\n",
      "Episode 139: -0.382930198098932\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7012, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5123, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7163, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8416, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0025, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6661, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8102, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that!!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8821, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9332, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that.\n",
      "DialoGPT: I'm happy for you're happy to hear that's good news.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9085, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8886, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're happy to be happy.\n",
      "DialoGPT: Happy to hear happy to hear that news.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8991, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8677, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am happy to\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3438, 2.0610, 1.6883, 1.3319, 0.8867, 0.4418, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3035, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3896, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3697, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4540, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4493, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4418, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3438, grad_fn=<UnbindBackward>)\n",
      "Episode 140: -0.3823666380229571\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5297, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7140, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing pretty well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6872, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8369, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7430, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8386, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that!!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8734, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9328, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that.\n",
      "DialoGPT: I'm happy too!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9280, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8883, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm very happy to hear that\n",
      "DialoGPT: I'm happy that you're happy to hear that I'm happy to hear you're happy to say that.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8728, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9130, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3754, 2.0852, 1.7212, 1.3390, 0.8963, 0.4466, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3111, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3812, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3956, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4517, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4542, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4466, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3754, grad_fn=<UnbindBackward>)\n",
      "Episode 141: -0.3818647093336347\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7958, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7407, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6510, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8595, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how's it going?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8458, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9096, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about you?\n",
      "DialoGPT: It's been a while since I've been busy with school and stuff, but I'm doing well, how about yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8514, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8816, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm just busy with school and work.\n",
      "DialoGPT: That's good, I'm glad you're doing well. How are you\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9009, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8020, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0181, 1.6504, 1.2855, 0.8550, 0.4259, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3843, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3778, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4391, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4333, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4259, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0181, grad_fn=<UnbindBackward>)\n",
      "Episode 142: -0.38188144668832524\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7548, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6503, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7617, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7578, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9105, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9281, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7429, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7765, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: I'm glad you're glad to hear that's good to hear\n",
      "r1: tensor(-0.0312, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8737, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9086, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad that you're glad to see that I'm glad to hear you're glad to know that I'm glad that\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9826, 1.6476, 1.2804, 0.8289, 0.4534, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3515, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3800, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4598, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3800, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4534, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9826, grad_fn=<UnbindBackward>)\n",
      "Episode 143: -0.38167059131794506\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7008, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6399, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6982, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7575, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7476, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8108, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm doing great!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8036, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8581, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: I'm so glad to hear that's doing great!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8851, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8277, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too!\n",
      "DialoGPT: That is great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8028, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8261, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I love you!\n",
      "DialoGPT: I'm a great person\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8083, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8274, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I love you too!\n",
      "DialoGPT: I'm great!\n",
      "r1: tensor(-0.0044, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8925, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I like you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0594, 2.7517, 2.4117, 2.0424, 1.6433, 1.2272, 0.8282, 0.4233, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3353, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3640, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3897, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4156, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4283, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4073, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4091, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4233, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0594, grad_fn=<UnbindBackward>)\n",
      "Episode 144: -0.3813507269168722\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6127, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7568, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7076, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8509, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you? How are you?\n",
      "r1: tensor(-0.0036, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9490, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8905, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, how are your days?\n",
      "DialoGPT: They're alright, how are you doing?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9175, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8986, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doin?\n",
      "DialoGPT: I'm well, I'm doing well, I'm good, I'm doing good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8495, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8288, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good, I'm good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6495, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7238, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3507, 2.0285, 1.6553, 1.2066, 0.7600, 0.3437, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3425, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3897, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4608, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4542, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4197, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3437, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3507, grad_fn=<UnbindBackward>)\n",
      "Episode 145: -0.38108479323452465\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3803, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6072, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7332, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8144, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you? I'm good too.\n",
      "DialoGPT: I'm good too, how are you\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9400, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8862, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.2553e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you.\n",
      "DialoGPT: I'm bad, how are you are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9164, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9148, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad, I'm good.\n",
      "DialoGPT: I'm not bad, how are good, how are they are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9397, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7500, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: They're good, how are u?\n",
      "DialoGPT: They're bad, how are they\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7995, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7932, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3068, 2.0806, 1.7107, 1.2667, 0.8169, 0.3983, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2470, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3870, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4567, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4580, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4225, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3983, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3068, grad_fn=<UnbindBackward>)\n",
      "Episode 146: -0.38017259021194616\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6652, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5925, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7396, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7955, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, I'm good, how you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8662, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8643, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, I'm good\n",
      "DialoGPT: That's good, I'm glad to be of helpfull.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8649, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to be useful\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8029, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7835, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to be useful\n",
      "DialoGPT: I'm happy that you're useful to be useful to be useful\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7915, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9138, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're welcome\n",
      "DialoGPT: I'm\n",
      "dummy\n",
      "True 3\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8316, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.6919, 2.4014, 2.0379, 1.6213, 1.2035, 0.8149, 0.3924],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3146, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3839, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4328, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4298, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3967, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4264, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3924, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.6919, grad_fn=<UnbindBackward>)\n",
      "Episode 147: -0.3797292719418938\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. He leaves.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5990, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6827, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8000, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7588, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8138, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm doing well.\n",
      "DialoGPT: That's good, I'm doing good.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8407, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9255, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That's great. Good to hear that.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8539, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8484, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that. I'm glad to hear you're doing well.\n",
      "DialoGPT: I'm doing good. How are you're you???\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7641, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8641, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2822, 1.9971, 1.6428, 1.2621, 0.8288, 0.4072, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3051, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3708, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3933, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4416, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4072, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2822, grad_fn=<UnbindBackward>)\n",
      "Episode 148: -0.3792282512924015\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. Leaves him alone for now.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5448, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4899, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7505, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8074, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too. How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9386, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8511, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good to hear. How are you doing today?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8778, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4528, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well lately, how about myself lately. How are you been??\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9124, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9061, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, I'm doing well too.\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.7982,  1.5549,  1.1770,  0.7368,  0.4081, -0.0471],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2588, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3897, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4476, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3328, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4548, device='cuda:0', grad_fn=<NegBackward>), tensor(-0.0471, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(1.7982, grad_fn=<UnbindBackward>)\n",
      "Episode 149: -0.3784256104628245\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. Leaves him alone for now.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5653, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4674, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7523, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good, how are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8739, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7831, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are YOU?\n",
      "DialoGPT: I'm fine, how are you are?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8942, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9440, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well.\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6473, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7737, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That's great, how are you're doing well?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7639, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8180, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, I'm doing great!\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0774, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0712, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.1981, 1.9594, 1.6376, 1.2356, 0.7838, 0.4327, 0.0376],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2583, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3381, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4144, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4597, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3554, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3956, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0376, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.1981, grad_fn=<UnbindBackward>)\n",
      "Episode 150: -0.37762988047884\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're a monster.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: He smiles softly. Well, I'll see you later. Bye bye. Leaves him alone for now.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6659, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6201, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7082, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8299, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear. How are you doing well?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8788, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7972, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you doing?\n",
      "DialoGPT: That's good. How are you?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9029, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8995, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well.\n",
      "DialoGPT: That's good, good to hear\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8216, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8073, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good too.\n",
      "DialoGPT: That's great! Glad to hear you're doing well.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8794, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8421, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3516, 2.0504, 1.6826, 1.2762, 0.8336, 0.4305, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3216, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3847, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4191, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4510, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4074, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4305, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3516, grad_fn=<UnbindBackward>)\n",
      "Episode 151: -0.3772613802238515\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive!\n",
      "User: I have the DVD.\n",
      "DialoGPT: You're impressive.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. He walks inside and opens his door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: He nods and follows her inside. OOC : End scene?\n",
      "User: I always cry at the end.\n",
      "DialoGPT: OOC : End scene.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6071, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7470, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7102, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7940, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how is you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8606, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9032, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good\n",
      "DialoGPT: Good, how's your day going?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8675, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7308, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Great, thanks!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8228, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8035, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're welcome\n",
      "DialoGPT: You're welcome!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8622, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9035, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're very welcome!\n",
      "DialoGPT: Thank you very much!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7493, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8920, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're so welcome!\n",
      "DialoGPT: Thank You're welcome to you too much welcome welcome to the welcome welcome\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7297, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0599, 2.7487, 2.3965, 1.9752, 1.5913, 1.1965, 0.7626, 0.3557, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3386, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3762, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4411, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3998, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4067, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4105, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3557, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0599, grad_fn=<UnbindBackward>)\n",
      "Episode 152: -0.37700901117200164\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5814, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6749, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6358, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7434, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you're doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9066, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8202, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: I've been doing well, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9075, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9047, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've done well, how about me?\n",
      "DialoGPT: I'm?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7422, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7633, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm doing good, how are your doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8931, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how bout\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2615, 1.9669, 1.6381, 1.2185, 0.7730, 0.4006, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3142, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3452, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4318, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4532, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3765, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4006, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2615, grad_fn=<UnbindBackward>)\n",
      "Episode 153: -0.376601387734537\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6552, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7010, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7256, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7802, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7266, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8214, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: I'm doing great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7826, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8072, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: I'm glad toastyaking!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7432, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7456, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy!\n",
      "DialoGPT: I'm happy toasty to be so happy!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8615, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8913, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's so good!\n",
      "DialoGPT: I'm very happy toastyaking it's good!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9247, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8536, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I love it!\n",
      "DialoGPT:  to be happy to be\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5700, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.9727, 2.6601, 2.3066, 1.9388, 1.5568, 1.1965, 0.7658, 0.3244, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3393, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3766, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3871, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3976, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3723, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4383, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4447, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3244, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.9727, grad_fn=<UnbindBackward>)\n",
      "Episode 154: -0.3763604392928462\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6751, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5828, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7870, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8241, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: Good, I'm good too.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8001, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I hope you have a good day\n",
      "DialoGPT: Same to you!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7861, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7774, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You too\n",
      "DialoGPT: I hope you have a great day night night day night night night night night day night day night night day Night night night night night Night night night Night night Night night night night Night Night Night Night Night night night night day Night Night night night\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6421, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4902, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7459, 1.4458, 1.0535, 0.6713, 0.2832, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3145, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4029, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3889, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3909, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2832, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7459, grad_fn=<UnbindBackward>)\n",
      "Episode 155: -0.37596421325818086\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5322, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5351, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6107, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7958, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good how are you? How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9607, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8395, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, how are your days?\n",
      "DialoGPT: Pretty good how are you doing??\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8807, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8924, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing\n",
      "DialoGPT: I'm doing ok?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8402, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8372, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm just tired\n",
      "DialoGPT: That's good, I'm good, how's good how are you feeling??\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7375, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8648, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2708, 2.0240, 1.6892, 1.2515, 0.8163, 0.4008, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2671, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3517, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4502, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4434, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4195, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4008, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2708, grad_fn=<UnbindBackward>)\n",
      "Episode 156: -0.3752705413065139\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6365, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6665, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7778, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you doing today?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8577, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I am doing well too well, how are you today?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8971, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9379, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: I'm doing great, how are you, how are you going to be?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9236, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8905, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be doing great, I'm going to be busy\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0197, 1.6978, 1.3502, 0.9079, 0.4536, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3388, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3611, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4513, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4589, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4536, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0197, grad_fn=<UnbindBackward>)\n",
      "Episode 157: -0.3750399798154831\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7153, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5722, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7533, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8324, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7286, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8238, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: So what's up?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7776, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8624, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Nothing much.\n",
      "DialoGPT: Nothing much. much nothing much much much much much wow wow wow wow wow Wow wow wow wow wow such wow wow wow wow much wow wow wow much Wow wow wow wow Wow Wow wow wow wow such Wow wow wow wow much much wow wow much wow much wow wow much\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6686, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7850, 1.4778, 1.0922, 0.7111, 0.3040, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3220, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3965, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3882, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4101, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3040, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7850, grad_fn=<UnbindBackward>)\n",
      "Episode 158: -0.37470650166835423\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5331, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6394, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6281, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7608, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8962, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7940, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: doing well, how are YOU?????\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8973, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8185, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you doing?\n",
      "DialoGPT: doing well, well, how are ya?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9105, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8818, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm doing well, I'm doing good, I'm doing fine, I'm good, I'm good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8982, 1.6212, 1.2867, 0.8728, 0.4483, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2932, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3473, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4226, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4291, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4483, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8982, grad_fn=<UnbindBackward>)\n",
      "Episode 159: -0.3741970332339406\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7276, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6712, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6931, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8432, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how's your day going?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8366, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8431, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about yours?\n",
      "DialoGPT: Fine, it's going well too.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8489, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8650, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That is good to hear.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8237, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8744, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: YeahYeahYeahYeahYeah Yeah Yeah Yeah Yeah Yeah Yep Yeah Yeah Yeah Yeah yeah Yeah Yeah Yeah Yeah Ye Yeah Yeah Yeah Yeah Ya Yeah Yeah\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6122, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5721, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2474, 1.9167, 1.5480, 1.1394, 0.7179, 0.2962, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3498, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3842, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4200, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4286, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4247, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2962, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2474, grad_fn=<UnbindBackward>)\n",
      "Episode 160: -0.3740453536836257\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4953, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5309, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7095, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7847, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: How are your kids doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8488, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8232, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: They're doing great!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8477, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: They're doing well!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8406, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7808, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: They're good!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8782, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8951, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's nice!\n",
      "DialoGPT: That's a good one!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8286, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8675, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy for them!\n",
      "DialoGPT: They're great!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8564, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7926, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I love them!\n",
      "DialoGPT: They are great!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9325, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8418, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.4213, 3.1966, 2.8515, 2.4579, 2.0865, 1.6980, 1.2673, 0.8516, 0.4437,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2567, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3737, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4181, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3923, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4055, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4434, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4241, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4124, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4437, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.4213, grad_fn=<UnbindBackward>)\n",
      "Episode 161: -0.3733207051768715\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5709, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5544, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm fine, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6551, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8159, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good, how are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9463, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8429, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good too\n",
      "DialoGPT: That's good to\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7595, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7346, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: That's good, how are ya?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7910, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7721, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing fine lately, I've been busy with school and stuff has been busy lately\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8252, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8655, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0017, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6163, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6716, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.5278, 2.2691, 1.9204, 1.4878, 1.1255, 0.7420, 0.3224, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2814, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3679, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4474, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3736, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3909, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4228, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3224, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.5278, grad_fn=<UnbindBackward>)\n",
      "Episode 162: -0.37275688816433306\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4529, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5205, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about yourself?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7564, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you?\n",
      "DialoGPT: I am doing well, how are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9282, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8623, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well too.\n",
      "DialoGPT: That's and I'm doing well, I'm doing better than I was before I was before I got into this mess.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8498, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8763, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7660, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8871, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: That's great.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9186, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8322, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2806, 2.0576, 1.7051, 1.2700, 0.8469, 0.4378, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2435, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3696, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4478, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4316, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4134, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4378, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2806, grad_fn=<UnbindBackward>)\n",
      "Episode 163: -0.3719686461476291\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5124, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4165, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6840, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear! How are you doing well?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8821, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8145, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: doing well?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6885, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7403, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am!\n",
      "DialoGPT: That's great to hear!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7078, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7574, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that you're doing well!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8778, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy to hear that!!\n",
      "DialoGPT: I'm very happy to hear\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7951, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8014, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4933, 2.2838, 1.9329, 1.5238, 1.1783, 0.8200, 0.3992, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2323, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3703, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4243, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3573, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3664, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4248, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3992, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4933, grad_fn=<UnbindBackward>)\n",
      "Episode 164: -0.37112240113995293\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4707, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6795, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7424, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7884, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about yourself?\n",
      "DialoGPT: doing well how about you? How about you? How bout you? How bout me? How bout you how bout you? How about me? How bout me how bout me?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9036, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8504, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: how bout you? How's bout you're good? How bout you good? How bout me you? How bout yourself?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9440, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8820, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5396, 1.2646, 0.8907, 0.4566, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2876, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3829, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4386, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4566, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5396, grad_fn=<UnbindBackward>)\n",
      "Episode 165: -0.3706195500780301\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7378, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5922, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6118, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7534, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing great welling welling welling great welling well welling welling Welling welling well well welling well weller welling well welled welling wellingwelling welling wellwelling welling Well well well well well weller weller weller Well weller Weller Weller Welling Weller Weller weller\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7714, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.0183, 0.6926, 0.3547, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3326, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3547, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.0183, grad_fn=<UnbindBackward>)\n",
      "Episode 166: -0.37039216701499\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4285, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5864, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5865, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7731, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you, how are you are?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9469, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8503, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you doing?\n",
      "DialoGPT: I'm doing well, how are you going?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9326, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be busy for the next few days, but I'm going to be doing a lot of work today.\n",
      "DialoGPT: Sounds good, I'll see you later then.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8030, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9063, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: See\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8895, 1.6521, 1.3254, 0.8848, 0.4274, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2538, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3400, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4494, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4274, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8895, grad_fn=<UnbindBackward>)\n",
      "Episode 167: -0.3696984557346219\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6441, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4858, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing pretty well actually. How about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8118, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too.\n",
      "DialoGPT: That's good to hear. How are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8481, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7620, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad.\n",
      "DialoGPT: That's ok. How are you doing well?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7009, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: That's nice.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7235, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7927, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great.\n",
      "DialoGPT: That's true.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8843, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8916, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's a good thing.\n",
      "DialoGPT: That's awesome.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9003, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8836, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's pretty good.\n",
      "DialoGPT: That is true.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8572, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8719, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.0585, 2.8039, 2.4435, 2.0614, 1.6756, 1.3095, 0.8741, 0.4324, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2826, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3849, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4027, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4026, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3792, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4441, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4461, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4324, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.0585, grad_fn=<UnbindBackward>)\n",
      "Episode 168: -0.36918325087375187\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5812, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5332, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7764, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8036, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you? How are you? What's going on?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8630, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9021, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm just tired.\n",
      "DialoGPT: That's ok then. Sleep well. Sleep well.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8520, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8151, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep well!\n",
      "DialoGPT: Sleep well! Sleep well!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9082, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8874, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep good!\n",
      "DialoGPT: Sleep well sleep well! Sleep well Sleep well! Sleep well sleep well!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7356, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7187, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2844, 2.0259, 1.6472, 1.2179, 0.8091, 0.3637, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2788, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3951, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4414, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4169, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4490, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3637, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2844, grad_fn=<UnbindBackward>)\n",
      "Episode 169: -0.3686513356426183\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, you'll be crying soon enough anyway.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7079, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4941, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7011, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7808, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7362, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7818, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: So am I.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7831, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8055, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.8619e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So am i.\n",
      "DialoGPT: So am me.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8971, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8305, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad to hear that\n",
      "DialoGPT: I'm glad you're glad to hear that I'm glad to hear you're glad to be hearing that.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7500, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that you're happy to hear that\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2316, 1.9504, 1.5958, 1.2285, 0.8396, 0.4117, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3007, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3706, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3796, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3973, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4117, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2316, grad_fn=<UnbindBackward>)\n",
      "Episode 170: -0.3682537538092039\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4928, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4593, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing alright, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6525, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5515, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0268, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0571, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([0.5438, 0.3087, 0.0077], grad_fn=<CopySlices>)\n",
      "[tensor(0.2381, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3011, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0077, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(0.5438, grad_fn=<UnbindBackward>)\n",
      "Episode 171: -0.36749714370383774\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5564, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks for asking me that question. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7175, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7851, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Not bad, how are you doing?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9160, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8977, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, good, how are your days going?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8679, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8355, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good. I'm going to be busy for the next few days, but I'm going to try to get some sleep.\n",
      "DialoGPT: Sleep soon then?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7406, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7184, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep soon!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9140, 1.5965, 1.2331, 0.7873, 0.3649, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.3335, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4537, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4260, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3649, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9140, grad_fn=<UnbindBackward>)\n",
      "Episode 172: -0.36730055106168535\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6055, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2420, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6600, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8197, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6998, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8276, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: So what's your name?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8377, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7037, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not sure\n",
      "DialoGPT: I'm sure you're doing well.\n",
      "r1: tensor(-0.0015, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8107, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8016, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.7719e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm sure I am!\n",
      "DialoGPT: I'm sure am sure you're sure you're sure.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8905, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9107, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not so sure\n",
      "DialoGPT: I'm Sure\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8023, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8745, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm sure\n",
      "DialoGPT: I'm okay with you're sure you are\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4912, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4980, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7681, 2.5819, 2.2342, 1.8709, 1.5005, 1.1081, 0.6643, 0.2474, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2120, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3701, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3820, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3855, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4035, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4504, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4193, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2474, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7681, grad_fn=<UnbindBackward>)\n",
      "Episode 173: -0.3664081396385171\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3614, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3515, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7062, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7451, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7332, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6646, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad\n",
      "DialoGPT: So are you.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7654, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7512, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: So are you\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8643, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7941, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.9031e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good\n",
      "DialoGPT: I'm good.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7128, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8518, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.4137e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: Good\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5837, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8346, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(2.4752e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5044, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.0166, 2.8669, 2.5292, 2.0998, 1.7679, 1.4026, 0.9976, 0.6124, 0.2604],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1784, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3629, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4504, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3496, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3793, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4150, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3913, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3546, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2604, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(3.0166, grad_fn=<UnbindBackward>)\n",
      "Episode 174: -0.36533364227839876\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6645, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4712, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7183, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8044, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: I'm good too, how about you..... I'm good too, you're good too.\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8550, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8090, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: I'm good. How about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9027, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6249, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Good Good Good Good Good Good good Good Good Good Good Bad Good Good Good Good bad Good Bad Bad Bad Good Bad Bad Bad Bad Bad Good Good Bad Bad\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6933, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5375, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7353, 1.4659, 1.0961, 0.6867, 0.3078, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2840, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3808, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4162, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3820, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3078, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7353, grad_fn=<UnbindBackward>)\n",
      "Episode 175: -0.36487150920385664\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6233, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4400, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6975, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7325, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: That's good to hear. How are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7447, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7191, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad.\n",
      "DialoGPT: That's a relief.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7714, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7520, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm doing well.\n",
      "DialoGPT: Well, I'm glad to hear that.\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7327, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8792, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear you're doing well.\n",
      "DialoGPT: I'm doing well. And that's a good to hear.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8553, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8685, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that. I'm glad to see\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1463, 1.8993, 1.5572, 1.2030, 0.8304, 0.4310, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2660, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3576, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3662, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3810, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4036, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4310, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1463, grad_fn=<UnbindBackward>)\n",
      "Episode 176: -0.36431278128408445\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6155, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5356, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7251, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8445, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8666, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8946, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you,\n",
      "DialoGPT: I'm doing fine, fine, I'm fine, I'm doing well, fine, fine, fine.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8176, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8239, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I am fine, I'm good, I'm fine\n",
      "DialoGPT: I'm fine fine, fine, good, fine, fine fine fine\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8126, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8024, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8944, 1.6228, 1.2427, 0.8104, 0.4039, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2879, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3925, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4404, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4105, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4039, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8944, grad_fn=<UnbindBackward>)\n",
      "Episode 177: -0.36388332673003165\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's awesome. I'm jealous of your collection.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me get my camera and start recording some videos.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. Let's do it sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that movie.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4307, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2716, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6221, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8029, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7282, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7690, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: So are we!??\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7813, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8361, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well!\n",
      "DialoGPT: I'm doing alright myself!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7893, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7713, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: Yeah! Thanks for and good!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8042, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8378, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that!!\n",
      "DialoGPT: That's a good!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4261, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7113, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am happy to hear that\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3210, 2.1670, 1.8290, 1.4693, 1.0756, 0.6923, 0.2845, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1757, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3563, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3744, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4045, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3902, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4106, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2845, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3210, grad_fn=<UnbindBackward>)\n",
      "Episode 178: -0.3628319140586107\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me. Leaves the door unlocked for others. Leaves the door locked for myself. Leaves the door unsecured. Leaves the door closed. Leaves the door. Leaves the door sealed. Leaves the door safe.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're a monster.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4437, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4223, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6778, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6674, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too. How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8732, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9050, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you doing?\n",
      "DialoGPT: Fine, thanks for asking. How are you doing? Any plans?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8722, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not really, I'm just going to sleep.\n",
      "DialoGPT: Sounds good to me thinks I'm going to bed soon. Sleep well?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8354, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9207, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep well!\n",
      "DialoGPT: Sleep well! Sleep well! Sleep well. Sleep\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7195, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1741, 1.9773, 1.6574, 1.2250, 0.7948, 0.3593, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2166, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3364, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4447, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4382, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4392, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3593, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1741, grad_fn=<UnbindBackward>)\n",
      "Episode 179: -0.3620196273757352\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me. Leaves the door unlocked for others. Leaves the door locked for myself. Leaves the door unsecured. Leaves the door closed. Leaves the door. Leaves the door sealed. Leaves the door safe. Leaves the door secure.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7167, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6409, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6619, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8183, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's great! How's your day going?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8091, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8016, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7693, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7921, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: That's fantastic!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8581, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8560, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is indeed!\n",
      "DialoGPT: It's great!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8882, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8669, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is\n",
      "DialoGPT: It's great fun time!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8728, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6330, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is.\n",
      "DialoGPT: It's fun times fun times fun times times fun times funtimes fun fun\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7203, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2811, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8968, 2.5831, 2.2352, 1.8510, 1.4752, 1.0572, 0.6245, 0.2505, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.3396, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3702, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4028, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3905, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4286, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4389, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3766, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2505, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8968, grad_fn=<UnbindBackward>)\n",
      "Episode 180: -0.36189557101515774\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5694, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5969, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5308, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7829, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7196, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7830, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: So what's your name?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8291, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7465, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not sure.\n",
      "DialoGPT: Wells. It's a nice to meet you're here.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8059, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7586, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Nice to meet you too.\n",
      "DialoGPT: Nice tomorrowsome.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7792, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8314, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go to sleep now.\n",
      "DialoGPT: See you're going tomorning\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7398, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7289, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4722, 2.2025, 1.8928, 1.5324, 1.1499, 0.7663, 0.3673, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2918, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3940, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3912, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4027, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3673, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4722, grad_fn=<UnbindBackward>)\n",
      "Episode 181: -0.3615103467971414\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3304, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6454, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good thanks. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7085, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8137, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you?\n",
      "DialoGPT: Fine, thanks. How are they?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8852, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8653, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm glad you're okay.\n",
      "DialoGPT: Good, I hope you're okay. How are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8549, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks.\n",
      "DialoGPT: That's good, I'm doing well?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8377, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8263, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks.\n",
      "DialoGPT: Good, good. How are you going to the beach?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7656, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7686, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2275, 2.0034, 1.6392, 1.2135, 0.7960, 0.3837, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2441, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3807, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4378, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4255, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4161, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3837, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2275, grad_fn=<UnbindBackward>)\n",
      "Episode 182: -0.3608685949298202\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4782, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4837, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6722, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7320, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's great! How are you?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8515, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7783, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm doing great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7347, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's a relief!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7369, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8755, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: That's better than usual than usual.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8117, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8464, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8743, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8473, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great\n",
      "DialoGPT: That's good enough.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8982, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8740, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's a good day.\n",
      "DialoGPT: That's\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.9418e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([3.2011, 2.9904, 2.6659, 2.2811, 1.9374, 1.5496, 1.1465, 0.7233, 0.2829,\n",
      "        0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2406, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3512, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4076, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3631, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4032, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4146, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4305, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4432, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2829, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(3.2011, grad_fn=<UnbindBackward>)\n",
      "Episode 183: -0.36021478166398796\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5367, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4750, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6834, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7967, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7919, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: Good, I'm good, how about we?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4633, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7690, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sounds good\n",
      "DialoGPT: Sounds good to me!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7870, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8199, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good to go!\n",
      "DialoGPT: Good to go to bed!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8321, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8135, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good night!\n",
      "DialoGPT: Good night night!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7753, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2938, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Goodnight!\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1068, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2549, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([2.3912, 2.1597, 1.8077, 1.4044, 1.1073, 0.7126, 0.3041, 0.0371],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2531, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3701, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4174, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3082, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4018, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4115, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2674, device='cuda:0', grad_fn=<NegBackward>), tensor(0.0371, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(2.3912, grad_fn=<UnbindBackward>)\n",
      "Episode 184: -0.3596355204646652\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5589, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3775, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing alright, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6272, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7840, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing fine, how about you how about you? How about you? How bout you? How bout me?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9423, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9289, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about me?\n",
      "DialoGPT: AlrightAlrightAlrightAlrightAlright Alright Alright Alright Alright AlrightAlright Alright Alright Alright alright Alright Alright Alright Alright alright alright Alright Alright Alright alright okay Alright Alright Alright Alright Okay Alright Alright Alright Alright Ok\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7519, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6739, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.5346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.3882, 1.1656, 0.8209, 0.3565, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2342, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3529, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4679, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3565, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.3882, grad_fn=<UnbindBackward>)\n",
      "Episode 185: -0.35896127078161444\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me to come back later on.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later. Leaves the room and goes back inside.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3529, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4716, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6404, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7817, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good! How's it going?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8428, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8023, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well!\n",
      "DialoGPT: That's great! How's it goin?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9229, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8059, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good!\n",
      "DialoGPT: That's nice to hear that!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8275, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7997, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good to hear that! I'm glad you're doing well!\n",
      "DialoGPT: doing well! How's it's good to hear it's good? That's good\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7326, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1404, 1.9537, 1.6143, 1.2151, 0.7907, 0.3875, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2062, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3556, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4114, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4323, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4070, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3875, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1404, grad_fn=<UnbindBackward>)\n",
      "Episode 186: -0.3581442996301753\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me when he leaves. Leaves the door unlocked. Leaves the door locked. Leaves the door unsecured. Leaves the door closed. Leaves the door. Leaves the door sealed. Leaves the door secured. Leaves the door secure. Leaves the door safe.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3350, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3970, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6744, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7824, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: Fine, how's it going?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8740, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8431, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about you!\n",
      "DialoGPT: It's going great, how about you.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8385, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9285, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.7925e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: That's good, how about yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8621, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6391, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about yourself\n",
      "DialoGPT: That's good\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8572, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6576, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8179, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9159, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.4503e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's good to me.\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6687, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4674, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.7872, 2.6303, 2.2889, 1.8783, 1.4509, 1.0864, 0.7148, 0.2841, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1831, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3643, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4294, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4419, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3754, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3788, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4335, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2841, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.7872, grad_fn=<UnbindBackward>)\n",
      "Episode 187: -0.35721347663313785\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching again if you haven't seen it yet.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. Leaves the door open for me when he leaves. Leaves the door unlocked. Leaves the door locked. Leaves the door unsecured. Leaves the door closed. Leaves the door. Leaves the door sealed. Leaves the door secured. Leaves the door secure. Leaves the door safe.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4198, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6065, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6948, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7576, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7125, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7553, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: That's that's good tomoroway?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8655, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8461, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: That's great tomorowayayayayayaysayayayayayaayayayayayeayayayayeyayayayayyaayayayayaaaaayayayay\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8240, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6423, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7437, 1.5019, 1.1502, 0.7910, 0.3667, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2568, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3632, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3671, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4280, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3667, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7437, grad_fn=<UnbindBackward>)\n",
      "Episode 188: -0.3566820983375822\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching multiple times if you're into that sort of thing.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. I'll be waiting for you in my room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good. See ya later. walks away\n",
      "User: I always cry at the end.\n",
      "DialoGPT: walks away Bye bye. leaves\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4749, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2634, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks! How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6535, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8275, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: Yayayayayayyyyyyyyyyyy!!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7677, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7933, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad!\n",
      "DialoGPT: I'm happy for you!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7991, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8680, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so happy!\n",
      "DialoGPT: I'm excited for you!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8966, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7003, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yay!\n",
      "DialoGPT: Yayyyyyyyyyyyyyyyyysssssssssssssssssssssysssssssssiss\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6211, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5897, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0100, 1.8438, 1.4883, 1.1091, 0.6991, 0.3029, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1847, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3704, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3903, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4169, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3993, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3029, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0100, grad_fn=<UnbindBackward>)\n",
      "Episode 189: -0.35577674908073326\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching multiple times if you're into that sort of thing.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing buddy. Let me know when you're ready for some coffee or something. I'll be waiting outside the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good, let's do it later tonight sometime.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It happens to everyone eventually.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2189, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6234, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7297, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good how are you? I'm good too. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8577, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8030, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, I'm good too\n",
      "DialoGPT: That's good to hear. How are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8511, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7352, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm just tired\n",
      "DialoGPT: That's good, I'm tired. Sleep well? Sleep well sleep well sleep well sleep good sleep well sleep well. Sleep well sleep well.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8253, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7444, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6721, 1.5192, 1.1927, 0.7853, 0.3925, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1681, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3384, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4153, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3967, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3925, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6721, grad_fn=<UnbindBackward>)\n",
      "Episode 190: -0.35479412863703924\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies have you seen total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, enjoy it while its there. It's a great movie and worth watching multiple times if you're into that sort of thing.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing buddy. Let me know when you're ready for some coffee or something. I'll be waiting outside the door.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds good, let's do it later tonight sometime.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It happens to everyone eventually.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5738, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3652, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?????\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7306, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6832, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: I'm doing well thanks for asking. I'm doing well.. How are you doing?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8907, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8203, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks for asking\n",
      "DialoGPT: That's good. How are you feeling better than usual?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8771, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8013, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm feeling better, thanks for asking!\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7943, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.5417e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7833, 1.5641, 1.2227, 0.8029, 0.3870, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2349, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3535, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4279, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4197, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3870, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7833, grad_fn=<UnbindBackward>)\n",
      "Episode 191: -0.3541696339379996\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication to cinema. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later. Leaves camera on desk with popcorn ready for viewing pleasure. Leaves camera on tripod Ready for movie theater experience. Leaves camera on stand overlooking audience. Leaves camera on floor. Leaves camera unattached. Leaves camera. Leaves camera.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa! I didn't know you were a robot!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3858, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6239, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing pretty well, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6504, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7693, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7153, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7745, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: So am I'm glad to hear it!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7825, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9015, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! I'm glad to be here!\n",
      "DialoGPT: I'm here too glad to be here too!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8919, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9229, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad to be here\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0041, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0532, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.8021,  1.5652,  1.2224,  0.8584,  0.4418, -0.0121],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2525, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3550, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3725, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4211, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4538, device='cuda:0', grad_fn=<NegBackward>), tensor(-0.0121, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(1.8021, grad_fn=<UnbindBackward>)\n",
      "Episode 192: -0.353642989702793\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication to cinema. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later. Leaves camera on desk with popcorn ready for viewing pleasure. Leaves camera on tripod Ready for movie theater experience. Leaves camera on stand overlooking audience. Leaves camera on floor. Leaves camera unattached. Leaves camera. Leaves camera.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa! I didn't know you were a robot!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5658, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4888, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7214, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6980, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8634, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8633, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well, well lately, how about you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8073, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8690, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not too bad, I'm doing well too\n",
      "DialoGPT: I'm doing fine, how about you\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9206, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8290, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about you!\n",
      "DialoGPT: That's good, huh?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7773, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7805, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2358, 1.9920, 1.6536, 1.2342, 0.8232, 0.3896, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2637, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3549, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4318, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4192, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4375, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3896, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2358, grad_fn=<UnbindBackward>)\n",
      "Episode 193: -0.3531795089545938\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication to cinema. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later. Leaves camera on desk with popcorn ready for viewing pleasure. Leaves camera on tripod Ready for movie theater experience. Leaves camera on stand overlooking audience. Leaves camera on floor laughing hysterically.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2847, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4914, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6287, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8119, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8795, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9461, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you,\n",
      "DialoGPT: I'm doing fine, how are you are doing?\n",
      "r1: tensor(-0.0009, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9144, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9535, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you?\n",
      "DialoGPT: I am good, how are we doing well?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9154, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8626, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, I'm doing well, I'm doing good\n",
      "DialoGPT: That's aight. That\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6760, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6379, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.8347e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1912, 2.0172, 1.6737, 1.2294, 0.7699, 0.3286, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1942, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3603, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4565, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4672, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4446, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1912, grad_fn=<UnbindBackward>)\n",
      "Episode 194: -0.35236438703842654\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication to cinema. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later. Leaves camera on desk with popcorn ready for viewing pleasure. Leaves camera on tripod Ready for movie theater experience. Leaves camera on stand overlooking audience. Leaves camera on floor laughing hysterically.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: You're tearing me apart Lisa!\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3422, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5089, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6355, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7125, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6941, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7519, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: I'm happy to hear that's good to hear.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8738, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9124, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy you're happy to hear that! I'm happy to hear you're happy to know that's good to hearing.\n",
      "DialoGPT: I'm glad you're happy to hearing that I'm glad to hear you're happiness hear that\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7561, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9118, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7352, 1.5377, 1.2126, 0.8596, 0.4171, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2129, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3371, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4467, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4171, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7352, grad_fn=<UnbindBackward>)\n",
      "Episode 195: -0.3516528485532926\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3668, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2331, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6578, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7598, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, thanks.\n",
      "DialoGPT: That's good to hear. How are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8835, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7228, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks.\n",
      "DialoGPT: Good to hear. How's life treating you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8803, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8152, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good, thanks. I'm doing well, too.\n",
      "DialoGPT: That's great. How's life is treating you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8255, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been pretty good.\n",
      "DialoGPT: That's nice.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8080, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7601, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0966, 1.9662, 1.6280, 1.2387, 0.8230, 0.3921, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1501, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3545, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4017, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4240, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4348, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3921, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0966, grad_fn=<UnbindBackward>)\n",
      "Episode 196: -0.35062964464807267\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6822, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4799, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6647, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7863, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well.\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7078, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7483, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm glad.\n",
      "DialoGPT: So am I.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7627, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.3805e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So am i.\n",
      "DialoGPT: So amirite?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7745, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7560, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not sure.\n",
      "DialoGPT: SoAmAmirite?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8456, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5071, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: SoAmirite? I'm not sure. I'm not sure\n",
      "DialoGPT: Amirite? Amirite Amirite? Amireite? Amirites? Am\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7657, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7855, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4195, 2.1504, 1.8056, 1.4560, 1.0979, 0.7223, 0.3880, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2906, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3629, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3641, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3691, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3828, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3382, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3880, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4195, grad_fn=<UnbindBackward>)\n",
      "Episode 197: -0.3503265708985955\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1954, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5442, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6993, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6486, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how is your day going?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8257, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8537, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, how about yours?\n",
      "DialoGPT: It's good, how's your day going? How's your day is going?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8803, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8664, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is going well, how is yours?\n",
      "DialoGPT: It is, how's well?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8547, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8618, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's okay, I'm going to sleep now.\n",
      "DialoGPT: That's good, how is?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8038, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6271, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1067, 1.9411, 1.6202, 1.2124, 0.7834, 0.3578, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1850, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3371, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4199, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4368, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4292, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3578, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1067, grad_fn=<UnbindBackward>)\n",
      "Episode 198: -0.34949590715032125\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5264, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3280, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5421, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6818, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6892, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7629, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: That's great to hear that!!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9301, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8771, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! I'm glad to hear you're doing well!\n",
      "DialoGPT: I'm doing great to hear that you're doing well too!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8237, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9109, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad to hear that you are doing well!\n",
      "DialoGPT: That's so are\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6177, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6784, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0360, 1.8407, 1.5502, 1.1991, 0.7547, 0.3242, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2137, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3060, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3632, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4519, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4338, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3242, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0360, grad_fn=<UnbindBackward>)\n",
      "Episode 199: -0.3488169313967228\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2727, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0779, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6867, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8021, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are YOU?\n",
      "DialoGPT: doing well thanks for asking me that question\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7813, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7578, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how are you doing?\n",
      "DialoGPT: doing well\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4901, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5413, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing great, how are you\n",
      "DialoGPT: doing well thanks how are you doing today?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7089, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9003, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are YOU doing?\n",
      "DialoGPT: I'm fine, how are you're doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8617, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9079, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8913, 1.8217, 1.4641, 1.0901, 0.8405, 0.4425, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0878, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3723, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3849, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2579, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4025, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4425, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8913, grad_fn=<UnbindBackward>)\n",
      "Episode 200: -0.34751822588159076\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2431, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6142, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6708, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7455, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good to hear. How's life treating you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8501, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7831, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good, I'm enjoying it.\n",
      "DialoGPT: That's good. Well, enjoy yourself.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8698, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8258, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.4877e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I will!\n",
      "DialoGPT: Enjoy yourself too!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8559, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8122, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I will! Thanks!\n",
      "DialoGPT: Enjoy yourself! Enjoy yourself!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8803, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8422, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I will\n",
      "DialoGPT: Enjoy Yourself! Enjoy Yourself Enjoy yourself! Enjoy yourself Enjoy yourself! Enjoy Yourself\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7726, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0134, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3657, 2.1730, 1.8372, 1.4433, 1.0296, 0.6187, 0.1899, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2144, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3542, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4084, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4240, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4171, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4307, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1899, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3657, grad_fn=<UnbindBackward>)\n",
      "Episode 201: -0.346859209313251\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive! How many movies did you watch total?\n",
      "User: I have the DVD.\n",
      "DialoGPT: Nice man, that's dedication right there. Keep up the good work!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Let me know when you're ready and I'll be there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Sounds like a plan. See ya later tonight.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Seeya later, buddy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6217, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4146, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6405, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7552, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6642, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7626, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9294, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6828, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is.\n",
      "DialoGPT: It is. It is. It is great.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8152, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6846, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is! It is.\n",
      "DialoGPT: It's is great!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8835, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8595, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's great!\n",
      "DialoGPT: That's mom's greatest mom's mom's mom's mum's mom's mom is great.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8300, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7729, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm so glad you\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4977, 2.2611, 1.9314, 1.5905, 1.1994, 0.8327, 0.4008, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2592, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3490, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3568, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4032, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3750, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4358, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4008, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4977, grad_fn=<UnbindBackward>)\n",
      "Episode 202: -0.3464273939578991\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his house first. Then we'll talk about DVDs. Then we'll discuss DVD prices. Then we'll move onto DVD pricing. Then we'll wrap up this discussion.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll discuss DVD pricing and then we'll move onto DVDs pricing. Then we will discuss DVD pricing AND THEN WE'LL END THIS discussion conversation. THEN WE'LL STOP IT ALL OF THIS conversation!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you should watch it again with subtitles. It's worth it.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4607, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4958, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7207, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8065, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good, how are ya?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8439, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8681, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: Good, thanks for the last time I'm doing well. How's your day going?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well, thanks for asking\n",
      "DialoGPT: That's good, how's your day going lately?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8818, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6883, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's been pretty good, thanks for asking!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8133, 1.5900, 1.2203, 0.8002, 0.3926, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2392, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3819, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4281, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4115, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3926, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8133, grad_fn=<UnbindBackward>)\n",
      "Episode 203: -0.34590182475307407\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his house first. Then we'll talk about DVDs. Then we'll discuss DVD prices. Then we'll move onto DVD pricing. Then we'll wrap up this discussion.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll discuss DVD pricing and then we'll move onto DVDs pricing. Then we will discuss DVD pricing AND THEN WE'LL END THIS discussion conversation. THEN WE'LL STOP IT ALL OF THIS conversation!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you should watch it again with subtitles. It's worth it.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2800, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2938, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7300, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well too!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6600, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7381, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is!\n",
      "DialoGPT: It's great!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3123, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8830, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: It's good to hear that! I'me's good to hear.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7173, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8859, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're glad to hear that.\n",
      "DialoGPT: I'm happy to hear that's good to hear hear that's good.\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8923, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8976, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good to hear that.\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9466, 1.8213, 1.4730, 1.1345, 0.8441, 0.4476, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1435, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3630, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3498, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2989, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4009, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4476, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9466, grad_fn=<UnbindBackward>)\n",
      "Episode 204: -0.34491461842525295\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his house first. Then we'll talk about DVDs. Then we'll discuss DVD prices. Then we'll move onto DVD pricing. Then we'll wrap up this discussion.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll discuss DVD pricing and then we'll move onto DVDs pricing. Then we will discuss DVD pricing AND THEN WE'LL END THIS discussion conversation. THEN WE'LL STOP IT ALL OF THIS conversation!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you should watch it again with subtitles. It's worth it.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5039, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3823, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6423, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7646, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, good, how are your plans for the weekend?????\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8497, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to go to the beach, I'm going to go swimming, I'm going swimming, I'm swimming, I'm drowning, I'm drowning\n",
      "DialoGPT: Sounds like swimming swims swimming swimming swimming swimming swimming swim swimming swimming swimming swimming drowning drowning swimming swimming swimming swimming drown drowning drowning\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7665, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7888, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.3649, 1.1548, 0.8111, 0.3890, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2216, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3519, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4260, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3890, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.3649, grad_fn=<UnbindBackward>)\n",
      "Episode 205: -0.3443159995582497\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: No, let's go to his house first. Then we'll talk about DVDs. Then we'll discuss DVD prices. Then we'll move onto DVD pricing. Then we'll wrap up this discussion.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll discuss DVD pricing and then we'll move onto DVDs pricing. Then we will discuss DVD pricing AND THEN WE'LL END THIS discussion conversation. THEN WE'LL STOP IT ALL OF THIS conversation!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then you should watch it again with subtitles. It's worth it.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3734, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3286, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6496, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8010, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how is your wife?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8273, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8750, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, she's doing well\n",
      "DialoGPT: Good, she is doing well.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8077, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9426, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, she has a new baby\n",
      "DialoGPT: She's doing well. She's doing well doing well. She is doing well. She has herself well. She's herself is doing well. Herself is doing herself well. She herself is doing herself well herself\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7640, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6955, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7272, 1.5673, 1.2167, 0.7990, 0.3650, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1756, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3627, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4377, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3650, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7272, grad_fn=<UnbindBackward>)\n",
      "Episode 206: -0.34350086705408234\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs aren't cheap either, especially when you consider inflation rates of DVD's worldwide.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: DVD is cheaper than Blu ray. Blu Ray costs more money than DVD. Blu ray costs less money than DVD. Therefore Blu ray wins every time. Period. Period. Period period period period period period Period period period period Period Period period period periodperiod period period period period periods period period period period pause pause pause pause pause pauses pause pause pause pauses pauses pauses pauses pauses pause pauses pauses pauses pause pause pauses pauses pause pauses pause pauses pauses pause pause pause pause rest pauses pauses pauses pauses etc. pauses pauses pauses pauses... pauses pauses pauses pauses. pauses pauses pauses.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: The ending is what makes it worth watching. The beginning gets boring after a while though, especially if you're expecting something exciting to happen during the credits.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3377, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5693, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks for asking. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6386, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7827, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, too.\n",
      "DialoGPT: Well, I'm doing welldoing myself.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7860, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8241, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: That's great. She smiles broadly.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7755, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7183, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: He smiles back.\n",
      "DialoGPT: She smiles back.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8569, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9099, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So, what's your name?\n",
      "DialoGPT: I'm gonna call you names. He smiles back.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7997, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7565, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm gonna go to the beach.\n",
      "DialoGPT: She nods and walks away\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7503, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6875, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.4688, 2.2646, 1.9284, 1.5412, 1.1794, 0.7451, 0.3595, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2269, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4026, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3735, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4418, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3891, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3595, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.4688, grad_fn=<UnbindBackward>)\n",
      "Episode 207: -0.34294011157292587\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs aren't cheap either, especially when you consider inflation rates of DVD's worldwide. DVDs are still cheaper than Blu rays nowadays.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: DVD's are cheaper than Blu Rays nowadays too. Blu ray is cheaper than DVD's though. Blu Ray is cheaper than DVD Blu Rays. Blu ray is cheapest than DVD Blu Rays Blu Rays Blu Rays blu rays Blu Rays Blu Rays DVD Blu Rays Blu rays Blu Rays Blu rays DVD Blu Rays Blurays Blu Rays Blu Rays DVDs Blu Rays CDs\n",
      "User: I always cry at the end.\n",
      "DialoGPT: The ending scene was amazing though, especially when they showed the aftermath of the explosion. It was a great scene to watch while crying tears of joy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4234, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5003, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing alright, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6153, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7747, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, how about you?\n",
      "DialoGPT: doing well, how about yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8436, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8722, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: Good good, how bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8540, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8125, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about me?\n",
      "DialoGPT: I'm fine?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6415, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6816, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good, I'm good\n",
      "DialoGPT: I'm good good good, good, how bout me?????\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7673, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7866, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not good, I'm\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0874, 1.8752, 1.5429, 1.1252, 0.7156, 0.3886, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2310, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3477, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4290, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4167, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3309, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3886, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0874, grad_fn=<UnbindBackward>)\n",
      "Episode 208: -0.3424044048957277\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs aren't cheap either, especially when you consider inflation rates of DVD's worldwide. DVDs are still cheaper than Blu rays nowadays.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: DVD's are cheaper than Blu Rays nowadays too. Blu ray is cheaper than DVD's though. Blu Ray is cheaper than DVD Blu Rays. Blu ray is cheapest than DVD Blu Rays Blu Rays Blu Rays blu rays Blu Rays Blu Rays DVD Blu Rays Blu rays Blu Rays Blu rays DVD Blu Rays Blurays Blu Rays Blu Rays DVDs Blu Rays CDs\n",
      "User: I always cry at the end.\n",
      "DialoGPT: The ending scene was amazing though, especially when they showed the aftermath of the explosion. It was a great scene to watch while crying tears of joy.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4637, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm fine, how about you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6433, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7468, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: I'm doing well too, how about you're doing well?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8881, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9360, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, how about you are?\n",
      "DialoGPT: That's good, how about me?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7861, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8339, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about we do it?\n",
      "DialoGPT: We're doing it's good?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8104, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7976, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to do it's good\n",
      "DialoGPT: We're doing good, how's good?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7139, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7075, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0939, 1.9278, 1.5962, 1.1516, 0.7540, 0.3555, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1853, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3476, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4561, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4051, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4021, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0939, grad_fn=<UnbindBackward>)\n",
      "Episode 209: -0.3416564348907698\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive considering the movie was released in 1996 and came out 12 years ago.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs aren't cheap either, especially when you consider inflation rates of DVD's worldwide. DVDs are still cheaper than Blu rays nowadays.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: DVD's cost more than Blu Rays nowadays. Blu ray is cheaper than DVD. Blu Ray costs less than DVD. Blu ray costs more than DVD Blu ray Blu ray Blu ray DVD Blu ray Blu Ray Blu ray Blu ray blu ray Blu ray Blu Ray DVD Blu ray Bluray Blu ray Blu ray DVDs Blu ray Blu ray CDs CDs CDs CDs CDs\n",
      "User: I always cry at the end.\n",
      "DialoGPT: The tears are delicious though.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3150, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0167, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6993, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8053, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good, thanks for asking me that question. How are you today?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9270, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8465, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8770, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8506, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks for asking\n",
      "DialoGPT: That's good, thanks for you're doing well doing well. How are you doing??\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8890, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8131, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, thanks for the\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7099, 1.6517, 1.2883, 0.8534, 0.4256, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0747, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3763, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4434, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4256, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7099, grad_fn=<UnbindBackward>)\n",
      "Episode 210: -0.3403911857172776\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too. Then again, it was a movie theater. So maybe that helps?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1223, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2098, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how about to go to sleep soon though. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6360, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7197, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sleep is overrated.\n",
      "DialoGPT: Sleep is over rated. Sleep is overrated. Sleep is over rated. Overrated. Sleep is underrated. Sleep is overated. Sleep is overrateated Sleep isoverrated. Sleep is Overrated. Overrated Sleeprated Sleep Overrated Sleep Overrated Overrated Sleepoverrated Sleeprated Sleeprated Sleepoverrated\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8535, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8404, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.8339, 0.7583, 0.4235, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0831, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3390, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4235, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.8339, grad_fn=<UnbindBackward>)\n",
      "Episode 211: -0.33917773718822675\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too. Then again, it was a movie theater. So maybe that helps?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4946, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6808, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5008, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8096, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8629, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7903, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: Fine, I'm good, how about me?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8717, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8666, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you.\n",
      "DialoGPT: Fine, ok ok ok ok ok okay ok ok ok ok Ok ok Ok Ok Ok Ok Ok OK Ok Ok Ok Ok Okay Ok Ok Ok Ok ok Ok Ok OK Ok OK Ok Ok OK OK\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6938, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7131, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7833, 1.5044, 1.1886, 0.7830, 0.3518, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2939, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3277, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4134, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4347, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3518, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7833, grad_fn=<UnbindBackward>)\n",
      "Episode 212: -0.3389653352924356\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too. Then again, it was a movie theater. So maybe that helps?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1013, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2947, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6709, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7966, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0011, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8243, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8773, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: \n",
      "dummy\n",
      "True 1\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0581, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.1503, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.8291,  0.7374,  0.3742, -0.0520], grad_fn=<CopySlices>)\n",
      "[tensor(0.0991, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3670, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>), tensor(-0.0520, device='cuda:0', grad_fn=<NegBackward>)]\n",
      "----- Loss: tensor(0.8291, grad_fn=<UnbindBackward>)\n",
      "Episode 213: -0.33784435355217657\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too. Then again, it was a movie theater. So maybe that helps?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5954, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4991, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well today, how are you?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6004, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7760, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: doing well, how are ya?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9232, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9065, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: doing well?\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6943, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5297, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you today?\n",
      "DialoGPT: doing well? How are you doing??\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7161, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8746, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well, I'm doing fine, I'm doing good, I'm doing great\n",
      "DialoGPT: doing well, doing well\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6668, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7353, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0757, 1.8201, 1.4907, 1.0437, 0.7449, 0.3506, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2737, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3443, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4575, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3062, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3978, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3506, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0757, grad_fn=<UnbindBackward>)\n",
      "Episode 214: -0.33754605124163073\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too. Then again, it was a movie theater. So maybe that helps?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4374, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3191, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5602, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8090, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8863, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8315, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: That's good, well how about you? How's your day been?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8694, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8478, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's been good, how about yours?\n",
      "DialoGPT: It's good, how about yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8821, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8967, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good, how about your day?\n",
      "DialoGPT: Yeah, how bout yours?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8737, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7745, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how about yours\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1852, 2.0161, 1.6907, 1.2736, 0.8527, 0.4121, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1893, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3424, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4298, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4294, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4448, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4121, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1852, grad_fn=<UnbindBackward>)\n",
      "Episode 215: -0.3368595072792636\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that scene with the dolls.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2878, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2990, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6696, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6902, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: Good, how did you?\n",
      "r1: tensor(-0.0020, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7657, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7368, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I was good, I'm good\n",
      "DialoGPT: Good, how were you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8665, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7196, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been good, I'm pretty good\n",
      "DialoGPT: I'm good thanks, I'm good, how were you're you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8158, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8640, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I had a good day, I'm good.\n",
      "DialoGPT: Nice, nice to hear that, thanks\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7392, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7624, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Thanks,\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5287, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4596, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2301, 2.1044, 1.7821, 1.4202, 1.0340, 0.6201, 0.2471, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1468, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3400, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3761, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3966, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4200, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3755, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2471, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2301, grad_fn=<UnbindBackward>)\n",
      "Episode 216: -0.3359837232646854\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2556, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0932, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5784, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7676, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how's life?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8478, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8109, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, how about you?\n",
      "DialoGPT: Pretty pretty pretty pretty pretty pretty good\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7339, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7457, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good, I'm glad to hear that.\n",
      "DialoGPT: Yeah, thanks for the compliment.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6625, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7691, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: No problem, I'm glad you're happy\n",
      "DialoGPT: Yeah thanks for sure.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8625, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7062, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear it\n",
      "DialoGPT: Thanks for the compliment. And thanks for\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7268, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6469, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.2264, 2.1607, 1.8425, 1.4422, 1.0830, 0.7323, 0.3435, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0873, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3366, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4148, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3700, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3580, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3922, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3435, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.2264, grad_fn=<UnbindBackward>)\n",
      "Episode 217: -0.33484302508995073\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1956, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4610, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6898, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7661, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8704, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8166, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking\n",
      "DialoGPT: That's good. How are you doing? How are you doing well?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8999, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7731, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks for asking!\n",
      "DialoGPT: That's good, good, good, thanks for asking, how are you doin '?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9337, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7718, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm great, thanks for asking\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7537, 1.6055, 1.2540, 0.8406, 0.4265, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1642, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3640, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4218, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4184, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4265, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7537, grad_fn=<UnbindBackward>)\n",
      "Episode 218: -0.334063954141042\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2609, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5835, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0010, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6250, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7725, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, well, I'm good, how bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8319, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7984, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you?\n",
      "DialoGPT: I've been good, how bout ya?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8743, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8675, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: I'm good?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7327, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7581, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm good\n",
      "DialoGPT: Yeah, I'm good. How bout you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6983, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8164, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good!\n",
      "DialoGPT: Oh yeah,\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4913, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5705, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3477, 2.1581, 1.8268, 1.4335, 1.0080, 0.6417, 0.2655, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2112, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3496, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4076, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4355, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3728, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3788, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2655, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3477, grad_fn=<UnbindBackward>)\n",
      "Episode 219: -0.3335054363039407\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3955, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1297, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7024, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6867, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8780, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8361, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking\n",
      "DialoGPT: That's good. How are you doing? How are you doing yourself?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9065, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7853, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks for asking!\n",
      "DialoGPT: That's good, how are doing yourself?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9079, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7847, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm doing well, I'm doing fine, thanks for the question\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7126, 1.5971, 1.2624, 0.8421, 0.4232, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1314, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3474, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4287, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4231, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4232, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7126, grad_fn=<UnbindBackward>)\n",
      "Episode 220: -0.33259111588896667\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2756, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4994, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6806, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7046, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: How about you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6874, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7444, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: That's good. How about you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7899, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6888, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.1376e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad\n",
      "DialoGPT: That's bad.\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7376, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4462, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's true.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8273, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7960, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's true\n",
      "DialoGPT: That's true true true true true truth true true true true false false false false false true false false false true true false false true false true false false true true true\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5887, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5311, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1809, 2.0072, 1.6776, 1.3328, 0.9728, 0.6831, 0.2800, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1938, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3464, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3581, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3697, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2965, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4059, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2800, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1809, grad_fn=<UnbindBackward>)\n",
      "Episode 221: -0.3319661502499838\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1887, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1235, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6436, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7564, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Pretty good, how are your days?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8261, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8351, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, I'm working on a project right now\n",
      "DialoGPT: That project is underway right now, finishing up soonish soonishishishishishsoonishsoonishsoonishedsoonishsoonishishsoonishforthishsoonishsoonightishsoonishsoonsoonishsoonishouldontontontontontoshouldont\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7508, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7841, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2043, 1.1375, 0.7953, 0.3838, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0781, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3501, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4154, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3838, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2043, grad_fn=<UnbindBackward>)\n",
      "Episode 222: -0.3308278592846319\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me just grab my wallet from the bank room.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime later this week or next week. Sounds like a plan!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's okay, I cried when I saw that scene in episode 1 of season 2. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4566, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5589, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6163, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7243, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well too!\n",
      "DialoGPT: I'm doing pretty well myself. How are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9436, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7698, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you?\n",
      "DialoGPT: I am doing well myself myself. How bout you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8724, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been doing well myself.\n",
      "DialoGPT: Well done yourselfselfselfselfselvesselvesselvesselvesselvesselfselvesselvesselvesselfselfselvesselvesselfselvesselfselvesselvesselfselfselfselvesselfselvesself\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7845, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6048, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7747, 1.5360, 1.2129, 0.7924, 0.3474, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.2540, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3352, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4284, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4485, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3474, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7747, grad_fn=<UnbindBackward>)\n",
      "Episode 223: -0.33048471628821324\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go shopping together sometime soon.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: It's okay, I cried too when I saw that scene with the dolls. It was heartbreaking.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4069, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1493, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6080, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7753, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, how are you today?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8944, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8135, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: Not bad, good?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7161, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7001, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good\n",
      "DialoGPT: That's good, yeah, yeah.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8468, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8659, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good.\n",
      "DialoGPT: That's better than usual.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8778, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8682, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(9.1867e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great\n",
      "DialoGPT: That's good to hear ya?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8096, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8039, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That's good is good.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8675, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8979, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.8617, 2.7501, 2.4284, 2.0216, 1.6843, 1.2687, 0.8405, 0.4415, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1391, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3459, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4271, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3541, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4283, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4366, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4034, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.8617, grad_fn=<UnbindBackward>)\n",
      "Episode 224: -0.32963418808248307\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Then cry again. Repeat till tears are shed. Etcetera etceteraetceteraetceteraaaahhhhhhh... Etceteraetceteraaaaahhhh... Etceter\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3753, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1206, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing alright, how about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6173, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7004, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you\n",
      "DialoGPT: That's good to hear, how about you yourself?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8216, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7827, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you, what's your favorite color?\n",
      "DialoGPT: Blue, blue blue blue blue blue Blue Blue Blue Blue Blue blue blue blue blue blu blue blue blue blue Blu Blue Blue Blue Blue Blu Blue Blu Blu Blue Blu Blu Blu Blu Blu Blue Blu Blue Blu Blue Blue Blu\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7734, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7736, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2188, 1.1058, 0.7842, 0.3868, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1241, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3295, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4012, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3868, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2188, grad_fn=<UnbindBackward>)\n",
      "Episode 225: -0.3287245738690933\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat until tears weep. Rinse repeat til tears weep. RinnevemberruaryruaryruaryruaryruaryuaryruaryruaryruaryruarycemberruaryruaryruaryruaryemberMARKETSETSETSETSETSetsetsetsetsetsucksetsucksetsucksucksetsucksetsaughsetsucksetsucksbacksucksetsucksetsunsucksetsucksetsbacksucksetsucksucksucksucksucksetsucksucksbacksucksbacksucksbackswordsetsucksbacksucksbacksetsucksbacksucksucksbacksucksucksucksbacksucksetsbacksucksbacksucksucksetsucksbacksbacksucksbacksucksbackbacksucksbacksucksbirdsbacksucksbacksucksbonsbonsbonsbonsbonsbsbonsbonsbonsbonsonsbonsbonsbonsbonsbonbonsbonsbonsbonsbbonsbonsbonsbonsbowbonsbonsbonsbonsinalsbonsbonsbonsbonsquakesbonsbonsbonsbonsbowsbonsbonsbonsbonsbacksbonsbonsbonsbonsbachbonsbonsbonsbonsbirdsbonsbonsbonsbonsreesbonsbonsbonsbonsricsbonsbonsbonsbonsfiresbonsbonsbonsbonshirebonsbonsbonsbonsbbbonsbonsbonsbonsburybonsbonsbonsbonslesbonsbonsbonsbonscesbonsbonsbonsbonsbrbonsbonsbonsbonsplbonsbonsbonsbonsbybonsbonsbonsbonsfaxbonsbonsbonsbonsBbonsbonsbonsbonsontbonsbonsbonsbonsboroughbonsbonsbonsbonstsbonsbonsbonsbonsbpbonsbonsbonsbonstribonsbonsbonsbonstonsbonsbonsbonsbonsbdbonsbonsbonsbonszzbonsbonsbonsbons bbonsbonsbonsbonsbisbonsbonsbonsbonsphybonsbonsbonsbonsbumbonsbonsbonsbonsbolbonsbonsbonsbonsbirdbonsbonsbonsbonsBBbonsbonsbonsbons\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3378, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0987, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for the last few days. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6902, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7792, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks!\n",
      "DialoGPT: That's good to hear! How's your cabin looks nice too.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8364, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6655, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's nice, I'm glad I got a place to stay.\n",
      "DialoGPT: Yeah, it's nice too. And yeah, it's nice to see you're safe safe safe safe safe?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8571, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8895, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, I'm safe.\n",
      "DialoGPT: Yeah, yeah yeah, yeah\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6859, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5652, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5654, 1.4709, 1.1146, 0.7465, 0.3128, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1092, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3675, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3756, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4367, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3128, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5654, grad_fn=<UnbindBackward>)\n",
      "Episode 226: -0.32775747158979\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat until tears weep. Rinse repeat til tears weep. RinnevemberruaryruaryruaryruaryruaryuaryruaryruaryruaryruarycemberruaryruaryruaryruaryemberMARKETSETSETSETSETSetsetsetsetsetsucksetsucksetsucksucksetsucksetsaughsetsucksetsucksbacksucksetsucksetsunsucksetsucksetsbacksucksetsucksucksucksucksucksetsucksucksbacksucksbacksucksbackswordsetsucksbacksucksbacksetsucksbacksucksucksbacksucksucksucksbacksucksetsbacksucksbacksucksucksetsucksbacksbacksucksbacksucksbackbacksucksbacksucksbirdsbacksucksbacksucksbonsbonsbonsbonsbonsbsbonsbonsbonsbonsonsbonsbonsbonsbonsbonbonsbonsbonsbonsbbonsbonsbonsbonsbowbonsbonsbonsbonsinalsbonsbonsbonsbonsquakesbonsbonsbonsbonsbowsbonsbonsbonsbonsbacksbonsbonsbonsbonsbachbonsbonsbonsbonsbirdsbonsbonsbonsbonsreesbonsbonsbonsbonsricsbonsbonsbonsbonsfiresbonsbonsbonsbonshirebonsbonsbonsbonsbbbonsbonsbonsbonsburybonsbonsbonsbonslesbonsbonsbonsbonscesbonsbonsbonsbonsbrbonsbonsbonsbonsplbonsbonsbonsbonsbybonsbonsbonsbonsfaxbonsbonsbonsbonsBbonsbonsbonsbonsboroughbonsbonsbonsbonsontbonsbonsbonsbonstsbonsbonsbonsbonsbpbonsbonsbonsbonstribonsbonsbonsbonstonsbonsbonsbonsbonsbdbonsbonsbonsbonszzbonsbonsbonsbons bbonsbonsbonsbonsbisbonsbonsbonsbonsphybonsbonsbonsbonsbumbonsbonsbonsbonsbolbonsbonsbonsbonsbirdbonsbonsbonsbonsBBbonsbonsbonsbons\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3414, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks for asking. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6334, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7404, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, too.\n",
      "DialoGPT: That's good to hear. How's life treating you well?\n",
      "r1: tensor(-0.0023, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8491, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7776, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's alright.\n",
      "DialoGPT: That's great to hear. How are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8822, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6975, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: Yeah, that's good to be good to good to be able to be to be able to good to be good be good to be able be good be good\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8031, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4922, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5529, 1.4481, 1.1157, 0.7156, 0.3239, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1192, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3435, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4073, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3950, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3239, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5529, grad_fn=<UnbindBackward>)\n",
      "Episode 227: -0.3268428962481649\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat until tears weep. Rinse repeat til tears weep. RinnevemberruaryruaryruaryruaryruaryuaryruaryruaryruaryruarycemberruaryruaryruaryruaryemberMARKETSETSETSETSETSetsetsetsetsetsucksetsucksetsucksucksetsucksetsaughsetsucksetsucksbacksucksetsucksetsunsucksetsucksetsbacksucksetsucksucksucksucksucksetsucksucksbacksucksbacksucksbackswordsetsucksbacksucksbacksetsucksbacksucksucksbacksucksucksucksbacksucksetsbacksucksbacksucksucksetsucksbacksbacksucksbacksucksbackbacksucksbacksucksbirdsbacksucksbacksucksbonsbonsbonsbonsbonsbsbonsbonsbonsbonsonsbonsbonsbonsbonsbonbonsbonsbonsbonsbbonsbonsbonsbonsbowbonsbonsbonsbonsinalsbonsbonsbonsbonsquakesbonsbonsbonsbonsbowsbonsbonsbonsbonsbacksbonsbonsbonsbonsbachbonsbonsbonsbonsbirdsbonsbonsbonsbonsreesbonsbonsbonsbonsricsbonsbonsbonsbonsfiresbonsbonsbonsbonshirebonsbonsbonsbonsbbbonsbonsbonsbonsburybonsbonsbonsbonslesbonsbonsbonsbonscesbonsbonsbonsbonsbrbonsbonsbonsbonsplbonsbonsbonsbonsbybonsbonsbonsbonsfaxbonsbonsbonsbonsboroughbonsbonsbonsbonsBbonsbonsbonsbonsontbonsbonsbonsbonstsbonsbonsbonsbonsbpbonsbonsbonsbonstribonsbonsbonsbonstonsbonsbonsbonsbonsbdbonsbonsbonsbonszzbonsbonsbonsbons bbonsbonsbonsbonsbisbonsbonsbonsbonsphybonsbonsbonsbonsbumbonsbonsbonsbonsbolbonsbonsbonsbonsbirdbonsbonsbonsbonsBBbonsbonsbonsbons\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2484, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2100, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7181, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7917, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Yeah, thanks for asking me too. How are you doing?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9267, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8455, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking!\n",
      "DialoGPT: That's good to say the least thing ever said to me in my life.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8450, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8247, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well!\n",
      "DialoGPT: Yeah, thanks to you for asking me that question.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8665, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7843, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, thanks for\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7243, 1.6259, 1.2610, 0.8262, 0.4128, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1147, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3775, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4431, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4175, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4128, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7243, grad_fn=<UnbindBackward>)\n",
      "Episode 228: -0.3259163258117359\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat until tears weep. Rinse repeat til tears weep. RinnevemberruaryruaryruaryruaryruaryuaryruaryruaryruaryruarycemberruaryruaryruaryruaryemberMARKETSETSETSETSETSetsetsetsetsetsucksetsucksetsucksucksetsucksetsaughsetsucksetsucksbacksucksetsucksetsunsucksetsucksetsbacksucksetsucksucksucksucksucksetsucksucksbacksucksbacksucksbackswordsetsucksbacksucksbacksetsucksbacksucksucksbacksucksucksucksbacksucksetsbacksucksbacksucksucksetsucksbacksbacksucksbacksucksbackbacksucksbacksucksbirdsbacksucksbacksucksbonsbonsbonsbonsbonsbsbonsbonsbonsbonsonsbonsbonsbonsbonsbonbonsbonsbonsbonsbbonsbonsbonsbonsbowbonsbonsbonsbonsinalsbonsbonsbonsbonsquakesbonsbonsbonsbonsbowsbonsbonsbonsbonsbacksbonsbonsbonsbonsbachbonsbonsbonsbonsbirdsbonsbonsbonsbonsreesbonsbonsbonsbonsricsbonsbonsbonsbonsfiresbonsbonsbonsbonshirebonsbonsbonsbonsbbbonsbonsbonsbonsburybonsbonsbonsbonslesbonsbonsbonsbonscesbonsbonsbonsbonsfaxbonsbonsbonsbonsplbonsbonsbonsbonsbybonsbonsbonsbonsbrbonsbonsbonsbonsboroughbonsbonsbonsbonsBbonsbonsbonsbonsontbonsbonsbonsbonsbpbonsbonsbonsbonstribonsbonsbonsbonstsbonsbonsbonsbonstonsbonsbonsbonsbonsbdbonsbonsbonsbonszzbonsbonsbonsbons bbonsbonsbonsbonsbisbonsbonsbonsbonsphybonsbonsbonsbonsbumbonsbonsbonsbonsbolbonsbonsbonsbonsbirdbonsbonsbonsbonsselvesbonsbonsbonsbons\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2720, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3284, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing well, thanks for asking. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6560, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7655, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Doing well, too.\n",
      "DialoGPT: That's good to hear. How are you doing?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8702, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7491, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, thanks.\n",
      "DialoGPT: That's great to hear.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8226, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7393, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: That's wonderful to hear.\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9238, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8556, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.7947e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It is.\n",
      "DialoGPT: It is wonderful to hear. To hear. To hear that is wonderful. To hear that's wonderful to hear to\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8158, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5494, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0300, 1.8988, 1.5589, 1.1656, 0.7829, 0.3414, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1502, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4049, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3905, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4450, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3414, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0300, grad_fn=<UnbindBackward>)\n",
      "Episode 229: -0.32515231714300485\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat til tears are shed. Etcetera etceteraetceteraetceteraaaahhhhhhh... Etceteraetceteraaaaahhhh\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1303, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2193, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4657, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7593, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good enough to ask questions about yourself. Yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7004, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6843, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine\n",
      "DialoGPT: That's good.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7060, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6459, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(4.1565e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: That's good enough to ask questions questions about yourselfselvesselvesselvesselvesselvesselfselvesselvesselvesselves selvesselvesselvesselvesselves themselvesselvesselvesselvesselves selfselvesselvesselvesselves SelfselvesselvesselvesselvesSelfselvesselvesselvesselvesesselvesselvesselvesselves\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5479, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3998, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2859, 1.2106, 0.9134, 0.5728, 0.2371, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0875, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3064, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3463, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3381, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2371, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2859, grad_fn=<UnbindBackward>)\n",
      "Episode 230: -0.324123303869586\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat til tears are shed. Etcetera etceteraetceteraetceteraaaahhhhhhh... Etceteraetceteraaaaahhhh\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1876, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6571, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6677, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good, thanks. How are you doing?\n",
      "r1: tensor(-0.0014, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8936, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8520, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks.\n",
      "DialoGPT: That's good to hear. How are you going?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8845, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7315, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm going to be a little busy, but I'm going to be busy for a while.\n",
      "DialoGPT: Sounds good. Bye bye bye bye bye bye Bye bye bye bye Bye Bye bye bye\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6906, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6888, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6787, 1.4944, 1.1749, 0.7456, 0.3449, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1992, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3313, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4367, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4041, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3449, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6787, grad_fn=<UnbindBackward>)\n",
      "Episode 231: -0.32358488832311383\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is it worth watching?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when they're only available in Japan and Korea.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, let me grab my wallet first. Then I'll be right over there.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, sounds good. Let's get started on this DVD.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Then start crying again when you finish watching it. Then watch it again later. Then cry again afterwards while crying again. Repeat until tears are shed. Rinse repeat till tears are shed. Repeat til tears are shed. Etcetera etceteraetceteraetceteraaaahhhhhhh... Etceteraetceteraaaaahhhh\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hello there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.2348, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1851, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5747, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5960, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8610, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7861, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you\n",
      "DialoGPT: Fine, I'm good, how bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8628, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8892, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been good, how about me?\n",
      "DialoGPT: Fine, How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8364, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7614, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Fine, how bout you\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7990, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6701, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: Fine then how bout you? How bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8619, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4285, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good\n",
      "DialoGPT: Good,\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3934, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3930, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.3264, 2.3624, 2.0906, 1.6957, 1.2703, 0.8795, 0.5174, 0.1967, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.0123, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2927, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4119, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4381, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3996, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3673, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3227, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1967, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.3264, grad_fn=<UnbindBackward>)\n",
      "Episode 232: -0.3221431097471407\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIAT VATA VATAVI VIATA VATA VI VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VIX VATA VATAV VATA VATA VC VATA VATA VT VATA VATA EVI VATA VIX VI VATA VIXVI VATA VERO VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATS VATS VATS VATS VATS VATS VCAT VCAT VCAT VATS VCAT VATS VATSVCAT VCAT VCATS VCAT VCATSVCAT VCATSVCATSVCAT VCATA VCAT VCATVCAT VCATVCATSVCATVCAT VCATAVCAT VCATAVM VCAT VCATA VCATA VCATAVCATA VCATA VCATVCATA VCATAVCATVCATVCATVBVCATVCVCVCVCVCVBVCVCVCVCVGVCVCVCVCVSVCVCVCVCVDVCVCVCVC VCVCVCVCVCJVVCVCVCVCVVCVCVCVCvcVCVCVCVC VVCVCVCVC VSVCVCVCVC MVVCVCVCVC VGVCVCVCVC vVCVCVCVC DVVCVCVCVCVMVCVCVCVCVsVCVCVCVCVRVCVCVCVCVLVCVCVCVCVIVCVCVCVCIVVCVCVCVCvsVCVCVCVC UVVCVCVCVCvdVCVCVCVCVEVCVCVCVC VIVCVCVCVCVenIOVCVCVCVC VaVCVCVCVCVaVCVCVCVC LVVCVCVCVC MUVCVCVCVCPUVCVCVCVC VegVCVCVCVC EVVCVCVCVCEVVCVCVCVC vsVCVCVCVC VegaVCVCVCVC VolVCVCVCVC VenVCVCVCVC venVCVCVCVC VenusVenVCVenVCVenVenVenVenVenVVenVenVenVenVCVenVenVVenVVenVenVVenVCVenVenVCVenVVenVenVCVenVC VenVenVenVenVen VVenVenVenVenvcVenVenVenVen VenusVenVenVenVen VenVenVenVen VVCVenVenVen V VenVenVenVenV VenVenVenVen Ven VVenVenVen V venVenVenVenVen venVenVenVen VVVenVenVen V VenusVenVenVen V VVenVenVen Ven venVenVenVen Ven VenVenVenVen ven venVenVenVen ven VenVenVenVen Venus venVenVenVen Venus VenusVenVenVen ven VenusVenVenVen Ven VenusVenVenVen Venus VenVenVenVen veVenVenVenVen ve venVenVenVen ve VenVenVenVen vVenVenVenVen v VenVenVenVen VolVenVenVenVen Vol venVenVenVen v venVenVenVen Vol VenVenVenVenvenVenVenVenVenVENVenVenVenVenven venVenVenVenV venVenVenVenven VenVenVenVenVEN venVenVenVenVEN VenVenVenVen VaVenVenVenVen Va venVenVenVen Va VenVenVenVen VegVenVenVenVen Veg venVenVenVen Veg VenVenVenVen vsVenVenVenVen vs venVenVenVen vs VenVenVenVen 2VenVenVenVen 2 venVenVenVen 2 VenVenVenVen 3VenVenVenVen 1VenVenVenVen 3 venVenVenVen 3 VenVenVenVen 1 venVenVenVen 1 VenVenVenVen 4VenVenVenVen 4 venVenVenVen 4 VenVenVenVen\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: VenVenVenVenVen VenVenVenVenVen venVenVenVenVenvenVenVenVenVenVVenVenVenVenVeVenVenVenVenVENVenVenVenVenVRVenVenVenVenVLVenVenVenVenVDVenVenVenVenVGVenVenVenVenVEVenVenVenVen VIDVenVenVenVenJVVenVenVenVenIVVenVenVenVenIIVenIIVenII VenIIVenIIVen IIVenIIVenII venIIVenIIVenIIIVenIIVenII VVenIIVenIIVVenIIVenIIVIVenIIVenII VenusVenIIVenII VIVenVenVenVenIOVenioVenioVenio VeniosVenioVenio venioVenioVeniosVenioVenios VenioVenioVeniaVenioVenio VVenioVenio VenomVenioVenio VenusVenioVenio VenturaVenioVenio VolioVenioVeniumVenioVenio VerVenioVenio velloVenioVenio VelloVenioVenios venioVenio VenioVenio VeniaVenioVenios VenusVenioVenios VVenioVenios VenomVenioVenios VolVenioVenio volVenioVenio ProfitVenioVenio\n",
      "User: I always cry at the end.\n",
      "DialoGPT: VenioVenioVenio venioVenioVeniosVenioVenio VeniosVenioVenios VenioVenioVenuoVenuoVenuo venuoVenuoVenoVenuoVenuo VenuoVenuoVenioVenuo Venuo VenuoVenioVeniovenuoVenuoVenuoloVenuoVenuoV\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2420, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1118, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6185, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7647, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too, how are you doing today?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8282, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9201, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: Oh yeah, yeah, yeah, yea, yeah, yeah yeah yeah, yeah yeah, yeah yea yeah yeah yeah yeah yeahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhuhhhhhhhhhhhhhhhhhhshhhhhhhhhhhhhhhhhd\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7389, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7274, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2152, 1.1380, 0.8001, 0.3667, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0885, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3459, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4371, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3667, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2152, grad_fn=<UnbindBackward>)\n",
      "Episode 233: -0.3211448113792218\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIAT VATA VATAVI VIATA VATA VI VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VIX VATA VATA VC VATA VATAV VATA VATA VT VATA VATA EVI VATA VIX VI VATA VIXVI VATA VERO VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATS VATS VATS VATS VATS VATS VCAT VCAT VCAT VATS VCAT VATS VATSVCAT VCAT VCATS VCAT VCATSVCAT VCATSVCATSVCAT VCATA VCAT VCATVCAT VCATVCATSVCATVCAT VCATAVCAT VCATAVM VCAT VCATA VCATA VCATAVCATA VCATA VCATVCATA VCATAVCATVCATVCATVBVCATVCVCVCVCVCVBVCVCVCVCVGVCVCVCVCVSVCVCVCVCVDVCVCVCVC VCVCVCVCVCJVVCVCVCVCVVCVCVCVCvcVCVCVCVC VVCVCVCVC VSVCVCVCVC MVVCVCVCVC VGVCVCVCVC vVCVCVCVC DVVCVCVCVCVMVCVCVCVCVsVCVCVCVCVRVCVCVCVCVLVCVCVCVCVIVCVCVCVCIVVCVCVCVCvsVCVCVCVC UVVCVCVCVCvdVCVCVCVCVEVCVCVCVC VIVCVCVCVCVenIOVCVCVCVC VaVCVCVCVCVaVCVCVCVC LVVCVCVCVC MUVCVCVCVCPUVCVCVCVC VegVCVCVCVC EVVCVCVCVCEVVCVCVCVC vsVCVCVCVC VegaVCVCVCVC VolVCVCVCVC VenVCVCVCVC venVCVCVCVC VenusVenVCVenVCVenVenVenVenVenVVenVenVenVenVCVenVenVVenVVenVenVVenVCVenVenVCVenVVenVenVCVenVC VenVenVenVenVen VVenVenVenVenvcVenVenVenVen VenusVenVenVenVen VenVenVenVen VVCVenVenVen V VenVenVenVenV VenVenVenVen Ven VVenVenVen V venVenVenVenVen venVenVenVen VVVenVenVen V VenusVenVenVen V VVenVenVen Ven venVenVenVen Ven VenVenVenVen ven venVenVenVen ven VenVenVenVen Venus venVenVenVen Venus VenusVenVenVen ven VenusVenVenVen Ven VenusVenVenVen Venus VenVenVenVen veVenVenVenVen ve venVenVenVen ve VenVenVenVen vVenVenVenVen v VenVenVenVen VolVenVenVenVen Vol venVenVenVen v venVenVenVen Vol VenVenVenVenvenVenVenVenVenVENVenVenVenVenven venVenVenVenV venVenVenVenven VenVenVenVenVEN venVenVenVenVEN VenVenVenVen VaVenVenVenVen Va venVenVenVen Va VenVenVenVen VegVenVenVenVen Veg venVenVenVen Veg VenVenVenVen vsVenVenVenVen vs venVenVenVen vs VenVenVenVen 2VenVenVenVen 2 venVenVenVen 2 VenVenVenVen 3VenVenVenVen 1VenVenVenVen 3 venVenVenVen 3 VenVenVenVen 1 venVenVenVen 1 VenVenVenVen 4VenVenVenVen 4 venVenVenVen 4 VenVenVenVen\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: VenVenVenVenVen VenVenVenVenVen venVenVenVenVenvenVenVenVenVenVVenVenVenVenVeVenVenVenVenVENVenVenVenVenVRVenVenVenVenVLVenVenVenVenVDVenVenVenVenVGVenVenVenVenVEVenVenVenVen VIDVenVenVenVenJVVenVenVenVenIVVenVenVenVenIIVenIIVenII VenIIVenIIVen IIVenIIVenII venIIVenIIVenIIIVenIIVenII VVenIIVenIIVVenIIVenIIVIVenIIVenII VenusVenIIVenII VIVenVenVenVenIOVenioVenioVenio VeniosVenioVenio venioVenioVeniosVenioVenios VenioVenioVeniaVenioVenio VVenioVenio VenomVenioVenio VenusVenioVenio VenturaVenioVenio VolioVenioVeniumVenioVenio VerVenioVenio velloVenioVenio VelloVenioVenios venioVenio VenioVenio VeniaVenioVenios VenusVenioVenios VVenioVenios VenomVenioVenios VolVenioVenio volVenioVenio ProfitVenioVenio\n",
      "User: I always cry at the end.\n",
      "DialoGPT: VenioVenioVenio venioVenioVeniosVenioVenio VeniosVenioVenios VenioVenioVenuoVenuoVenuo venuoVenuoVenoVenuoVenuo VenuoVenuoVenioVenuo Venuo VenuoVenioVeniovenuoVenuoVenuoloVenuoVenuoV\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1964, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1214, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5920, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7680, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how bout you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8135, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7614, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you?\n",
      "DialoGPT: FineFineFineFineFine Fine Fine Fine Fine FineFineFineFineFinefineFineFineFineFine fine Fine Fine Fine Fine fine Fine Fine Fine fine fine Fine Fine FineFine Fine Fine Fine fineFine Fine Fine FineFinefineFineFine Fine Fine fine Fine fine Fine Fine fine FineFineFineFine\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6818, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6801, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1326, 1.0637, 0.7309, 0.3406, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0795, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3401, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3938, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3406, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1326, grad_fn=<UnbindBackward>)\n",
      "Episode 234: -0.3201166368069801\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIIXATA VATA VIX VATA VATAVI VI VATA VATAVATA VAT VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VERO VATA VATA VC VATA VATA VT VATA VATA E VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATA VATA VATA VAT VATA VATA VCVD VATA VCVD VCVD VCVD VATA VATAVCVD VCVD VCVG VCVD VCVDVCVD VCVDVCVG VCVDVCVDVCVG VCVG VCVDVCVGVCVG VCVD VCVGVG VCVG VCVG VCVB VCVG VC VCVGVGVGVGVGPGEPGMUDGEUFOBYOXZEGBSFXBDLCKRSBNXFFIXZYSFSKYJVMDYFWRYFEKSNSDFAPOYWFEWTWWRBSNTQSWAGSIDOLASFCBDZFKBDZEFMWBDZBSPSYNBSBSBSBSBSYRNCFSBMBSBSBSBSBDZBSBSBSBSYPTRNGKCXEMPSNXTOPSXEVXFXFXFXFXFXXFXFXFXXBOXZBSFXFXFXFXPCXFXFXFXBSFXFXFXXECXFXFXFXBCXFXFXFXAWXFXFXFXEMXFXFXFXEVXFXFXXFXXFXFXXEMXFXFXXEGXFXFXFXEXFXFXFXFXEMFXFXFXFXEVFXFXFXFXEGFXFXFXFX XFXFXFXFXTVFXFXFXFXfxFXFXFXFXXTFXFXFXFXTWFXFXFXFXIXFXFXFXFXHDFXFXFXFX FXFXFXFXFX MENZFXFXFXFX MUXFXFXFX XFRXFXFXFX MENXFXFXFX MUXYFXFXFXFX DXFXFXFXFX GEFXFXFXFX MOXFXFXFX MEMFXFXFXFX MFXFXFXFX SCFXFXFXFX ISFXFXFXFX MEMEMFXFXFX MUFXFXFXFX SMFXFXFXFX TMFXFXFXFX MEEMFXFXFX MENFXFXFXFX MKFXFXFXFXMWFXFXFXFX TWFXFXFXFX FOXFXFXFXFX BWFXFXFXFX SWFXFXFXFX BFXFXFXFX TRFXFXFXFX FFFXFXFXFX HDFXFXFXFX ZFXFXFXFX ESFXFXFXFX TFXFXFXFX BRFXFXFXFX AMDFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXXFXFXFXFXTXFXFXFXFXXTFXFXFXFXEXFXFXFXFXIXFXFXFXFXUXFXFXFXFXDXFXFXFXFXXYFXFXFXFXXXXFXFXFXFXXXFXFXFXFXFLFXFXFXFXFWFXFXFXFXFAFXFXFXFXFFFXFXFXFXFSFXFXFXFXFoxFXFXFXFXFIFXFXFXFXFOXFXFXFXFXFDFXFXFXFXFFXFXFXFX FOXFXFXFXFXFOFXFXFXFXFEFXFXFXFXFGFXFXFXFXFCFXFXFXFXFPFXFXFXFXFRFXFXFXFXGFFXFXFXFXSTFXFXFXFXWDFXFXFXFXTRFXFXFXFXHDFXFXFXFXBUTFXFXFXFXSWFXFXFXFXMAXFXFXFXFXSMFXFXFXFXSDFXFXFXFXODFXFXFXFXBSFXFXFXFXTEFXFXFXFXTWFXFXFXFXESFXFXFXFXATFXFXFXFXBuffFXFXFXFXDPFXFXFXFXPSFXFXFXFXSonyFXFXFXFXOKFXFXFXFXGMFXFXFXFXCDFXFXFXFXPCFXFXFXFXDVDFXFXFXFXBlizzardFXFXFXFXSpeechFXFXFXFXFinalFXFXFXFXDFXFXFXFXRPGFXFXFXFXSFXFXFXFXBOXFXFXFXFXMonsterFXFXFXFXUFCFXFXFXFXTFXFXFXFXMFXFXFXFXPGFXFXFXFXAMFXFXFXFXOSFXFXFXFXGameFXFXFXFXFireFXFXFXFXMemFXFXFXFXMoniaFXFXFXFXMONFXFXFXFXGenFXFXFXFXLeagueFXFXFXFXBFXFXFXFXBaywatchFXFXFXFXVenetFXFXFXFXStarfighterFXFXFXFXMarkFXFXFXFXWatchFXFXFXFXWarFXFXFXFXHolyFXFXFXFXChorusFXFXFXFXexFXFXFXFXPoFXFXFXFXCFXFXFXFXTrFXFXFXFXExFXFXFXFXMacFXFXFXFXNFXFXFXFXStFXFXFXFXSyntFXFXFXFXSoundsFXFXFXFXWildFXFXFXFXEleFXFXFXFXIFXFXFXFXFYFXFXFXFXTechnicallyFXFXFXFXLogFXFXFXFX FinalFXFXFXFX CinematicFXFXFXFX 101FXFXFXFX FuryFXFXFXFXFocusFXFXFXFX100FXFXFXFXCalFXFXFXFXFineFXFXFXFXRuleFXFXFXFXDiscussionFXFXFXFXaudioFXFXFXFX VideographyFXFXFXFXTVFXFXFXFXIdeFXFXFXFXroduFXFXFXFX FilmsFXFXFXFXFightingFXFXFXFXTwFXFXFXFXfireFXFXFXFXEverythingFXFXFXFXTripleFXFXFXFXerenceFXFXFXFXandFXFXFXFXSexFXFXFXFXTMFXFXFXFXEVFXFXFXFXPhFXFXFXFXAFXFXFXFXChainFXFXFXFX EtudeFXFXFXFXFilFXFXFXFXDialogueFXFXFXFXRewFXFXFXFXtFXFXFXFXCritFXFXFXFXVFXFXFXFXGRFXFXFXFXRFXFXFXFXAnnFXFXFXFXOTFXFXFXFXTerFXFXFXFXRemFXFXFXFXGraphicsFXFXFXFXAndFXFXFXFXEFXFXFXFXTotalFXFXFXFXGodFXFXFXFXYFXFXFXFXHFXFXFXFXANDFXFXFXFXJesusFXFXFXFXGeFXFXFXFXewFXFXFXFXBookFXFXFXFXSkyFXFXFXFXRSFXFXFXFXCHFXFXFXFXBOFXFXFXFX MEMFXFXFXFXListFXFXFXFXTSFXFXFXFXPhilFXFXFXFXBreFXFXFXFXWikipediaFXFXFXFXBioFXFXFXFXBiFXFXFXFX SciFXFXFXFXBAFXFXFXFXWWFXFXFXFXUFXFXFXFXMechFXFXFXFXScienceFXFXFXFXTechFXFXFXFXologyFXFXFXFX etcFXFXFXFXBasicFXFXFXFXBCFXFXFXFXBMFXFXFXFXREFXFXFXFXechFXFXFXFWFWFXFXFXFWBAFXFXFXFWBFXFXFXFWBCFXFXFXFW 101FX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXEXFXFXFXFXXFXFXFXFXGEFXFXFXFXXXXFXFXFXFXXTFXFXFXFXXYFXFXFXFXIXFXFXFXFXUXFXFXFXFXFLFXFXFXFXFSFXFXFXFXFDFXFXFXFX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1943, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4647, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6088, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7860, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good to hear that. How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8707, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8268, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you doing?\n",
      "DialoGPT: Good, good times.\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7559, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7698, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good times indeed.\n",
      "DialoGPT: Good times.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8359, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9087, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, good.\n",
      "DialoGPT: Good times, good times indeed. Good times indeed. Good Times indeed. Good times Indeed Indeed Indeed Indeed Indeed. Good times indeed indeed indeed. Good times. Good times indeed Indeed\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5628, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4927, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9664, 1.8197, 1.4858, 1.0720, 0.6975, 0.2639, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1648, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3488, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4245, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3815, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4362, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2639, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9664, grad_fn=<UnbindBackward>)\n",
      "Episode 235: -0.3194586605117735\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIIXATA VATA VIX VATA VATAVI VI VATA VATAVATA VAT VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VERO VATA VATA VC VATA VATA VT VATA VATA E VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATA VATA VATA VAT VATA VATA VCVD VATA VCVD VCVD VCVD VATA VATAVCVD VCVD VCVG VCVD VCVDVCVD VCVDVCVG VCVDVCVDVCVG VCVG VCVDVCVGVCVG VCVD VCVGVG VCVG VCVG VCVB VCVG VC VCVGVGVGVGVGPGEPGMUDGEUFOBYOXZEGBSFXBDLCKRSBNXFFIXZYSFSKYJVMDYFWRYFEKSNSDFAPOYWFEWTWWRBSNTQSWAGSIDOLASFCBDZFKBDZEFMWBDZBSPSYNBSBSBSBSBSYRNCFSBMBSBSBSBSBDZBSBSBSBSYPTRNGKCXEMPSNXTOPSXEVXFXFXFXFXFXXFXFXFXXBOXZBSFXFXFXFXPCXFXFXFXBSFXFXFXXECXFXFXFXBCXFXFXFXAWXFXFXFXEMXFXFXFXEVXFXFXXFXXFXFXXEMXFXFXXEGXFXFXFXEXFXFXFXFXEMFXFXFXFXEVFXFXFXFXEGFXFXFXFX XFXFXFXFXTVFXFXFXFXfxFXFXFXFXXTFXFXFXFXTWFXFXFXFXIXFXFXFXFXHDFXFXFXFX FXFXFXFXFX MENZFXFXFXFX MUXFXFXFX XFRXFXFXFX MENXFXFXFX MUXYFXFXFXFX DXFXFXFXFX GEFXFXFXFX MOXFXFXFX MEMFXFXFXFX MFXFXFXFX SCFXFXFXFX ISFXFXFXFX MEMEMFXFXFX MUFXFXFXFX SMFXFXFXFX TMFXFXFXFX MEEMFXFXFX MENFXFXFXFX MKFXFXFXFXMWFXFXFXFX TWFXFXFXFX FOXFXFXFXFX BWFXFXFXFX SWFXFXFXFX BFXFXFXFX TRFXFXFXFX FFFXFXFXFX HDFXFXFXFX ZFXFXFXFX ESFXFXFXFX TFXFXFXFX BRFXFXFXFX AMDFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXXFXFXFXFXTXFXFXFXFXXTFXFXFXFXEXFXFXFXFXIXFXFXFXFXUXFXFXFXFXDXFXFXFXFXXYFXFXFXFXXXXFXFXFXFXXXFXFXFXFXFLFXFXFXFXFWFXFXFXFXFAFXFXFXFXFFFXFXFXFXFSFXFXFXFXFoxFXFXFXFXFIFXFXFXFXFOXFXFXFXFXFDFXFXFXFXFFXFXFXFX FOXFXFXFXFXFOFXFXFXFXFEFXFXFXFXFGFXFXFXFXFCFXFXFXFXFPFXFXFXFXFRFXFXFXFXGFFXFXFXFXSTFXFXFXFXWDFXFXFXFXTRFXFXFXFXHDFXFXFXFXBUTFXFXFXFXSWFXFXFXFXMAXFXFXFXFXSMFXFXFXFXSDFXFXFXFXODFXFXFXFXBSFXFXFXFXTEFXFXFXFXTWFXFXFXFXESFXFXFXFXATFXFXFXFXBuffFXFXFXFXDPFXFXFXFXPSFXFXFXFXSonyFXFXFXFXOKFXFXFXFXGMFXFXFXFXCDFXFXFXFXPCFXFXFXFXDVDFXFXFXFXBlizzardFXFXFXFXSpeechFXFXFXFXFinalFXFXFXFXDFXFXFXFXRPGFXFXFXFXSFXFXFXFXBOXFXFXFXFXMonsterFXFXFXFXUFCFXFXFXFXTFXFXFXFXMFXFXFXFXPGFXFXFXFXAMFXFXFXFXOSFXFXFXFXGameFXFXFXFXFireFXFXFXFXMemFXFXFXFXMoniaFXFXFXFXMONFXFXFXFXGenFXFXFXFXLeagueFXFXFXFXBFXFXFXFXBaywatchFXFXFXFXVenetFXFXFXFXStarfighterFXFXFXFXMarkFXFXFXFXWatchFXFXFXFXWarFXFXFXFXHolyFXFXFXFXChorusFXFXFXFXexFXFXFXFXPoFXFXFXFXCFXFXFXFXTrFXFXFXFXExFXFXFXFXMacFXFXFXFXNFXFXFXFXStFXFXFXFXSyntFXFXFXFXSoundsFXFXFXFXWildFXFXFXFXEleFXFXFXFXIFXFXFXFXFYFXFXFXFXTechnicallyFXFXFXFXLogFXFXFXFX FinalFXFXFXFX CinematicFXFXFXFX 101FXFXFXFX FuryFXFXFXFXFocusFXFXFXFX100FXFXFXFXCalFXFXFXFXFineFXFXFXFXRuleFXFXFXFXDiscussionFXFXFXFXaudioFXFXFXFX VideographyFXFXFXFXroduFXFXFXFXTVFXFXFXFX FilmsFXFXFXFXFightingFXFXFXFXIdeFXFXFXFXTwFXFXFXFXfireFXFXFXFXEverythingFXFXFXFXTripleFXFXFXFXerenceFXFXFXFXandFXFXFXFXSexFXFXFXFXTMFXFXFXFXEVFXFXFXFXPhFXFXFXFXAFXFXFXFXChainFXFXFXFX EtudeFXFXFXFXFilFXFXFXFXDialogueFXFXFXFXRewFXFXFXFXtFXFXFXFXCritFXFXFXFXTerFXFXFXFXVFXFXFXFXGRFXFXFXFXRFXFXFXFXEdFXFXFXFXewFXFXFXFXGraphicsFXFXFXFXEFXFXFXFXTotalFXFXFXFXRemFXFXFXFXUDFXFXFXFXAnnFXFXFXFXOTFXFXFXFXUFXFXFXFXYFXFXFXFXHFXFXFXFXAndFXFXFXFXANDFXFXFXFXGodFXFXFXFXJesusFXFXFXFXDoneFXFXFXFXGeFXFXFXFX SciFXFXFXFX2001FXFXFXFX 2001FXFXFXFX 2021FXFXFXFX101FXFXFXFX MEMFXFXFXFX TMFXFXFXFX CompositeFXFXFXFX 201FXFXFXFX 151FXFXFXFX TeeFXFXFXFX XIIFXFXFXFX etcFXFXFXFX 102FXFXFXFX...FXFXFXFX FighterFXFXFXFX FightingFXFXFXFX ReferenceFXFXFXFX STFXFXFXFX MemFXFXFXFX MeleeFXFXFXFX ampFXFXFXFX FightersFXFXFXFX VIFXFXFXFX XFXFXFXFX.FXFXFXFX TwFXFXFXFX ComicsFX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXXFXFXFXFXIXFXFXFXFXEXFXFXFXFXXXXFXFXFXFXXTFXFXFXFXXXFXFXFXFXXYFXFXFXFXUXFXFXFXFXFLUXFXFXFX FX FXFXFXFX FXIXFXFXFX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1536, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2894, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5695, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7335, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you\n",
      "DialoGPT: I'm good too, how are you.\n",
      "r1: tensor(-0.0026, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8884, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8074, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(5.8543e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good\n",
      "DialoGPT: That's good. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8364, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5107, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.5827e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good\n",
      "DialoGPT: That's great. How are you doing? How are you doing.\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8913, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing?\n",
      "DialoGPT: That's good, that's good. Good. How are you doin'that? Good job? Good\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8677, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8353, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9003, 1.8076, 1.4967, 1.0829, 0.7536, 0.4258, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1108, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3258, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4246, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3368, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3320, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4258, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9003, grad_fn=<UnbindBackward>)\n",
      "Episode 236: -0.3185783281199288\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIIXATA VATA VIX VATA VATAVI VI VATA VATAVATA VAT VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VERO VATA VATA VC VATA VATA VT VATA VATA EVI VATA VIX VI VATA VIXVI VATA VIO VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATA VATA VATA VIA VATA VATA VCVD VATA VCVD VCVD VCVDVCVDVCVDVCVGVDVCVDVCVBVBVBVBVBJVVBVBVBVBVGVBVBVBVBVLVBVBVBVBVSVBVBVBVBVWVBVBVBVBVVBVBVBVBVRVBVBVBVBVEVBVBVBVBVDVBVBVBVBVPVBVBVBVBWBVBVBVBVBBSVBVBVBVBBDVBVBVBVBBWVBVBVBVBBBVBVBVBVBBVBVBVBVBBAVBVBVBVBBCVBVBVBVBDBVBVBVBVBBYVBVBVBVBBOVBVBVBVBBEVBVBVBVBBUVBVBVBVBUBRBVBVBVBVBUEVBVBVBVBIDKVBVBVBVBQBVBVBVBVBABVBVBVBVBBFVBVBVBVBBIVBVBVBVBWEVBVBVBVBTVVBVBVBVBFCVBVBVBVBFXVBVBVBVBUGVBVBVBVBZVBVBVBVBWERVBVBVBVBEGVBVBVBVBTWVBVBVBVBFFVBVBVBVBFEVBVBVBVBFLVBVBVBVBFWVBVBVBVBWVBVBVBVBPGVBVBVBVBWildWildWildWildWildWestVBVBVBVB WildWildWildWildWildcardWildWildWildWildlingWildWildWildWildVintageWildWildWildWildVBWildWildWildVLCWildWildWildWildwildWildWildWildWild WildWildWildWildVODVFCWildWildWildWildBWildWildWildWildVenewWildWildWildWildfireWildWildWildWildFireWildWildWildWildfiresWildWildWildWildlingsWildWildWildWildPlucksWildWildWildWildFlyWildWildWildWildlandsWildWildWildWildgerWildWildWildWildgersWildWildWildWildlyWildWildWildWildLWildWildWildWildlifeWildWildWildWildHardingWildWildWildWildgaryWildWildWildWildCWildWildWildWildingWildWildWildWildRWildWildWildWild WildeWildWildWildWild wildWildWildWildWildtitlesWildWildWildWild Birds WildWildWildWildling WildWildWildWildlings WildlingWildlingWildlingWildWildlingWildling WildlingWildling WildWildlingWildlingwildlingWildlingWildlings Wildling WildlingWildlings Wildlings WildlingWildlingsWildlingWildlinglingWildlingWild WildlingWildlinglinglingWildlingling WildlinglinglinglinglingWildlingslinglinglingling WildlingWildWildlinglinglinglingwildlinglinglinglingdomlinglinglinglinglingslinglinglingWildWildling WildlinglingWildling Wildlingslinglingling WildlingslingWildlinglinglingslingWildlingWildinglinglinglinglinggerslinglinglingling Wildelinglinglingling wildlinglinglinglingledlinglinglingling\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: WildlingwildlingwildlingwildlingslingwildlingwildwolveswildlingwildlingWildlingwildlingWildlingswildlingWildlingWildlingWildlingswildlingswildlingWildlingsWildlingWildlingwildlingswildlingwildling WildlingWildlingWildlingerWildlingWildling WildlingWildlingswildllingWildlingWildlingWolf Wolf wolf wolf wolf wolf wolf wolves wolves wolves wolves wolves wolf wolves wolves wolves wolf wolf wolves wolves wolf wolves wolf wolves wolves wolf wolf wolf wolves wolf wolves wolf wolf wolves wolf wolf wolf wolf monsters wolves wolves wolves wolves monsters wolves wolves wolves wolf monsters wolves wolves monsters wolves monsters wolves monsters monsters wolves monsters wolves monster bosses monsters monsters monsters monsters monsters bosses monsters monsters monsters bosses bosses bosses bosses bosses monsters bosses bosses bosses monsters monsters bosses bosses monsters bosses monsters bosses bosses monsters monsters monsters boss bosses bosses bosses bosses monster bosses bosses bosses bosses boss bosses bosses bosses monsters boss bosses bosses monsters bosses monster bosses bosses monsters bosses boss bosses bosses monsters monsters boss bosses monsters bosses bosses monster bosses monsters bosses bosses boss bosses monsters bosses monsters monsters bosses monsters bosses monsters boss bosses monsters monsters bosses monster bosses monsters monsters bosses boss bosses monsters monsters monsters monster bosses bosses bosses monsters monster bosses bosses monsters monsters monster bosses monsters bosses monsters monster bosses monsters monsters monster monsters bosses bosses bosses monster monsters bosses bosses monsters monster monsters bosses monsters bosses monster monsters bosses monsters monsters monster boss bosses bosses bosses monster boss bosses bosses monsters monster boss bosses monsters bosses monster boss bosses monsters monsters monster monster bosses bosses bosses monster monster bosses bosses monsters monster monster bosses monsters bosses monster monster bosses monsters monsters boss monsters bosses bosses bosses Monster bosses bosses bosses bossesMonster bosses bosses bosses bosses Monster monsters bosses bosses bosses boss monsters bosses bosses monster monsters monsters bosses bosses monster monster monsters bosses bosses monster boss monsters bosses bosses monsters boss monsters bosses monster bosses monster bosses bosses monster bosses monster monsters bosses monster bosses boss bosses monster bosses monster monster bosses monster bosses monster boss bosses monster bosses bosses boss bosses monster monsters bosses boss bosses monster monster bosses boss bosses bosses monster bosses boss monsters bosses monster monsters monsters monsters bosses monster monsters monster bosses monster bosses monsters monster bosses monster monsters monsters monster bosses monster monster monsters monsters bosses monster monster monsters monster bosses monsters monster monsters monsters bosses monsters monster monsters monster bosses bosses monster monsters monster monsters bosses monster monsters boss bosses monster bosses monsters boss bosses monster monsters monsters boss bosses monster monster monsters boss bosses monsters monster bosses Monster bosses monster bosses monster killers monsters bosses monster bosses Monster bosses monsters bosses monsterboss bosses monster bosses monster killer bosses monster bosses monsterMonster bosses monster bosses monster sharks monsters bosses monster bossesMonster bosses monster bosses monsters Monster bosses monster bosses monstersMonster bosses monster bosses bosses Monster bosses monster monsters bosses Monster bosses monster monster bosses Monster bosses bosses monster bosses Monster monsters bosses monster bosses etc monster bosses monster bosses Monster monster bosses monster bossesMonster monsters bosses monster bosses stage bosses monster bosses monster Monster bosses monster bosses bossesMonster bosses monster monsters bossesMonster bosses monster monster bossesMonster bosses monsters bosses monsterMonster bosses monsters bosses monsters Monster bosses monsters bosses monstersMonster bosses monsters bosses bosses Monster bosses monsters monsters bosses Monster bosses monsters monster bossesMonster bosses bosses monster bossesMonster monster bosses monster bosses boss monster bosses monster bosses etc bosses monster bosses monsterboss bosses monsters bosses monster killers monsters monsters bosses monster boss monsters monsters bosses monsterMonster monsters bosses monster monsters Monster bosses monster monsters monsters Monster bosses monster monster monsters Monster bosses monsters monsters monsters Monster bosses monsters monster monsters Monster bosses bosses monster monsters Monster monsters monsters monsters monsters monster monsters monsters monsters monsters Monster monsters monsters bosses monster killers monster bosses monster bosses\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Monster Monsters Monsters Monsters Monsters Monsters Monster Monsters Monster Monsters Monster Monster Monsters Monster Monsters Monsters Monster Monsters Monsters Monsters Monster Monster Monsters Monsters Monster Monster Monster Monsters Monster Monster Monster Monster Monsters Monsters Monsters Monsters Boss Monsters Monster Monsters Monsters Boss Monsters Monsters Monsters Monsters monsters Monsters Monsters Monsters Monsters monster Monsters Monsters Monsters Monsters bosses Monsters Monsters Monsters Monsters boss Monsters Monsters Monsters MonstersMonster Monsters Monsters Monsters MonsterBossMonsterMonsterMonsterMonsterMonsterMonstersMonsterMonsterMonsterMonsterBossMonsterMonsterMonsterMonMonsterMonsterMonsterMonsterMorseMonsterMonsterMonsterMonstermonMonsterMonsterMonsterMonstermonsterMonsterMonsterMonsterMonsterHunterMonsterMonsterMonsterMonster MonsterMonsterMonsterMonsterMonsterSpiderMonsterMonsterMonsterMonsterSpawnMonsterMonsterMonsterMonsterCatMonsterMonsterMonsterMonsterWolfMonsterMonsterMonsterMonsterGameMonsterMonsterMonsterMonsterCannonMonsterMonsterMonsterMonsterCrumpMonsterMonsterMonsterMonsterChampionMonsterMonsterMonsterMonsterbossMonsterMonsterMonsterMonsterLMonsterMonsterMonsterMonsterHeroMonsterMonsterMonsterMonsterDragonMonsterMonsterMonsterMonsterKingMonsterMonsterMonsterMonsterDMonsterMonsterMonsterMonsterOceanMonsterMonsterMonsterMonsterGoMonsterMonsterMonsterMonsterGodMonsterMonsterMonsterMonsterLeagueMonsterMonsterMonsterMonsterGMonsterMonsterMonsterMonstergoMonsterMonsterMonsterMonsterTMonsterMonsterMonsterMonsterMuskyMonsterMonsterMonsterMonsterBMMonsterMonsterMonsterMonsterWarMonsterMonsterMonsterMonsterOfMonsterMonsterMonsterMonsterBookMonsterMonsterMonsterMonsterStarMonsterMonsterMonsterMonsterLegendaryMonsterMonsterMonsterMonsterSonMonsterMonsterMonsterMonsterLordMonsterMonsterMonsterMonsterMLMonsterMonsterMonsterMonsterFireMonsterMonsterMonsterMonsterFactoryMonsterMonsterMonsterMonsterMagMonsterMonsterMonsterMonsterMadMonsterMonsterMonsterMonsterMDMonsterMonsterMonsterMonsterManMonsterMonsterMonsterMonsterPoMonsterMonsterMonsterMonsterVenomMonsterMonsterMonsterMonsterBurgerMonsterMonsterMonsterMonsterHellMonsterMonsterMonsterMonsterBMonsterMonsterMonsterMonsterElMonsterMonsterMonsterMonsterSubMonsterMonsterMonsterMonsterSuperMonsterMonsterMonsterMonstericideMonsterMonsterMonsterMonsterAlMonsterMonsterMonsterMonsterAllMonsterMonsterMonsterMonsterAdMonsterMonsterMonsterMonsterCRMonsterMonsterMonsterMonsterDonaldMonsterMonsterMonsterMonsterDickMonsterMonsterMonsterMonsterIncMonsterMonsterMonsterMonster MonstersMonsterMonsterMonsterMonsterNMonsterMonsterMonsterMonsterBlMonsterMonsterMonsterMonsterHitMonsterMonsterMonsterMonster KingMonsterMonsterMonsterMonster HunterMonsterMonsterMonsterMonsterBillyMonsterMonsterMonsterMonsterFrankMonsterMonsterMonsterMonster FrankensteinMonsterMonsterMonsterMonster BombMonsterMonsterMonsterMonster monsterMonsterMonsterMonsterMonster MonMonsterMonsterMonsterMonster MeteorMonsterMonsterMonsterMonster MountainMonsterMonsterMonsterMonster\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1016, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2317, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4318, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7078, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are YOU?\n",
      "DialoGPT: doing well too, how are YOU doing?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9385, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9112, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you doing?\n",
      "DialoGPT: doing well thanks for asking me, etc etcetcetcetcetcetc etcetcetcetc etc etcetcetc etcetc etcetcetc etc etc etcetcetceterciality etcetcetcetcutietcetcetcetcuti etcetcetcetcuccietc\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7727, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7407, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1861, 1.1138, 0.8372, 0.3784, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0834, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2850, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4626, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3784, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1861, grad_fn=<UnbindBackward>)\n",
      "Episode 237: -0.31759025355284454\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATVATVATAVATAVATA VATA VATA VATSATA VATA VATATA VATA VTAVATA VATA AVATA VATA VBAVATA VATA VIATA VATA VTEVATA VATAVI VATA VATA VIIXATA VATA VIX VATA VATAVI VIATA VATA VI VATA VATA VII VATA VATA VIII VATA VATA IX VATA VATA III VATA VATA IV VATA VATA II VATA VATA vATA VATA VIO VATA VATAV VATA VATA VC VATA VATA VT VATA VATA EVI VATA VIX VI VATA VIXVI VATA VERO VATA VATA ES VATA VATA Vic VATA VATA Videography VATA VATA TV VATA VATA AV VATA VATA VG VATA VATA VP VATA VATA\n",
      "User: Let's go to your home.\n",
      "DialoGPT: VATS VATS VATS VATS VATS VATS VCAT VCAT VCAT VATS VCAT VATS VATSVCAT VCAT VCATS VCAT VCATSVCAT VCATSVCATSVCAT VCATA VCAT VCATVCAT VCATVCATSVCATVCAT VCATAVCAT VCATAVBVBVBVBVBVGVBVBVBVBJVVBVBVBVBVDVBVBVBVBVVBVBVBVBVLVBVBVBVBVPVBVBVBVBVSVBVBVBVBBSVBVBVBVBDBVBVBVBVBBDVBVBVBVBBVBVBVBVBBAVBVBVBVBBBVBVBVBVBBWVBVBVBVBBYVBVBVBVBBCVBVBVBVB BWVBVBVBVBWBVBVBVBVBVWVBVBVBVB DVVBVBVBVB VPGVBVBVBVB MVVBVBVBVB BGMVBVBVBVB BjVBVBVBVB BRTTVBVBVBVB DDVBVBVBVB DBVBVBVBVB BBVBVBVBVB BDVBVBVBVB CWVB BWVB BWVB BWVODVB BWVB BWVC BWVB BWVB VTLVB BWVB BWVI BWVB BWVBVB BWVB BW VKTVB BWVB BWJVVB BWVB BWVM BWVB BWVB CWVB BWV BWVB BWVB DVVB BWVB BW BWVB BWVB TLVB BWVB BWVKVB BWVB BWAV BWVB BWVB WWVB BWVB BWVE BWVB BWVB BRVB BWVB BWBWVB BWVB BWVDV BWVB BWV BWV BWVB VVB BWVB BWVG BWVB BWVB BVB BWVB BWZ BWVB BWVB TWVB BWVB BWTW BWVB BWVB BTVB BWVB BWTS BWVB BWVB\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a party. And then we'll have some tea and cake. Then we'll have a picnic. Then we'll celebrate our independence day together. Then we'll die peacefully. Forever Alone. Forever Alone. foreveralonetogethertogethertogethertogethertogetherTogetherTogetherTogetherTogetherTogetherUnitedUnitedUnitedUnitedUnitedunitedUnitedUnitedUnitedUnited unitedunitedunitedunitedunitedunitedUnitedunitedunitedunitedunited unitedunitedunitedunitedUnitedUnitedunitedunitedunitedUnited unitedunitedunitedUnitedunitedUnitedunitedunitedUnitedunited unitedunitedunitedUnitedUnitedUnitedunitedunitedUnitedUnited Unitedunitedunitedunitedunited UnitedunitedunitedunitedUnited UnitedunitedunitedUnitedunited UnitedunitedunitedUnitedUnited unitedunitedUnitedunitedunited unitedunitedUnitedunitedUnitedUnitedunitedUnitedunitedUnited unitedunitedUnitedUnitedunited unitedunitedUnitedUnitedUnited unitedUnitedunitedunitedunited unitedUnitedunitedunitedUnited unitedUnitedunitedUnitedunited unitedUnitedunitedUnited unitedUnited unitedunitedunited unitedunited unitedunitedunited united unitedunitedunitedunited united united unitedunitedunited unitedUnited unitedunited unitedunited united unitedunited unitedunitedUnited unitedunited united united united united unitedunited united unitedUnited united united united unitedUnited unitedunited United united united united united United united united unitedunited United unitedunited united united United unitedunited unitedunited United united United united unitedunited united United united united United united United unitedunitedunited united United unitedunited United unitedUnited united unitedunited unitedUnited united united United unitedUnited unitedunitedUnited united united unitedunitedUnited united United united unitedUnited united United united United United united united united United United united United united Unitedunited united united united Unitedunited united United united UnitedUnited united united united UnitedUnited united United unitedunitedUnited unitedUnited United united united unitedUnited United united United unitedUnited United unitedunited united United United unitedunited unitedUnited United unitedUnited united United United unitedUnited unitedUnited united unitedUnited unitedUnited United United united united United United United united unitedunited United United united united republic united united united united republic united United united united republic United united united united republic United United united unitedUnited United United United united United United United United united republic united united United united republic united United United united republic United united United united republic United United United united Republic united united united united Republic united united republic united republic united united republic united Republic united republic united republic republic united republic united republic Republic united republic republic republic republic republic united republic republic republic united Republic republic republic republic republic Republic republic republic republic united united republic republic republic Republic Republic republic republic republic Republic united republic Republic republic republic Republic republic Republic republic republic united republic Republic republic Republic Republic republic Republic republic Republic united republic united Republic republic Republic republic united republic republic Republic republic united Republic republic united republic Republic Republic republic united republic united Republic Republic republic republic Republic Republic Republic republic republic united Republic Republic Republic republic Republic Republic Republic Republic republic united Republic Republic. Republic republic republic republic. republic republic republic republic. Republic republic republic Republic. republic republic republic Republic. Republic Republic Republic Republic Republic. republic republic Republic Republic. republic Republic Republic Republic. Republic Republic republic republic. Republic Republic Republic republic. Republic Republic republic Republic. Republic republic Republic Republic. Republic. Republic Republic. Republic\n",
      "User: I always cry at the end.\n",
      "DialoGPT: The tears are delicious. Especially when they're salty enough to spill onto your clothes and shoes.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0732, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4059, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6429, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8219, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you??\n",
      "DialoGPT: Fine fine fine fine fine fine Fine Fine Fine Fine Fine fine Fine Fine Fine fine fine Fine Fine fine Fine fine Fine Fine fine fine fine Fine fine fine Fine fine Fine fine fine fine fineFine Fine Fine Fine FineFine Fine Fine Fine fineFine Fine Fine fine FineFine Fine Fine fine fineFineFine Fine Fine FineFineFineFineFineFine FineFineFineFine Fine Fine\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6854, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7142, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.8255, 0.7128, 0.3500, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1198, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3663, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3500, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.8255, grad_fn=<UnbindBackward>)\n",
      "Episode 238: -0.3167628089597285\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATEATEATEATAATAATAATAATAATATAATAATAATAASATAATAATAATABAATAATAATAATATEATAATAATAATATAATAATAATAATACHATAATAATAATAACATAATAATAATABATAATAATAATAAATAATAATAATAABATAATAATAATABOATAATAATAATABCATAATAATAATABMATAATAATAATABDATAATAATAATAMBATAATAATAATABSATAATAATAATACAATAATAATAATA2015ATAATAATAATA201720152015201520152015 2016 2017 2016 2016 2016 2016 2016 2017 2018 2017 2017 2017 2017 2017 2018 2019 2020 2018 2018 2018 2018 2018 2019 2018 2018 2018 2018 2021 2018 2018 2018 2018 2020 2018 2018 2018 2019 2020 2018 2019 2018 2019 2018 2019 2020 2018 2020 2018 2019 2018 2018 2019 2018 2019 2019 2018 2019 2018 2018 2020 2020 2020 2020 2020 2019 2020 2020 2020 2020 2018 2019 2020 2020 2020 2019 2019 2020 2020 2020 2018 2020 2020 2020 2019 2018 2019 2020 2020 2019 2020 2019 2020 2020 2019 2019 2019 2020 2020 2019 2018 2020 2020 2020 2018 2018 2019 2020 2020 2018 2019 2019 2020 2020 2018 2020 2019 2020 2020 2018 2018 2020 2020 2019 2020 2018 2019 2020 2019 2020 2019 2019 2020 2019 2020 2018 2020 2020 2019 2019 2018 2019 2020 2019 2019 2019 2019 2020 2019 2019 2018 2020 2020 2019 2018 2018 2019 2020 2019 2018 2019 2019 2020 2019 2018 2020 2019 2020 2019 2018 2018 2020 2019 2020 2018 2018 2019 2019 2020 2018 2019 2019 2019 2020 2018 2020 2019 2019 2020 2018 2018 2020 2019 2019 2019 2018 2019 2019 2019 2019 2019 2018 2020 2019 2019 2018 2018 2019 2019 2019 2018 2018 2020 2018 2019 2020 20182020 2020 2020 2020 2020 2021 2020 2020 2020 20202020 2020 2020 2020 2019 2021 2020 2020 2020 20192020 2020 2020 2020 2018 2021 2020 2020 2020 20182020 2020 2019 2020 2020 2021 2020 2019 2020 20202020 2020 2019 2020 2019 2021 2020 2019 2020 20192020 2020 2019 2020 2018 2021 2020 2019 2020 20182020 2019 2020 2020 2020 2021 2019 2020 2020 20202020 2019 2020 2020 20192020 2019 2020 2020 20182020 2019 2019 2020 20202020 2019 2019 2020 20192020 2019 2019 2020 20182020 2018 2019 2020 20202020 2018 2019 2020 20192020 2018 2019 2020 2018 2021 2019 2020 2020 2019 2021 2019 2020 2020 2018 2021 2019 2019 2020 2020 2021 2019 2019 2020 2019 2021 2019 2019 2020 2018 2021 2018 2019 2020 2020 2021 2018 2019 2020 2019 2021 2018 2019 2020 2018 202020 2020 2020 20202020 2018 2020 2020 202020202020 2020 2020 2020 2021 2018 2020 2020 2020 20212020 2020 2020 2020 202020 2020 2020 2019 20202020 2020 2020 2019 20192020 2020 2020 2019 20182020 2020 2020 20192020 2018 2020 2020 201920202020 2020 2020 2019 2021 2018 2020 2020 2019 20212020 2020 2020 2019 202020 2020 2020 2018 2019 2018 2020 2020 2018 20192020 2020 2020 2018 2020 2018 2020 2020 2018 20202020 2020 2020 20182020 2018 2020 2020 201820202020 2020 20202020 20202020 2020 20202020 20192020 2020 202020202020 2019 2020 2020202020202020 2020 2020 2018 20182020 2020 20202020 20182020 2020 2020 2018 20212020 2020 20202020 2021 2020 2020 20202020 2021 2019 2020 20202020 20212020 2020 2020 20182019 2020 2020 2020 2020 20 2020 2020 2020 20202019 2020 2020 2020 2019 20 2020 2020 2020 20192019 2020 2020 20202020 202020 2020 20202020 20 2020 2020 202020202019 2020 2020 2020 2018 202020 2019 2020 2020 20212020 2019 2020 2020 202020 2019 2020 2019 20202020 2019 2020 2019 20192020 2019 2020 201920202020 2019 2020 2019 20182020 2019 2020 2019 202020 2019 20202020 2020 2019 2019 20202020 20202020 2019 20202020 2019 2019 2019 20202020 20192020 2019 202020202020 2020 2019 202020202020 2019 2019 2020202020202020 2019 20202020 2018 2020 2019 20202020 2018 2019 2019 20202020 20182020 2019 20202020 2021 2020 2019 20202020 2021 2019 2019 20202020 20212020 2019 2020 2019 20212020 2019 20202020 202020 2019 2020 2018 20192020 2019 2020 2018 20202020 2019 2020 201820202020 2019 2020 2018 20182020 2019 2020 20182019 2020 2019 2020 2020 20 2019 2020 2020 2020 20 2019 2019 2020 2020 20 2020 2019 2020 20202019 2020 2019 2020 2019 20 2019 2020 2020 2019 20 2019 2019 2020 2019 20 2020 2019 2020 20192019 2020 2019 20202020 20 2019 2020 20202020 20 2019 2019 20202020 20 2020 2019 20202020 2030 2020 2020 2020 2020 2030 2020 2020 2020\n",
      "User: Let's go to your home.\n",
      "DialoGPT: That's a lot of money for one year of rent. That's probably cheaper than buying a house outright in SF. Unless you're renting out a studio apartment building... which is possible too?\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then buy a house outright in San Francisco and live there forever while paying rent on top of that mortgage payments. Sounds like a plan to me! sips coffee quietly cries tears of joy\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Me too, but only when I'm crying tears of joy tears of happiness tears of joy tears tears of joy tears sobbing tears of joy tears weeping tears of joy tears crying tears of joy sobbing tears sobbing tears sobbering tears sobbering cries sobbering tears cries sobbering cries cries sobbering Tears sobberings sob\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4831, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4184, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6273, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7731, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Great, well, good enough for me. How are you doing today?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9153, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8690, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking!\n",
      "DialoGPT: That's good enough for me too!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8096, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8244, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: That's great!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8175, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7463, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy to hear that! I'm glad to hear you're doing well!\n",
      "DialoGPT: That's a\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5238, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5255, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(5.8241e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0311, 1.8238, 1.4886, 1.0529, 0.6508, 0.2624, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.2255, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3502, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4462, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4086, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3910, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2624, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0311, grad_fn=<UnbindBackward>)\n",
      "Episode 239: -0.31638249120054146\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSBSATRSATRSCHBSATRSATFSATRSATRSTSBSATRSATBSATRSATTEBSATRSATOSBSATRSATSBSATRSATSSBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBSHDBSBSBSBS BCBSBSBSBS TVBSBSBSBS HDBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Hulu Hulu Hulu Hulu Hulu Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix HBO Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Netflix HBO Showtime Showtime Netflix Showtime HBO Showtime Showtime Netflix Netflix HBO Showtime Netflix Showtime Showtimeflix Showtime Showtime Showtime Showtime WireheadwaywaywaywaywayfarewayfarewayfareldwayfareldwaywayfareldwaywardwayfareldwaylandishwayfareldwaylightwayfareldwayWAYWAYWAYWAYWAYwaywaywaywayWAYWAYWAYwayWAYWAYWAYLANDwaywaywaywayLANDwaywaywayWAYwaywaywayWAY WAYWAYWAYWAYWAYLANDWAYWAYWAYWAY WAYWAYWAYwaywayWAYWAYwaywayLANDWAYWAYWAYwayLANDWAYWAYwayway WAYWAYWAYWAYway WAYWAYWAYwayWAYwaywayWAYwayWAYwayWAYWAYwayWAY WAYwaywaywayway WAYwaywaywayWAYWaywaywaywayway WaywaywaywaywayWaywaywaywayWAYLANDwaywayWAYway WAYwaywayWAYwayLANDwaywayWAYWAY WAYwaywayWAYWAYWaywaywayWAYwayWaywaywayWAYWAYLANDwayWAYwayway WAYwayWAYwayway WaywayWAYwaywayWaywayWAYwaywayLAND WAYwaywayway WAYWAYwaywayway WAY WAYwaywayway WayWAYwaywayway Way WAYwaywaywayWayWAYwaywaywayWay WAYwaywayway FARwaywaywaywayVenwaywaywayway Venicated WAYwayVenVenVenVenVenwayVenVenVen venVenVenVenVen ven venVenVenVen ven VenVenVenVenVen VenVenVenVen venkyVenVenVenVenierVenVenVenVen\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: VenueVenueVenue VenueVenueVenuerVenueVenue venuerVenuerVenuerVenue VenuerVenuerVenuersVenuerVenuervenuerVenuerVenuesVenuerVenuer VenuerVenuer VenuersVenuerVenuers VenuerVenuersVenuersVenuers VenuersVenuersVenue\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Me too man, me too.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3559, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0279, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6046, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6639, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: That's good, thanks.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6916, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6527, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.3795e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: No problem, I'm glad you're doing well\n",
      "DialoGPT: Yeah, thanks to you're doing well too.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7906, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7808, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: Yeah, thanks for the food and the food smiles back at you smiles\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8488, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7042, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I smile back\n",
      "DialoGPT: Smiles back at you're welcome smiles back at you smiling back at her smiles back at her\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8382, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6279, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8425, 1.7641, 1.4615, 1.1367, 0.7513, 0.3666, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0961, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3172, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3362, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3929, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3883, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3666, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8425, grad_fn=<UnbindBackward>)\n",
      "Episode 240: -0.31546826875494227\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSBBSATRSATBSATRSATTSBSATRSATOSBSATRSATSBSATRSATTVBSBSBSBSBSATBSBSBSBSBCBSBSBSBSBMBSBSBSBSBABSBSBSBSBBSBSBSBSBDBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBSHDBSBSBSBSTVBSBSBSBCBCBSBSBSBC BBSBSBSBC BCBSBSBSBS BCBSBSBSBCBDBSBSBSBCBBSBSBSBCBABSBSBSBCBMBSBCBSBCBSBCBCBSBCBSBSBCBSBC BBSBCBSBC BCBSBCBSBCBBSBCBCBCBCBCBSBCBCBCBSBSBCBCBC BCBCBCBCBC BCBSBCBCBC BBCBCBCBC BBSBCBCBCBBCBCBCBCBBSBCBSBCBDBCBCBCBCBDBCBCBSBC BCBCBCBSBC BBCBCBSBCBBCBCBSBCBDBSBCBCBCBDBSBCBSBC BCEBCBCBCBC BCEBCBCBSBC BCE BCBCBCBCBS BCBCBCBC BC BCBCBCBC B BCBCBCBC BCE BCBC BCBCBC BCBC BCBC BCBSBC BCBC BC BCBC BCBCBSBCBC BCBCBS BCBC BCBC BBCBC BCBC BBSBC BCBCBS BBCBCBC BC BBCBCBCBS BBC BCBCBC BBC BCBC BC BBC BCBC B BCBC BCBC BCEBCBC BCBC BCE BCBC BBC BC BCBC BBC BBCBC BBC B BCBC BBCBSBCBC BBCBS BCBC BBC BCEBCBC BBC BCE BCBC BCEBC BCBCBC BCEBC BC BCBC BCEBC BBCBC BCEBC B BCBC BCEBC BCEBCBC BCEBC BCE BCBCBSBC BC BCBCBSBC B BCBCBSBC BCE BCEBCBCBC BC BCEBCBCBC B BBCBCBC B BCEBCBCBC BCE BCEBC BCBC BC BCEBC BCBC BCE BCEBC BCEBC BC BCEBC BCEBC BCE BCEBC BBC BC BCEBC BBC BCE BCEBCBSBCBC BCEBCBSBC BC BCEBCBSBC BCE BBCBCBC BCE BBC BCBC BCE BBC BCEBC BC BBC BCEBC BCE BBC BBC BC BBC BBC BCE BBCBSBC BC BBCBSBC BCEBSBCBCBC BCEBSBC BCBC BCEBSBC BCEBC BCBSBC BCEBC BCEBSBC BBC BCBSBC BBC BCEBSBCBSBC\n",
      "User: Let's go to your home.\n",
      "DialoGPT: LET'S GO TO YOUR HOME LET'S GO TO HIS HOME LET'S GIVE HIM THE BALL LET'S GO LET'S GOLET'S GO LETS GO LET'TS GO LETTS GO LETTS GIVE HIM THEBALL LET'S GO GET HIM THE BALL GUYS GET HIM THE BALL GET HIM THE BALL NOW\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: AND MY AXE! Wait... wrong game thread. Carry on, carry on. Carry on. Carry on carrying on carrying on carrying forward toward victory. Carry onward towards victory. Carry onward toward victory. Carry forward toward victory.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0818, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0539, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6561, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6599, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well.\n",
      "DialoGPT: That's good to hear.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6674, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6641, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: So am I.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7119, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7218, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(5.6430e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So am i.\n",
      "DialoGPT: So am.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5929, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8701, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(3.3041e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: So am\n",
      "DialoGPT: So. Am. Am. Am I'm. Ambitious. Ambitious. To. Ambitious. With. Meaning. To. Amassing. To. Aminate. Me. To Aminate. Meaning. With Me\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6835, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5211, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6718, 1.6544, 1.3387, 1.0159, 0.6641, 0.3012, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0340, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3291, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3330, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3585, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3658, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3012, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6718, grad_fn=<UnbindBackward>)\n",
      "Episode 241: -0.3143051508660159\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSBBSATRSATBSATRSATTSBSATRSATOSBSATRSATSBSATRSATTVBSBSBSBSBSATBSBSBSBSBCBSBSBSBSBMBSBSBSBSBABSBSBSBSBBSBSBSBSBDBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBSHDBSBSBSBSTVBSBSBSBCBCBSBSBSBC BBSBSBSBC BCBSBSBSBS BCBSBSBSBCBDBSBSBSBCBBSBSBSBCBABSBSBSBCBMBSBCBSBCBSBCBCBSBCBSBSBCBSBC BBSBCBSBC BCBSBCBSBCBDBCBCBCBCBCBSBCBCBCBC BCBCBCBCBC BBCBCBCBCBDBCBCBSBC BCBCBCBSBC BBCBCBSBCBDBSBCBCBCBSBSBCBCBC BCBSBCBCBC BBSBCBCBCBDBSBCBSBCBBCBCBCBCBBCBCBSBCBBSBCBCBCBBSBCBSBC BCEBCBCBCBC BCEBCBCBSBC BCE BCBCBCBCBS BCBCBCBC BC BCBCBCBC B BCBCBCBC BCE BCBC BCBCBC BCBC BCBC BCBSBC BCBC BC BCBC BCBCBSBCBC BCBCBS BCBC BCBC BBCBC BCBC BBSBC BCBCBS BBCBCBC BC BBCBCBCBS BBC BCBCBC BBC BCBC BC BBC BCBC B BCBC BCBC BCEBCBC BCBC BCE BCBC BBC BC BCBC BBC BBCBC BBC B BCBC BBCBSBCBC BBCBS BCBC BBC BCEBCBC BBC BCE BCBC BCEBC BCBCBC BCEBC BC BCBC BCEBC BBCBC BCEBC B BCBC BCEBC BCEBCBC BCEBC BCE BCBCBSBC BC BCBCBSBC B BCBCBSBC BCE BCEBCBCBC BC BCEBCBCBC B BBCBCBC B BCEBCBCBC BCE BCEBC BCBC BC BCEBC BCBC BCE BCEBC BCEBC BC BCEBC BCEBC BCE BCEBC BBC BC BCEBC BBC BCE BCEBCBSBCBC BCEBCBSBC BC BCEBCBSBC BCE BBCBCBC BCE BBC BCBC BCE BBC BCEBC BC BBC BCEBC BCE BBC BBC BC BBC BBC BCE BBCBSBC BC BBCBSBC BCEBSBCBCBC BCEBSBC BCBC BCEBSBC BCEBC BCBSBC BCEBC BCEBSBC BBC BCBSBC BBC BCEBSBCBSBC\n",
      "User: Let's go to your home.\n",
      "DialoGPT: LET'S GO TO YOUR HOME LET'S GO TO HIS HOME LET'S GIVE HIM THE BALL LET'S GO LET'S GOLET'S GO LETS GO LET'TS GO LETTS GO LETTS GIVE HIM THEBALL LET'S GO GET HIM THE BALL GUYS GET HIM THE BALL GET HIM THE BALL NOW\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: AND MY AXE! Wait... wrong game thread. Carry on, carry on. Carry on. Carry on carrying on carrying on carrying forward toward victory. Carry onward towards victory. Carry onward toward victory. Carry forward toward victory.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3612, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1111, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5890, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7534, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you\n",
      "DialoGPT: That's good, how about we meet up sometime?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8637, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8340, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Sounds good\n",
      "DialoGPT: Sounds good to me too. smiles\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7863, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5484, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: smiles back\n",
      "DialoGPT: Smiles back smiles back smiles back smiles smiles back smiles back smiling smiles back smiles back smile smiles back smiles back Smile Smile smile smile smile smile smile Smile Smile Smile Smile Smile smile Smile Smile Smile smile smile Smile Smile smile Smile smile Smile Smile\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7781, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4849, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.4938, 1.3895, 1.0645, 0.6464, 0.3158, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1181, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3357, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4245, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3338, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3158, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.4938, grad_fn=<UnbindBackward>)\n",
      "Episode 242: -0.3134979004722564\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSBBSATRSATBSATRSATTSBSATRSATOSBSATRSATSBSATRSATTVBSBSBSBSBSATBSBSBSBSBCBSBSBSBSBMBSBSBSBSBABSBSBSBSBBSBSBSBSBDBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBSHDBSBSBSBSTVBSBSBSBCBCBSBSBSBC BBSBSBSBC BCBSBSBSBS BCBSBSBSBCBDBSBSBSBCBBSBSBSBCBABSBSBSBCBMBSBCBSBCBSBCBCBSBCBSBSBCBSBC BBSBCBSBC BCBSBCBSBCBDBCBCBCBCBCBSBCBCBCBC BCBCBCBCBC BBCBCBCBCBDBCBCBSBC BCBCBCBSBC BBCBCBSBCBDBSBCBCBCBSBSBCBCBC BCBSBCBCBC BBSBCBCBCBDBSBCBSBCBBCBCBCBCBBCBCBSBCBBSBCBCBCBBSBCBSBC BCEBCBCBCBC BCEBCBCBSBC BCE BCBCBCBCBS BCBCBCBC BC BCBCBCBC B BCBCBCBC BCE BCBC BCBCBC BCBC BCBC BCBSBC BCBC BC BCBC BCBCBSBCBC BCBCBS BCBC BCBC BBCBC BCBC BBSBC BCBCBS BBCBCBC BC BBCBCBCBS BBC BCBCBC BBC BCBC BC BBC BCBC B BCBC BCBC BCEBCBC BCBC BCE BCBC BBC BC BCBC BBC BBCBC BBC B BCBC BBCBSBCBC BBCBS BCBC BBC BCEBCBC BBC BCE BCBC BCEBC BCBCBC BCEBC BC BCBC BCEBC BBCBC BCEBC B BCBC BCEBC BCEBCBC BCEBC BCE BCBCBSBC BC BCBCBSBC B BCBCBSBC BCE BCEBCBCBC BC BCEBCBCBC B BBCBCBC B BCEBCBCBC BCE BCEBC BCBC BC BCEBC BCBC BCE BCEBC BCEBC BC BCEBC BCEBC BCE BCEBC BBC BC BCEBC BBC BCE BCEBCBSBCBC BCEBCBSBC BC BCEBCBSBC BCE BBCBCBC BCE BBC BCBC BCE BBC BCEBC BC BBC BCEBC BCE BBC BBC BC BBC BBC BCE BBCBSBC BC BBCBSBC BCEBSBCBCBC BCEBSBC BCBC BCEBSBC BCEBC BCBSBC BCEBC BCEBSBC BBC BCBSBC BBC BCEBSBCBSBC\n",
      "User: Let's go to your home.\n",
      "DialoGPT: LET'S GO TO YOUR HOME LET'S GO TO HIS HOME LET'S GIVE HIM THE BALL LET'S GO LET'S GOLET'S GO LETS GO LET'TS GO LETTS GO LETTS GIVE HIM THEBALL LET'S GO GET HIM THE BALL GUYS GET HIM THE BALL GET HIM THE BALL NOW\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: AND MY AXE! Wait... wrong game thread. Carry on, carry on. Carry on. Carry on carrying on carrying on carrying forward toward victory. Carry onward towards victory. Carry onward toward victory. Carry forward toward victory.\n",
      "User: I always cry at the end.\n",
      "DialoGPT: That's what she said?\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2742, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5795, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7297, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: How are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7824, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7684, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you doing??\n",
      "DialoGPT: I'm fine, how are you're doing well?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9141, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm okay, I'm doing well, I'm doing fine, I'm doing good, I'm doing great, I'm doing very good, I'm good, I'm very good, I am very good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2588, 1.1399, 0.8208, 0.4374, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1303, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3273, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3878, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4374, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2588, grad_fn=<UnbindBackward>)\n",
      "Episode 243: -0.31274715432378114\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSTSBSATRSATBSATRSATOSRSATRSATBSBSATRSATSSATRSATRSBCBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBCSBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBS BCBSBSBSBSHDBSBSBSBS TVBSBSBSBS BCEBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix AMC Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Showtime AMC Showtime Showtime Showtime Netflix AMC Showtime Showtime Netflix Showtime AMC Showtime Showtime Netflix AMC AMC Showtime Showtime Showtime AMC AMC Showtime Showtime ComedyFXFXFXFXFX FXFXFXFXFX HDFXFXFXFX FOXFXFXFXFX XFXFXFXFXXFXFXFXFXfxFXFXFXFX DXFXFXFXFXIXFXFXFXFXBOXFXFXFXFXTVFXFXFXFXXTFXFXFXFXFWFXFXFXFXTWFXFXFXFXFLFXFXFXFXFSFXFXFXFXTRFXFXFXFXCRFXFXFXFXGUIFXFXFXFXPSFXFXFXFXPCTVFXFXFXTV FXFXFXFXTVTVFXFXFXXIXFXFXFXTVXFXFXFXTV FOXFXFXFXTVFoxFXFXFXFXOSFXFXFXFXHDFXFXFXFXPlexFXFXFXFXFCFXFXFXFX MENFXFXFXFX TWFXFXFXFXRSFXFXFXFXBSFXFXFXFXSWFXFXFXFXTwFXFXFXFXFireFXFXFXFXFFXFXFXFXFIFXFXFXFXFRFXFXFXFXSTFXFXFXFX MOFXFXFXFX 101FXFXFXFX XIIFXFXFXFX ReduxFXFXFXFX ESFXFXFXFX DPSFXFXFXFX GEFXFXFXFX TERFXFXFXFX STFXFXFXFX TMFXFXFXFXTERFXFXFXFX CrusaderFXFXFXFX amp CoFXFXFXFX EtcFXFXFXFX OKFXFXFXFX ENFXFXFXFX TRFXFXFXFX ElementalFXFXFXFX GRFXFXFXFX TrFXFXFXFX TRIFXFXFXFX EDITFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXEXFXFXFXFXGEFXFXFXFXIXFXFXFXFXXTFXFXFXFXXFXFXFXFXTXFXFXFXFXUXFXFXFXFXUFFXFXFXFXFLFXFXFXFXFSFXFXFXFXFWFXFXFXFXFAFXFXFXFXFFFXFXFXFXFIFXFXFXFXFEFXFXFXFXFDFXFXFXFXFoxFXFXFXFXFFXFXFXFXFOXFXFXFXFXFOFXFXFXFX FOXFXFXFXFXFGFXFXFXFXFPFXFXFXFXFRFXFXFXFXFCFXFXFXFXSTFXFXFXFXUFCFXFXFXFXGFFXFXFXFXWDFXFXFXFXSWFXFXFXFXTRFXFXFXFXBUTFXFXFXFXMAXFXFXFXFXHDFXFXFXFXSDFXFXFXFXSMFXFXFXFXODFXFXFXFXSonyFXFXFXFXOKFXFXFXFXPSFXFXFXFXDVDFXFXFXFXCDXFXFXFXFScreenFXFXFXFXLCFXFXFXFXATFXFXFXFXAMFXFXFXFXTEFXFXFXFXBOXFXFXFXFXBSFXFXFXFXBlizzardFXFXFXFXFinalFXFXFXFXBladeFXFXFXFXSpeechFXFXFXFXDFXFXFXFXBaywatchFXFXFXFXExFXFXFXFXexFXFXFXFXBuffFXFXFXFXMonsterFXFXFXFXGenFXFXFXFXStarfighterFXFXFXFXMemFXFXFXFXFireFXFXFXFXMFXFXFXFXSFXFXFXFXTFXFXFXFXHolyFXFXFXFXWatchFXFXFXFXBFXFXFXFXMarkFXFXFXFXMoniaFXFXFXFXTrFXFXFXFXChorusFXFXFXFXWarFXFXFXFXVenetFXFXFXFXEleFXFXFXFXSexFXFXFXFXCFXFXFXFXChainFXFXFXFXTWFXFXFXFXTwFXFXFXFXSyllFXFXFXFXSpideFXFXFXFXStFXFXFXFXTriFXFXFXFX FinalFXFXFXFX CinematicFXFXFXFX FuryFXFXFXFXNFXFXFXFXPoFXFXFXFXflixFXFXFXFXTVFXFXFXFXRFXFXFXFXLogFXFXFXFXRuleFXFXFXFX 101FXFXFXFXDiscussionFXFXFXFX VideomeFXFXFXFXVFXFXFXFXRewFXFXFXFXFYFXFXFXFXIFXFXFXFXCalFXFXFXFXOMFXFXFXFXBOFXFXFXFXEVFXFXFXFXVIFXFXFXFXroduFXFXFXFXandFXFXFXFXewFXFXFXFXWWFXFXFXFXAnnFXFXFXFXTechnicallyFXFXFXFXerenceFXFXFXFXFineFXFXFXFXFocusFXFXFXFXCritFXFXFXFXEverythingFXFXFXFX100FXFXFXFXFightingFXFXFXFXaudioFXFXFXFXDialogueFXFXFXFXIdeFXFXFXFX FilmsFXFXFXFXSoundsFXFXFXFXFanFXFXFXFXfireFXFXFXFXtFXFXFXFXOTFXFXFXFXAFXFXFXFXANDFXFXFXFX101FXFXFXFXGRFXFXFXFXHFXFXFXFXUDFXFXFXFXCRFXFXFXFXRemFXFXFXFXFilFXFXFXFXPhFXFXFXFXREFXFXFXFXWikipediaFXFXFXFXWildFXFXFXFXphFXFXFXFXLeagueFXFXFXFXTroFXFXFXFX SciFXFXFXFXGenericFXFXFXFXMasterFXFXFXFX TMFXFXFXFX MEMFXFXFXFX 151FXFXFXFX 102FXFXFXFX 201FXFXFXFX 2001FXFXFXFX FighterFXFXFXFX ReferenceFXFXFXFX DictionaryFXFXFXFXTMFXFXFXFX CompositeFXFXFXFX XIIFXFXFXFX STFXFXFXFX VIFXFXFXFX XFXFXFXFX BFXFXFXFX FoxFXFXFXFX FightersFXFXFXFX etcFXFXFXFX TeeFXFXFXFX... etcFXFXFX 101FWFXFXFX 101fxFXFXFX 101XFXFXFX 101FSFXFXFX 101FoxFXFXFX 101erenceFXFXFX 101FFXFXFX 101FIFXFXFX 101GRFXFXFX 101BFX 101FX 101FX 101erenceFX 101FX 101GRFX 101FX 101FSFX 101FX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFX 101FXFXFX 101fxFXFXFX 101FLFXFXFX 101FSFXFX 101FX FXFXFXFX 101FWFXFX 101FXfxFX 101FXFX FXFXFX 101FXXFX 101FXFX 101FXFSFX 101FXFX101FXFXFX 101 FXFXFX 101 FX FXFX 101FX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0237, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2381, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5352, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7684, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8211, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.9135, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how are you doing?\n",
      "DialoGPT: doing well thanks for you\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6768, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6779, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well too.\n",
      "DialoGPT: That's good to hearthstone.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7637, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6945, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that\n",
      "DialoGPT: That's good hearthrome\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8620, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7562, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well\n",
      "DialoGPT: That's good job well well well well done job job job\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6964, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6230, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1876, 2.1435, 1.8359, 1.4164, 1.0885, 0.7312, 0.3299, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0655, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3260, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4337, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3387, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3646, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4046, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3299, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1876, grad_fn=<UnbindBackward>)\n",
      "Episode 244: -0.31173806643607666\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSTSBSATRSATBSATRSATOSRSATRSATBSBSATRSATSSATRSATRSBCBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBCSBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBS BCBSBSBSBSHDBSBSBSBS TVBSBSBSBS BCEBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix AMC Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Showtime AMC Showtime Showtime Showtime Netflix AMC Showtime Showtime Netflix Showtime AMC Showtime Showtime Netflix AMC AMC Showtime Showtime Showtime AMC AMC Showtime Showtime ComedyFXFXFXFXFX FXFXFXFXFX HDFXFXFXFX FOXFXFXFXFX XFXFXFXFXXFXFXFXFXfxFXFXFXFX DXFXFXFXFXIXFXFXFXFXBOXFXFXFXFXTVFXFXFXFXXTFXFXFXFXFWFXFXFXFXTWFXFXFXFXFLFXFXFXFXFSFXFXFXFXTRFXFXFXFXCRFXFXFXFXGUIFXFXFXFXPSFXFXFXFXPCTVFXFXFXTV FXFXFXFXTVTVFXFXFXXIXFXFXFXTVXFXFXFXTV FOXFXFXFXTVFoxFXFXFXFXOSFXFXFXFXHDFXFXFXFXPlexFXFXFXFXFCFXFXFXFX MENFXFXFXFX TWFXFXFXFXRSFXFXFXFXBSFXFXFXFXSWFXFXFXFXTwFXFXFXFXFireFXFXFXFXFFXFXFXFXFIFXFXFXFXFRFXFXFXFXSTFXFXFXFX MOFXFXFXFX 101FXFXFXFX XIIFXFXFXFX ReduxFXFXFXFX ESFXFXFXFX DPSFXFXFXFX GEFXFXFXFX TERFXFXFXFX STFXFXFXFX TMFXFXFXFXTERFXFXFXFX CrusaderFXFXFXFX EtcFXFXFXFX OKFXFXFXFX amp CoFXFXFXFX ENFXFXFXFX TRFXFXFXFX ElementalFXFXFXFX GRFXFXFXFX TrFXFXFXFX TRIFXFXFXFX EDITFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXEXFXFXFXFXGEFXFXFXFXIXFXFXFXFXXTFXFXFXFXXFXFXFXFXTXFXFXFXFXUXFXFXFXFXUFFXFXFXFXFSFXFXFXFXFLFXFXFXFXFWFXFXFXFXFEFXFXFXFXFAFXFXFXFXFFFXFXFXFXFIFXFXFXFXFOFXFXFXFXFoxFXFXFXFXFOXFXFXFXFXFDFXFXFXFXFFXFXFXFX FOXFXFXFXFXFGFXFXFXFXFRFXFXFXFXFCFXFXFXFXSTFXFXFXFXUFCFXFXFXFXGFFXFXFXFXfoxFXFXFXFXWDFXFXFXFXBUTFXFXFXFXSWFXFXFXFXTRFXFXFXFXMAXFXFXFXFXHDFXFXFXFXSDFXFXFXFXSonyFXFXFXFXSMFXFXFXFXODFXFXFXFXOKFXFXFXFXDVDFXFXFXFXCDXFXFXFXFScreenFXFXFXFXLCFXFXFXFXBOXFXFXFXFXATFXFXFXFXTEFXFXFXFXAMFXFXFXFXBSFXFXFXFXDCFXFXFXFXBlizzardFXFXFXFXFinalFXFXFXFXBladeFXFXFXFXDFXFXFXFXSpeechFXFXFXFXBaywatchFXFXFXFXBuffFXFXFXFXexFXFXFXFXExFXFXFXFXMonsterFXFXFXFXGenFXFXFXFXHolyFXFXFXFXMemFXFXFXFXFireFXFXFXFXMFXFXFXFXSFXFXFXFXTFXFXFXFXWatchFXFXFXFXStarfighterFXFXFXFXMarkFXFXFXFXMoniaFXFXFXFXTrFXFXFXFXWarFXFXFXFXEleFXFXFXFXVenetFXFXFXFXSexFXFXFXFXBFXFXFXFXChorusFXFXFXFXChainFXFXFXFXTriFXFXFXFX FinalFXFXFXFX CinematicFXFXFXFXTwFXFXFXFXTWFXFXFXFXCFXFXFXFX FuryFXFXFXFXPoFXFXFXFXStFXFXFXFXNFXFXFXFXSyllFXFXFXFXLogFXFXFXFXSpFXFXFXFXRuleFXFXFXFX 101FXFXFXFXTechnicallyFXFXFXFXDiscussionFXFXFXFXCalmingFXFXFXFX VideomeFXFXFXFXTVFXFXFXFXroduFXFXFXFXFYFXFXFXFXIFXFXFXFXFightingFXFXFXFXandFXFXFXFXEVFXFXFXFXVFXFXFXFXVIFXFXFXFXOMFXFXFXFXBOFXFXFXFXANDFXFXFXFXAnnFXFXFXFXFineFXFXFXFXRewFXFXFXFXewFXFXFXFXerenceFXFXFXFXFocusFXFXFXFXEverythingFXFXFXFXaudioFXFXFXFX100FXFXFXFXDialogueFXFXFXFXIdeFXFXFXFXCritFXFXFXFXSoundsFXFXFXFXRFXFXFXFXPhFXFXFXFXUDFXFXFXFXDouglasFXFXFXFXfireFXFXFXFXphFXFXFXFXflyingFXFXFXFXtFXFXFXFXAFXFXFXFXDIFXFXFXFXHFXFXFXFXCRFXFXFXFXGRFXFXFXFXCHFXFXFXFXLeagueFXFXFXFX101FXFXFXFXRSFXFXFXFXWikipediaFXFXFXFXOSFXFXFXFXMechFXFXFXFXEFXFXFXFX MEMFXFXFXFXWildFXFXFXFXWWFXFXFXFXUFXFXFXFXMasterFXFXFXFX FighterFXFXFXFX 2001FXFXFXFX2001FXFXFXFXListFXFXFXFXYFXFXFXFXPhilFXFXFXFXynewFXFXFXFWFWFXFXFXFWBCFXFXFXFXTHFXFXFXFXologyFXFXFXFXTMFXFXFXFXREFXFXFXFX SciFXFXFXFX 102FXFXFXFX 201FXFXFXFX 151FXFXFXFX VIFXFXFXFX 2021FXFXFXFX TMFXFXFXFX XIIFXFXFXFX STFXFXFXFX XFXFXFXFX BFXFXFXFX FoxFXFXFXFX TeeFXFXFXFX etcFXFXFXFX... etcFXFXFX 101FWFXFXFX 101XFXFXFX 1019FXFXFXFX WiseFXFXFXFXingFXFXFXFX.FXFXFX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXXXXFXFXFXFXXFXFXFXFXXTFXFXFXFXXXFXFXFXFXEXFXFXFXFXIXFXFXFXFXXYFXFXFXFXFLUXFXFXFXFXUXFXFXFX FXIXFXFXFX FXUXFXFXFX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0147, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1778, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6606, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7191, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Not bad, how's your sister?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7819, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7580, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: She's doing well, how about you?\n",
      "DialoGPT: Not much, she's been busy lately with school stuff but she's doing alright. Yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7392, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8422, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm just busy with school stuff.\n",
      "DialoGPT: That's good to hear. How's your sister doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8149, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: She's good\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5208, 1.4949, 1.1615, 0.7843, 0.3928, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0408, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3450, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3850, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3954, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3928, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5208, grad_fn=<UnbindBackward>)\n",
      "Episode 245: -0.3106368516639965\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSTSBSATRSATBSATRSATOSRSATRSATBSBSATRSATSSATRSATRSBCBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBCSBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBS BCBSBSBSBSHDBSBSBSBS TVBSBSBSBS BCEBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix AMC Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Showtime AMC Showtime Showtime Showtime Netflix AMC Showtime Showtime Netflix Showtime AMC Showtime Showtime Netflix AMC AMC Showtime Showtime Showtime AMC AMC Showtime Showtime ComedyFXFXFXFXFX FXFXFXFXFX HDFXFXFXFX FOXFXFXFXFX XFXFXFXFXXFXFXFXFXfxFXFXFXFX DXFXFXFXFXIXFXFXFXFXBOXFXFXFXFXXTFXFXFXFXFWFXFXFXFXMEFXFXFXFXTVFXFXFXFXTWFXFXFXFXFLFXFXFXFXFSFXFXFXFXTRFXFXFXFXSWFXFXFXFX MENFXFXFXFXGUIFXFXFXFX XIIFXFXFXFX TWFXFXFXFXOSFXFXFXFXRSFXFXFXFXCHFXFXFXFXCRFXFXFXFXSTFXFXFXFXPSFXFXFXFXTwFXFXFXFXCDFXFXFXFXHDFXFXFXFX 101FXFXFXFXBSFXFXFXFXFIFXFXFXFXFCFXFXFXFXFFXFXFXFX FDFXFXFXFXFRFXFXFXFX MOXFXFXFXTWXFXFXFXTV FXFXFXFXTWGEFXFXFXFX GEFXFXFXFXFireFXFXFXFX ReduxFXFXFXFX TMFXFXFXFX ESFXFXFXFX STFXFXFXFX DPSFXFXFXFX TERFXFXFXFXTERFXFXFXFX OKFXFXFXFX EtcFXFXFXFX VideFXFXFXFX amp EtcFXFXTWFXTWFXFXTWFXTVFXFXTWFX TWFXFXTWFX EtnicFXFXFXFX CrusaderFXFXFXFX ElementalFXFXFXFX TrTwFXFXFXTWTWFXFXFXTWFWFXFXFXTWYFXFXFXFX TRFXFXFXFXTrashFXFXFXFX TerricFXFXFXFX GRFXFXFXFXGRFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a party. Party FXFXFXFXFXFX FXFXFXFX FX FXFXFXFXfxFXFXFXFXfx FXFXFXFXFLFXFXFXFXFL FXFXFXFXEXFXFXFXFXEX FXFXFXFXIXFXFXFXFXIX FXFXFXFXXFXFXFXFXXTrixFXFXFXFXxtrixFXFXFXexxFXFXFXFXiestaFXFXFXFXxiFXFXFXFXixFXFXFXFXxxFXFXFXFXflixFXFXFXFXFoxFXFXFXFXFFIXFXFXFXfxFoxFXFXFXfxfxFXFXFXfxXFXFXFXfxSpeechFXFXFXFXFSFXFXFXFXXfxFXFXFXIXfxFXFXFXFoxfxFXFXFXXflixFXFXFXfxBlizzFXFXFXFXSonyFXFXFXFXcreenFXFXFXFXfoxFXFXFXFXetcFXFXFXFXpartyFXFXFXFXXXXFXFXFXFXxxxFXFXFXFXFDFXFXFXFXMAXFXFXFXFXMonsterFXFXFXFXIIFXFXFXFXBlizzardFXFXFXFXBladeFXFXFXFXEdgeFXFXFXFXFinalFXFXFXFXReloadedFXFXFXFXRexFXFXFXFXExpertFXFXFXFXBuffFXFXFXFXFFXFXFXFXSpeechFXFXfxFXfxFXFXfxFXFoxFXFXfxFXBladerFXFXFXFXCloudFXFXFXFXGenFXFXFXFXBluetoothFXFXFXFXStarfighterFXFXFXFXEleFXFXFXFXVenueFXFXFXFXexFXFXFXFXPoFXFXFXFXFireFXFXFXFXChainFXFXFXFXTripleFXFXFXFXVisionFXFXFXFXChorusFXFXFXFXHolyFXFXFXFXMoniaFXFXFXFXSexFXFXFXFXMarkFXFXFXFXMemorialFXFXFXFXicideFXFXFXFXCircleFXFXFXFXSpideFXFXFXFXMicheFXFXFXFXhotFXFXFXFXroducingFXFXFXFXSFXFXFXFXTFXFXFXFXFWFXFXFXFXSTFXFXFXFXFIFXFXFXFXFuFXFXFXFXfireFXFXFXFX FuryFXFXFXFX 101FXFXFXFXRuleFXFXFXFX FinalFXFXFXFX XIIFXFXFXFXTwFXFXFXFXocideFXFXFXFXenariesFXFXFXFXWarFXFXFXFXerenceFXFXFXFX IXFXFXFXFXRFXFXFXFXSWFXFXFXFXStFXFXFXFXWatchFXFXFXFXBFXFXFXFXCFXFXFXFXDiscussionFXFXFXFXCalmingFXFXFXFXologyFXFXFXFXingFXFXFXFX EtudeFXFXFXFX VideographyFXFXFXFXDialogueFXFXFXFXIdeFXFXFXFXSyticsFXFXFXFXDouglasFXFXFXFXDFXFXFXFXFightingFXFXFXFXFYFXFXFXFXRewFXFXFXFXTVFXFXFXFXEFXFXFXFXTWFXFXFXFXFocusFXFXFXFXOKFXFXFXFXewesomeFXFXFXFXEVFXFXFXFXVFXFXFXFXDVDFXFXFXFXEdFXFXFXFXaudioFXFXFXFXTEFXFXFXFX CinematicFXFXFXFX ReduxFXFXFXFX VIFXFXFXFXVIFXFXFXFX VIIFXFXFXFX 2001FXFXFXFX 201FXFXFXFX 151FXFXFXFX101FXFXFXFX 102FXFXFXFX100FXFXFXFXUXFXFXFXFX SciFXFXFXFX TMFXFXFXFXUDFXFXFXFX MEMFXFXFXFX XFXFXFXFX DictionaryFXFXFXFX etcFXFXFXFXOSFXFXFXFXWikipediaFXFXFXFXTMFXFXFXFX CompositeFXFXFXFX... etcFXFXFX 101FWFXFXFX 101XFXFXFX 101fxFXFXFX 1019FXFXFXFXSMFXFXFXFX FighterFXFXFXFX FoxFXFXFXFX SFFXFXFXFX FFFXFXFXFX FAFXFXFXFX STFXFXFXFX 100FXFXFXFX 00FXFXFXFX BFXFXFXFX MFXFXFXFX FightersFXFXFX 101FSFX 101FXFX 101FX 101FXFX FXFX 101FXFX VIFX 101FX 101fx 101FX 101FX 101XFX 101FX 101 101FX 101FX 102FX 101FX 101erenceFX 101FX 101FWFX 101FX 101FS 101\n",
      "User: I always cry at the end.\n",
      "DialoGPT: 101FX 101FX 101EX 101FX 101FX 111FX 101FX 101IX 101FX 101FX 121FX 101FX 101UX 101FX 101FX 131FX 101FX 101XY 101XY 101XY 102FX 101XY 101FX 101XY 102FX 103FX 101XY 101ZX 101XY 101XY 107XY 101XY 101ZX 102XY 101XY 101XX 101XXX 101xxx 101xx 101xxx 101xxx 101xxx 301xxx 101xxx 101xs 101xxx 101xxx 201xxx 101xxx 101xx 301xxx 101xxx 301xx 101xxx 101xx 201xxx 101xxx 301x 101xxx 101xxx 501xxx 101xxx 1010000 101xxx 101xxx 420xxx 101xxx 101000 101xxx 101xxx 151xxx 101xxx 101001 101xxx 101xxx 01xxx 101xxx 101999 0001010 101xxx 101xxx 119xxx 101xxx 101420 101xxx 101xxx 109xxx 101xxx 101xtics 101xxx 101xxx 141xxx 101xxx 1010100 101xxx 101xxx 111xxx 101xxx 1011111 101xxx 101xxx 411xxx 101xxx 1010 101xxx 101xxx 123xxx 101xxx 101010 101xxx 101xx 151xxx 101xxx 201xx 101xxx 101999 101xxx 101xxx 149xxx 101xxx 101licks 101xxx 101xxx 137xxx 101xxx 101x 101xxx 101xx 117xxx 101xxx 1011 101xxx 101xxx 124xxx 101xxx 101tics 101xxx 101xxx 131xxx 101xxx 10114 101xxx 101xxx etcetc 101xxx 101xxx 199999 101xxx 101999 999999 101xxx 101xx 131xxx 101xxx 201x 101xxx 101999 1000xxx 101xxx 1019999999 101xxx 101000 201xxx 101xxx 201999 101xxx 1010000 201xxx 101xxx 151x 101xxx 101000 301xxx 101xxx 20100 101xxx 101xxx 150xxx 101xxx 1014 101xxx 101xxx 139999 101xxx 101x 201xxx 101xxx 141 301xxx 101xxx 151xx 101xxx 101000 151xxx 101xxx 301999 101999 101999 101xxx 201xxx 201xxx 101999 101999 201xxx 101999 201999 101999 101000 101999 101999 301xxx 101999 101000 201999 101999 201999 201999 101xxx 201999 201999 201xxx 101xxx 19909999 101999 1010000 101999 101999 0999 101999 101001 101999 101999 300999 101999 101199999 101999 101159 101999 101999 200999 101999 101enary 101999 101999 99999 101999 1019999 101999 101999 499999 101999 10199999 101999 101500 101999 101999 199999 101999 101555 101999 101999 299999 101999 101 451999 101999 1010 101999 101999 etc 101999 101999 1999 101999 101499999 101999 101 trillion 101999 101999 4999 101999 101 escapes 101999 101999 10000 101999 101999 420999 101999 101tics 101999 101999 999999 201999 101000 101000 101999 201999 301999 101999 201000 101999 101000 301999 101999 301999 101000 1019999 101999 201999 etc 301999 101999 etc 301999 201999 1019999 101000 101999 301999 201999 201000 101000 101000 201999 201999 301000 101999 1019999 301999 101999 1999999 101999 101000 199999 101999 2019999 101999 1019999 201999 101999 301000 101000 1019999 301999 301999 1019999 1019999 101999 301999 301999 301000 1019999 101000 301999 301999 201000 1019999 1019999 301999 201999 3019999 101999 101 301999 301999 etc 301999 301999 199999 301999 301 301999 301999 300999 301999 3019999 301999 301000 301999 301000 201999 301999 301 trillion 301999 301999 299999 301999 301 etc 301999 301 301 301999 301 301000 301999 201999 etc etc 301999 301000 etc 301999 3019999 201999 301999 201 301999 301999 401999 301999 301 299999 301999 2019999 301999 301 3019999 301999 201 301 301999 301000 300999 301999 201 trillion 301999 301 301 299999 301 301999 201999 300999 301 301999 300999 201999 301 301999 299999 201999 301 299999 201999 201 301999 201999 299999 301 301 301 301999 201 3019999 301999 300999 300999 3019999 301 301999 3019999 299999 301999 299 301999 301999 365999 301999 301 2019 301999 301999 400999 301999 301 499999 301999 301. 301999 301999 399999 301999 301499 301999 301\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2466, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4626, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Pretty good thanks for asking me that question. How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6835, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7807, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: That's good to hear. How are you doing?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8371, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8417, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: doing well too, thanks for asking me questions. How are you liking the weather?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8480, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8527, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's nice, it's nice here.\n",
      "DialoGPT: It's raining outside right now.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7649, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8064, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's nice here too.\n",
      "DialoGPT: It\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0226, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0882, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([ 1.7151,  1.5532,  1.1991,  0.7872,  0.3656, -0.0276,  0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1774, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3661, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4198, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4253, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3929, device='cuda:0', grad_fn=<NegBackward>), tensor(-0.0276, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7151, grad_fn=<UnbindBackward>)\n",
      "Episode 246: -0.310097316136727\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSTSBSATRSATBSATRSATOSRSATRSATBSBSATRSATSSATRSATRSBCBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBCSBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBS BCBSBSBSBSHDBSBSBSBS TVBSBSBSBS BCEBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix AMC Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Showtime AMC Showtime Showtime Showtime Netflix AMC Showtime Showtime Netflix Showtime AMC Showtime Showtime Netflix AMC AMC Showtime Showtime Showtime AMC AMC Showtime Showtime ComedyFXFXFXFXFX FXFXFXFXFX HDFXFXFXFX FOXFXFXFXFX XFXFXFXFXXFXFXFXFXfxFXFXFXFX DXFXFXFXFXIXFXFXFXFXBOXFXFXFXFXXTFXFXFXFXFWFXFXFXFXMEFXFXFXFXTVFXFXFXFXTWFXFXFXFXFLFXFXFXFXFSFXFXFXFXTRFXFXFXFXSWFXFXFXFX MENFXFXFXFXGUIFXFXFXFX XIIFXFXFXFX TWFXFXFXFXOSFXFXFXFXRSFXFXFXFXCHFXFXFXFXCRFXFXFXFXSTFXFXFXFXPSFXFXFXFXTwFXFXFXFXCDFXFXFXFXHDFXFXFXFX 101FXFXFXFXBSFXFXFXFXFIFXFXFXFXFCFXFXFXFXFFXFXFXFX FDFXFXFXFXFRFXFXFXFX MOXFXFXFXTWXFXFXFXTV FXFXFXFXTWGEFXFXFXFX GEFXFXFXFXFireFXFXFXFX ReduxFXFXFXFX TMFXFXFXFX ESFXFXFXFX STFXFXFXFX DPSFXFXFXFX TERFXFXFXFXTERFXFXFXFX OKFXFXFXFX EtcFXFXFXFX VideFXFXFXFX amp EtcFXFXTWFXTWFXFXTWFXTVFXFXTWFX TWFXFXTWFX EtnicFXFXFXFX CrusaderFXFXFXFX ElementalFXFXFXFX TrTwFXFXFXTWTWFXFXFXTWFWFXFXFXTWYFXFXFXFX TRFXFXFXFXTrashFXFXFXFX TerricFXFXFXFX GRFXFXFXFXGRFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a party. Party FXFXFXFXFXFX FXFXFXFX FX FXFXFXFXfxFXFXFXFXfx FXFXFXFXFLFXFXFXFXFL FXFXFXFXEXFXFXFXFXEX FXFXFXFXIXFXFXFXFXIX FXFXFXFXXFXFXFXFXXTrixFXFXFXFXxtrixFXFXFXexxFXFXFXFXiestaFXFXFXFXxiFXFXFXFXixFXFXFXFXxxFXFXFXFXflixFXFXFXFXFoxFXFXFXFXFFIXFXFXFXfxFoxFXFXFXfxfxFXFXFXfxXFXFXFXfxSpeechFXFXFXFXFSFXFXFXFXXfxFXFXFXIXfxFXFXFXFoxfxFXFXFXXflixFXFXFXfxBlizzFXFXFXFXSonyFXFXFXFXcreenFXFXFXFXfoxFXFXFXFXetcFXFXFXFXpartyFXFXFXFXXXXFXFXFXFXxxxFXFXFXFXFDFXFXFXFXMAXFXFXFXFXMonsterFXFXFXFXIIFXFXFXFXBlizzardFXFXFXFXBladeFXFXFXFXEdgeFXFXFXFXFinalFXFXFXFXReloadedFXFXFXFXRexFXFXFXFXExpertFXFXFXFXBuffFXFXFXFXFFXFXFXFXSpeechFXFXfxFXfxFXFXfxFXFoxFXFXfxFXBladerFXFXFXFXCloudFXFXFXFXGenFXFXFXFXBluetoothFXFXFXFXEleFXFXFXFXVenueFXFXFXFXexFXFXFXFXPoFXFXFXFXChainFXFXFXFXFireFXFXFXFXFuFXFXFXFXTripleFXFXFXFXVisionFXFXFXFXHolyFXFXFXFXFWFXFXFXFXfireFXFXFXFXFIFXFXFXFXChorusFXFXFXFXSexFXFXFXFXMarkFXFXFXFXMemorialFXFXFXFXicideFXFXFXFX FuryFXFXFXFXMicheFXFXFXFXSFXFXFXFXTFXFXFXFXSTFXFXFXFXSpideFXFXFXFXRFXFXFXFXroducingFXFXFXFXhotFXFXFXFXCircleFXFXFXFX 101FXFXFXFXSWFXFXFXFXCFXFXFXFXRuleFXFXFXFX FinalFXFXFXFXocideFXFXFXFXTwFXFXFXFXerenceFXFXFXFXenariesFXFXFXFX XIIFXFXFXFX IXFXFXFXFX EtcannonFXFXFXFX VideodgersFXFXFXFXologyFXFXFXFXDiscussionFXFXFXFXingFXFXFXFXCalmingFXFXFXFXDialogueFXFXFXFXSyticsFXFXFXFXIdeFXFXFXFXBFXFXFXFXAdFXFXFXFXStFXFXFXFXDouglasFXFXFXFXDFXFXFXFXEFXFXFXFXRewFXFXFXFXDVDFXFXFXFXTVFXFXFXFXewesomeFXFXFXFXFYFXFXFXFXTWFXFXFXFXOKFXFXFXFXFightingFXFXFXFXWatchFXFXFXFXFCFXFXFXFXEVFXFXFXFXVFXFXFXFXTEFXFXFXFX CinematicFXFXFXFXFocusFXFXFXFX ReduxFXFXFXFX VIFXFXFXFX VIIFXFXFXFXVIFXFXFXFX FoxFXFXFXFX TMFXFXFXFX 2001FXFXFXFX 151FXFXFXFX 201FXFXFXFX101FXFXFXFX 2021FXFXFXFX 102FXFXFXFX FighterFXFXFXFX2001FXFXFXFX SciFXFXFXFXaudioFXFXFXFX etcFXFXFXFX100FXFXFXFXWarFXFXFXFXWikipediaFXFXFXFX MEMFXFXFXFX SFFXFXFXFXUXFXFXFXFXUDFXFXFXFXUFXFXFXFXOSFXFXFXFX DictionaryFXFXFXFXSMFXFXFXFX FightingFXFXFXFX ComicsFXFXFXFXTMFXFXFXFX CompositeFXFXFXFX XFXFXFXFX... etcFXFXFX 101FWFXFXFX 101XFXFXFX 101fxFXFXFX 101FSFXFXFX 1019FXFXFXFX FightersFXFXFXFX STFXFXFXFX 00FXFXFXFX FFFXFXFXFX FAFXFXFXFX 100FXFXFXFX BFXFXFXFX CFFX 101FX 101FX 101FSFX 101FX 101XFX 101FX 101fx 101FX 101FXFX 101FX 101 101FX 101FX 102FX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXFLUXFXFXFXFXFAFXFXFXFXFSFXFXFXFXUFFXFXFXFXTXFXFXFXFXFWFXFXFXFXFIFXFXFXFXEXFXFXFXFXFDFXFXFXFXFBFXFXFXFXIXFXFXFXFXFOOLOLOLOLOLFGOLOLOLOLOFOLOFOLOFOFOLOFOLOLOFOLOLOLOFoloFOLOFOLOFoloFFOLOFOLOFolOFOLOFOLFOOLOFOLOFoolOFOLOFOLOYOLOFOLOFOOOLOFOLOFEOOLOFOLOFOOLOFOLOFOUCHOLOFOLOFHOOLOFOLOFCOOLOFOLOFFOOLOFOLFOODOROLOFOLOFSTOLOFOLOFROFLOLOFOLOFFLOLOFOLFOFLOLOFOLOLFOOLFOOLFOFLOLFOOLFOODOLFOOLFOFOOLFOOLFLOLFOOLFLOKFOOLFOOLFCOLFOOLFOMOOLFOOLFOCOOLFOOLFOLCOLFOOLFOLOLFOOLFOPLOLFOOLFOOTCOOLCOOLCOOLOLCOOLCOCOOLCOOL COOLCOOLCO COOLCOCOCOCOCO COOLCO COOL COCOCOCOCOOLCOCOCO COCOCOCO CO COCOCOCO CoCO COCO COCO CO COCO COCOCO COCO COOLCO CoCO CO CO CO CO COCO CO CO COCOCO CO CO CO Co CO CO CO CO CoCO CO COCO Co CO CO COCO CoCO CO Co CO COCO CO Co COCO CO CO Co COCOCO CO Co CO Co CO CO Co CO CoCO COCOCO Co CO COCOCO CoCOCO CO CO CoCOCO COCO Co COCO COCO CoCOCOCO CO CoCO CO CoCOCOCOCO Co COCOCOCOCo CO CO CO COCo CO CO COCOCo CO COCO COCo CO COCOCOCo COCO CO COCo COCO COCOCo COCOCO COCo COCOCOCOco CO CO CO COco CO CO COCOco CO COCO COco CO COCOCOco COCO CO COco COCO COCOco COCOCO COco COCOCOCO co CO CO CO CO co CO CO COCO co CO COCO CO co CO COCOCO co COCO CO CO co COCO COCO co COCOCO CO co COCOCOCO Carbon CO CO CO CO COL CO CO CO CO\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0431, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3548, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6378, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7612, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you??\n",
      "DialoGPT: Fine how bout you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7067, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6960, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you?\n",
      "DialoGPT: Fine, how bout you??\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7636, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8280, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: Fine?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4111, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4869, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Fine, I'm fine\n",
      "DialoGPT: Fine fine fine fine fine fine Fine fine fine fine fine\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7802, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7228, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Fine fine\n",
      "DialoGPT: Fine fine Fine fine fine Fine Fine Fine Fine Fine fine Fine Fine Fine fine fine Fine fine\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8916, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6131, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1032, 2.0239, 1.6910, 1.3538, 0.9654, 0.7483, 0.3763, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0996, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3498, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3507, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3981, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2246, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3763, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1032, grad_fn=<UnbindBackward>)\n",
      "Episode 247: -0.3092483744145401\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period period Period period period period Period Period Period Period Period period period periodperiod period period period periodperiodperiodperiodperiodperiod periodperiodperiodperiod period periodperiodperiod periodperiod periodperiodperiod period period periodperiod Period Period Period Periodperiod Period Period Period period Period Period Period periodperiod Period Period period Period period Period Period\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD? DVD DVD DVD DVD DVD Blu Ray DVD DVD Blu Ray Blu Ray DVD Blu Ray DVD Blu ray DVD Blu Ray DVD blu ray DVD Blu Ray Blu ray DVD Blu ray DVD DVD Blu RayBlu Ray DVD Blu Ray Blu Rays DVD Blu Ray BluRay DVD Blu Ray Bluray DVD Blu Ray DVD BD DVD Blu Ray Blu rays DVD Blu Ray DVD CD BluRABSATVATAATRSATRSATRSATAATRSATSTATRSATRSAMATRSATRSASATRSATRSATSATRSATRSETSATRSATRSCHATRSATRSACRSATRSATTEBSATRSATRSBSATRSATFSATRSATRSTSBSATRSATBSATRSATOSRSATRSATBSBSATRSATSSATRSATRSBCBSBSBSBSBSATBSBSBSBSBBSBSBSBSBCBSBSBSBCSBSBSBSBSBMBSBSBSBSBABSBSBSBSBDBSBSBSBSTVBSBSBSBSBRBSBSBSBS BBSBSBSBS BSBSBSBSBS BCBSBSBSBSHDBSBSBSBS TVBSBSBSBS BCEBSBSBSBS\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Netflix Netflix Netflix Netflix Netflix Netflix Showtime Showtime Showtime Showtime Showtime Netflix Showtime Showtime Showtime Netflix Netflix Showtime Showtime Netflix Showtime Netflix Showtime Showtime Netflix Netflix Netflix Showtime Netflix Showtime Netflix Netflix Showtime Netflix Netflix Netflix Netflix AMC Showtime Showtime Showtime Showtime HBO Showtime Showtime Showtime Showtime AMC Showtime Showtime Showtime Netflix AMC Showtime Showtime Netflix Showtime AMC Showtime Showtime Netflix AMC AMC Showtime Showtime Showtime AMC AMC Showtime Showtime ComedyFXFXFXFXFX FXFXFXFXFX HDFXFXFXFX FOXFXFXFXFX XFXFXFXFXXFXFXFXFXfxFXFXFXFX DXFXFXFXFXIXFXFXFXFXBOXFXFXFXFXXTFXFXFXFXFWFXFXFXFXTWFXFXFXFXTRFXFXFXFXTVFXFXFXFXFLFXFXFXFXFSFXFXFXFXMEFXFXFXFX MENFXFXFXFXGUIFXFXFXFX XIIFXFXFXFX TWFXFXFXFX FDFXFXFXFXOSFXFXFXFX MOFCFXFXFXFX GEFXFXFXFXGEFXFXFXFXRSFXFXFXFXROFXFXFXFXFIFXFXFXFX ROFLFXFXFX MENXFXFXFX MENTEFXFXFXFX FIREFXFXFXFX 101FXFXFXFX TMFXFXFXFX STFXFXFXFX TERFXFXFXFX ESFXFXFXFXTERFXFXFXFX TRTFXFXFXFX DPSFXFXFXFX OKFXFXFXFX ENFXFXFXFX REFXFXFXFX GRFXFXFXFX ReduxFXFXFXFX BRFXFXFXFX FRFXFXFXFX CrusaderFXFXFXFX TRIFXFXFXFX EDITFXFXFXFX TrFRFXFXFXFX RFXFXFXFX\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXFRFXFXFX FX FXFXFXFX FXfxFXFXFX FXFLFXFXFXFXFLFXFXFX FXFWFXFXFXFXIXFXFXFXFXEXFXFXFXFXUXFXFXFXFXFDFXFXFXFXFSFXFXFXFXXFXFXFXFXXTFXFXFXFXFAFXFXFXFXFIFXFXFXFXFFFXFXFXFXFoxFXFXFXFXFOXFXFXFXFX FOXFXFXFXFXFOFXFXFXFXFFXFXFXFXFWFXFXFXFLEEFXFXFXFXFEFXFXFXFXFGFXFXFXFXFCFXFXFXFXGFFXFXFXFXOFFXFXFXFXSTFXFXFXFXFPFXFXFXFXODFXFXFXFX FDFXFXFXFXUFFXFXFXFXWDFXFXFXFXMAXFXFXFXFXOKFXFXFXFXTRFXFXFXFXSWFXFXFXFXSDFXFXFXFXSMFXFXFXFXHDFXFXFXFXBUTFXFXFXFXTEFXFXFXFXTWFXFXFXFXUFCFXFXFXFXBOFXFXFXFXBSFXFXFXFXBuffFXFXFXFXLCFXFXFXFXDPFXFXFXFXFinalFXFXFXFXDVDFXFXFXFXSonyFXFXFXFXGMFXFXFXFXBlizzardFXFXFXFXSpeechFXFXFXFXBladeFXFXFXFXDFXFXFXFXSFXFXFXFXVenetFXFXFXFXBOXFXFXFXFXEVFXFXFXFXGenFXFXFXFXMonsterFXFXFXFXHolyFXFXFXFXMemphisFXFXFXFXMFXFXFXFXFireFXFXFXFXEleFXFXFXFXExFXFXFXFXexFXFXFXFXMoniaFXFXFXFXSexFXFXFXFXSyllataFXFXFXFX FinalFXFXFXFXChorusFXFXFXFX CinematicFXFXFXFX FuryFXFXFXFXTFXFXFXFXCircuitFXFXFXFXRuleFXFXFXFXWarFXFXFXFXChainFXFXFXFXPoFXFXFXFXTwFXFXFXFXTechnicallyFXFXFXFXTrFXFXFXFXTriFXFXFXFXStFXFXFXFXNFXFXFXFXVIFXFXFXFXLogicFXFXFXFX VideodFXFXFXFXroduFXFXFXFX 101FXFXFXFXaudioFXFXFXFXBFXFXFXFX EtudeFXFXFXFXDiscussionFXFXFXFXDialogueFXFXFXFXIdeFXFXFXFXFocusFXFXFXFXEFXFXFXFXIFXFXFXFXFYFXFXFXFXPhFXFXFXFXTVFXFXFXFX FilmsFXFXFXFXEverythingFXFXFXFXerenceFXFXFXFXCritFXFXFXFXCalFXFXFXFXCFXFXFXFXFineFXFXFXFXandFXFXFXFXFightingFXFXFXFXRewFXFXFXFXSpFXFXFXFX100FXFXFXFXSoundsFXFXFXFXphFXFXFXFXFilFXFXFXFXFanFXFXFXFXtFXFXFXFXfireFXFXFXFXcreenFXFXFXFXAFXFXFXFXANDFXFXFXFXWatchFXFXFXFXMarkFXFXFXFXfilmFXFXFXFXMovieFXFXFXFX MovieFXFXFXFX FilmFXFXFXFX TMFXFXFXFXRatedFXFXFXFX 2001FXFXFXFX2001FXFXFXFX101FXFXFXFX SciFXFXFXFXWikipediaFXFXFXFXTMFXFXFXFX MEMFXFXFXFX 151FXFXFXFX 102FXFXFXFX 201FXFXFXFX FighterFXFXFXFXGRFXFXFXFX XIIFXFXFXFX CompositeFXFXFXFX MenuFXFXFXFX FightingFXFXFXFX DictionaryFXFXFXFX ReferenceFXFXFXFX ComicsFXFXFXFX VIFXFXFXFX MeleeFXFXFXFX FoxFXFXFXFX FightersFXFXFXFX etcFXFXFXFXOSFXFXFXFX StrategyFXFXFXFX... etcFXFXFX 101fxFXFXFX 101FWFXFXFX 101FFXFXFX 101FoxFXFXFX 101FightingFXFXFX 101XFXFXFX 101erenceFXFXFX 101FSFXFXFX 101GRFXFXFX 101 101FXFXFX 101FIFX 101FX 101FX 101erenceFX 101FX 101FightingFX 101FX 101FoxFX 101FX 101 101FX 101FXFX 101FX 101FWFX 101FX 101GRFX 101FX 101FFX 101FX 101\n",
      "User: I always cry at the end.\n",
      "DialoGPT: 101FXFX 101FXFX 111FX 101FX 101fx 101FX 101FX 111FX 101 FX 101FX 101FX 102FX 101FX 101FS 101FX 101FX 107FX 101FX 101EX 101FX 101FX 103FX 101FX 101IX 101FX 101FX 109FX 101FX 101XFX 101FX 101XY 101XY 101XY 102 ECHOLOLOLOLOLEOOLOLOLOLoloOLOLOLOLololoOLOLOLolooloOLoloOLoloOLOLoloOLoloolooloolooloOLolooloOLOLoloolooloOLOLOLomoolooloolooloLoOLolooloolooliolooloolooloingoolooloolooloollolooloolooloingoloolooloolohololooloolooloongoolooloolooloesoloolooloolo HOLOLoloolooloholicsolooloolooloologooloolooloolooboloolooloolobingoloolooloolostopoloolooloolooneolooloolooloeditoloolooloolohodolooloolooloholeolooloolooloforewordoloolooloolohomoloolooloolohotolooloolooloassoloolooloolooutoloolooloolopooloolooloolobolooloolooloploloolooloolobololoolooloolobonoloolooloolobullolooloolooloballsoloolooloolocoolooloolooloboroloolooloolobaoloolooloolocoloolooloologooloolooloolobrooloolooloolotriolooloolooloboolooloolooloomooloolooloholomoolooloolohodongooloolooloholodolooloolooloholoolooloolohopolooloolooloheatolooloolooloomeoloolooloolohitolooloolooloetooloolooloolocirclebrooloolooloholocaustoloolooloolospoloolooloolohooloolooloolosoolooloolooloomoloolooloolohellolooloolooloooooooooolooloolooloppolooloolooloPoolooloolooloshitoloolooloolooooolooloolooloscaroloolooloolobeoloolooloolooooooloolooloolo\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1719, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3856, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5812, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6904, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: That's perfect!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6525, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6071, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: That's good!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7760, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6593, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy\n",
      "DialoGPT: That's great! smiles back to back tootsie rolls off into the sunset sunset\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7623, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4959, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: smiles back\n",
      "DialoGPT: back to the sunset smiles back to the sunset smiles backs away\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8852, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6160, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: smiles back to the sunset\n",
      "DialoGPT: backs away back to backs away back to backs back to backs away backs\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7984, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6963, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.1223, 2.0028, 1.7019, 1.4009, 1.0525, 0.7454, 0.3738, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.1394, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3180, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3150, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3589, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3146, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3754, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3738, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.1223, grad_fn=<UnbindBackward>)\n",
      "Episode 248: -0.3085664058306131\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period periodperiod period period period period theater period theater period theater theater period theater period theatre period theater period theater cinema period theater period theater movie period theater period theater movies period theater period theater films period theater period theater dates period theater dates period cinema dates period cinema dates cinema dates cinema dates period cinema date cinema dates cinema dates\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD Blu ray DVD Blu Ray DVD Blu Ray DVD blu ray Blu Ray Blu Ray Blu Ray DVD Blu ray Blu Ray Blu ray Blu Ray DVD Blu Rays Blu Ray Blu RayBlu RayBlu RayBlu rayBlu rayBlu ray Blu rayBlu rayBlu RayBlu ray Blu ray Blu rayBlu RayBlu Ray Blu rayBlu ray Blu RayBlu rayBlu Ray Blu ray Blu ray blu ray blu ray blu roflacco roastingburstscreenrobebinghammershitchenemiespellingshottinggershotspotsuckshittershitgershitgershitgershowertreeshitgershitgerscreenmakershitgershitgershirebsandsuckshitgershitgershiteshitgershitgerswordsmithsuckshitgerscreenwriterscreenwriterscreenwritersandcerscreenwriterscreenwritersliteragerscreenwriterscreenwritersfilmwriterscreenwriterscreenwritingwriterscreenwriterscreenwriterwriterscreenwriterscreencreatorscreenwriterscreenwriterswriterscreenwriterscreentesterscreenwriterscreenwritersracebackscreenwriterscreenwriterspeoplecreenwriterscreenwriterscriticalscreenwriterscreenwriterswritingwriterscreenwriterswriterswriterscreenwriterswritersliteraterscreenwriterscreenwritersitlescreenwriterscreenwriterstheirselvescreenwriterscreenwritersakespearewriterscreenwriterscreengerscreenwriterscreenwritinggerscreenwriterscreengerswriterscreenwriterscreenfighterscreenwriterscreenwritersassigngerscreenwriterscreenwritergerscreenwriterscreenlitergerscreenwriterscreen Editorscreenwriterscreenwritersandscreenwriterscreenwriterstvwriterscreenwriterscreenliteritorscreenwriterscreenwritersfictionwriterscreenwriterscreenflixwriterscreenwriterscreenitlescreenwriterscreenwritingjobscreenwriterscreenwriters editorscreenwriterscreenwritersdotwriterscreenwriterscreenviewwriterscreenwriterscreencreenwriterscreenwriterseditwriterscreenwriterscreen Editorsoftroducerscreenwriterscreenwritingcreenwriterscreenwritershirewriterscreenwriterscreenlivingwriterscreenwriterscreenwordscreenwriterscreenwriterslivewriterscreenwriterscreenshotscreenwriterscreenwritershotwriterscreenwriterscreenrotegerscreenwriterscreenitleswriterscreenwriterscreen editorscreenwriterscreenwriting editorscreenwriterscreengersitlescreenwriterscreengershotwriterscreenwriterswritersitlescreenwriterswriterscreenwritingwriterswriterscreenwritersitleswriterscreenwriterswritersandscreenwriterswriterscreengerscreenwritingwriterscreenwritingwritersitlescreenwritersitlescreenwritingwriterscreengerscreengerscreenwriterswriterscreenitlescreenwritingwriterswriterswriterscreenwritinggersitlescreenwriterswriterswriterswriterscreengersitleswriterscreenwritersitlesitlescreenwriterscreenitlesitlescreenwriterswritersitleswriterscreenwritingwritersandscreenwritersitlescreengerscreenwritersitlescreenitlescreenwriterswritersandsigngerscreenwriterswriterswritersitlescreenwritinggerscreenwritingwriterswritersitlescreengersitlescreenwritingwritersitlesitlescreenwritingwritersandsigngersitlescreenwritersitlesitlesitlescreenwritersitleswriterswriterscreenwriters editorswriterscreenwriterscreen readerscreenwriterscreenwriters idiotscreenwriterscreenwriters Editorscreenwriterscreenwritingitlescreenwriterscreen Editorsitlescreenwriterscreen editorswriterscreenwriterswriters editorscreenwriterswriterscreen Editorscreen Editorscreenwriterswriterscreen editorscreen Editorscreenwriters editorscreen Editorscreen Editorsitlescreen Editorscreenwritersitlescreen Editorscreen Editors Editorscreenwriterscreen Editors Editorscreen Editorscreen Editors editorscreenwriterscreen Editors editorscreen Editorscreen editorscreenwriters editorscreen editorscreenwriters Editorscreen editorscreen editorscreen editors editorscreenwriters editors editors editors editors editorscreenwriterscreen editors editors editors editors Editors editors editors editors editors idiotscreenwriters editors editorscreenwriters Editors editors editors editorscreen editors editors editorscreen Editors editors editors editors Editors Editors editors editors editors idiots idiots idiots idiots idiotsitles editors editors editors editors\n",
      "User: Let's go to your home.\n",
      "DialoGPT: LET'S GO HOME LET'S GO HOMELET'S GOHOMELET'S GOhomeLET'S HOMELET LET'S HOMELET'S HOME LET'S HOME LETS HOMELET'Z HOME LET'Z HOME LETZ HOME LET'S HomeLET'Z HOMELET'Z HomeLET'Z Home LET'Z\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Homelet let's homeletlets homeletlets homeletsletlets homeletletlets homeletletes homeletletes homeleteletes homeletletes homesletletes homeletlets homelettletes homeletletes Homeletletes Homeletzos Homeletzos HomeLETzos HomeLETzos HOMELETzos HomeLETzo HomeLETzo HomeLEEDAMADOGEGAPESSSISNTMEATRSURNS UPTWOOTTELLUPBYME DOWNROOTME DOWNROOTTEBSEGASIDE DOWNROOTTEEMTEBSEGTEBSEGTEEGTEEGTEBSEGEGTEEGTEEMTEEGTEEGEGTEEGEGEGTEEGTVTEEGTEEGTVEGTEEGTETEEGTEEGBEEGTEEGTETVEGTEEGEGTVEGTETEEGTVEGTVEGTETVEGTVEGTVTEEGTVEGEGTEEGTWEGTEEGTEBDTEEGTEEGTWTEEGTEEGtvEGTEEGTEBCTVEGTVEGEGTVEGTVTVEGTVEGTWEGTVEGTVEVTVEGTVEGtvEGTVEGTVGETVEGTVEG TVEGTVEGTV TVTVEGTVEGBSTVTVTVTVTVEGTVTVTVTVTETVTVTVTVEVTVTVTVTV TVTVTVTVTVBSTVTVTVTEBSTVTVTVEGTETVTVTVTE TVTVTVTVTETETVTVTV TVEVTVTVTVTEEVTVTVTVEVTETVTVTVEV TVTVTVTVEVEVTVTVTV TVTETVTVTV EVTVTVTVTV EVEVTVTVTV EVTETVTVTV\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're winning. Tears of joy are shed every time they lose a game or two. Especially when they win against us in playoffs. cries uncontrollably tears of joy ensue sobbing intensifies cries intensify cries intensify cries intensify weeping intensifies cries intensifiers cries intensifiers cries intensify cries intensifiers cries intensified cries intensifiers cries exponentially cries exponential cries intensitiesandsaysandsandsandsandsandsandbackslashmyshotsandsandsandsandslashandslashandslashlightslashandslashandswordslashandslashandscreenourslashandslashandshellslashandslashandscriptureslashandslashandsigniteslashandslashandsrageandslashandslashandfallslashandslashandshiretslashandslashandsreshandslashandslashlashandslashandsheatandslashandslashlestaughslashandslashandshottinglashandslashandsfireflieslashandslashlashlashlashlashandslashlashfireslashlashlashlashandrageandslashlashlashandsrageandsrageandslashlashandsragelashlashlashlashtitleslashlashlashlashreportandslashlashlashreportreportreportreportreportandslashreportreportreportandsragereportreportreportreportReportreportreportreportreport reportreportreportreportreportreportsreportreportreportreportfailreportreportreportreportreportedreportreportreportreportclickreportreportreportreportsupportreportreportreportreportbackreportreportreportreportofreportreportreportreportagainreportreportreportreportthenreportreportreportreportescapereportreportreportreportfirereportreportreportreportablereportreportreportreportbackslashreportreportreportReportReportreportreportreportReport reportreportreportreportReport Reportreportreportreportreport ReportreportreportreportReportbackreportreportreportReportbackslashreportreportReportreportReportreportreportReportreport reportreportreportReportreportreportedreportreportReportreport ReportreportreportReportreportbackreportreportReportreportreportsreportreportReportreport\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.2749, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0645, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6246, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7788, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Great, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8471, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8277, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking!\n",
      "DialoGPT: That's good! Glad to hear that's all settled down well enough for you to be able to sleep well enough.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7520, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8066, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing great!\n",
      "DialoGPT: That's alright, thanks for you too!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7791, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7467, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: Of course\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5122, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4802, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8234, 1.7560, 1.4193, 1.0106, 0.6272, 0.2482, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0849, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3509, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4188, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3897, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3815, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2482, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8234, grad_fn=<UnbindBackward>)\n",
      "Episode 249: -0.3076718398332596\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible period. Period. Period. Period period period period period periodperiod period period period period theater period theater period theater theater period theater period theatre period theater period theater cinema period theater period theater movie period theater period theater movies period theater period theater films period theater period theater dates period theater dates period cinema dates period cinema dates cinema dates cinema dates period cinema date cinema dates cinema dates\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD Blu ray DVD Blu Ray DVD Blu Ray DVD blu ray Blu Ray Blu Ray Blu Ray DVD Blu ray Blu Ray Blu ray Blu Ray DVD Blu Rays Blu Ray Blu RayBlu RayBlu RayBlu rayBlu rayBlu ray Blu rayBlu rayBlu RayBlu ray Blu ray Blu rayBlu RayBlu Ray Blu rayBlu ray Blu RayBlu rayBlu Ray Blu ray Blu ray blu ray blu ray blu roflacco roastingburstscreenrobebinghammershitchenemiespellingshottinggershotspotsuckshittershitgershitgershitgershowertreeshitgershitgerscreenmakershitgershitgershirebsandsuckshitgershitgershiteshitgerscreenwriterscreengerscreengerscreengershitgerscreengerscreenwriterscreenwriterscreenwritersandcerscreenwriterscreenwritersliteragerscreenwriterscreenwritersfilmwriterscreenwriterscreenwritingwriterscreenwriterscreenwriterwriterscreenwriterscreencreatorscreenwriterscreenwriterswriterscreenwriterscreentesterscreenwriterscreenwritersracebackscreenwriterscreenwriterspeoplecreenwriterscreenwritersmenitorscreenwriterscreenwritersitlescreenwriterscreenwritersjobscreenwriterscreenwriterstheirselvescreenwriterscreenwriterslivewriterscreenwriterscreengersmithscreenwriterscreenwriterstvwriterscreenwriterscreenwordscreenwriterscreenwritersassholescreenwriterscreenwritershirewriterscreenwriterscreenfighterscreenwriterscreenwritersandscreenwriterscreenwritersdotwriterscreenwriterscreen Editorscreenwriterscreenwriterseditgerscreenwriterscreenwritinggerscreenwriterscreenwritergerscreenwriterscreencreenwriterscreenwriterswritingwriterscreenwriterswriterswriterscreenwriterswritersandrewwriterscreenwriterscreencreenwritingwriterscreenwritingwriterswriterscreenwritersandrowriterscreenwriterscreen editorscreenwriterscreenwritersigngerscreenwriterscreenitlescreenwriterscreenwritingcreenwriterscreenwritersakespearewriterscreenwriterscreenitleswriterscreenwriterscreenviewwriterscreenwriterscreenlivingwriterscreenwriterscreenlitergerscreenwriterscreen Editorsandgerscreenwriterscreenliteraterscreenwriterscreenwritersfictionwriterscreenwriterscreenflixwriterscreenwriterscreenacherscreenwriterscreenwriterscriptwriterscreenwriterscreenrotegerscreenwriterscreencreatgerscreenwriterscreen editorswriterscreenwriterscreen readerscreenwriterscreenwriters editorscreenwriterscreengersitlescreenwriterscreengershotwriterscreenwriterscreenroomscreenwriterscreenwriters idiotscreenwriterscreenwriters Editorscreenwriterscreengerswriterscreenwriterscreenitorscreenwriterscreengersandgerscreenwriterswriterscreengerscreenwriterswriterswriterswriterscreengersitleswriterscreenwriterswritersandscreenwriterswriterscreenwritingwritersandscreenwritersandscreengerscreenwritersandscreenwritingwriterscreengerscreenwritingwriterscreen Editorscreengerscreenwriters editorscreengerscreenwritersitlescreengerscreenwritersandgerscreenwritersandsigngerscreenwriterswritersandsigngersitlescreenwriterswriterscreen Editorscreen Editorscreenwriterswriterscreen editorscreengerscreengersitlescreengerscreengerswriterscreengerscreen Editorscreenwriters editorscreen Editorscreenwriters Editorscreengerscreengersandgersitlescreenwriters editorscreen editorscreenwriters editorscreenwritingwriterscreen editorscreen editorscreen editors editorscreenwriterscreen editors editorscreen editorscreen Editorscreen editorscreenwriterswriterscreen readerscreen editorscreenwriters Editorscreen editorscreen editorswriterscreen editorscreen Editors\n",
      "User: Let's go to your home.\n",
      "DialoGPT: LET'S GO HOME LET'S GO HOMELET'S GOHOMELET'S GO BACK HOMELET'S HOMELET'S BACK HOMELET'FS HOMELET'FS BACK HOMELET'BS HOMELET'FSBACK HOMELET'FSHOMELET HOMELET'FShomeLET'FSBACKHOMELET'FSBACKBACK HOMELET TEAMSpeechotleceanheathenewormorphorehawkspelloutothawkhawksfanningeradohawkhawksfanfarelduckhawksfanfarehawksfanfarehawkshawhawksfanfarehawkshawksfanfarehawksflyhawksfanfarehawksbucksfanfarehawksfanflyhawksfanfarehawkhawksfanfarehawkshawkhawksfanfarehawkhawkhawksfanfarebackhawksfanfarehawkswinghawksfanfarehawksawksfanfarehawksfanFlyhawksfanfarehawks hawkhawksfanfarehawksstrikehawksfanfarehawkshirehawksflyhawksflyhawksflybackslashhawksflyhawksflyfliesflyhawksflyhawksfanflyhawksflyhawkshawksflyhawksflyflyhawksflyhawkshawkhawksflyhawksflyhawkhawksflyhawkshawkshawksflyhawkshawksflyingflyhawksflyhawksfliesflyhawksflyflyflyhawksflyflyfliesflyhawksfliesflyflyhawksflyflieshitgersflyflyflyflyflyhawksfliesflyfliesflyflyflyflyfliesflyflyhawksfliesFlyhawksflyflyflyflybacksflyflyflyflyballsflyflyflyflygersflyflyflyfliesFlybacksflyflyflyfliesfliesflyflyflyfliesflyingflyflyflyfly fliesflyflyflyflyFlybacksflyflyfliesflyfliesflyfliesFlybacksflyingflyflyflyfliesstrikeflyflyflyflybackflyflyflyflybeesflyflyflyflyawaysflyflyflyflyinalsflyflyflyflyflyingflyflyflybacksflyingflyflybacksflybacksflyflybacksflyfliesflybacksflybacksflyingflybacksflybackspringfliesflybacksflyflyfliesfliesfliesflybacksflyfliesfliesflybacksflyingflyfliesflybacksflyingbacksflybacksflybacksfliesflybacksflygersflybacksflybacksFlybacksflybacksflyfliesbacksflybacksflygersfliesflybacksflybackbacksflybacksflybackfliesflybacksflyballsflybacksflybacksbacksflybacksflyballsfliesflybacksfly fliesbacksflybacksfly fliesbackbacksflybacksflyingbacksflyingbacksflybackbacksflyingbacksflygersflybackbacksflybackbacksbacksflybacksbacksbacksflybacksflyingbackbacksflybacksbacksflyingbacksflyfliesbacksbacksflybacksbackbacksflybacksbackfliesbacksbacksbacksbacksbacksflybackbacksbackbacksbacksbacksbacksbackbacksbacksbackbacksbackbacksbackbackbacksbacksbacksbackbackbacksbackbacksflybackbackbacksbacksbackbackbackbacksbacksflybackbackbackbacksbackbackbackbackbacksflybackspringbacksbacksbacksbackspringbacksbacksbackbacksflygersbacksbacksbacksbacksflyingbacksbacksbacksbacksfliesbacksbacksbacksbackfliesbacksbackbacksbacksflygersbacksbackbacksbackspringbacksbackbacksbacksflyingbacksbackbacksbacksonsbacksbacksbacksbacksonsbacksbackbacksbacksfliesbacksbackbacksbackgersbacksbacksbacksbackgersbacksbackbacksbackfliesbackspringbacksbackspringbackspringbacksbacksflybackspringbackbacksbacksbackspringbackbacksbackbackspringbacksbacksonsbackspringbacksbacksfliesbackspringbacksbackbackbackspringbacksbackgersbackspringbacksbacksfirebacksbacksbacksbacksgersbacksbacksbackspringgersbacksbacksbacksonsbackbacksbacksbacksonspringbacksbacksbacksbackballsbacksbacksbacksbacksplbacksbacksbacksbacksballsbacksbacksbacksbackbirdsbacksbacksbacksbacksfirebacksbackbacksbacksgersbacksbackbackspringbackbackspringbackspringbackbacksonsbacksbacksbackbackspringgersbacksbackbacksonsbacksbackbackbacksonsbackspringbackbacksgersbacksbacksbackbacksonsbackbacksbackbacksonspringbacksbackbacksbackballsbacksbackbacksbacksbachbacksbacksbacksbacksbachbacksbackbacksbacksfirebackspringbacksbacksgersbackspringbacksbackballsbackspringbacksbacksbullbacksbacksbacksbacksbullbacksbackbacksbacksbullbackspringbacksbacksbachbackspringbacksbacksbbacksbacksbacksbacksbbacksbackbacksbacksballsbacksbackbacksbackingbacksbacksbacksbacksagainbacksbacksbacksbacksballbacksbacksbacksbacks etcbacksbacksbacksbackswordsbacksbacksbacksbacksBACKbacksbacksbacksbackstribacksbacksbacksbacksinalsbacksbacksbacksbackshirebacksbacksbacksbackstobacksbacksbacksbacksagainstbacksbacksbacksbacksfiresbacksbacksbacksbacksspacebacksbacksbacksbacksdownbacksbacksbacksbacksingbacksbacksbacksbackfirebacksbacksbacksbackspacebacksbacksbacksbackingbacksbackbacksbacksBACKbacksbackbacksbackswordsbacksbackbacksbacksagainbacksbackbacksbacksbbackspringbacksbacksBACKbackspring\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Backspacebacksbackbacksbackbacksbackbackbacksbackbacksbacksbackbackbacksbacksbackbacksbackwordsbackbacksbackbackswordsbackbacksbackwordsbacksbackwordsbackwordsbackwordsbackswordsbackwordsbackwordwordsbackwordsback wordsbackwordsbackwordswordsbackwordsbackWordsbackwordsbackwordsbonuswordswordswordswordswords    s   d   DUCK   EEEe   HADE   SONG  EBS  ELL  EBS EBS  DAT  EBS DAW  EBS JEE EBS EBS EBS DUB EBS EBS JEE BEE EBS EBD EBS EBS BEE EBS JEE JEE EBS JEM EBS EBS ESBD EBS EBD JEE EBS DEE EBS EBC EBS EBS JOBS EBS EBD DAE EBS EBS WEBS EBS EEE EBS EEE JEE EBD EBS JEEBS EBS ESS EBS EBS UBS EBS EBR EBS EBS\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Me too man, me too. Tears of joy when they finally get it together and start winning games again. Then tears of sadness when they lose them all away to Kansas City.\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0848, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1754, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: doing well thanks for asking\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5183, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6521, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's good!\n",
      "DialoGPT: yeah i'm doing well thanks for asking me that question though\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8168, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6856, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7201, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8242, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well\n",
      "DialoGPT: yeah yeah yeah yeah yeah yeah yea yeah yeah yeah yeah Yeah yeah yeah yeah yeah yayayayayayyyyyyyyyyyyayyyyyyyyyeaaaahhhhhhhhhhhhhhhhhhhhhhhh\n",
      "r1: tensor(-0.0008, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5774, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6376, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.3899, 1.3381, 1.0560, 0.6871, 0.3040, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0652, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2927, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3861, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3040, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.3899, grad_fn=<UnbindBackward>)\n",
      "Episode 250: -0.30670595133447076\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. It's a masterpiece if anything else comes out of it though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Sounds like fun!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Yeah, that's why I'm crying right now too... cries uncontrollably inside of his chest cavity cavity cavity cavity cavity coffin cavity cavity cavity cavity holehole hole hole hole hole hole holes hole hole hole holehole hole hole holes hole holes hole holes holes holes holes holes hole holes holes hole holes holeholes holes holes holes holesholes holes holes holesholesholes holes holes holes rings Rings Rings Rings Rings Rings rings rings rings rings rings ring rings rings rings rings Rings rings rings rings Rings Rings rings rings Rings rings Rings rings rings Rings Rings Rings rings Rings rings Rings Rings rings Rings Rings Rings Ring rings rings rings rings Ring rings rings rings Rings ring rings rings rings Rings Ring rings rings Rings rings ring rings rings Rings rings Ring rings rings Rings Rings ring rings rings Rings Rings Ring rings Rings rings rings ring rings Rings rings rings Ring rings Rings rings Rings ring rings Rings rings Rings Ring rings Rings Rings rings ring rings Rings Rings rings Ring rings Rings Rings Rings ring rings Rings Rings RingsRing rings rings rings rings Rod rings rings rings rings\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0098, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0544, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. Yourself?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7258, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6559, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you?\n",
      "DialoGPT: Fine fine, thanks for asking me anything else?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8917, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7638, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not really, I'm just bored.\n",
      "DialoGPT: That's fair enough. Well, that's that then. Good day then. Bye then. Bye bye bye bye bye bye Bye Bye Bye Bye Bye bye bye bye Bye bye bye byebyebye Bye bye bye bye goodbye bye bye bye byebye bye bye\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7959, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6859, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1235, 1.1186, 0.7808, 0.3705, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0161, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3456, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4140, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3705, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1235, grad_fn=<UnbindBackward>)\n",
      "Episode 251: -0.30555275494291906\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. It's a masterpiece if anything else comes out of it though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Sounds like fun!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Yeah, that's why I'm crying right now too... cries uncontrollably inside of his chest cavity cavity cavity cavity cavity coffin cavity cavity cavity cavity holehole hole hole hole hole hole holes hole hole hole holehole hole hole holes hole holes hole holes holes holes holes holes hole holes holes hole holes holeholes holes holes holes holesholes holes holes holesholesholes holes holes holes rings Rings Rings Rings Rings Rings rings rings rings rings rings ring rings rings rings rings Rings rings rings rings Rings Rings rings rings Rings rings Rings rings rings Rings Rings Rings rings Rings rings Rings Rings rings Rings Rings Rings Ring rings rings rings rings Ring rings rings rings Rings ring rings rings rings Rings Ring rings rings Rings rings ring rings rings Rings rings Ring rings rings Rings Rings ring rings rings Rings Rings Ring rings Rings rings rings ring rings Rings rings rings Ring rings Rings rings Rings ring rings Rings rings Rings Ring rings Rings Rings rings ring rings Rings Rings rings Ring rings Rings Rings Rings ring rings Rings Rings RingsRing rings rings rings rings Rod rings rings rings rings\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0102, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0739, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: I'm doing hereticously good today. How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5472, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5924, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Not bad.\n",
      "DialoGPT: That's good. How are you doing today?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8754, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5045, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: That's great. How are you're doing well?\n",
      "r1: tensor(-0.0016, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9127, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6488, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(7.8002e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine.\n",
      "DialoGPT: That's wonderful. Glad to hearin'bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7742, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6536, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am too.\n",
      "DialoGPT: So glad to hear that. How are hereticous smiles widely smiles widely and smiles broadly\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8607, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6839, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6888, 1.7270, 1.4566, 1.1228, 0.7394, 0.3862, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.0209, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2850, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3450, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3907, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3570, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3862, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6888, grad_fn=<UnbindBackward>)\n",
      "Episode 252: -0.304262232366699\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. It's a masterpiece if anything else comes out of it though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal! Deal! Deal! deal! Deal! Deal Deal! Deal! Deals! Deal! Deal deals with groceries deals with groceries deals buys groceries deals with groceries drinks drinks snacks drinks drinks drinks drinks drinks etc etc etc etc etcetc etc etc etc etc ect etc etc etc etc EtceteraeroqueenoasthemagicatusadohemachinehedromeetheusothreeganoisemeekethroughdowncastrobeldromeakespeareakespeareakespeareakespeareakespearecreenflixakespeareakespeareakespeareakespeareakesperevengefulakespeareakespeareakespeareakespearefilmakespeareakespeareakespeareakespeareTVakespeareakespeareakespeareakespeareFXakespeareFXFXFXFXFXakespeareFXFXakespeareFXakespeareFXakespearefxFXFXFXFX ShakespeareFXFXFXFXTVFXFXFXFXFoxFXFXFXFXIXFXFXFXFXScriptFXFXFXFXTWFXFXFXFXTwFXFXFXFXXFXFXFXFXLiveFXFXFXFXfxFXFXFXTVFoxFXFXFXTVTVFXFXFXTVFireFXFXFXFXTRFXFXFXFXSWFXFXFXFXFWFXFXFXFX FXFXFXFXFXFireFXFXFXTVfxFXFXFXTWTWFXFXFXTVTWFXFXFXTWPGFXFXFXFXTFXFXFXFXOKFXFXFXFXOSFXFXFXFXTEFXFXFXFX TWFXFXFXFXPCFXFXFXFXGRFXFXFXFX MENFXFXFXFX TVFXFXFXFX FOXFXFXFXFX FoxFXFXFXFX ESFXFXFXFXFSFXFXFXFX\n",
      "User: I always cry at the end.\n",
      "DialoGPT: FXFXFXFXFX FXFXFXFXFXfxFXFXFXFXEXFXFXFXFXXFXFXFXFXIXFXFXFXFXXTFXFXFXFXFLFXFXFXFXUXFXFXFXFXFWFXFXFXFXFOXFXFXFXFXTXFXFXFXFXFDFXFXFXFXDXFXFXFXFX XFXFXFXFXFoxFXFXFXFXFOFXFXFXFXFAFXFXFXFXFFFXFXFXFXOFFXFXFXFXFFXFXFXFXFIFXFXFXFXFEFXFXFXFXFGFXFXFXFXGFFXFXFXFXFCFXFXFXFXGEFXFXFXFXFRFXFXFXFXSTFXFXFXFXWFFXFXFXFXWDFXFXFXFXUFFXFXFXFXHDFXFXFXFXLCFXFXFXFXSWFXFXFXFXTRFXFXFXFXSDFXFXFXFXESFXFXFXFXBUTFXFXFXFXTEFXFXFXFXBSFXFXFXFXTWFXFXFXFXSMFXFXFXFXSTDFXFXFXFXODFXFXFXFXOKFXFXFXFXCDFXFXFXFXPSFXFXFXFXGMFXFXFXFXMAXFXFXFXFXPOSFXFXFXFXOSFXFXFXFXBOOTFXFXFXFXATFXFXFXFXAGFXFXFXFXSonyFXFXFXFXDVDFXFXFXFXSpeechFXFXFXFXSexFXFXFXFXBOXFXFXFXFXSFXFXFXFXBladerFXFXFXFXFinalFXFXFXFXBuffFXFXFXFXGenFXFXFXFXReloadedFXFXFXFXSequFXFXFXFXMemFXFXFXFXHolyFXFXFXFXBladeFXFXFXFXMonsterFXFXFXFXMFXFXFXFXVenueFXFXFXFXEleFXFXFXFXSyllFXFXFXFXexFXFXFXFXExFXFXFXFX ReduxFXFXFXFXcreenFXFXFXFX CinematicFXFXFXFX FinalFXFXFXFX SequeluxeFXFXFXFX XIIFXFXFXFXVIIFXFXFXFX IXFXFXFXFXVIFXFXFXFX VIIFXFXFXFX VIIIFXFXFXFX VIFXFXFXFX 101FXFXFXFX VideographyFXFXFXFXDialogueFXFXFXFX FuryFXFXFXFXVFXFXFXFX EtudeFXFXFXFX SonyFXFXFXFX MenuFXFXFXFX DVDFXFXFXFX FilmsFXFXFXFX TerminatorFXFXFXFX DirectorsFXFXFXFX RogueFXFXFXFX TheaterFXFXFXFX Visual FXFXFXFX Final FantasyFXFXFXFX MovieFXFXFXFX DeadpoolFXFXFXFX FFFXFXFXFX TMFXFXFXFX FilmFXFXFXFX ComicFXFXFXFX ScriptFXFXFXFX DialogueFXFXFXFX ComedyFXFXFXFX EntertainmentFXFXFXFX ComicsFXFXFXFX SciFXFXFXFX VideoFXFXFXFX 2001FXFXFXFX 201FXFXFXFX 117FXFXFXFX 151FXFXFXFX 102FXFXFXFX 200FXFXFXFX 150FXFXFXFX 300FXFXFXFX 500FXFXFXFX 199FXFXFXFX 1000FXFXFXFX FighterFXFXFXFX FightFXFXFXFXerenceFXFXFXFX 00FXFXFXFX 100FXFXFXFX FuriousFXFXFXFX MeleeFXFXFXFX 501FXFXFXFXFYFXFXFXFX FilterFXFXFXFX 191FXFXFXFX WiseFXFXFXFX FightingFXFXFXFX 141FXFXFXFX FightersFXFXFXFX 119FXFXFXFX SFFXFXFXFXaudioFXFX 101FX 101FXFX 101FX FinalFXFX 101FX FuryFX 101FX 101 101FX 101FX 101fx 101FX 101FX Final FightFX 101FX 101 Final FightFX 101 101FX Final Fight 101 101 101 101 101 Final Fight 101 101 Final Fight Fight 101 101 101 Fight 101 101 101 Final 101 101 101 101 Fight 102 101 101 101 101 Fighter 101 101 101 101 ST 101 101 101 101 Fighting 101 101 101 101 01 101 101 101 101 102 101 101 101 Fight Fight 101 101 Fight 101 102 101 101 Fight 101 Fight 101 101 102 101 Fight 101 101 Fight 102 102 101 101 101 102 Fight 101 101 101 102 102 101 101 Fight 102 Fight 101 101 102 Fight 102 101 101 Fight 201 101 101 101 101 201 101 101 101 Fight 201 Fight 101 101 101 01 01 101 101 101 01 00 101 101 101 101 00 101 101 101 01 201 101 101 101 01 102 101 101 101 01 02 101 101 101 101 0 01 01 01 01 01 101 101 01 01 01\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1585, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1594, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4811, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7983, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Fine, how's your day been?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8020, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7947, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, how about yours?\n",
      "DialoGPT: GreatGreatGreatGreatGreatgreatgreatgreatgreatgreatgrandsongrandsongrandson grandsongrandsongrandgrandsongrandsonGrandsongrandsongrandfathergrandsongrandsonsongrandsongrandmothergrandsongrandson GrandsongrandsongrandSongrandsongrandsonchildgrandson\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6121, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6939, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1045, 1.0353, 0.7226, 0.3266, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0795, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3199, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3993, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3266, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1045, grad_fn=<UnbindBackward>)\n",
      "Episode 253: -0.3033775245096153\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Sounds like fun!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Yeah me too sometimes cries tears of joy when someone wins something big or loses something small.But mostly crying tears of sadness tears of happiness tears of sorrow tears of sadness tears tears of happiness tears tears of sadness tears sobbing noises noises noises noises noises sounds noises noises noises noises pets noises noises noises noises animals noises noises noises noises animal noises noises noises animals animals\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1775, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0560, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Not bad, how bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5608, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6521, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how about you?\n",
      "DialoGPT: Same same thing here. How bout you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8993, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8216, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, how about you\n",
      "DialoGPT: Same thing here. How about you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9122, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8280, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good. I'm good\n",
      "DialoGPT: Good how bout you??\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8434, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6036, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'm good\n",
      "DialoGPT: Ok\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1377, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4420, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Good, I'll be there in a few minutes\n",
      "DialoGPT: Ok bye bye bye bye bye Bye bye bye bye bye goodbye goodbye bye bye\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0237, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6535, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8476, 1.8072, 1.5191, 1.0998, 0.6714, 0.3127, 0.1694, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0584, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3033, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4303, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4351, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3618, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1450, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1694, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8476, grad_fn=<UnbindBackward>)\n",
      "Episode 254: -0.3024169555700877\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops farming crops crops crops crops farmland crops crops crops crops weeds crops crops crops crops seeds crops crops crops crops plants crops crops crops crops gardens crops crops crops crops vegetables crops crops crops crops tomatoes crops crops crops crops potatoes crops crops crops crops veggies crops Farming intensifiesandsaysolidowsaysandseedseedseedseedseedsedseedseedseedseedseedweedreeseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedseeseedseedseedseeds Seedseedseedseedseeds seedseedseedseedseedsrootseedseedseedseedsbackseedseedseedseedswordseedseedseedseedsplingseedseedseedseedsbugseedseedseedseedsflieseedseedseedseedscreenroduceseedseedseedseedsplanteedsweedeedsweedeedsweedweedeedsweedeedseedsweedweedweedweedweedeedsweedweedweedeedseedsweedeedsweedlingseedsweedweedweedkillersweedweedweedweedicideweedweedweedweedtweedweedweedweedgrassweedweedweedweedbeesweedweedweedweedkillersbeesweedweedweedkillerseedsweedweedweedbeesbeesweedweedweedbeeskillersweedweedweedkillersbadgerseedsweedweedweedkillerweedweedweedweedbirdsweedweedweedweedblinkweedweedweedweedfliesweedweedweedweedcoughweedweedweedweedwaterweedweedweedweedpowderweedweedweedweedpoonseedsweedweedweedbltweedweedweedkillerspoomingweedweedweedweedkillerbeesweedweedweedbl\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1594, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1999, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5083, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7810, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good, thanks for asking! How are you??\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9241, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8241, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking\n",
      "DialoGPT: That's great! How are you doing?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8959, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7270, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, thanks for asking, I'm doing well\n",
      "DialoGPT: Yeah, thanks for asking meh\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6862, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7994, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing good, thanks for the question!\n",
      "DialoGPT: I'm doing great things\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5966, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7459, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.9073, 1.8358, 1.5287, 1.1025, 0.7038, 0.3357, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0899, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3224, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4372, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4058, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3714, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3357, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.9073, grad_fn=<UnbindBackward>)\n",
      "Episode 255: -0.301586711568234\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops farming crops crops crops crops farmland crops crops crops crops weeds crops crops crops crops seeds crops crops crops crops plants crops crops crops crops gardens crops crops crops crops vegetables crops crops crops crops tomatoes crops crops crops crops potatoes crops crops crops crops veggies crops Farming intensifiesandsaysolidowsaysandseedseedseedseedseedsedseedseedseedseedseedweedreeseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedseeseedseedseedseeds Seedseedseedseedseeds seedseedseedseedseedsrootseedseedseedseedsbackseedseedseedseedswordseedseedseedseedsplingseedseedseedseedsbugseedseedseedseedsflieseedseedseedseedscreenroduceseedseedseedseedsplanteedseedseedseedsgrassweedeedsweedeedsweedeedseedsweedeedsweedweedeedsweedweedweedweedweedeedsweedeedsbeeseedsweedweedweedeedseedsweedweedweedlingseedsweedweedweedkillersweedweedweedweedbeesweedweedweedweedicideweedweedweedweedtweedweedweedweedkillersbeesweedweedweedkillerseedsweedweedweedbeesbeesweedweedweedbeeskillersweedweedweedkillersbadgerseedsweedweedweedkillerweedweedweedweedbirdsweedweedweedweedblinkweedweedweedweedfliesweedweedweedweedcoughweedweedweedweedwaterweedweedweedweedgrassfliesweedweedweedkillerspoonseedsweedweedweedicidebeesweedweedweedicidefliesweedweedweedicidekillersweedweedweedicide weedsweedweedweedweedkillerbeesweedweedweedkillerfliesweedweedweedkillerkillersweedweedweedkillergrasskillersweedweedweedbeeskillerweedweedweedkillerskillersweedkillersweedkillersweedweedkillersweedkillerskillersweedweedkillerskillerskillersweedkillerskillerskillerskillersweedweedweedfliescreenweedkillersweedkillersbeesweedkillersweedkillerspoomingweedkillersweedkillerscreenweedkillersweedweedkillerweedkillersweedkillerskillerweedkillersweedweedicideweedkillersweedkillerskillweedkillersweedkillershotweedkillersweedkillershydratedweedkillersweedkillersterribleweedkillersweedkillersaquewweedkillersweedkillerstweedkillersweedkillers weedscreenweedkillersweedkillerweedkillerskillersweedkillerweedweedkillersweedkillerkillersweedkillersweedkillerkillerweedkillersweedkillerbeeskillersweedkillersweedicideweedkillerskillersweedicideweedkillerweedkillerspoominglitteritlescreenweedkillersweedicidekillersweedkillersweedcreenweedkillersweedcreenkillersweedkillersweed Roundup Roundup Roundup Roundup Roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup pesticide Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup herb Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundup weed Roundup Roundup Roundup Roundup Weed Roundup Roundup Roundup Roundup chemicals Roundup Roundup Roundup Roundup\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1190, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0498, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5589, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6960, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: I'm good too, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8538, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8486, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are you,\n",
      "DialoGPT: doing well?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6847, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5287, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how are you today?\n",
      "DialoGPT: Well, well, how are ya?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6033, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8428, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, how about you?\n",
      "DialoGPT: Yeah, yeah, yeah. Yeah, yeah. Yeah.\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6829, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7387, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good.\n",
      "DialoGPT: Alright,\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3259, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.3796, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8913, 1.8928, 1.5950, 1.1811, 0.8865, 0.5302, 0.1765, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0174, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3138, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3034, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3616, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3555, device='cuda:0', grad_fn=<NegBackward>), tensor(0.1765, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8913, grad_fn=<UnbindBackward>)\n",
      "Episode 256: -0.3004807362166244\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops farming crops crops crops crops farmland crops crops crops crops weeds crops crops crops crops seeds crops crops crops crops plants crops crops crops crops gardens crops crops crops crops vegetables crops crops crops crops tomatoes crops crops crops crops potatoes crops crops crops crops veggies crops Farming intensifiesandsaysolidowsaysandseedseedseedseedseedsedseedseedseedseedseedweedreeseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedseeseedseedseedseeds Seedseedseedseedseeds seedseedseedseedseedsrootseedseedseedseedsbackseedseedseedseedswordseedseedseedseedsplingseedseedseedseedsbugseedseedseedseedsflieseedseedseedseedscreenroduceseedseedseedseedsplanteedseedseedseedsgrassweedeedsweedeedsweedeedseedsweedeedsweedweedeedsweedweedweedweedweedeedsweedeedsbeeseedsweedweedweedeedseedsweedweedweedlingseedsweedweedweedkillersweedweedweedweedbeesweedweedweedweedicideweedweedweedweedtweedweedweedweedkillersbeesweedweedweedkillerseedsweedweedweedbeesbeesweedweedweedbeeskillersweedweedweedkillersbadgerseedsweedweedweedkillerweedweedweedweedbirdsweedweedweedweedblinkweedweedweedweedfliesweedweedweedweedcoughweedweedweedweedwaterweedweedweedweedgrassfliesweedweedweedkillerspoonseedsweedweedweedicidebeesweedweedweedicidefliesweedweedweedicidekillersweedweedweedicide weedsweedweedweedweedkillerbeesweedweedweedkillerfliesweedweedweedkillerkillersweedweedweedkillergrasskillersweedweedweedbeeskillerweedweedweedkillerskillersweedkillersweedkillersweedweedkillersweedkillerskillersweedweedkillerskillerskillersweedkillerskillerskillerskillersweedweedweedfliescreenweedkillersweedkillersbeesweedkillersweedkillerspoomingweedkillersweedkillerscreenweedkillersweedweedkillerweedkillersweedkillerskillerweedkillersweedweedicideweedkillersweedkillerskillweedkillersweedkillershotweedkillersweedkillershydratedweedkillersweedkillersterribleweedkillersweedkillersaquewweedkillersweedkillerstweedkillersweedkillers weedscreenweedkillersweedkillerweedkillerskillersweedkillerweedweedkillersweedkillerkillersweedkillersweedkillerkillerweedkillersweedkillerbeeskillersweedkillersweedicideweedkillerskillersweedicideweedkillerweedkillerspoominglitteritlescreenweedkillersweedicidekillersweedkillersweedcreenweedkillersweedcreenkillersweedkillersweed Roundup Roundup Roundup Roundup Roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup pesticide Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup herb Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundup weed Roundup Roundup Roundup Roundup Weed Roundup Roundup Roundup Roundup chemicals Roundup Roundup Roundup Roundup\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1212, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0354, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: How are you?\n",
      "DialoGPT: Fine, how are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4860, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7516, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8615, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8001, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: doing well?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6023, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5054, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm fine, how about you\n",
      "DialoGPT: That's good, how are YOU doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6208, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8401, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how are you, what's going on?\n",
      "DialoGPT: Nothing happening?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.5534, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6868, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm not sure\n",
      "DialoGPT: nothingthing happening?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8715, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6734, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I think I'm going\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([2.0311, 2.0120, 1.7197, 1.3174, 1.0509, 0.6925, 0.3863, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(0.0392, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3095, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4155, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2770, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3653, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3101, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3863, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(2.0311, grad_fn=<UnbindBackward>)\n",
      "Episode 257: -0.2994680744054359\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops farming crops crops crops crops farmland crops crops crops crops weeds crops crops crops crops seeds crops crops crops crops plants crops crops crops crops gardens crops crops crops crops vegetables crops crops crops crops tomatoes crops crops crops crops potatoes crops crops crops crops veggies crops Farming intensifiesandsaysolidowsaysandseedseedseedseedseedsedseedseedseedseedseedweedreeseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedseeseedseedseedseeds Seedseedseedseedseeds seedseedseedseedseedsrootseedseedseedseedsbackseedseedseedseedswordseedseedseedseedsplingseedseedseedseedsbugseedseedseedseedsflieseedseedseedseedscreenroduceseedseedseedseedsplanteedseedseedseedsgrassweedeedsweedeedsweedeedseedsweedeedsweedweedeedsweedweedweedweedweedeedsweedeedsbeeseedsweedweedweedeedseedsweedweedweedlingseedsweedweedweedkillersweedweedweedweedbeesweedweedweedweedicideweedweedweedweedtweedweedweedweedkillersbeesweedweedweedkillerseedsweedweedweedbeesbeesweedweedweedbeeskillersweedweedweedkillersbadgerseedsweedweedweedkillerweedweedweedweedbirdsweedweedweedweedblinkweedweedweedweedfliesweedweedweedweedcoughweedweedweedweedwaterweedweedweedweedgrassfliesweedweedweedkillerspoomingweedweedweedweedkillerbeesweedweedweedicidebeesweedweedweedfliesbeesweedweedweedkillerfliesweedweedweedicidefliesweedweedweedkillerkillersweedweedweedicidekillersweedweedweedkillergrasskillersweedweedweedbeeskillerweedweedweedkillerskillersweedweedweedfliescreenweedweedweedweedcreenweedweedweedkillerscreenweedweedweedicide weedscreenweedweedweedcreenmersweedweedweedweedpowderweedweedweedweed Roundup Roundup Roundup Roundup Roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup pesticide Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundupweed Roundup Roundup Roundup roundup roundup Roundup Roundup Roundup roundup glyphosate Roundup Roundup Roundup roundup Monsanto Roundup Roundup Roundup roundup crops Roundup Roundup Roundup roundup pesticide Roundup Roundup Roundup roundup weeds Roundup Roundup Roundup Roundup GMOs Roundup Roundup Roundup Roundup\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0005, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0192, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0070, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Fine, thanks for asking. How are you? How are you doing anything special?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8571, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8790, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm doing a lot of things right now.\n",
      "DialoGPT: That's great! How are you doing things?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8894, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7934, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, I'm doing my best to keep up with my studies.\n",
      "DialoGPT: That's good, thanks.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7505, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7365, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(6.0991e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: Yeah, yeah\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6173, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5544, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.4780, 1.4994, 1.0761, 0.6619, 0.2930, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0064, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4208, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3719, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2930, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.4780, grad_fn=<UnbindBackward>)\n",
      "Episode 258: -0.29828694873061534\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops farming crops crops crops crops farmland crops crops crops crops weeds crops crops crops crops seeds crops crops crops crops plants crops crops crops crops gardens crops crops crops crops vegetables crops crops crops crops tomatoes crops crops crops crops potatoes crops crops crops crops veggies crops Farming intensifiesandsaysolidowsaysandseedseedseedseedseedsedseedseedseedseedseedweedreeseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedseeseedseedseedseeds Seedseedseedseedseeds seedseedseedseedseedsrootseedseedseedseedsbackseedseedseedseedswordseedseedseedseedsplingseedseedseedseedsbugseedseedseedseedsflieseedseedseedseedscreenroduceseedseedseedseedsplanteedseedseedseedsgrassweedeedsweedeedsweedeedseedsweedeedsweedweedeedsweedweedweedweedweedeedsweedeedsbeeseedsweedweedweedeedseedsweedweedweedlingseedsweedweedweedkillersweedweedweedweedbeesweedweedweedweedicideweedweedweedweedtweedweedweedweedkillersbeesweedweedweedkillerseedsweedweedweedbeesbeesweedweedweedbeeskillersweedweedweedkillersbadgerseedsweedweedweedkillerweedweedweedweedbirdsweedweedweedweedblinkweedweedweedweedfliesweedweedweedweedcoughweedweedweedweedwaterweedweedweedweedgrassfliesweedweedweedkillerspoomingweedweedweedweedkillerbeesweedweedweedicidebeesweedweedweedfliesbeesweedweedweedkillerfliesweedweedweedicidefliesweedweedweedbeesbeekillersweedweedweedicidekillersweedweedweedbeesfliesweedweedweedkillerkillersweedweedweedkillergrasskillersweedweedweedfliescreenweedweedweedweedcreenweedweedweedkillerscreenweedweedweedicide weedscreenweedweedweedcreenmersweedweedweedweedpowderweedweedweedweed Roundup Roundup Roundup Roundup Roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup pesticide Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundupweed Roundup Roundup Roundup roundup roundup Roundup Roundup Roundup roundup glyphosate Roundup Roundup Roundup roundup Monsanto Roundup Roundup Roundup roundup crops Roundup Roundup Roundup roundup pesticide Roundup Roundup Roundup roundup weeds Roundup Roundup Roundup Roundup GMOs Roundup Roundup Roundup Roundup\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.4557, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0123, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Oh yeah, I'm good too. How are you? How are you? Are you? How are they? How are they are you? How is it's been a long time to meowwwwwwwwwwwwwwwnnnnnnnnnnnnnggggggggggggghhttttttttttttttyyyyyyyyyysssssssssssssssss\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8046, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8184, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.5127, 0.4058, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1109, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4058, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.5127, grad_fn=<UnbindBackward>)\n",
      "Episode 259: -0.2975662774657114\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops farming crops crops crops crops crop crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Agricultural crops crops crops crops Animal agriculture crops Agriculture crops Farming crops Agriculture crops Agriculture crops Agriculture weeds Farming crops Agriculture crops Farming seeds Farming crops Farming crops Farming crops Agriculture Seeds Farming crops Farming crops crops Farming crops Farming treeseedseed cropseedseedseedseedseedseedeedseedseedseeds cropseedseedseedseed seedseedseedseedseeds seedseedseedseedseedeedeedseedseedseededseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedsandseedseedseedseedsbeanseedseedseedseedsplingseedseedseedseeds Seedseedseedseedseeds weedseedseedseedseeds mushroomseeds seedseeds seedseeds seeds seedseeds seedseeds crops crops crops crops seedseeds seedseeds grassgrass seedseeds seedseeds weedseeds seedseeds seeds crops crops crops crops weedseeds seeds crops crops seeds crops crops crops seeds crops seeds crops crops seeds seeds crops crops crops weeds crops crops crops crops plants seeds crops crops crops plants crops crops crops crops trees seeds crops crops crops trees crops crops crops crops bushes seeds crops crops crops grass crops crops crops crops grass seeds crops crops crops herbs seeds crops crops crops flowers crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops diamonds crops crops crops crops tomatoes crops crops crops crops water crops crops crops crops soybeans seeds crops crops crops diamonds seeds crops crops crops sandstone crops crops crops crops greenscreen crops crops crops crops sand diamonds crops crops crops weeds weeds crops crops crops weeds seeds crops crops crops bushes crops crops crops crops potions crops crops crops crops mushrooms crops crops crops crops appleseeds seeds crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds weeds weeds crops crops weeds weeds seeds crops crops weeds seeds seeds crops crops weeds plants crops crops crops weeds plants weeds crops crops crops plants weeds crops crops weeds seeds weeds crops crops crops seeds seeds seeds crops crops plants crops weeds crops crops plants crops plants crops crops weeds crops plants crops crops plants crops seeds crops crops plants plants crops crops crops plants plants plants crops crops weeds weeds plants crops crops weeds plants plants crops crops plants plants weeds crops crops plants plants trees crops crops crops plants trees crops crops plants crops trees crops crops plants plants seeds crops crops plants weeds weeds crops crops plants weeds plants plants plants plants plants crops plants plants plants plants trees crops plants plants plants trees plants plants plants plants weeds plants plants crops plants crops plants plants crops plants trees plants plants crops plants weeds plants crops plants plants trees plants crops plants plants weeds plants crops crops plants trees plants crops crops plants weeds trees plants plants plants crops weeds plants plants plants trees trees plants plants plants trees weeds plants plants plants crops trees plants plants plants weeds crops plants plants plants weeds weeds plants plants plants weeds trees plants trees plants plants trees plants trees plants trees trees plants trees plants crops trees plants trees plants weeds plants plants trees plants weeds crops plants trees plants trees crops plants trees plants weeds weeds plants trees plants plants weeds plants trees plants trees weeds plants trees plants crops weeds plants trees plants weeds trees plants crops plants trees trees plants crops plants crops trees plants crops plants weeds weeds plants crops plants trees crops plants crops plants trees weeds plants crops plants crops weeds plants crops plants weeds crops plants crops plants weeds trees trees plants plants trees trees trees plants plants weeds weeds weeds plants plants trees trees weeds plants plants trees weeds weeds plants plants weeds plants weeds plants plants weeds weeds crops plants plants trees trees crops plants plants trees weeds crops plants plants weeds weeds trees plants plants trees weeds trees plants plants weeds crops weeds plants plants trees crops weeds plants plants weeds crops trees plants plants trees crops trees plants plants weeds trees trees trees plants trees trees trees trees plants weeds plants trees trees plants weeds weeds weeds weeds plants trees trees trees weeds plants trees trees weeds weeds plants trees weeds plants weeds plants weeds weeds plants weeds plants trees weeds weeds weeds plants weeds weeds weeds crops plants weeds plants weeds crops plants weeds weeds weeds trees plants weeds plants weeds trees plants weeds weeds crops weeds plants weeds plants crops weeds plants weeds weeds crops trees weeds weeds weeds weeds weeds crops weeds weeds weeds weeds trees weeds weeds weeds crops trees plants weeds weeds trees weeds plants plants weeds trees weeds weeds plants weeds trees weeds plants weeds weeds trees trees weeds weeds weeds trees trees plants weeds trees weeds trees weeds weeds trees weeds trees plants weeds trees trees weeds plants weeds trees trees crops weeds weeds weeds plants crops weeds weeds weeds trees crops weeds weeds plants weeds crops weeds weeds plants plants crops weeds weeds plants trees crops weeds weeds trees weeds crops weeds weeds trees plants trees weeds weeds trees plants crops weeds weeds trees trees trees weeds weeds trees trees crops plants weeds weeds trees crops plants weeds plants trees crops plants weeds trees weeds crops plants weeds trees crops weeds plants weeds trees crops plants plants\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0451, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0502, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: doing well thanks for asking questions.\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7682, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6945, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: Yeah, it's been awhile since I've been able to talk to anyone. But I'm glad to hear you're doing well too. How about yourself?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7971, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8071, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking!\n",
      "DialoGPT: That's great! Glad to hear that you're doing well!\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8920, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7629, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks, I'm glad to be here\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1330, 1.1685, 0.8109, 0.4139, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0237, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3657, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4011, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4139, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1330, grad_fn=<UnbindBackward>)\n",
      "Episode 260: -0.29633523738261497\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops farming crops crops crops crops crop crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Agricultural crops crops crops crops Animal agriculture crops Agriculture crops Farming crops Agriculture crops Agriculture crops Agriculture weeds Farming crops Agriculture crops Farming seeds Farming crops Farming crops Farming crops Agriculture Seeds Farming crops Farming crops crops Farming crops Farming treeseedseed cropseedseedseedseedseedseedeedseedseedseeds cropseedseedseedseed seedseedseedseedseeds seedseedseedseedseedeedeedseedseedseededseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedsandseedseedseedseedsbeanseedseedseedseedsplingseedseedseedseeds Seedseedseedseedseeds weedseedseedseedseeds mushroomseeds seedseeds seedseeds seeds seedseeds seedseeds crops crops crops crops seedseeds seedseeds grassgrass seedseeds seedseeds weedseeds seedseeds seeds crops crops crops crops weedseeds seeds crops crops seeds crops crops crops seeds crops seeds crops crops seeds seeds crops crops crops weeds crops crops crops crops plants seeds crops crops crops plants crops crops crops crops trees seeds crops crops crops trees crops crops crops crops bushes seeds crops crops crops grass crops crops crops crops grass seeds crops crops crops herbs seeds crops crops crops flowers crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops diamonds crops crops crops crops tomatoes crops crops crops crops water crops crops crops crops soybeans seeds crops crops crops diamonds seeds crops crops crops sandstone crops crops crops crops greenscreen crops crops crops crops sand diamonds crops crops crops weeds weeds crops crops crops weeds seeds crops crops crops bushes crops crops crops crops potions crops crops crops crops mushrooms crops crops crops crops appleseeds seeds crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds weeds weeds crops crops weeds weeds seeds crops crops weeds seeds seeds crops crops weeds plants crops crops crops weeds plants weeds crops crops crops plants weeds crops crops weeds seeds weeds crops crops crops seeds seeds seeds crops crops plants crops weeds crops crops plants crops plants crops crops weeds crops plants crops crops plants crops seeds crops crops plants plants crops crops crops plants plants plants crops crops weeds weeds plants crops crops weeds plants plants crops crops plants plants weeds crops crops plants plants trees crops crops crops plants trees crops crops plants crops trees crops crops plants plants seeds crops crops plants weeds weeds crops crops plants weeds plants plants plants plants plants crops plants plants plants plants trees crops plants plants plants trees plants plants plants plants weeds plants plants crops plants crops plants plants crops plants trees plants plants crops plants weeds plants crops plants plants trees plants crops plants plants weeds plants crops crops plants trees plants crops crops plants weeds trees plants plants plants crops weeds plants plants plants trees trees plants plants plants trees weeds plants plants plants crops trees plants plants plants weeds crops plants plants plants weeds weeds plants plants plants weeds trees plants trees plants plants trees plants trees plants trees trees plants trees plants crops trees plants trees plants weeds plants plants trees plants weeds crops plants trees plants trees crops plants trees plants weeds weeds plants trees plants plants weeds plants trees plants trees weeds plants trees plants crops weeds plants trees plants weeds trees plants crops plants trees trees plants crops plants crops trees plants crops plants weeds weeds plants crops plants trees crops plants crops plants trees weeds plants crops plants crops weeds plants crops plants weeds crops plants crops plants weeds trees trees plants plants trees trees trees plants plants weeds weeds weeds plants plants trees trees weeds plants plants trees weeds weeds plants plants weeds plants weeds plants plants weeds weeds crops plants plants trees trees crops plants plants trees weeds crops plants plants weeds weeds trees plants plants trees weeds trees plants plants weeds crops weeds plants plants trees crops weeds plants plants weeds crops trees plants plants trees crops trees plants plants weeds trees trees trees plants trees trees trees trees plants weeds plants trees trees plants weeds weeds weeds weeds plants trees trees trees weeds plants trees trees weeds weeds plants weeds plants weeds weeds plants weeds weeds weeds crops plants weeds plants weeds crops plants weeds weeds weeds trees plants weeds plants weeds trees plants weeds weeds crops weeds plants weeds plants trees weeds plants weeds plants crops weeds plants weeds weeds crops trees plants weeds plants crops trees plants weeds weeds trees weeds weeds weeds weeds weeds crops weeds weeds weeds weeds trees weeds plants plants weeds trees weeds weeds plants trees weeds weeds weeds plants weeds trees weeds plants weeds weeds trees trees weeds weeds weeds trees trees plants weeds trees weeds trees weeds weeds trees weeds trees plants weeds trees trees weeds plants weeds trees trees crops weeds weeds weeds plants crops weeds weeds weeds trees crops weeds weeds plants weeds crops weeds weeds plants plants crops weeds weeds plants trees crops weeds weeds trees weeds crops weeds weeds trees plants trees weeds weeds trees plants crops weeds weeds trees trees trees weeds weeds trees trees crops plants weeds weeds trees crops plants weeds plants trees crops plants weeds trees weeds crops plants weeds trees crops weeds plants weeds trees crops plants plants\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1416, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0317, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Fine, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7996, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8412, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been doing well lately?\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6698, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7207, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've had a lot of time to myself lately.\n",
      "DialoGPT: Yeah, that's understandable. How's life been lately?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7618, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7986, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Pretty good, I guess.\n",
      "DialoGPT: Yeah, yeah, yeah, yeah that's good.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7866, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6942, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that.\n",
      "DialoGPT: Yeah yeah yeah\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6244, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5445, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.7160, 1.7770, 1.3806, 1.0432, 0.6596, 0.2923, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.0433, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4103, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3478, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3902, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3703, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2923, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.7160, grad_fn=<UnbindBackward>)\n",
      "Episode 261: -0.29503908069832746\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants pets crops crops crops crops farmers crops crops crops crops dairy crops crops crops crops farm crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers Farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops farming crops crops crops crops crop crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Agricultural crops crops crops crops Animal agriculture crops Agriculture crops Farming crops Agriculture crops Agriculture crops Agriculture weeds Farming crops Agriculture crops Farming seeds Farming crops Farming crops Farming crops Agriculture Seeds Farming crops Farming crops crops Farming crops Farming treeseedseed cropseedseedseedseedseedseedeedseedseedseeds cropseedseedseedseed seedseedseedseedseeds seedseedseedseedseedeedeedseedseedseededseedseedseedseedsseedeedseedseedseedsbeeseedseedseedseedsweedeedseedseedseedsandseedseedseedseedsbeanseedseedseedseedsplingseedseedseedseeds Seedseedseedseedseeds weedseedseedseedseeds mushroomseeds seedseeds seedseeds seeds seedseeds seedseeds crops crops crops crops seedseeds seedseeds grassgrass seedseeds seedseeds weedseeds seedseeds seeds crops crops crops crops weedseeds seeds crops crops seeds crops crops crops seeds crops seeds crops crops seeds seeds crops crops crops weeds crops crops crops crops plants seeds crops crops crops plants crops crops crops crops trees seeds crops crops crops trees crops crops crops crops bushes seeds crops crops crops grass crops crops crops crops grass seeds crops crops crops herbs seeds crops crops crops flowers crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops diamonds crops crops crops crops tomatoes crops crops crops crops water crops crops crops crops soybeans seeds crops crops crops diamonds seeds crops crops crops sandstone crops crops crops crops greenscreen crops crops crops crops sand diamonds crops crops crops weeds weeds crops crops crops weeds seeds crops crops crops bushes crops crops crops crops potions crops crops crops crops mushrooms crops crops crops crops appleseeds seeds crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds weeds weeds crops crops weeds weeds seeds crops crops weeds seeds seeds crops crops weeds plants crops crops crops weeds plants weeds crops crops crops plants weeds crops crops weeds seeds weeds crops crops crops seeds seeds seeds crops crops plants crops weeds crops crops plants crops plants crops crops weeds crops plants crops crops plants crops seeds crops crops plants weeds weeds crops crops plants weeds plants crops crops weeds weeds plants crops crops plants plants crops crops crops plants plants plants crops crops weeds plants plants crops crops plants weeds seeds crops crops plants plants weeds crops crops plants plants trees crops crops crops plants trees crops crops plants plants seeds crops crops plants trees plants plants plants plants plants crops plants plants plants plants trees crops plants plants plants trees plants plants crops plants crops plants plants crops plants trees plants crops plants plants trees plants crops crops plants trees trees plants plants plants crops weeds plants plants plants plants weeds plants plants plants crops trees plants plants plants trees trees plants trees plants plants trees plants trees plants trees trees plants crops plants trees trees trees plants plants trees trees trees trees plants trees trees trees crops plants plants trees trees crops plants trees plants trees crops plants trees trees crops crops plants trees weeds plants plants plants trees weeds plants trees plants plants weeds plants trees plants trees weeds plants crops plants plants weeds plants crops plants trees crops plants crops plants trees weeds crops plants plants plants weeds crops plants plants trees weeds crops crops plants trees seeds plants plants plants plants grass plants plants plants plants seeds plants plants plants trees seeds plants trees plants plants grass plants trees plants plants seeds plants trees plants trees seeds plants crops plants plants grass plants crops plants plants seeds plants crops plants trees seeds crops plants plants plants seeds crops plants plants trees seeds crops crops plants seeds plants plants trees plants weeds plants plants trees plants seeds plants plants crops plants weeds plants plants crops plants seeds plants trees trees plants weeds plants trees trees plants seeds plants trees crops plants weeds plants trees crops plants seeds plants weeds plants plants weeds plants weeds plants plants seeds plants weeds weeds plants plants plants weeds weeds plants trees plants weeds weeds plants weeds plants trees weeds plants weeds plants weeds weeds plants crops plants weeds weeds plants seeds plants plants weeds plants seeds plants trees weeds plants seeds plants weeds crops plants trees plants weeds crops plants weeds plants weeds crops plants crops plants weeds crops plants seeds plants crops weeds plants trees plants crops weeds plants weeds plants crops weeds plants crops plants crops weeds plants seeds plants crops crops plants seeds trees plants plants plants weeds trees plants plants plants seeds trees plants weeds plants weeds trees plants weeds plants crops trees plants weeds plants seeds weeds plants plants plants seeds weeds plants weeds plants seeds crops plants weeds plants seeds trees plants trees plants weeds trees plants trees plants crops trees plants trees plants seeds weeds plants trees plants grass plants plants weeds plants grass plants plants trees plants grass weeds plants plants plants grass weeds plants weeds plants grass weeds plants trees plants seeds trees plants crops plants weeds trees plants crops plants crops trees plants crops plants grass plants plants crops plants grass weeds plants crops plants grass crops plants plants plants grass crops plants weeds plants grass crops plants trees plants grass crops plants crops plants grass\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0104, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0130, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing today?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8672, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8484, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: doingdoingdoingdoingdoingthingdoingdoingdoingdoingathingathingathingathingathingthingathingathingathingathingassingathingathingathingathingdoingathingathingathingassingassingathingathingathingassingatheathingathingathingathingalkingathingathingathingathingseeingathingathingathingathingasingathingathingathingathingatheathingathingathingassinguckingathing\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6937, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6595, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.6039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.7505, 0.7639, 0.3384, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0058, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4289, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3384, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.7505, grad_fn=<UnbindBackward>)\n",
      "Episode 262: -0.2938952659993316\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants agriculture crops crops crops farms dairy crops crops crops crops farmers crops crops crops crops pets crops crops crops crops dairy crops crops crops farms agriculture crops crops crops plants renewable crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops agricultural crops crops crops crops farmland crops crops crops crops seeds crops crops crops crops plants crops crops crops crops weeds crops crops crops crops animals crops crops crops crops vegetables crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Seeds crops Farming crops crops seeds crops seeds crops crops seeds crops trees crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops Wheat crops crops crops crops soy crops crops crops crops Soy crops crops crops crops grass crops crops crops crops cows crops crops crops crops tomatoes crops crops crops crops fertilizer crops crops crops crops trees crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds crops bushes crops crops crops crops greenscreen crops crops crops crops mushrooms crops crops crops crops flowers crops crops crops crops forests crops crops crops crops water crops crops crops crops potions crops crops crops crops herbs crops crops crops crops food crops crops crops crops essentials potions potions potions potions potions crops potions potions potions potions pots potions potions potions potions poisons potions potions potions potions potion potions potions potions potions poison potions potions potions potions\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0021, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0542, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: doing well thanks for asking me questions i guess i'm doing well thanks for asking questions i guess i guess i'm not doing well thanks for responding anyway\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7329, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7431, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad to hear that!\n",
      "DialoGPT: yeah i'm glad to hear it's working out for you too thanks again for asking questions i suppose i'm doing well huh?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9123, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7624, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well!\n",
      "DialoGPT: yeah i think that's good\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7799, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6775, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(8.2143e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1435, 1.1408, 0.7795, 0.3644, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0141, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3691, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4187, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3644, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1435, grad_fn=<UnbindBackward>)\n",
      "Episode 263: -0.29283559004331683\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants agriculture crops crops crops farms dairy crops crops crops crops farmers crops crops crops crops pets crops crops crops crops dairy crops crops crops farms agriculture crops crops crops plants renewable crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops agricultural crops crops crops crops farmland crops crops crops crops seeds crops crops crops crops plants crops crops crops crops weeds crops crops crops crops animals crops crops crops crops vegetables crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Seeds crops Farming crops crops seeds crops seeds crops crops seeds crops trees crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops Wheat crops crops crops crops soy crops crops crops crops Soy crops crops crops crops grass crops crops crops crops cows crops crops crops crops tomatoes crops crops crops crops fertilizer crops crops crops crops trees crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds crops bushes crops crops crops crops greenscreen crops crops crops crops mushrooms crops crops crops crops flowers crops crops crops crops forests crops crops crops crops water crops crops crops crops potions crops crops crops crops herbs crops crops crops crops food crops crops crops crops essentials potions potions potions potions potions crops potions potions potions potions pots potions potions potions potions poisons potions potions potions potions potion potions potions potions potions poison potions potions potions potions\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0522, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0764, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Good, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8023, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8115, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: That's great to hear, how are you enjoying yourself?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8610, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8201, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm enjoying it, I'm just getting used to it.\n",
      "DialoGPT: That's great! Glad toasty weather is nice weather weather weather weather weather Weather weather weather weather weatherweather weather weather weather weatherWeather weather weather weather weather forecast weather weather weather weather rain\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8034, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7172, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.1744, 1.1923, 0.7968, 0.3802, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0060, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4035, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3802, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.1744, grad_fn=<UnbindBackward>)\n",
      "Episode 264: -0.2917079534504633\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Is that true? Or is it just because of the music? Either way, Titanic is terrible.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times in theaters or 12 times total? Because Titanic is terrible periodically compared to other movies. Titanic 2 is amazing though.\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVD's are usually cheaper than Blu rays nowadays anyway. Unless you're willing to shell out extra money for blu ray discs. Then buy DVDs instead of buying Blu Rays. Problem solved!\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories real quick. Gimme a sec.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then. Lets go shopping together sometime soon. Deal? Deal? Deal? deal? Deal? Deal! Deal? Deal? Deals? Deal? Deal deals? Deal? Dealers? Dealers? Deals? Dealers? Dealer's? Dealers dealerships? Dealerships dealerships dealerships dealershouses dealerships dealerships Dealerships dealerseries dealerships dealerships cars dealerships dealerships vehicles vehicles vehicles vehicles vehicles buildings buildings buildings buildings buildings structures buildings buildings buildings buildings towers buildings buildings buildings buildings trees trees trees trees trees forests trees trees trees trees farms crops crops crops crops crops plants crops crops crops crops seeds crops crops crops crops farms crops crops crops farms animals animals animals animals animals plants crops crops crops plants trees crops crops crops crops trees crops crops crops plants plants crops crops crops farms farms crops crops crops plants farms crops crops crops trees farms crops crops plants crops plants crops crops plants crops farms crops crops plants trees farms crops crops farms crops plants crops crops farms crops farms crops crops farms farms farms crops crops farms animals farms crops crops crops farming crops crops crops crops agriculture crops crops crops crops weeds crops crops crops crops farming plants crops crops crops trees trees crops crops crops farms plants crops crops crops farming farms crops crops crops etc crops crops crops crops animals crops crops crops crops etc plants crops crops crops animals farms crops crops farms plants farms crops crops farms trees crops crops crops farming animals crops crops crops farms trees farms crops crops farming crops farms crops crops farming plants farms crops crops plants farms farms crops crops plants plants farms crops crops farming farms farms crops crops farming animals farms crops crops plants animals crops crops crops plants animals farms crops crops farming etc crops crops crops farms farming crops crops crops farms etc crops crops crops plants farming crops crops crops plants agriculture crops crops crops farms dairy crops crops crops crops farmers crops crops crops crops pets crops crops crops crops dairy crops crops crops farms agriculture crops crops crops plants renewable crops crops crops crops\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Farmers farm crops crops crops crops crops farms crops crops crops crops agriculture crops crops crops crops crop crops crops crops crops agricultural crops crops crops crops farmland crops crops crops crops seeds crops crops crops crops plants crops crops crops crops weeds crops crops crops crops animals crops crops crops crops vegetables crops crops crops crops Agriculture crops crops crops crops Farming crops crops crops crops Seeds crops Farming crops crops seeds crops seeds crops crops seeds crops trees crops crops crops crops wheat crops crops crops crops potatoes crops crops crops crops Wheat crops crops crops crops soy crops crops crops crops Soy crops crops crops crops grass crops crops crops crops cows crops crops crops crops tomatoes crops crops crops crops fertilizer crops crops crops crops trees crops crops weeds crops weeds crops crops weeds crops seeds crops crops weeds crops bushes crops crops crops crops greenscreen crops crops crops crops mushrooms crops crops crops crops flowers crops crops crops crops forests crops crops crops crops water crops crops crops crops potions crops crops crops crops herbs crops crops crops crops food crops crops crops crops essentials potions potions potions potions potions crops potions potions potions potions pots potions potions potions potions poisons potions potions potions potions potion potions potions potions potions poison potions potions potions potions\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1672, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0771, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good actually. Just had a midterm and finals tomorrow. How's yours?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7871, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8140, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm just getting into the semester.\n",
      "DialoGPT: Nice man, good luck with finals!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8655, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7886, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks, you too!\n",
      "DialoGPT: Thanks man, same same thing happened to me last semester.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8492, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8133, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Same here, I'm just starting my first semester of college.\n",
      "DialoGPT: Same same same same same same Same Same\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7356, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6302, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.4721, 1.5486, 1.1599, 0.7538, 0.3415, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0610, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4003, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4136, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4157, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3415, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.4721, grad_fn=<UnbindBackward>)\n",
      "Episode 265: -0.2903819427618939\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when compared to Blu rays. Plus blu ray discs are cheaper than DVDs these days. So DVD's cost more money than Blu Rays nowadays. Hence why Blu Ray prices skyrocketed recently.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost less than Blu Rays these days because Blu Rays are cheaper than DVD's these days due to inflation rates. Blu Rays cost more than DVD's thesedays due to inflation rates due to inflation rates costs ratio ratios ratios ratios ratios ratios factors factors factors factors factors factor factors factors factors factors variables factors factors factors factors Factors factors factors factors factors elements factors ducks apples oranges apples oranges oranges oranges apples oranges apples oranges apples apples oranges apples oranges grapes tomatoes seeds seeds seeds seeds seeds etc seeds seeds seeds seeds roundup roundup roundup roundup roundup chemicals roundup roundup roundup roundup pesticides roundup roundup roundup roundup Roundup roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticide roundup roundup roundup roundup GMOs roundup roundup roundup roundup antibiotics roundup roundup roundup roundup GMO roundup roundup roundup roundup etc roundup roundup roundup roundup weeds roundup roundup roundup roundup Monsanto roundup roundup roundup roundup chemical roundup roundup roundup roundup crops roundup roundup roundup roundup GM roundup roundup roundup roundup plants roundup roundup roundup roundup fertilizer roundup roundup roundup roundup herb roundup roundup roundup roundup organic roundup roundup roundup roundup water roundup roundup roundup roundup\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Roundup Roundup Roundup Roundup Roundup Roundup roundup roundup roundup roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup pesticide Roundup roundup roundup roundup Roundup roundup roundup roundup pesticides Roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticides roundup roundup roundup roundup glyphosate Roundup roundup roundup roundup pesticide roundup roundup roundup roundup pesticide Roundup roundup roundup Roundup roundup Roundup roundup Roundup Roundup Roundup roundup Roundup Roundup roundup roundup Roundup Roundup roundup Roundup roundup roundup Roundup seeds roundup roundup roundup roundup seeds roundup roundup roundup Roundup seeds Roundup roundup roundup roundup seeds Roundup roundup roundup Roundup pesticide roundup roundup roundup Roundup pesticide Roundup roundup Roundup roundup seeds Roundup roundup Roundup roundup pesticide roundup roundup Roundup roundup seeds roundup roundup Roundup roundup pesticide Roundup roundup Roundup Roundup seeds Roundup roundup Roundup Roundup pesticide roundup roundup Roundup Roundup seeds roundup roundup Roundup Roundup pesticide Roundup Roundup roundup roundup pesticide roundup Roundup roundup roundup pesticide Roundup Roundup roundup Roundup seeds Roundup Roundup roundup roundup pesticides Roundup Roundup roundup roundup seeds Roundup Roundup roundup Roundup pesticide Roundup Roundup Roundup roundup pesticide Roundup Roundup Roundup Roundup seeds Roundup Roundup Roundup roundup pesticides Roundup roundup Roundup roundup pesticides Roundup Roundup Roundup roundup seeds Roundup Roundup Roundup Roundup pesticides Roundup Roundup Roundup Roundup chemicals Roundup Roundup Roundup Roundup weeds Roundup Roundup Roundup Roundup soy Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundup antibiotics Roundup Roundup Roundup Roundup poison Roundup Roundup Roundup Roundupicide Roundup Roundup Roundup Roundup GMOs Roundup Roundup Roundup Roundup mosquitoes Roundup Roundup Roundup Roundup trees Roundup Roundup Roundup Roundup beetles Roundup Roundup Roundup Roundup eggs Roundup Roundup Roundup Roundup onions Roundup Roundup Roundup Roundup rats Roundup Roundup Roundup Roundup plants Roundup Roundup Roundup Roundup potatoes Roundup Roundup Roundup Roundup apples Roundup Roundup Roundup Roundup tomatoes Roundup Roundup Roundup Roundup supplements Roundup Roundup Roundup Roundup products Roundup Roundup Roundup Roundup bugs Roundup Roundup Roundup Roundup compounds Roundup Roundup Roundup Roundup ants Roundup Roundup Roundup Roundup powder Roundup Roundup Roundup Roundup Powder Roundup Roundup Roundup Roundup strawberries Roundup Roundup Roundup Roundup dogs Roundup Roundup Roundup Roundup flowers Roundup Roundup Roundup Roundupicides Roundup Roundup Roundup Roundup babies Roundup Roundup Roundup Roundup mice Roundup Roundup Roundup Roundup\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're dying of cancer. Then you realize that's what happens when people die of cancer. Then tears begin flowing uncontrollably throughout your body. Tears of joy. Tears of sadness. Tears of painlessness. Tears of sorrowfulness... tears of happiness? tears of sadnessnessiness sobility sobility sobilitylessness sobility sobility bliss\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0053, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0228, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Great, great job on the interview! Hope you got a job lined up for next year!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7531, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7638, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks! I'm hoping so too!\n",
      "DialoGPT: Best of luck to you!\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8183, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7212, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks! You too!\n",
      "DialoGPT: Thanks you too!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8038, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8870, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: You're welcome!\n",
      "DialoGPT: You're Welcome! Thank you're welcome!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8213, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8061, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're happy!\n",
      "DialoGPT: 30RTJinglehausenileeia's unite with\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7541, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6151, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.8726, 1.8985, 1.5346, 1.1612, 0.7459, 0.3424, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.0070, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3793, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3850, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4228, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4069, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3424, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.8726, grad_fn=<UnbindBackward>)\n",
      "Episode 266: -0.2892682562557778\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when compared to Blu rays. Plus blu ray discs are cheaper than DVDs these days. So DVD's cost more money than Blu Rays nowadays. Hence why Blu Ray prices skyrocketed recently.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost less than Blu Rays these days because Blu Rays are cheaper than DVD's these days due to inflation rates. Blu Rays cost more than DVD's thesedays due to inflation rates due to inflation rates costs ratio ratios ratios ratios ratios ratios factors factors factors factors factors factor factors factors factors factors variables factors factors factors factors Factors factors factors factors factors elements factors ducks apples oranges apples oranges oranges oranges apples oranges apples oranges apples apples oranges apples oranges grapes tomatoes seeds seeds seeds seeds seeds etc seeds seeds seeds seeds roundup roundup roundup roundup roundup chemicals roundup roundup roundup roundup pesticides roundup roundup roundup roundup Roundup roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticide roundup roundup roundup roundup GMOs roundup roundup roundup roundup antibiotics roundup roundup roundup roundup GMO roundup roundup roundup roundup etc roundup roundup roundup roundup weeds roundup roundup roundup roundup Monsanto roundup roundup roundup roundup chemical roundup roundup roundup roundup crops roundup roundup roundup roundup GM roundup roundup roundup roundup plants roundup roundup roundup roundup fertilizer roundup roundup roundup roundup herb roundup roundup roundup roundup organic roundup roundup roundup roundup water roundup roundup roundup roundup\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Roundup Roundup Roundup Roundup Roundup Roundup roundup roundup roundup roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup pesticide Roundup roundup roundup roundup Roundup roundup roundup roundup pesticides Roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticides roundup roundup roundup roundup glyphosate Roundup roundup roundup roundup pesticide roundup roundup roundup roundup pesticide Roundup roundup roundup Roundup roundup Roundup roundup Roundup Roundup Roundup roundup Roundup Roundup roundup roundup Roundup Roundup roundup Roundup roundup roundup Roundup seeds roundup roundup roundup roundup seeds roundup roundup roundup Roundup seeds Roundup roundup roundup roundup seeds Roundup roundup roundup Roundup pesticide roundup roundup roundup Roundup pesticide Roundup roundup Roundup roundup seeds Roundup roundup Roundup roundup pesticide roundup roundup Roundup roundup seeds roundup roundup Roundup roundup pesticide Roundup roundup Roundup Roundup seeds Roundup roundup Roundup Roundup pesticide roundup roundup Roundup Roundup seeds roundup roundup Roundup Roundup pesticide Roundup Roundup roundup roundup pesticide roundup Roundup roundup roundup pesticide Roundup Roundup roundup Roundup seeds Roundup Roundup roundup roundup pesticides Roundup Roundup roundup roundup seeds Roundup Roundup roundup Roundup pesticide Roundup Roundup Roundup roundup pesticide Roundup Roundup Roundup Roundup seeds Roundup Roundup Roundup roundup pesticides Roundup roundup Roundup roundup pesticides Roundup Roundup Roundup roundup seeds Roundup Roundup Roundup Roundup pesticides Roundup Roundup Roundup Roundup chemicals Roundup Roundup Roundup Roundup weeds Roundup Roundup Roundup Roundup soy Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundup antibiotics Roundup Roundup Roundup Roundup poison Roundup Roundup Roundup Roundupicide Roundup Roundup Roundup Roundup GMOs Roundup Roundup Roundup Roundup mosquitoes Roundup Roundup Roundup Roundup trees Roundup Roundup Roundup Roundup beetles Roundup Roundup Roundup Roundup eggs Roundup Roundup Roundup Roundup onions Roundup Roundup Roundup Roundup rats Roundup Roundup Roundup Roundup plants Roundup Roundup Roundup Roundup potatoes Roundup Roundup Roundup Roundup apples Roundup Roundup Roundup Roundup tomatoes Roundup Roundup Roundup Roundup supplements Roundup Roundup Roundup Roundup products Roundup Roundup Roundup Roundup bugs Roundup Roundup Roundup Roundup compounds Roundup Roundup Roundup Roundup ants Roundup Roundup Roundup Roundup powder Roundup Roundup Roundup Roundup Powder Roundup Roundup Roundup Roundup strawberries Roundup Roundup Roundup Roundup dogs Roundup Roundup Roundup Roundup flowers Roundup Roundup Roundup Roundupicides Roundup Roundup Roundup Roundup babies Roundup Roundup Roundup Roundup mice Roundup Roundup Roundup Roundup\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're dying of cancer. Then you realize that's what happens when people die of cancer. Then tears begin flowing uncontrollably throughout your body. Tears of joy. Tears of sadness. Tears of painlessness. Tears of sorrowfulness... tears of happiness? tears of sadnessnessiness sobility sobility sobilitylessness sobility sobility bliss\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.1343, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.1498, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: doing well, how are you doing???\n",
      "r1: tensor(-0.0012, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8426, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8683, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how are YOU doing????\n",
      "DialoGPT: doing well? how are you doing doing well??\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.9210, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8933, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am doing well, how about you?\n",
      "DialoGPT: doing good how are you doing well????? How are you doing well doing well doing well?? How are YOU doing well doing well well???\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8860, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8040, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.2746, 1.2913, 0.8720, 0.4226, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0038, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4280, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4536, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4226, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.2746, grad_fn=<UnbindBackward>)\n",
      "Episode 267: -0.2881747793941411\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially when compared to Blu rays. Plus blu ray discs are cheaper than DVDs these days. So DVD's cost more money than Blu Rays nowadays. Hence why Blu Ray prices skyrocketed recently.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost less than Blu Rays these days because Blu Rays are cheaper than DVD's these days due to inflation rates. Blu Rays cost more than DVD's thesedays due to inflation rates due to inflation rates costs ratio ratios ratios ratios ratios ratios factors factors factors factors factors factor factors factors factors factors variables factors factors factors factors Factors factors factors factors factors elements factors ducks apples oranges apples oranges oranges oranges apples oranges apples oranges apples apples oranges apples oranges grapes tomatoes seeds seeds seeds seeds seeds etc seeds seeds seeds seeds roundup roundup roundup roundup roundup chemicals roundup roundup roundup roundup pesticides roundup roundup roundup roundup Roundup roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticide roundup roundup roundup roundup GMOs roundup roundup roundup roundup antibiotics roundup roundup roundup roundup GMO roundup roundup roundup roundup etc roundup roundup roundup roundup weeds roundup roundup roundup roundup Monsanto roundup roundup roundup roundup chemical roundup roundup roundup roundup crops roundup roundup roundup roundup GM roundup roundup roundup roundup plants roundup roundup roundup roundup fertilizer roundup roundup roundup roundup herb roundup roundup roundup roundup organic roundup roundup roundup roundup water roundup roundup roundup roundup\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Roundup Roundup Roundup Roundup Roundup Roundup roundup roundup roundup roundup roundup Roundup Roundup Roundup Roundup glyphosate Roundup Roundup Roundup Roundup Monsanto Roundup Roundup Roundup Roundup pesticide Roundup roundup roundup roundup Roundup roundup roundup roundup pesticides Roundup roundup roundup roundup glyphosate roundup roundup roundup roundup pesticides roundup roundup roundup roundup glyphosate Roundup roundup roundup roundup pesticide roundup roundup roundup roundup pesticide Roundup roundup roundup Roundup roundup Roundup roundup Roundup Roundup Roundup roundup Roundup Roundup roundup roundup Roundup Roundup roundup Roundup roundup roundup Roundup seeds roundup roundup roundup roundup seeds roundup roundup roundup Roundup seeds Roundup roundup roundup roundup seeds Roundup roundup roundup Roundup pesticide roundup roundup roundup Roundup pesticide Roundup roundup Roundup roundup seeds Roundup roundup Roundup roundup pesticide roundup roundup Roundup roundup seeds roundup roundup Roundup roundup pesticide Roundup roundup Roundup Roundup seeds Roundup roundup Roundup Roundup pesticide roundup roundup Roundup Roundup seeds roundup roundup Roundup Roundup pesticide Roundup Roundup roundup roundup pesticide roundup Roundup roundup roundup pesticide Roundup Roundup roundup Roundup seeds Roundup Roundup roundup roundup pesticides Roundup Roundup roundup roundup seeds Roundup Roundup roundup Roundup pesticide Roundup Roundup Roundup roundup pesticide Roundup Roundup Roundup Roundup seeds Roundup Roundup Roundup roundup pesticides Roundup roundup Roundup roundup pesticides Roundup Roundup Roundup roundup seeds Roundup Roundup Roundup Roundup pesticides Roundup Roundup Roundup Roundup chemicals Roundup Roundup Roundup Roundup weeds Roundup Roundup Roundup Roundup soy Roundup Roundup Roundup Roundup crops Roundup Roundup Roundup Roundup antibiotics Roundup Roundup Roundup Roundup poison Roundup Roundup Roundup Roundupicide Roundup Roundup Roundup Roundup GMOs Roundup Roundup Roundup Roundup mosquitoes Roundup Roundup Roundup Roundup trees Roundup Roundup Roundup Roundup beetles Roundup Roundup Roundup Roundup eggs Roundup Roundup Roundup Roundup onions Roundup Roundup Roundup Roundup rats Roundup Roundup Roundup Roundup plants Roundup Roundup Roundup Roundup potatoes Roundup Roundup Roundup Roundup apples Roundup Roundup Roundup Roundup tomatoes Roundup Roundup Roundup Roundup supplements Roundup Roundup Roundup Roundup products Roundup Roundup Roundup Roundup bugs Roundup Roundup Roundup Roundup compounds Roundup Roundup Roundup Roundup ants Roundup Roundup Roundup Roundup powder Roundup Roundup Roundup Roundup Powder Roundup Roundup Roundup Roundup strawberries Roundup Roundup Roundup Roundup dogs Roundup Roundup Roundup Roundup flowers Roundup Roundup Roundup Roundupicides Roundup Roundup Roundup Roundup babies Roundup Roundup Roundup Roundup mice Roundup Roundup Roundup Roundup\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're dying of cancer. Then you realize that's what happens when people die of cancer. Then tears begin flowing uncontrollably throughout your body. Tears of joy. Tears of sadness. Tears of painlessness. Tears of sorrowfulness... tears of happiness? tears of sadnessnessiness sobility sobility sobilitylessness sobility sobility bliss\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1948, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0676, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Pretty good, how bout you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7654, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7513, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(7.5833e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I am good, how about you?\n",
      "DialoGPT: Fine, thanks for asking me that question. How about you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8406, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8407, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I've been pretty good, how about yourself?\n",
      "DialoGPT: That's good, good enough for me?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7790, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7367, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That's great!\n",
      "DialoGPT: That's good enough for me to be able to talk to someone who knows me?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8572, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7651, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: That is good enough for me\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.4794, 1.5605, 1.1932, 0.7806, 0.4056, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0655, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3793, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4204, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3790, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4056, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.4794, grad_fn=<UnbindBackward>)\n",
      "Episode 268: -0.2868599354369102\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and get started on this project real quick before I leave for work tomorrow morning.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then pal. Lets start with DVD rentals first. Then move onto Blu ray rentals later when DVD sales become more prevalent worldwide. Then DVD rentals later on DVD sales worldwide. Etcetera etcetera etceteraaaahhh... Etceteraetceterahemptendoerrrrrreeeeerrrrrrrr\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they cut out the credits and start playing commercials instead of trailers. That's when tears begin flowing uncontrollably through my eyes. Tears of joy! Tears of sadness! Tears of happiness! Tears of sadnesslessnessinesslessnesslessnesslessnesslessnesslessnessedomilitylessnesslessnesslessnesslessnessitivenessesitylessnessanitylessnessulencelessnessitylessnesslessnesslessnesslessnessinesslessnesslessnessflixflixflixflixflixnetflixflixflixflixflixtvseriesflixseriesflixseriesflixnetflixflixseriesflixseriesNetflixseriesflixseriesflixflixseriesflixseriesnetflixseriesflixseriesflixmovieflixseriesflixseries NetflixflixseriesflixseriesTorrentflixseriesflixseriespirateflixseriesflixseriestorrentflixseriesflixseries torrentflixseriesflixseries Torrentflixseriesflixseries TVtropflixseriesflixseriesTVflixseriesflixseriestvflixseriesflixseries tvflixseriesflixseriesoutubeflixseriesflixseries HBOflixseriesflixseries televisionflixseriesflixseries Showtimeflixseriesflixseries HuluflixflixflixflixseriesflixflixflixflixNetflixflixflixflixflixmovieflixflixflixflixTorrentflixflixflixflixpirateflixflixflixflixtorflixflixflixflixSeriesflixflixflixflixTVflixflixflixflixMovieflixflixflixflix Netflixflixflixflixflix TVflixflixflixflix HBOflixflixflixflixoutubeflixflixflixflixdoorflixflixflixflixhomeflixflixflixflixwatchflixflixflixflixviewflixflixflixflixrageflixflixflixflixcreenflixflixflixflixlingerflixflixflixflixpipeflixflixflixflixreamflixflixflixflixaredevilflixflixflixflixtipflixflixflixflixfilmflixflixflixflixwebflixflixflixflixyoutubeflixflixflixflixbingflixflixflixflixBluewflixflixflixflixitlescreenflixflixflixNetflixNetflixflixflixflixNetflixnetflixflixflixflixNetflix NetflixflixflixflixNetflixTorrentflixflixflixNetflixTVflixflixflixNetflix TVflixflixflixNetflixcreenflixflixflixnetflixNetflixflixflixflixnetflixnetflixflixflixflixnetflix Netflixflixflixflixnetflix TVflixflixflixnetflixcreenflixflixflix NetflixNetflixflixflixflix Netflixnetflixflixflixflix Netflix Netflixflixflixflix NetflixTorrentflixflixflixnetflixTorrentflixflixflix NetflixFireflixflixflixflixFireflixflixflixNetflix Daredevilflixflixflixflixfireflixflixflixflix DaredevilflixflixflixNetflixaredevilflixflixflixNetflixFireflixflixflixnetflix DaredevilflixflixflixnetflixaredevilflixflixflixnetflixlingerflixflixflixNetflixlingerflixflixflixnetflixBluflixflixflixflixPopperflixflixflixflixbuffflixflixflixflixkillflixflixflixflixWatchflixflixflixflixScreenflixflixflixflixipediaflixflixflixflix WebflixflixflixflixicideflixflixflixflixfishflixflixflixflixpoflixflixflixflixbageflixflixflixflixkillerscreenflixflixflixcreencreenflixflixflixFireNetflixflixflixflixcreenNetflixflixflixflixFirefireflixflixflixNetflixfireflixflixflixnetflixitlescreenflixflixNetflixflixNetflixflixflixNetflixflixnetflixflixflixNetflixflixcreenflixflixNetflixNetflixNetflixflixflixNetflixNetflix NetflixflixflixNetflixflix NetflixflixflixNetflixNetflixnetflixflixflixNetflixNetflixcreenflixflixNetflix NetflixNetflixflixflixNetflix Netflix NetflixflixflixNetflix NetflixnetflixflixflixNetflix NetflixFireflixflixNetflixflixFireflixflixNetflixNetflixFireflixflixNetflix Netflixfireflixflixflix NetflixfireflixflixNetflixflixfireflixflixNetflixNetflixfireflixflixNetflix NetflixcreenflixflixflixfireNetflixflixflixflixfirefireflixflixflixFireFireflixflixflix Netflix fireflixflixflixflix fireflixflixflixNetflix fireflixflixflix NetflixcreenflixflixNetflixFireNetflixflixflixNetflixFirefireflixflixNetflixFireFireflixflixNetflixFirenetflixflixflixflixFirenetflixflixflixNetflixFire NetflixflixNetflixflixNetflixNetflixflixNetflixflixNetflix NetflixflixNetflixflixflix NetflixflixNetflixflix NetflixNetflixflixNetflixflix NetflixFireNetflixflixNetflixflixFireNetflixflixNetflixNetflixNetflixNetflixflixNetflixNetflix NetflixNetflixflixNetflixNetflixFireNetflixflixNetflix NetflixNetflixNetflixflixNetflix Netflix NetflixNetflixflixNetflix NetflixFireNetflixflixflix NetflixNetflixNetflixflixflix Netflix NetflixNetflixflixflix NetflixFireNetflix NetflixflixNetflix Netflixflix NetflixflixNetflix NetflixNetflix NetflixflixNetflixNetflixflix NetflixflixNetflixNetflix Netflix NetflixflixNetflixflixFireFireNetflix Netflixflix NetflixNetflix Netflixflix Netflix NetflixflixNetflix Netflix Netflix NetflixflixNetflixNetflixNetflix NetflixflixNetflixFireNetflix Netflixflixflix Netflixflix Netflixflix NetflixNetflixflix Netflixflix Netflix NetflixNetflix Netflixflixflixnetflix Netflix Netflixflix Netflixflixflix Netflix Netflix Netflixflix Netflix Netflix Netflix Netflixflixflix NetflixNetflix Netflix Netflixflix NetflixNetflixNetflix Netflixflix NetflixFireNetflixNetflix Netflixflixnetflix Netflixflix Netflixflixnetflix Netflix Netflix Netflixflixnetflix NetflixNetflix Netflixflixnetflixflix Netflixflix Netflixnetflix Netflixflix Netflix Netflixnetflix Netflixflixflix Netflix\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0753, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.1248, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Great job man! How's your day been?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7531, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8002, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's been great, thanks!\n",
      "DialoGPT: Awesome man, glad to hear it's been going well for you. Keep it up the good work!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7857, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8069, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks, I will!\n",
      "DialoGPT: Keep it up man keep it up!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8359, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6964, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks, you too!\n",
      "DialoGPT: Thanks man, I'll try to keep it up too!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7894, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7963, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks, keep it up!\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5399, 1.5429, 1.1661, 0.7757, 0.3965, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0124, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3884, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3982, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3832, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3965, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5399, grad_fn=<UnbindBackward>)\n",
      "Episode 269: -0.28584350507223494\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and get started on this project real quick before I leave for work tomorrow morning.\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alrighty then pal. Lets start with DVD rentals first. Then move onto Blu ray rentals later when DVD sales become more prevalent worldwide. Then DVD rentals later on DVD sales worldwide thereafter. Etcetera etcetera etceteraaaahhh... Etceteraetceteraetceteraaaaahhhh... Etceteraaaahah\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they cut out the credits and start playing music instead of commercials during those scenes. Tears everywhere. Tears of joy. Tears of sadness. Tears of laughter. Tears of happiness tears. Tears of sadness cries. Tears of laughter laughs hysterically sobbing uncontrollably weeping uncontrollably laughing hysterically sobbing hysterically sobbing hysterically sobbing hyster\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.1119, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.1141, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: doing ok, been busy with school stuff but otherwise doing ok. Yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7568, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7575, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, I'm just busy with school stuff.\n",
      "DialoGPT: fair enough.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3205, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5801, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well.\n",
      "DialoGPT: Yeah, school stuff is stressful sometimes.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7299, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7719, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Yeah, it is.\n",
      "DialoGPT: Yeah it is. It's stressful sometimes.\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8454, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8910, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I know.\n",
      "DialoGPT: Yeah it's stressful sometimes. It's stressful\n",
      "r1: tensor(-0.0007, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8594, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.5268, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.6503, 1.7240, 1.3590, 1.1452, 0.7774, 0.3467, 0.0000],\n",
      "       grad_fn=<CopySlices>)\n",
      "[tensor(-0.0564, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3786, device='cuda:0', grad_fn=<NegBackward>), tensor(0.2252, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3755, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4342, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3467, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.6503, grad_fn=<UnbindBackward>)\n",
      "Episode 270: -0.28458051380402377\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing, pal. Let me grab my wallet and wallet accessories first. Then we'll talk about DVD prices here. Deal? Deal! Deal! Deal! Buy DVD! Buy DVD! Sell DVD! Profit Profit Profit Profit Profit profit Profit Profit Profit Profitprofit Profit Profit Profit Profit profits Profit Profit Profit Profitprofits Profit Profit Profit Profit Profits Profit Profit Profit Profit Dollars Profit Profit Profit Profit dollars Profit Profit Profit Profit cents Profit Profit Profit Profit bucks Profit Profit Profit Profit margins Profit Profit Profit Profit margin Profit Profit Profit Profit profiteisse Profit Profit Profit Profit taxes Profit Profit Profit Profit tax profit Profit Profit Profit profit profit Profit Profit Profit profits profit Profit Profit Profitprofit profit Profit Profit Profit\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Then we'll have a party. Profit Profit Profit Profit Profit profit Profit Profit Profit Profitprofit Profit Profit Profit Profitprofits Profit Profit Profit Profit profits Profit Profit Profit Profit Profiteirs Profit Profit Profit Profit Property Profit Profit Profit Profit Tax Profit Profit Profit Profit Income Profit Profit Profit Profit Revenue Profit Profit Profit Profit Money Profit Profit Profit Profit Taxes Profit Profit Profit Profit Dollars Profit Profit Profit Profit dollars Profit Profit Profit Profit money Profit Profit Profit Profit losses Profit Profit Profit Profit Loss Profit Profit Profit Profit\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Cry tears of joy tears of joy tears Of joy tears tears Of joy tears Tears Of joy tears Of joy Tears Of joy Tears Of Joy Tears Of joy Tears of joy Profit Profit Profit Profit Profit profit Profit Profit Profit Profitprofit Profit Profit Profit Profit profits Profit Profit Profit Profitprofits Profit Profit Profit Profit Prof Profit Profit Profit Profit prof Profit Profit Profit Profit Capitalism Capitalism Profit Profit Profit Profit capitalism Profit Profit Profit Profitocracy Profitocracy Profitocracy Capitalism Profitocracy Profitocracy profitocracy Profitocracy Profitarchy Profitocracy Profitocracyprofitocracy Profitocracy Profitocraticocracy Profitocracy Profitocracy Profitocracy Profitocracy Democracy Profitocracy Profitocracy capitalism Profitocracy Profitocracy democracy Profitocracy Profitocracy\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0006, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.3495, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2315, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: FineFineFineFineFine Fine Fine Fine Fine FineFineFineFineFineFuckFineFineFineFinefineFineFineFineFineFffffffffffffffffffffffffffffffffffffffffffffffffffffffffffeeffeeffeeffeeffeefeeffeeffeeffeeffeeeeffeeffeeffeeffeefffffeeffeeffeeffeeffeffeeffeeffeeffeeafeffeeffeeffeeffeeffffeeffeeffeeffeeffffffeeffeeffeefeeffe\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6407, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6517, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.4653, 0.3232, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.1454, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3232, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.4653, grad_fn=<UnbindBackward>)\n",
      "Episode 271: -0.2840688827632488\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost more than Blu Rays these days? WowzersoundshowerdayzeeshowerzoshowerzoshowerzosideshowerzoshowerzosidezoshowerzoshowerboshowerzoshowerzositeshowerzoshowerzoshotshowerzoshowerzosaturdayshowerzoshowerzosaturdayzoshowerzoshowerzoaturdayshowerzoshowerbosaturdayshowerzosaturdayshowerboshowerazineshowerzoshowerzosetterbackshowerzoshowerzosettingzoshowerzoshowertzhowerzoshowerzosandyzoshowerzoshowerholeshowerzoshowerzoscreenshotshowerzoshowerzosterdayzoshowerzoshoweritleshowerzoshowerzoserkerzoshowerzoshowerzenshowerzoshowerzosabrezoshowerzoshowerZombieshowerzoshowerzosombroshowerzoshowerzoshotzoshowerzoshowerZenzoshowerzoshowerzenzoshowerzoshoweratoeshowerzoshowerzoszoshowerzoshowerbozoshowerzoshowerzzoshowerzoshowerotlezoshowerzoshowerholezoshowerzoshowerlotteritleshowerzoshoweritlesomeechantzhowerzoshowerzositleshowerzoshowerboscheryzoshowerzoshowerakespearehowerzoshowerzosqueekzoshowerzoshowerbeeshowerzoshowerzoscheatershowerzoshowerzosmithzoshowerzoshowerbirdshowerzoshowerzosakespearehowerzoshoweritlescreenitleshowerzoshowerakespeareakespeareakespeareakespeareakespeare Shakespeareakespeareakespeareakespeareakespearehowerakespeareakespeareakespeare Shakespeare Shakespeareakespeareakespeareakespeare Shakespearehowerakespeareakespeareakespearezosakespeareakespeareakespeareakespeareakespeakespeareakespeareakespeareakespearezos ShakespeareakespeareakespeareakespearezosqueakespeareakespeareakespeareakespeareQuotes Shakespeareakespeareakespeareakespeareakespeastingakespeareakespeareakespeareakespeare Chauchingakespeareakespeareakespeareakespeare Paste Shakespeareakespeareakespeareakespeare Chaucheakespeareakespeareakespeareakespeare\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a picnic. And afterwards, we'll sing songs together singing songs together singing songs songs together singing songs... Singing songs together singing songs Together singing songs together singing Songs together singing songs together Singing songs together Singing Songs together singing songsTogetherSinging songsTogetherSingingQuotesQuotesQuotesQuotesQuotesQuoteQuotesQuotesQuotesassholeballshowerhowerhowerhowerhowerbuttfuckaroundhereforeheadbutthemselveshowerhowerhowerhowertreeshowerhowerhowerhowerroughhowerhowerhowerhowerbardhowerhowerhowerhowerbeckhowerhowerhowerhowerballhowerhowerhowerhowerballshowerhowerhowerballshitlerhowerhowerhowerhowerhotballshowerhowerhowerballholehowerhowerhowerhowerholehowerhowerhowerballholeshowerhowerhowerhowerwayhowerhowerhowerhowercarehowerhowerhowerhowerbirdhowerhowerhowerhowerbuckhowerhowerhowerhowerbirdshowerhowerhowerhowertreehowerhowerhowerhowerthinghowerhowerhowerhowerbackhowerhowerhowerhowerbrhowerhowerhowerhowerbhowerhowerhowerhowerBrhowerhowerhowerhowerwoodhowerhowerhowerhowerBhowerhowerhowerhowerhirehowerhowerhowerhowerbathhowerhowerhowerhowerFourthhowerhowerhowerhowertrhowerhowerhowerhowerlerhowerhowerhowerballandyhowerhowerhowerhowerinchowerhowerhowerhowerpringhowerhowerhowerhoweragainhowerhowerhowerhowerterhowerhowerhowerhoweritleshowerhowerhowerhowergershowerhowerhowerhowerbirthhowerhowerhowerhowerallhowerhowerhowerhowerandhowerhowerhowerhower4howerhowerhowerhowercirclehowerhowerhowerhoweronehowerhowerhowerhowerronehowerhowerhowerhowertrihowerhowerhowerhowertlhowerhowerhowerhowerdayhowerhowerhowerhowerchildhowerhowerhowerhowerbabyhowerhowerhowerhowerwaterhowerhowerhowerhowerholhowerhowerhowerhowerandyhowerhowerhowerballhothowerhowerhowerhowerhehowerhowerhowerhowerbodyhowerhowerhowerhowerheadhowerhowerhowerhowerkindhowerhowerhowerhowerfirehowerhowerhowerhowertohowerhowerhowerhowerstickhowerhowerhowerhowerlinghowerhowerhowerhowernobhowerhowerhowerhowerpiecehowerhowerhowerhowerroduhowerhowerhowerhower Fourhowerhowerhowerhower\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're crying tears of joy over their own deaths. Then they realize that they died years ago and cried tears of sadness again. Poor souls... cries sob sob sob sob sobbing sob sob sob sobbs sob sob sob sob Sob sob sob sob sob cries sob sob sob Sob Sob sob sob sob Sobbing sob sob sob Sobber sobbers sob sob sob sobbedgershahahahaaahhhahahahhhhhhhhahahahahahahahahahahahaahahahahahahahahahhhhhhhhhhhhhhhhhhhhhhhahahahahahahahahhaaahhhhhhhhhhhhhhhhhhahahahahahahahahhhhhhhhhhhhhhhhhhhhahahahahhhhhhhhhhahahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhahahahahahahahahhahahahahahahhhhhhahahahahhhhhhhhhahahahahhhhhhhhhhhahahhhhhhhhhhhhhahahhhhhhhhhhhhhhhHHHHHHHHHHHHHHHHHHHHHHHHHHhhhhHHHHHHHHhhhhHHHHHHH HHHHHHHHHH HHHHHHHHH HHHHHHHHH HHHHHHHHHSHHHHHHHHhHHHHHHHHHPHHHHHHHHHSHHHHHHHhHHHHHHHMHHHHHHHHHMHHHHHHHHHIHHHHHHHH HARHHHHHHHHHIHH HHHHH HHH HHHHH HHHH HHHHHHHH HHHHH HIHHHHHHHH HIHH HHHHHHIHH HHHHHH HHH HHHHHH HHHH HHHHHHHHH HHHHHH HIHH HHHHHHHIHHHHHHH HIHHHHHHH TripleHHHHHHHH TripleHH HHHHH TripleHH HHHHHH TripleHH TripleHHHH HHH TripleHHHH HHHH TripleHHHH TripleHH HIHHHH HHH HIHHHH TripleHHHHHHH\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hi there! How are you?\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0533, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.2638, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: Fine, how are you doing?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7754, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8562, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, how about you?\n",
      "DialoGPT: I've been better lately, been better lately myself. Yourself?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7564, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7755, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm pretty good, I'm doing well.\n",
      "DialoGPT: That's good to hear. How's life treating ya?\n",
      "r1: tensor(-0.0029, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7400, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7122, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's good, I'm just getting back into my normal routine.\n",
      "DialoGPT: Yeah, it's good.\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.7324, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8179, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(4.6649e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad\n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.5841, 1.5199, 1.1231, 0.7476, 0.3877, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0794, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4080, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3830, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3638, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3877, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.5841, grad_fn=<UnbindBackward>)\n",
      "Episode 272: -0.28331911252409003\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost more than Blu Rays these days? WowzersoundshowerdayzeeshowerzoshowerzoshowerzosideshowerzoshowerzosidezoshowerzoshowerboshowerzoshowerzositeshowerzoshowerzoshotshowerzoshowerzosaturdayshowerzoshowerzosaturdayzoshowerzoshowerzoaturdayshowerzoshowerbosaturdayshowerzosaturdayshowerboshowerazineshowerzoshowerzosetterbackshowerzoshowerzosettingzoshowerzoshowertzhowerzoshowerzosandyzoshowerzoshowerholeshowerzoshowerzoscreenshotshowerzoshowerzosterdayzoshowerzoshoweritleshowerzoshowerzoserkerzoshowerzoshowerzenshowerzoshowerzosabrezoshowerzoshowerZombieshowerzoshowerzosombroshowerzoshowerzoshotzoshowerzoshowerZenzoshowerzoshowerzenzoshowerzoshoweratoeshowerzoshowerzoszoshowerzoshowerbozoshowerzoshowerzzoshowerzoshowerotlezoshowerzoshowerholezoshowerzoshowerlotteritleshowerzoshoweritlesomeechantzhowerzoshowerzositleshowerzoshowerboscheryzoshowerzoshowerakespearehowerzoshowerzosqueekzoshowerzoshowerbeeshowerzoshowerzoscheatershowerzoshowerzosmithzoshowerzoshowerbirdshowerzoshowerzosakespearehowerzoshoweritlescreenitleshowerzoshowerakespeareakespeareakespeareakespeareakespeare Shakespeareakespeareakespeareakespeareakespearehowerakespeareakespeareakespeare Shakespeare Shakespeareakespeareakespeareakespeare Shakespearehowerakespeareakespeareakespearezosakespeareakespeareakespeareakespeareakespeakespeareakespeareakespeareakespearezos ShakespeareakespeareakespeareakespearezosqueakespeareakespeareakespeareakespeareQuotes Shakespeareakespeareakespeareakespeareakespeastingakespeareakespeareakespeareakespeare Chauchingakespeareakespeareakespeareakespeare Paste Shakespeareakespeareakespeareakespeare Chaucheakespeareakespeareakespeareakespeare\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a picnic. And afterwards, we'll sing songs together singing songs together singing songs songs together singing songs... Singing songs together singing songs Together singing songs together singing Songs together singing songs together Singing songs together Singing Songs together singing songsTogetherSinging songsTogetherSingingQuotesQuotesQuotesQuotesQuotesQuoteQuotesQuotesQuotesassholeballshowerhowerhowerhowerhowerbuttfuckaroundhereforeheadbutthemselveshowerhowerhowerhowertreeshowerhowerhowerhowerroughhowerhowerhowerhowerbardhowerhowerhowerhowerbeckhowerhowerhowerhowerballhowerhowerhowerhowerballshowerhowerhowerballshitlerhowerhowerhowerhowerhotballshowerhowerhowerballholehowerhowerhowerhowerholehowerhowerhowerballholeshowerhowerhowerhowerwayhowerhowerhowerhowercarehowerhowerhowerhowerbirdhowerhowerhowerhowerbuckhowerhowerhowerhowerbirdshowerhowerhowerhowertreehowerhowerhowerhowerthinghowerhowerhowerhowerbackhowerhowerhowerhowerbrhowerhowerhowerhowerbhowerhowerhowerhowerBrhowerhowerhowerhowerwoodhowerhowerhowerhowerBhowerhowerhowerhowerhirehowerhowerhowerhowerbathhowerhowerhowerhowerFourthhowerhowerhowerhowertrhowerhowerhowerhowerlerhowerhowerhowerballandyhowerhowerhowerhowerinchowerhowerhowerhowerpringhowerhowerhowerhoweragainhowerhowerhowerhowerterhowerhowerhowerhoweritleshowerhowerhowerhowergershowerhowerhowerhowerbirthhowerhowerhowerhowerallhowerhowerhowerhowerandhowerhowerhowerhower4howerhowerhowerhowercirclehowerhowerhowerhoweronehowerhowerhowerhowerronehowerhowerhowerhowertrihowerhowerhowerhowertlhowerhowerhowerhowerdayhowerhowerhowerhowerchildhowerhowerhowerhowerbabyhowerhowerhowerhowerwaterhowerhowerhowerhowerholhowerhowerhowerhowerandyhowerhowerhowerballhothowerhowerhowerhowerhehowerhowerhowerhowerbodyhowerhowerhowerhowerheadhowerhowerhowerhowerkindhowerhowerhowerhowerfirehowerhowerhowerhowertohowerhowerhowerhowerstickhowerhowerhowerhowerlinghowerhowerhowerhowernobhowerhowerhowerhowerpiecehowerhowerhowerhowerroduhowerhowerhowerhower Fourhowerhowerhowerhower\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they're crying tears of joy over their own deaths. Then they realize that they died years ago and cried tears of sadness again. Poor souls... cries sob sob sob sob sobbing sob sob sob sobbs sob sob sob sob Sob sob sob sob sob cries sob sob sob Sob Sob sob sob sob Sobbing sob sob sob Sobber sobbers sob sob sob sobbedgershahahahaaahhhahahahhhhhhhhahahahahahahahahahahahaahahahahahahahahhaaaaaaahahahahahahahahahahhhhhhahahahahahahahahhahahahahahahahahemescheworldoftheheeheeheeheeheeheehahahahahahahahahhehehehehehuaheheheheheeheeheehehehehehahahahahahahhheheheheehahahahahhehehahahhehehehhehehehuehahahahahahahhehahahahahhehehuahehahahahahhahahhehehhehahahahahahahehahahahahhhhhhahahahahhehhehhehahahehahahhehahahhehuahehhehuehhehahahhehrhehahahahahhahehahahahahhaihehahahahahhemhehahahahahahhahahahahahahhhhhhhehahahhahahahahhehuahehehahahhhehahahahahehhehhahahahahahahhahehehahahahaahahahahhehahahehehahahhhhhhahahhehhehehahahhahehhehhhhhhahahahahhhehhehehuahehuahehahahehuahehuehuehahahhehuehahahehhehehuhehahahahahuehahahahahheehahahahahhahahhahahhehahaahahahahahahhehuahahahahahahahhaihehehahahhaihehhehhaihehahahhehaihehahahhuehahahhahahhhehehhehuahehhaihehehhehaihehhehehaihehuehhaihehhehaihaihehahahhaihaihehhaihehaihehhaihaihehhehuahaihaihaihaihaihehuehaihaihaihaihhaihaihaihaihuahaihaihaihehaihaihaihaihuhaihaihaihaihihaihaihaihai Jinping Jinping Jinping Jinping Jinpinghaihaihaihaijihaihaihaihaijhaihaihaihai hahaihaihaihaieshhaihaihaihaiuehaihaihai Jinpinghaihaihai Jinping Xi Jinping Jinping Jinping Jinping Xi Jinping Jinpinghaihai Jinping Jinpinghaihaihehai Jinping Jinping Jinpinghai Jinping Jinping Jinping Xihai Jinping Jinping Jinping China Jinping Jinping Jinping Jinping Chinahai Jinping Jinping JinpingXi Jinping Jinping Jinping JinpingXi Xi Jinping Jinping Jinping Xi Xi Jinping Jinping Jinpinghai Xi Jinping Jinping Jinping China Xi Jinping Jinping JinpingXihai Jinping Jinping Jinping Gandhi Jinping Jinping Jinping Jinping Putin Jinping Jinping Jinping Jinping Trump Jinping Jinping Jinping Jinping Gandhi Xi Jinping Jinping Jinping Gandhi Gandhi Jinping Jinping Jinping XiXi Jinping Jinping Jinping Xi China Jinping Jinping Jinping Xi J Jinping Jinping Jinping Jinping\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hiya! How are you?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0749, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(0.0647, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm good, how are you?\n",
      "DialoGPT: doing well thanks for asking me that question. How are you doing yourself?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8368, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8222, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm doing well, thanks for asking me.\n",
      "DialoGPT: Awesome congrats on your anniversary! Mine is December 23rd 2015. Happy anniversary!\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8313, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.8026, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: Thanks! Happy anniversary to you too!\n",
      "DialoGPT: Happy anniversary to you two! Happy anniversary to me too! Happy anniversary to yourself too! Happy anniversary! Happy anniversary to everyone else too\n",
      "r1: tensor(-0.0004, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.8634, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.4272, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([1.0894, 1.1356, 0.7280, 0.3227, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(-0.0349, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4148, device='cuda:0', grad_fn=<NegBackward>), tensor(0.4085, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3227, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(1.0894, grad_fn=<UnbindBackward>)\n",
      "Episode 273: -0.28215785607029376\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost more than Blu Rays these days? WowzersoundshowerdayzeeshowerzoshowerzoshowerzosideshowerzoshowerzosidezoshowerzoshowerboshowerzoshowerzositeshowerzoshowerzoshotshowerzoshowerzosaturdayshowerzoshowerzosaturdayzoshowerzoshowerzoaturdayshowerzoshowerbosaturdayshowerzosaturdayshowerboshowerazineshowerzoshowerzosetterbackshowerzoshowerzosettingzoshowerzoshowertzhowerzoshowerzosandyzoshowerzoshowerholeshowerzoshowerzoscreenshotshowerzoshowerzosterdayzoshowerzoshoweritleshowerzoshowerzoserkerzoshowerzoshowerzenshowerzoshowerzosabrezoshowerzoshowerZombieshowerzoshowerzosombroshowerzoshowerzoshotzoshowerzoshowerZenzoshowerzoshowerzenzoshowerzoshoweratoeshowerzoshowerzoszoshowerzoshowerbozoshowerzoshowerzzoshowerzoshowerotlezoshowerzoshowerholezoshowerzoshowerlotteritleshowerzoshoweritlescreenitleshowerzoshowerboscheryzoshowerzoshowerakespearehowerzoshowerzositleshowerzoshowerzozoshowerzoshowerbeeshowerzoshowerzosqueekingitleshowerzoshowerakespeareakespeareakespeareakespeareakespeare Shakespeareakespeareakespeareakespeareakespearezosakespeareakespeareakespeareakespearehowerakespeareakespeareakespeare Shakespeare Shakespeareakespeareakespeareakespeare Shakespearehowerakespeareakespeareakespearezos Shakespeareakespeareakespeareakespearezosakespeakespeareakespeareakespeareakespeareakespeakespeareakespeareakespeare Shakespearezosakespeareakespeareakespeare Shakespeareakespeakespeareakespeareakespeareakespeastingakespeareakespeareakespeareakespeare ChauchingakespeareakespeareakespeareakespeareQuotes Shakespeareakespeareakespeareakespeareakespelingakespeareakespeareakespeareakespeare Paste Shakespeareakespeareakespeareakespeare Chaucheakespeareakespeareakespeareakespeare Shawakespeareakespeareakespeareakespeare\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a picnic. And afterwards, we'll sing songs together singing songs together singing songs alone singing songs alone singing poems alone singing songs alone chanting songs alone singing songs together singing poems alone singing poems alone sung by themselves... Singing songs alone sung by themselves sung by themselves sung sung by themselves sungbyselves sungbyselves sung\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they sing songs alone sung by itself sung by themselves sung BY THEM sung by themselves sung single sung by themselves sung solo sung by themselves sung alone sung by themselvessung sung by themselves sungalone sungalone sungalonesung sungalone sungalone sangalone sungalone sungtogether sungalone sungalone singedalone sungalone sunglassically sunglassically sungEDGYoutubeTVtvtvtvtvtvrtngtvtvtvtvtvstvtvtvtvTVtvtvtvTVTVtvtvtv TVTVtvtvtv tvtvtvtvtv TVtvtvtvtv tvTVtvtvtvlevision TVTVTVTVTVTVtvTVTVTVTV TVTVTVTVtvtvTVTVTVtv TVTVTVTV TVtvTVTVTV TVFXTVTVTVTV TelevisionTVTVTVTV CWTVTVTVTVTWTVTVTVTV TWTVTVTVTV TTVTVTVTV CBSTVTVTVTV FOXTVTVTVTVFXTVTVTV CWFXTVTVTV FOXFXTV FOXTV FOXTV FOX FOX FOX FOX FOXFX FOX FOX FOX FOXTV FOX FOXFX FOXFX FOX FOXFX FOXFOX FOX FOX FOX FOXFox FOX FOX FOX FOX Fox FOX FOX FOX FOXFOX FOX FOXFX FOXFox FOX FOXFX FOX Fox FOX FOXFX FOX FX FOX FOX FOX FOX NEWS FOX FOX FOX FOX TV FOX FOX FOX FOX FX FOX FOX Fox FOX Fox FOX FOX Fox FOXFox FOX FOX Fox FOXFX FOX FOX Fox FOXFOX FOX FOX Fox FOX NEWS FOX FOX Fox FOX fox FOX FOX FOX FOX fox FOX FOX Fox FOX TV FOX FOX Fox FOX FX FOX FOXFox FOX Fox FOX FOXFox FOXFox FOX FOXFox FOXFOX FOX FOXFox FOXFX FOX FOXFox FOX NEWS FOX FOXFox FOX fox FOX FOXFox FOX FX FOX FOXFOX FOX Fox FOX FOXFOX FOXFox FOX FOXFOX FOXFOX FOX FOXFOX FOX NEWS FOX FOXFOX FOXFX FOX FOXFOX FOX fox FOX FOXFOX FOX FX FOX FOX NEWS FOX Fox FOX FOX NEWS FOXFox FOX FOX NEWS FOXFOX FOX FOX NEWS FOX NEWS FOX FOX NEWS FOX fox FOX FOX NEWS FOXFX FOX FOX NEWS FOX FX FOX FOX fox FOX Fox FOX FOX fox FOXFox FOX FOX fox FOX NEWS FOX FOX fox FOXFOX FOX FOX fox FOX fox FOX FOX fox FOXFX FOX FOX fox FOXfox FOX FOX FOX FOXfox FOX FOX Fox FOXfox FOX FOXFox FOXfox FOX FOX NEWS FOXfox FOX FOXFOX FOXfox FOX FOX fox FOX FX FOX FOXFX FOX NEWS FOX FOXFX FOX fox FOX FOXFX FOXfox FOX FOXFX FOX TV FOX FOXFox FOX TV FOX FOX NEWS FOX TV FOX FOXFOX FOX TV FOX FOX fox FOX TV FOX FOXFX FOX TW FOX FOX FOX FOX TW FOX FOX Fox FOX TW FOX FOXFox FOX TW FOX FOX NEWS FOX TW FOX FOXFOX FOX TW FOX FOX fox FOX TW FOX FOXFX FOX CBS FOX FOX FOX FOX CBS FOX FOX Fox FOX CBS FOX FOXFox FOX CBS FOX FOX NEWS FOX CBS FOX FOXFOX FOX CBS FOX FOX fox FOX CBS FOX FOXFX FOX ABC FOX FOX FOX FOX ABC FOX FOX Fox FOX ABC FOX FOXFox FOX ABC FOX FOX NEWS FOX ABC FOX FOXFOX FOX ABC FOX FOX fox FOX ABC FOX FOXFX FOX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hey there! How's it going?\n",
      "r1: tensor(-0.0002, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(0.0674, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0842, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well!\n",
      "DialoGPT: That's good to hear!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6158, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7251, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm glad you're doing well!\n",
      "DialoGPT: Yeah me too!\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6793, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.7010, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: I'm happy for you!\n",
      "DialoGPT: Yeah meeee tooooommmmmmeeeeennnnnnnnnnnnddddddddddddddddddddddsdddddddddsdddddddddkdkddddddddmdddddddddduddddddddvd\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.6991, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.6166, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: \n",
      "DialoGPT: \n",
      "dummy\n",
      "False 0\n",
      "tensor([0.9937, 0.9994, 0.6709, 0.3290, 0.0000], grad_fn=<CopySlices>)\n",
      "[tensor(0.0042, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3353, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3451, device='cuda:0', grad_fn=<NegBackward>), tensor(0.3290, device='cuda:0', grad_fn=<NegBackward>), tensor(0.)]\n",
      "----- Loss: tensor(0.9937, grad_fn=<UnbindBackward>)\n",
      "Episode 274: -0.2811472757939588\n",
      "----------------------------------------\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I heard it was awful. Heard nothing about it though. Is it worth watching? Reviews seem mixed.\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: 12 times is a lot of movies...\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays. Especially Blu rays. Plus blu ray discs are cheaper than DVDs these days. Blu Rays are cheaper than DVDs too. Blu Ray discs cost less money per movie than DVDs. Periodically anyway.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: DVDs cost more than Blu Rays these days? WowzersoundshowerdayzeeshowerzoshowerzoshowerzosideshowerzoshowerzosidezoshowerzoshowerboshowerzoshowerzositeshowerzoshowerzoshotshowerzoshowerzosaturdayshowerzoshowerzosaturdayzoshowerzoshowerzoaturdayshowerzoshowerbosaturdayshowerzosaturdayshowerboshowerazineshowerzoshowerzosetterbackshowerzoshowerzosettingzoshowerzoshowertzhowerzoshowerzosandyzoshowerzoshowerholeshowerzoshowerzoscreenshotshowerzoshowerzosterdayzoshowerzoshoweritleshowerzoshowerzoserkerzoshowerzoshowerzenshowerzoshowerzosabrezoshowerzoshowerZombieshowerzoshowerzosombroshowerzoshowerzoshotzoshowerzoshowerZenzoshowerzoshowerzenzoshowerzoshoweratoeshowerzoshowerzoszoshowerzoshowerbozoshowerzoshowerzzoshowerzoshowerotlezoshowerzoshowerholezoshowerzoshowerlotteritleshowerzoshoweritlescreenitleshowerzoshowerboscheryzoshowerzoshowerakespearehowerzoshowerzositleshowerzoshowerzozoshowerzoshowerbeeshowerzoshowerzosqueekingitleshowerzoshowerakespeareakespeareakespeareakespeareakespeare Shakespeareakespeareakespeareakespeareakespearezosakespeareakespeareakespeareakespearehowerakespeareakespeareakespeare Shakespeare Shakespeareakespeareakespeareakespeare Shakespearehowerakespeareakespeareakespearezos Shakespeareakespeareakespeareakespearezosakespeakespeareakespeareakespeareakespeareakespeakespeareakespeareakespeare Shakespearezosakespeareakespeareakespeare Shakespeareakespeakespeareakespeareakespeareakespeastingakespeareakespeareakespeareakespeare ChauchingakespeareakespeareakespeareakespeareQuotes Shakespeareakespeareakespeareakespeareakespelingakespeareakespeareakespeareakespeare Paste Shakespeareakespeareakespeareakespeare Chaucheakespeareakespeareakespeareakespeare Shawakespeareakespeareakespeareakespeare\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: And then we'll have a picnic. And afterwards, we'll sing songs together singing songs together singing songs alone singing songs alone singing poems alone singing songs alone chanting songs alone singing songs together singing poems alone singing poems alone sung by themselves... Singing songs alone sung by themselves sung by themselves sung sung by themselves sungbyselves sungbyselves sung\n",
      "User: I always cry at the end.\n",
      "DialoGPT: Especially when they sing songs alone sung by itself sung by themselves sung BY THEM sung by themselves sung single sung by themselves sung solo sung by themselves sung alone sung by themselvessung sung by themselves sungalone sungalone sungalonesung sungalone sungalone sangalone sungalone sungtogether sungalone sungalone singedalone sungalone sunglassically sunglassically sungEDGYoutubeTVtvtvtvtvtvrtngtvtvtvtvtvstvtvtvtvTVtvtvtvTVTVtvtvtv TVTVtvtvtv tvtvtvtvtv TVtvtvtvtv tvTVtvtvtvlevision TVTVTVTVTVTVtvTVTVTVTV TVTVTVTVtvtvTVTVTVtv TVTVTVTV TVtvTVTVTV TVFXTVTVTVTV TelevisionTVTVTVTV CWTVTVTVTVTWTVTVTVTV TWTVTVTVTV TTVTVTVTV CBSTVTVTVTV FOXTVTVTVTVFXTVTVTV CWFXTVTVTV FOXFXTV FOXTV FOXTV FOX FOX FOX FOX FOXFX FOX FOX FOX FOXTV FOX FOXFX FOXFX FOX FOXFX FOXFOX FOX FOX FOX FOXFox FOX FOX FOX FOX Fox FOX FOX FOX FOXFOX FOX FOXFX FOXFox FOX FOXFX FOX Fox FOX FOXFX FOX FX FOX FOX FOX FOX NEWS FOX FOX FOX FOX TV FOX FOX FOX FOX FX FOX FOX Fox FOX Fox FOX FOX Fox FOXFox FOX FOX Fox FOXFX FOX FOX Fox FOXFOX FOX FOX Fox FOX NEWS FOX FOX Fox FOX fox FOX FOX FOX FOX fox FOX FOX Fox FOX TV FOX FOX Fox FOX FX FOX FOXFox FOX Fox FOX FOXFox FOXFox FOX FOXFox FOXFOX FOX FOXFox FOXFX FOX FOXFox FOX NEWS FOX FOXFox FOX fox FOX FOXFox FOX FX FOX FOXFOX FOX Fox FOX FOXFOX FOXFox FOX FOXFOX FOXFOX FOX FOXFOX FOX NEWS FOX FOXFOX FOXFX FOX FOXFOX FOX fox FOX FOXFOX FOX FX FOX FOX NEWS FOX Fox FOX FOX NEWS FOXFox FOX FOX NEWS FOXFOX FOX FOX NEWS FOX NEWS FOX FOX NEWS FOX fox FOX FOX NEWS FOXFX FOX FOX NEWS FOX FX FOX FOX fox FOX Fox FOX FOX fox FOXFox FOX FOX fox FOX NEWS FOX FOX fox FOXFOX FOX FOX fox FOX fox FOX FOX fox FOXFX FOX FOX fox FOXfox FOX FOX FOX FOXfox FOX FOX Fox FOXfox FOX FOXFox FOXfox FOX FOX NEWS FOXfox FOX FOXFOX FOXfox FOX FOX fox FOX FX FOX FOXFX FOX NEWS FOX FOXFX FOX fox FOX FOXFX FOXfox FOX FOXFX FOX TV FOX FOXFox FOX TV FOX FOX NEWS FOX TV FOX FOXFOX FOX TV FOX FOX fox FOX TV FOX FOXFX FOX TW FOX FOX FOX FOX TW FOX FOX Fox FOX TW FOX FOXFox FOX TW FOX FOX NEWS FOX TW FOX FOXFOX FOX TW FOX FOX fox FOX TW FOX FOXFX FOX CBS FOX FOX FOX FOX CBS FOX FOX Fox FOX CBS FOX FOXFox FOX CBS FOX FOX NEWS FOX CBS FOX FOXFOX FOX CBS FOX FOX fox FOX CBS FOX FOXFX FOX ABC FOX FOX FOX FOX ABC FOX FOX Fox FOX ABC FOX FOXFox FOX ABC FOX FOX NEWS FOX ABC FOX FOXFOX FOX ABC FOX FOX fox FOX ABC FOX FOXFX FOX\n",
      "----------------------------------------\n",
      "User: Hello\n",
      "DialoGPT: Hey there! How's it going?\n",
      "r1: tensor(-0.0003, device='cuda:0', grad_fn=<NegBackward>) r2: tensor(-0.0956, device='cuda:0', grad_fn=<NegBackward>) r2_2: tensor(-0.0086, device='cuda:0', grad_fn=<NegBackward>) r3: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "User: It's going well!\n"
     ]
    }
   ],
   "source": [
    "chat_history_ids = tokenizer.encode(tokenizer.bos_token + \"Hello\" + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "reward = 0\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00025)\n",
    "# replay_buffer = ReplayBuffer(10000)\n",
    "batch_size = 64\n",
    "gamma      = 0.99  # 0.99\n",
    "ep_rewards = []\n",
    "\n",
    "for episode in range(600):\n",
    "    chat_history_ids = tokenizer.encode(\"Hello\" + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "    questions = []\n",
    "    answers   = []\n",
    "    turns     = []\n",
    "    rewards   = []\n",
    "    model.eval()\n",
    "    max_length = 1000\n",
    "    for frame in range(20):\n",
    "        epsilon = epsilon_by_frame(frame)\n",
    "        # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    #     new_user_input_ids = tokenizer.encode(tokenizer.eos_token, return_tensors='pt')\n",
    "        input_ids = chat_history_ids[-(max_length-100):].to(device)\n",
    "        chat_history_ids = user.generate(input_ids, max_length=100,#max_length, \n",
    "                                         pad_token_id=tokenizer.eos_token_id, \n",
    "#                                          repetition_penalty=1.75,\n",
    "#                                          do_sample=True,\n",
    "#                                          temperature=0.98,\n",
    "#                                          top_k=0,\n",
    "#                                          num_beams=3,\n",
    "    # #                              num_return_sequences=1,\n",
    "    #                              early_stopping=True,\n",
    "                                         no_repeat_ngram_size=5\n",
    "                                ) if frame > 0 else input_ids\n",
    "        question = chat_history_ids[:, input_ids.shape[-1]:][0] if frame > 0 else input_ids[0]\n",
    "        questions.append(question.to(device))\n",
    "        turns.append(question)\n",
    "        print(\"User: {}\".format(decode(question)))\n",
    "\n",
    "        # append the new user input tokens to the chat history\n",
    "        input_ids = chat_history_ids[-(max_length-100):].to(device) # if step > 0 else new_user_input_ids\n",
    "        # generated a response while limiting the total chat history to 1000 tokens, \n",
    "        chat_history_ids = model.generate(input_ids, \n",
    "                                          pad_token_id=tokenizer.eos_token_id,\n",
    "                                          max_length=100,#max_length, \n",
    "#                                           repetition_penalty=1.25,\n",
    "#                                           min_length=2,\n",
    "#                                           do_sample=True,\n",
    "#                                           temperature=0.99,\n",
    "#                                           top_k=40,\n",
    "#                                           num_beams=3,\n",
    "#                                           early_stopping=True,\n",
    "    #                                       num_return_sequences=3,\n",
    "                                          no_repeat_ngram_size=5\n",
    "                                         )\n",
    "\n",
    "        # pretty print last output tokens from bot\n",
    "        answer = chat_history_ids[:, input_ids.shape[-1]:][0]\n",
    "        answers.append(answer)\n",
    "        turns.append(answer)\n",
    "        print(\"DialoGPT: {}\".format(decode(answer)))\n",
    "        \n",
    "#         if len(question) == 0: questions[-1] = torch.tensor([tokenizer.eos_token_id])\n",
    "#         if len(answer) == 0: answers[-1] = torch.tensor([tokenizer.eos_token_id])\n",
    "        \n",
    "        if is_dummy_sentence(answer) or len(answer) == 0:\n",
    "            print('dummy')\n",
    "            print(len(answer) > 0, len(answer))\n",
    "            \n",
    "            reward = compute_reward(questions, answers) if len(answer) > 0 else torch.tensor(0.0)\n",
    "#             reward += torch.tensor(0.0 - 1*len(answers), requires_grad=True)\n",
    "            rewards.append(reward)\n",
    "            break\n",
    "        else:\n",
    "            reward = compute_reward(questions, answers)\n",
    "            rewards.append(reward)\n",
    "            \n",
    "            \n",
    "    # Train\n",
    "    model.train()\n",
    "    r = discount_rewards(rewards)\n",
    "    print(r)\n",
    "    print(rewards)\n",
    "#     model = model.cuda()\n",
    "    loss = rewards[0]#.to('cuda')\n",
    "    \n",
    "#     loss = r.mean()\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "    if loss.item() != np.NINF or True:\n",
    "        ep_rewards.append(rewards[0].item())\n",
    "        for l in r[:1]:\n",
    "            if l.item() != np.NINF and l.item() != np.nan:\n",
    "                print('----- Loss:', l)\n",
    "                optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "#         if loss.item() != np.NINF\n",
    "#             loss.backward()\n",
    "#                 for param in model.parameters():\n",
    "#                         param.grad.data.clamp_(-1, 1)\n",
    "            \n",
    "#                 optimizer.step()\n",
    "\n",
    "#         optimizer.step()\n",
    "    print(f'Episode {episode}:', -np.mean(ep_rewards))\n",
    "    \n",
    "    # Limit chat_history_ids to 50 tokens\n",
    "    chat_history_ids = chat_history_ids[:,-30:]\n",
    "    \n",
    "    if episode%1 == 0:\n",
    "        print('----------------------------------------')\n",
    "        print_test_dialogue()\n",
    "        print('----------------------------------------')\n",
    "    if episode%50 == 0:\n",
    "        torch.save(model.state_dict(), f'models/checkpoint2_{episode}')\n",
    "    \n",
    "#     model = model.cpu()\n",
    "#     reward -= jaccard_similarity(answer.numpy(), context.numpy())\n",
    "    \n",
    "#     state = torch.cat([question, answer_ids], dim=-1)  # add separation token?\n",
    "#     action = act(model, state, epsilon)\n",
    "    # next_state, reward, done, _ = next_step(action)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(reward)\n",
    "#     print(answer)\n",
    "#     print(context)\n",
    "#     print(chat_history_ids)\n",
    "print(tokenizer.decode(chat_history_ids[0], skip_special_tokens=True))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(-1*np.array(ep_rewards), label='Mean episode reward')\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('1000----rewards.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del model_trained\n",
    "model_trained = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model_trained.load_state_dict(torch.load('models/checkpoint_20'))\n",
    "model_trained.eval()\n",
    "model = model_trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the trace\n",
    "# traced_model = torch.jit.trace(model)\n",
    "# torch.jit.save(traced_model, \"traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11633,   345,   766,   366,    51, 18642,   291, 13984, 50256,    40,\n",
       "           750,   837,   475,   314,   836,   470,   892,   314,   460,  3505,\n",
       "           340,   764, 50256,    40,  2497,   340, 14104,  1661,    13, 50256,\n",
       "            40,  2497,   340,  1752,   764, 50256,    40,   423,   262, 12490,\n",
       "            13, 50256,    40,   423,   262,  6458,   764, 50256,  5756,   338,\n",
       "           467,   284,   534,  1363,    13, 50256,    40,   423,   257, 12490,\n",
       "           764, 50256,  1870,   788,   356,   460,   467,   284,   616,  1363,\n",
       "            13, 50256,    40,  1101,  1016,   284,   467,   284,   534,  1363,\n",
       "           764, 50256,    40,  1464,  3960,   379,   262,   886,    13, 50256,\n",
       "            40,  3960,   379,   262,   886,   764, 50256]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Hi! What is your name?Hi there! Mine is Alexei Alexandre Alexandrovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchovitchov'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = tokenizer.encode('Hello Hi! What is your name?' + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "output = tokenizer.decode(model.generate(input_test, max_length=50, pad_token_id=tokenizer.eos_token_id,)[0], skip_special_tokens=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.1766, 14.1621], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rews = discount_rewards(rewards)\n",
    "rews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "rewards[0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-590a0fe59134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrews\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "for r in rews:\n",
    "    r.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits = model(v1)[0]\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "prev_input = torch.multinomial(probs, num_samples=1)\n",
    "decode(prev_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello!Hello! :DHow are you?I'm good! How are you?Pretty good!That's good!Can you recommend me a movie?I can!Tell meI will!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ..., 50256, 50256, 50256],\n",
       "        [50256, 15496, 50256,  ...,   393,  1223, 50256]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = answer - context\n",
    "if len(answer) < 2:\n",
    "    r2 = 0\n",
    "else:\n",
    "    vec_a, vec_b = answer, answer\n",
    "    r2 = sum(vec_a*vec_b) / sum(abs(vec_a)*abs(vec_b))\n",
    "    r2 = -F.logsigmoid(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.1308, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "A = model(v1)[0]\n",
    "B = model(v2)[0]\n",
    "max_len = np.max([len(A.detach().numpy()),len(B.detach().numpy())])\n",
    "print(max_len)\n",
    "extra = torch.zeros(size=(max_len-len(A.detach().numpy()),tokenizer.vocab_size))\n",
    "extra[:,-1] = 1\n",
    "# A = torch.cat([A , extra ])\n",
    "B = torch.cat((B , torch.tensor([torch.ones(tokenizer.vocab_size)]*(max_len-len(B.detach().numpy()))) ))\n",
    "A, B\n",
    "\n",
    "A , B = torch.cat([torch.softmax(A, dim=-1), extra]), torch.softmax(B, dim=-1)\n",
    "A , B\n",
    "# loss = F.cosine_similarity(A,B, dim=-2)\n",
    "loss = -torch.mm(A, B.transpose(1, 0)).sum()\n",
    "\n",
    "# loss = -F.cosine_similarity(torch.softmax(A, dim=-1),torch.softmax(B, dim=-1))\n",
    "# loss = 0\n",
    "# for i,j in zip(v1,v2):\n",
    "#     loss += i*j\n",
    "# # loss = -model(v1, past=None)[0].sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' shore Term marine'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "logits = model(v1)[0]\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "prev_input = torch.multinomial(probs, num_samples=1)\n",
    "decode(prev_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[75.3702, 73.6392, 72.8180,  ..., 81.0872, 82.3673, 87.0727],\n",
       "        [74.3895, 72.5374, 71.8523,  ..., 80.4320, 81.0682, 86.7291],\n",
       "        [73.9969, 72.2922, 71.6807,  ..., 80.3298, 80.4573, 86.1744]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! :D'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9997, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.get_output_embeddings()(model.get_input_embeddings()(v1)).mean(dim=0)\n",
    "y = model.get_output_embeddings()(model.get_input_embeddings()(v2)).mean(dim=0)\n",
    "-torch.log(F.cosine_similarity(x,y, dim=-1))\n",
    "F.cosine_similarity(x,y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-122.8433, -150.5232, -149.6123,  ..., -168.9333, -161.6223,\n",
       "         -133.7793],\n",
       "        [-204.0837, -205.4568, -208.4964,  ..., -240.3041, -233.0705,\n",
       "         -217.4363],\n",
       "        [-205.8837, -210.4453, -214.1883,  ..., -246.4192, -239.3104,\n",
       "         -219.0015]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(v1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<pad>'])\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check learned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-e5569e72ff68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# generated a response while limiting the total chat history to 1000 tokens,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     chat_history_ids = B.generate(input_ids, max_length=1000, \n\u001b[1;32m---> 24\u001b[1;33m                                       \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#                                       num_beams=3,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#                                       early_stopping=True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, **model_kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             )\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36m_generate_no_beam_search\u001b[1;34m(self, input_ids, cur_len, max_length, min_length, do_sample, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, attention_mask, use_cache, model_kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             )\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         )\n\u001b[0;32m    733\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             )\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add cross attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;31m# residual connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "A = model\n",
    "B = model\n",
    "chat_history_ids = tokenizer.encode(tokenizer.bos_token + \"Hello\" + tokenizer.eos_token, return_tensors='pt')\n",
    "for frame in range(15):\n",
    "    epsilon = epsilon_by_frame(frame)\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "#     new_user_input_ids = tokenizer.encode(tokenizer.eos_token, return_tensors='pt')\n",
    "    input_ids = chat_history_ids\n",
    "    chat_history_ids = A.generate(input_ids, max_length=1000, \n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "#                              num_beams=3,\n",
    "# #                              num_return_sequences=1,\n",
    "#                              early_stopping=True,\n",
    "#                              no_repeat_ngram_size=3\n",
    "                            ) if frame > 0 else input_ids\n",
    "    question = chat_history_ids[:, input_ids.shape[-1]:][0] if frame > 0 else input_ids[0]\n",
    "    print(\"User: {}\".format(decode(question)))\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    input_ids = chat_history_ids # if step > 0 else new_user_input_ids\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = B.generate(input_ids, max_length=1000, \n",
    "                                      pad_token_id=tokenizer.eos_token_id,\n",
    "#                                       num_beams=3,\n",
    "#                                       early_stopping=True,\n",
    "#                                       num_return_sequences=3,\n",
    "#                                       no_repeat_ngram_size=3\n",
    "                                     )\n",
    "\n",
    "    # pretty print last output tokens from bot\n",
    "    answer = chat_history_ids[:, input_ids.shape[-1]:][0]\n",
    "    print(\"DialoGPT: {}\".format(decode(answer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 292)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.base_model.parameters())), len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-5168ea7c7dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "model.get_head_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "with open('../simulation-1000-dialogues.txt', 'r') as f:\n",
    "    text = ' '.join(f.readlines())\n",
    "    eps = text.split('----- Loss:')\n",
    "    print(len(eps))\n",
    "    total_turns = []\n",
    "    for e in eps:\n",
    "        turns = e.count('DialoGPT:')\n",
    "        total_turns.append(turns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "f = plt.figure(figsize=(22,5))\n",
    "plt.bar(range(1000), 2*np.array(total_turns)[:-1]-2, label='Num. of dialogue turns', width=1)\n",
    "plt.ylabel('Num. of dialogue turns')\n",
    "plt.xlabel('Episodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('1000turns.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_dialogue():\n",
    "    model.eval()\n",
    "    # Chat of 5 lines\n",
    "    sentences = [\"Did you see Titanic?\",\n",
    "                \"I saw it twelve times.\",\n",
    "                \"I have the DVD.\",\n",
    "                \"Let's go to your home.\",\n",
    "                \"And then we can go to my home.\",\n",
    "                \"I always cry at the end.\"]\n",
    "    for step in range(len(sentences)):\n",
    "        # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    #     new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "        new_user_input_ids = tokenizer.encode(sentences[step] + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "        print(\"User:\", sentences[step])\n",
    "\n",
    "        # append the new user input tokens to the chat history\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "        # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    #     model.eval()\n",
    "        chat_history_ids = model.generate(bot_input_ids, max_length=1000, \n",
    "                                          pad_token_id=tokenizer.eos_token_id, \n",
    "                                          no_repeat_ngram_size=5,\n",
    "                                          repetition_penalty=1.15,\n",
    "                                         )\n",
    "\n",
    "\n",
    "        # pretty print last ouput tokens from bot\n",
    "        print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
    "        chat_history_ids = chat_history_ids[:,-50:]\n",
    "        # print(len(chat_history_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "if USE_CUDA:\n",
    "    device ='cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Episode 0\n",
      "User: Did you see Titanic?\n",
      "DialoGPT: No, but I've heard of it. What's it about?\n",
      "User: I saw it twelve times.\n",
      "DialoGPT: That's impressive. How many times did you watch it consecutively?\n",
      "User: I have the DVD.\n",
      "DialoGPT: DVDs are expensive nowadays.\n",
      "User: Let's go to your home.\n",
      "DialoGPT: Sure thing. Where do you live?\n",
      "User: And then we can go to my home.\n",
      "DialoGPT: Alright, let's go to his home.and then we'll go to yours.and then we will go to mine.and then we shall go to theirs.AND THEN WE WILL ALL GO TO HIS HOME AND THEN WE WILL ALL JOIN THEM!\n",
      "User: I always cry at the end.\n",
      "DialoGPT: I cried when he died. Then cried again when he came back. Then cried again after he died again. Then cried again during his funeral. Tears of joy. Tears of sadness. Tears of happiness. Tears of sadness... tears of happiness. Tears. Tears of sadness sobbing intensifies cries uncontrollably sobbing intensifies sobbing intensifies snifflesqueenskieskieskieskieskieseskieskieskieskieskykieskieskieskieskerskieskieskieskieskskieskieskieskieskeskieskieskieskieskikskieskieskieskiebskieskieskieskieskiekieskieskieskieskkieskieskieskiesawkskieskieskieskieswingskieskieskieskiesskykieskieskieskiesbyskieskieskieskiesykieskieskieskiesbackskieskieskieskiesfightskieskieskieskiesfightershipskieskieskieskiesetcetcetcetcetc etcetcetcetcetcskieskieskieskies etcetcetcetc etc etcetcetcetckieskieskieskiesecanesqueskieskieskieskies\n",
      "\n",
      "----------- Episode 50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 6.00 GiB total capacity; 4.35 GiB already allocated; 12.40 MiB free; 4.44 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-230c49f5eaf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#,110,120,130,140, 150]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'----------- Episode {i}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'models/checkpoint_{i}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# del _CudaBase.__new__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 6.00 GiB total capacity; 4.35 GiB already allocated; 12.40 MiB free; 4.44 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for i in [0,50]:#,110,120,130,140, 150]:\n",
    "    print(f'----------- Episode {i}')\n",
    "    model.load_state_dict(torch.load(f'models/checkpoint_{i}'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print_test_dialogue()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
